> A10_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/network/a10/a10_server.py)

  Manage SLB (Server Load Balancer) server objects on A10 Networks devices via aXAPIv2.

Options (= is mandatory):

= host
        Hostname or IP of the A10 Networks device.
        [Default: None]
- partition
        set active-partition
        [Default: None]
= password
        Password for the `username' account.
        [Default: None]
- server_ip
        The SLB server IPv4 address.
        [Default: None]
= server_name
        The SLB (Server Load Balancer) server name.

- server_ports
        A list of ports to create for the server. Each list item should be a dictionary which specifies the `port:' and
        `protocol:', but can also optionally specify the `status:'. See the examples below for details. This parameter is
        required when `state' is `present'.
        [Default: None]
- server_status
        The SLB virtual server status.
        (Choices: enabled, disabled)[Default: enabled]
- state
        This is to specify the operation to create, update or remove SLB server.
        (Choices: present, absent)[Default: present]
= username
        An account with administrator privileges.
        [Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled devices using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
- write_config
        If `yes', any changes will cause a write of the running configuration to non-volatile memory. This will save
        `all' configuration changes, including those that may have been made manually or through other modules, so care
        should be taken when specifying `yes'.
        (Choices: yes, no)[Default: no]
Notes:
  * Requires A10 Networks aXAPI 2.1.
  * Requires A10 Networks aXAPI 2.1
EXAMPLES:
# Create a new server
- a10_server:
    host: a10.mydomain.com
    username: myadmin
    password: mypassword
    partition: mypartition
    server: test
    server_ip: 1.1.1.100
    server_ports:
      - port_num: 8080
        protocol: tcp
      - port_num: 8443
        protocol: TCP


RETURN VALUES:
content:
  description: the full info regarding the slb_server
  returned: success
  type: string
  sample: "mynewserver"


MAINTAINERS: Eric Chou (@ericchou) 2016, Mischa Peters (@mischapeters) 2014

METADATA:
	Status: ['preview']
	Supported_by: community
> A10_SERVER_AXAPI3    (/usr/lib/python2.7/site-packages/ansible/modules/network/a10/a10_server_axapi3.py)

  Manage SLB (Server Load Balancer) server objects on A10 Networks devices via aXAPIv3.

Options (= is mandatory):

= host
        Hostname or IP of the A10 Networks device.
        [Default: None]
- operation
        Create, Update or Remove SLB server. For create and update operation, we use the IP address and server name
        specified in the POST message. For delete operation, we use the server name in the request URI.
        (Choices: create, update, remove)[Default: create]
= password
        Password for the `username' account.
        [Default: None]
= server_ip
        The SLB (Server Load Balancer) server IPv4 address.

= server_name
        The SLB (Server Load Balancer) server name.

- server_ports
        A list of ports to create for the server. Each list item should be a dictionary which specifies the `port:' and
        `protocol:'.
        [Default: None]
- server_status
        The SLB (Server Load Balancer) virtual server status.
        (Choices: enable, disable)[Default: enable]
= username
        An account with administrator privileges.
        [Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled devices using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
- write_config
        If `yes', any changes will cause a write of the running configuration to non-volatile memory. This will save
        `all' configuration changes, including those that may have been made manually or through other modules, so care
        should be taken when specifying `yes'.
        (Choices: yes, no)[Default: no]
Notes:
  * Requires A10 Networks aXAPI 2.1
EXAMPLES:
# Create a new server
- a10_server:
    host: a10.mydomain.com
    username: myadmin
    password: mypassword
    server: test
    server_ip: 1.1.1.100
    validate_certs: false
    server_status: enable
    write_config: yes
    operation: create
    server_ports:
      - port-number: 8080
        protocol: tcp
        action: enable
      - port-number: 8443
        protocol: TCP


RETURN VALUES:
#


MAINTAINERS: Eric Chou (@ericchou) based on previous work by Mischa Peters (@mischapeters)

METADATA:
	Status: ['preview']
	Supported_by: community
> A10_SERVICE_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/network/a10/a10_service_group.py)

  Manage SLB (Server Load Balancing) service-group objects on A10 Networks devices via aXAPIv2.

Options (= is mandatory):

= host
        Hostname or IP of the A10 Networks device.
        [Default: None]
- partition
        set active-partition
        [Default: None]
= password
        Password for the `username' account.
        [Default: None]
- servers
        A list of servers to add to the service group. Each list item should be a dictionary which specifies the
        `server:' and `port:', but can also optionally specify the `status:'. See the examples below for details.
        [Default: None]
= service_group
        The SLB (Server Load Balancing) service-group name
        [Default: None]
- service_group_method
        The SLB service-group load balancing method, such as round-robin or weighted-rr.
        (Choices: round-robin, weighted-rr, least-connection, weighted-least-connection, service-least-connection,
        service-weighted-least-connection, fastest-response, least-request, round-robin-strict, src-ip-only-hash, src-ip-
        hash)[Default: round-robin]
- service_group_protocol
        The SLB service-group protocol of TCP or UDP.
        (Choices: tcp, udp)[Default: tcp]
= username
        An account with administrator privileges.
        [Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled devices using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
- write_config
        If `yes', any changes will cause a write of the running configuration to non-volatile memory. This will save
        `all' configuration changes, including those that may have been made manually or through other modules, so care
        should be taken when specifying `yes'.
        (Choices: yes, no)[Default: no]
Notes:
  * Requires A10 Networks aXAPI 2.1.
  * When a server doesn't exist and is added to the service-group the server will be created.
  * Requires A10 Networks aXAPI 2.1
EXAMPLES:
# Create a new service-group
- a10_service_group:
    host: a10.mydomain.com
    username: myadmin
    password: mypassword
    partition: mypartition
    service_group: sg-80-tcp
    servers:
      - server: foo1.mydomain.com
        port: 8080
      - server: foo2.mydomain.com
        port: 8080
      - server: foo3.mydomain.com
        port: 8080
      - server: foo4.mydomain.com
        port: 8080
        status: disabled


RETURN VALUES:
content:
  description: the full info regarding the slb_service_group
  returned: success
  type: string
  sample: "mynewservicegroup"


MAINTAINERS: Eric Chou (@ericchou) 2016, Mischa Peters (@mischapeters) 2014

METADATA:
	Status: ['preview']
	Supported_by: community
> A10_VIRTUAL_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/network/a10/a10_virtual_server.py)

  Manage SLB (Server Load Balancing) virtual server objects on A10 Networks devices via aXAPIv2.

Options (= is mandatory):

= host
        Hostname or IP of the A10 Networks device.
        [Default: None]
- partition
        set active-partition
        [Default: None]
= password
        Password for the `username' account.
        [Default: None]
= username
        An account with administrator privileges.
        [Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled devices using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
= virtual_server
        The SLB (Server Load Balancing) virtual server name.
        [Default: None]
- virtual_server_ip
        The SLB virtual server IPv4 address.
        [Default: None]
- virtual_server_ports
        A list of ports to create for the virtual server. Each list item should be a dictionary which specifies the
        `port:' and `type:', but can also optionally specify the `service_group:' as well as the `status:'. See the
        examples below for details. This parameter is required when `state' is `present'.
        [Default: (null)]
- virtual_server_status
        The SLB virtual server status, such as enabled or disabled.
        (Choices: enabled, disabled)[Default: enable]
- write_config
        If `yes', any changes will cause a write of the running configuration to non-volatile memory. This will save
        `all' configuration changes, including those that may have been made manually or through other modules, so care
        should be taken when specifying `yes'.
        (Choices: yes, no)[Default: no]
Notes:
  * Requires A10 Networks aXAPI 2.1.
  * Requires A10 Networks aXAPI 2.1
EXAMPLES:
# Create a new virtual server
- a10_virtual_server:
    host: a10.mydomain.com
    username: myadmin
    password: mypassword
    partition: mypartition
    virtual_server: vserver1
    virtual_server_ip: 1.1.1.1
    virtual_server_ports:
      - port: 80
        protocol: TCP
        service_group: sg-80-tcp
      - port: 443
        protocol: HTTPS
        service_group: sg-443-https
      - port: 8080
        protocol: http
        status: disabled


RETURN VALUES:
content:
  description: the full info regarding the slb_virtual
  returned: success
  type: string
  sample: "mynewvirtualserver"


MAINTAINERS: Eric Chou (@ericchou) 2016, Mischa Peters (@mischapeters) 2014

METADATA:
	Status: ['preview']
	Supported_by: community
> ACCELERATE    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/helper/_accelerate.py)

  This modules launches an ephemeral `accelerate' daemon on the remote node which Ansible can use to communicate with
  nodes at high speed. The daemon listens on a configurable port for a configurable amount of time. Fireball mode is AES
  encrypted

DEPRECATED: 
Use SSH with ControlPersist instead.

Options (= is mandatory):

- ipv6
        The listener daemon on the remote host will bind to the ipv6 localhost socket if this parameter is set to true.
        [Default: False]
- minutes
        The `accelerate' listener daemon is started on nodes and will stay around for this number of minutes before
        turning itself off.
        [Default: 30]
- multi_key
        When enabled, the daemon will open a local socket file which can be used by future daemon executions to upload a
        new key to the already running daemon, so that multiple users can connect using different keys. This access still
        requires an ssh connection as the uid for which the daemon is currently running.
        [Default: False]
- port
        TCP port for the socket connection
        [Default: 5099]
- timeout
        The number of seconds the socket will wait for data. If none is received when the timeout value is reached, the
        connection will be closed.
        [Default: 300]
Notes:
  * See the advanced playbooks chapter for more about using accelerated mode.
Requirements:  python >= 2.4, python-keyczar

EXAMPLES:
# To use accelerate mode, simply add "accelerate: true" to your play. The initial
# key exchange and starting up of the daemon will occur over SSH, but all commands and
# subsequent actions will be conducted over the raw socket connection using AES encryption

- hosts: devservers
  accelerate: true
  tasks:
      - command: /usr/bin/anything


MAINTAINERS: James Cammarata (@jimi-c)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> ACL    (/usr/lib/python2.7/site-packages/ansible/modules/files/acl.py)

  Sets and retrieves file ACL information.

Options (= is mandatory):

- default
        if the target is a directory, setting this to yes will make it the default acl for entities created inside the
        directory. It causes an error if path is a file.
        (Choices: yes, no)[Default: False]
- entity
        actual user or group that the ACL applies to when matching entity types user or group are selected.
        [Default: (null)]
- entry
        DEPRECATED. The acl to set or remove.  This must always be quoted in the form of '<etype>:<qualifier>:<perms>'.
        The qualifier may be empty for some types, but the type and perms are always required. '-' can be used as
        placeholder when you do not care about permissions. This is now superseded by entity, type and permissions
        fields.
        [Default: None]
- etype
        the entity type of the ACL to apply, see setfacl documentation for more info.
        (Choices: user, group, mask, other)[Default: None]
- follow
        whether to follow symlinks on the path if a symlink is encountered.
        (Choices: yes, no)[Default: True]
= path
        The full path of the file or object.
        [Default: None]
- permissions
        Permissions to apply/remove can be any combination of r, w and  x (read, write and execute respectively)
        [Default: None]
- recursive
        Recursively sets the specified ACL (added in Ansible 2.0). Incompatible with `state=query'.
        (Choices: yes, no)[Default: False]
- state
        defines whether the ACL should be present or not.  The `query' state gets the current acl without changing it,
        for use in 'register' operations.
        (Choices: query, present, absent)[Default: query]
Notes:
  * The "acl" module requires that acls are enabled on the target filesystem and that the setfacl and getfacl
        binaries are installed.
  * As of Ansible 2.0, this module only supports Linux distributions.
  * As of Ansible 2.3, the `name' option has been changed to `path' as default, but `name' still works as well.
EXAMPLES:
# Grant user Joe read access to a file
- acl:
    path: /etc/foo.conf
    entity: joe
    etype: user
    permissions: r
    state: present

# Removes the acl for Joe on a specific file
- acl:
    path: /etc/foo.conf
    entity: joe
    etype: user
    state: absent

# Sets default acl for joe on foo.d
- acl:
    path: /etc/foo.d
    entity: joe
    etype: user
    permissions: rw
    default: yes
    state: present

# Same as previous but using entry shorthand
- acl:
    path: /etc/foo.d
    entry: "default:user:joe:rw-"
    state: present

# Obtain the acl for a specific file
- acl:
    path: /etc/foo.conf
  register: acl_info

RETURN VALUES:
acl:
    description: Current acl on provided path (after changes, if any)
    returned: success
    type: list
    sample: [ "user::rwx", "group::rwx", "other::rwx" ]


MAINTAINERS: Brian Coca (@bcoca), Jérémie Astori (@astorije)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> ADD_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/inventory/add_host.py)

  Use variables to create new hosts and groups in inventory for use in later plays of the same playbook. Takes variables
  so you can define the new hosts more fully.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- groups
        The groups to add the hostname to, comma separated.
        [Default: (null)]
= name
        The hostname/ip of the host to add to the inventory, can include a colon and a port number.

Notes:
  * This module bypasses the play host loop and only runs once for all the hosts in the play, if you need it to
        iterate use a with\_ directive.
EXAMPLES:
# add host to group 'just_created' with variable foo=42
- add_host:
    name: "{{ ip_from_ec2 }}"
    groups: just_created
    foo: 42

# add a host with a non-standard port local to your machines
- add_host:
    name: "{{ new_ip }}:{{ new_port }}"

# add a host alias that we reach through a tunnel (Ansible <= 1.9)
- add_host:
    hostname: "{{ new_ip }}"
    ansible_ssh_host: "{{ inventory_hostname }}"
    ansible_ssh_port: "{{ new_port }}"

# add a host alias that we reach through a tunnel (Ansible >= 2.0)
- add_host:
    hostname: "{{ new_ip }}"
    ansible_host: "{{ inventory_hostname }}"
    ansible_port: "{{ new_port }}"


MAINTAINERS: Ansible Core Team, Seth Vidal

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> AIRBRAKE_DEPLOYMENT    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/airbrake_deployment.py)

  Notify airbrake about app deployments (see http://help.airbrake.io/kb/api-2/deploy-tracking)

Options (= is mandatory):

= environment
        The airbrake environment name, typically 'production', 'staging', etc.

- repo
        URL of the project repository
        [Default: (null)]
- revision
        A hash, number, tag, or other identifier showing what revision was deployed
        [Default: (null)]
= token
        API token.

- url
        Optional URL to submit the notification to. Use to send notifications to Airbrake-compliant tools like Errbit.
        [Default: https://airbrake.io/deploys.txt]
- user
        The username of the person doing the deployment
        [Default: (null)]
- validate_certs
        If `no', SSL certificates for the target url will not be validated. This should only be used on personally
        controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- airbrake_deployment:
    token: AAAAAA
    environment: staging
    user: ansible
    revision: '4.2'


MAINTAINERS: Bruce Pennypacker (@bpennypacker)

METADATA:
	Status: ['preview']
	Supported_by: community
> AIX_INITTAB    (/usr/lib/python2.7/site-packages/ansible/modules/system/aix_inittab.py)

  Manages the inittab on AIX.

Options (= is mandatory):

= action
        Action what the init has to do with this entry.
        (Choices: respawn, wait, once, boot, bootwait, powerfail, powerwait, off, hold, ondemand, initdefault, sysinit)
= command
        What command has to run.

- insertafter
        After which inittabline should the new entry inserted.
        [Default: (null)]
= name
        Name of the inittab entry.

= runlevel
        Runlevel of the entry.

- state
        Whether the entry should be present or absent in the inittab file
        (Choices: present, absent)[Default: present]
Notes:
  * The changes are persistent across reboots, you need root rights to read or adjust the inittab with the lsitab,
        chitab, mkitab or rmitab commands.
  * tested on AIX 7.1.
Requirements:  itertools

EXAMPLES:
# Add service startmyservice to the inittab, directly after service existingservice.
- name: Add startmyservice to inittab
  aix_inittab:
    name: startmyservice
    runlevel: 4
    action: once
    command: "echo hello"
    insertafter: existingservice
    state: present
  become: yes

# Change inittab enrty startmyservice to runlevel "2" and processaction "wait".
- name: Change startmyservice to inittab
  aix_inittab:
    name: startmyservice
    runlevel: 2
    action: wait
    command: "echo hello"
    state: present
  become: yes

# Remove inittab entry startmyservice.
- name: remove startmyservice from inittab
  aix_inittab:
    name: startmyservice
    runlevel: 2
    action: wait
    command: "echo hello"
    state: absent
  become: yes

RETURN VALUES:
name:
    description: name of the adjusted inittab entry
    returned: always
    type: string
    sample: startmyservice
msg:
    description: action done with the inittab entry
    returned: changed
    type: string
    sample: changed inittab entry startmyservice
changed:
    description: whether the inittab changed or not
    return: always
    type: boolean
    sample: true


MAINTAINERS: Joris Weijters (@molekuul)

METADATA:
	Status: ['preview']
	Supported_by: community
> ALTERNATIVES    (/usr/lib/python2.7/site-packages/ansible/modules/system/alternatives.py)

  Manages symbolic links using the 'update-alternatives' tool Useful when multiple programs are installed but provide
  similar functionality (e.g. different editors).

Options (= is mandatory):

- link
        The path to the symbolic link that should point to the real executable.
        This option is required on RHEL-based distributions
        [Default: (null)]
= name
        The generic name of the link.

= path
        The path to the real executable that the link should point to.

- priority
        The priority of the alternative
        [Default: 50]
Requirements:  update-alternatives

EXAMPLES:
- name: correct java version selected
  alternatives:
    name: java
    path: /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java

- name: alternatives link created
  alternatives:
    name: hadoop-conf
    link: /etc/hadoop/conf
    path: /etc/hadoop/conf.ansible

- name: make java 32 bit an alternative with low priority
  alternatives:
    name: java
    path: /usr/lib/jvm/java-7-openjdk-i386/jre/bin/java
    priority: -10


MAINTAINERS: David Wittman (@DavidWittman), Gabe Mulley (@mulby)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_ASN_POOL    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_asn_pool.py)

  Apstra AOS ASN Pool module let you manage your ASN Pool easily. You can create and delete ASN Pool by Name, ID or by
  using a JSON File. This module is idempotent and support the `check' mode. It's using the AOS REST API.

Options (= is mandatory):

- content
        Datastructure of the ASN Pool to manage. The data can be in YAML / JSON or directly a variable. It's the same
        datastructure that is returned on success in `value'.
        [Default: (null)]
- id
        AOS Id of the ASN Pool to manage. Only one of `name', `id' or `content' can be set.
        [Default: (null)]
- name
        Name of the ASN Pool to manage. Only one of `name', `id' or `content' can be set.
        [Default: (null)]
- ranges
        List of ASNs ranges to add to the ASN Pool. Each range must have 2 values.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the ASN Pool (present or not).
        (Choices: present, absent)[Default: present]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: "Create ASN Pool"
  aos_asn_pool:
    session: "{{ aos_session }}"
    name: "my-asn-pool"
    ranges:
      - [ 100, 200 ]
    state: present
  register: asnpool

- name: "Save ASN Pool into a file in JSON"
  copy:
    content: "{{ asnpool.value | to_nice_json }}"
    dest: resources/asn_pool_saved.json

- name: "Save ASN Pool into a file in YAML"
  copy:
    content: "{{ asnpool.value | to_nice_yaml }}"
    dest: resources/asn_pool_saved.yaml


- name: "Delete ASN Pool"
  aos_asn_pool:
    session: "{{ aos_session }}"
    name: "my-asn-pool"
    state: absent

- name: "Load ASN Pool from File(JSON)"
  aos_asn_pool:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/asn_pool_saved.json') }}"
    state: present

- name: "Delete ASN Pool from File(JSON)"
  aos_asn_pool:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/asn_pool_saved.json') }}"
    state: absent

- name: "Load ASN Pool from File(Yaml)"
  aos_asn_pool:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/asn_pool_saved.yaml') }}"
    state: present
  register: test

- name: "Delete ASN Pool from File(Yaml)"
  aos_asn_pool:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/asn_pool_saved.yaml') }}"
    state: absent


MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_BLUEPRINT    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_blueprint.py)

  Apstra AOS Blueprint module let you manage your Blueprint easily. You can create create and delete Blueprint by Name or
  ID. You can also use it to retrieve all data from a blueprint. This module is idempotent and support the `check' mode.
  It's using the AOS REST API.

Options (= is mandatory):

- id
        AOS Id of the IP Pool to manage (can't be used to create a new IP Pool). Only one of `name' or `id' can be set.
        [Default: (null)]
- name
        Name of the Blueprint to manage. Only one of `name' or `id' can be set.
        [Default: (null)]
- reference_arch
        When creating a blueprint, this value identifies a known AOS reference architecture value. `Refer to AOS-server
        documentation for available values'.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the Blueprint.
        (Choices: present, absent, build-ready)[Default: present]
- template
        When creating a blueprint, this value identifies, by name, an existing engineering design template within the
        AOS-server.
        [Default: (null)]
- timeout
        When `state=build-ready', this timeout identifies timeout in seconds to wait before declaring a failure.
        [Default: 5]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:
- name: Creating blueprint
  aos_blueprint:
    session: "{{ aos_session }}"
    name: "my-blueprint"
    template: "my-template"
    reference_arch: two_stage_l3clos
    state: present

- name: Access a blueprint and get content
  aos_blueprint:
    session: "{{ aos_session }}"
    name: "{{ blueprint_name }}"
    template: "{{ blueprint_template }}"
    state: present
  register: bp

- name: Delete a blueprint
  aos_blueprint:
    session: "{{ aos_session }}"
    name: "my-blueprint"
    state: absent

- name: Await blueprint build-ready, and obtain contents
  aos_blueprint:
    session: "{{ aos_session }}"
    name: "{{ blueprint_name }}"
    state: build-ready
  register: bp


MAINTAINERS: jeremy@apstra.com (@jeremyschulman)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_BLUEPRINT_PARAM    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_blueprint_param.py)

  Apstra AOS Blueprint Parameter module let you manage your Blueprint Parameter easily. You can create access, define and
  delete Blueprint Parameter. The list of Parameters supported is different per Blueprint. The option `get_param_list'
  can help you to access the list of supported Parameters for your blueprint. This module is idempotent and support the
  `check' mode. It's using the AOS REST API.

Options (= is mandatory):

= blueprint
        Blueprint Name or Id as defined in AOS.

- get_param_list
        Get the complete list of supported parameters for this blueprint and the description of those parameters.
        [Default: (null)]
- name
        Name of blueprint parameter, as defined by AOS design template. You can use the option `get_param_list' to get
        the complete list of supported parameters for your blueprint.
        [Default: (null)]
- param_map
        Defines the aos-pyez collection that will is used to map the user-defined item name into the AOS unique ID value.
        For example, if the caller provides an IP address pool `param_value' called "Server-IpAddrs", then the aos-pyez
        collection is 'IpPools'. Some `param_map' are already defined by default like `logical_device_maps'.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the Blueprint Parameter (present or not).
        (Choices: present, absent)[Default: present]
- value
        Blueprint parameter value.  This value may be transformed by using the `param_map' field; used when the the
        blueprint parameter requires an AOS unique ID value.
        [Default: (null)]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: Add Logical Device Maps information in a Blueprint
  aos_blueprint_param:
    session: "{{ aos_session }}"
    blueprint: "my-blueprint-l2"
    name: "logical_device_maps"
    value:
      spine_1: CumulusVX-Spine-Switch
      spine_2: CumulusVX-Spine-Switch
      leaf_1: CumulusVX-Leaf-Switch
      leaf_2: CumulusVX-Leaf-Switch
      leaf_3: CumulusVX-Leaf-Switch
    state: present

- name: Access Logical Device Maps information from a Blueprint
  aos_blueprint_param:
    session: "{{ aos_session }}"
    blueprint: "my-blueprint-l2"
    name: "logical_device_maps"
    state: present

- name: Reset Logical Device Maps information in a Blueprint
  aos_blueprint_param:
    session: "{{ aos_session }}"
    blueprint: "my-blueprint-l2"
    name: "logical_device_maps"
    state: absent

- name: Get list of all supported Params for a blueprint
  aos_blueprint_param:
    session: "{{ aos_session }}"
    blueprint: "my-blueprint-l2"
    get_param_list: yes
  register: params_list
- debug: var=params_list

- name: Add Resource Pools information in a Blueprint, by providing a param_map
  aos_blueprint_param:
    session: "{{ aos_session }}"
    blueprint: "my-blueprint-l2"
    name: "resource_pools"
    value:
        leaf_loopback_ips: ['Switches-IpAddrs']
        spine_loopback_ips: ['Switches-IpAddrs']
        spine_leaf_link_ips: ['Switches-IpAddrs']
        spine_asns: ['Private-ASN-pool']
        leaf_asns: ['Private-ASN-pool']
        virtual_network_svi_subnets: ['Servers-IpAddrs']
    param_map:
        leaf_loopback_ips: IpPools
        spine_loopback_ips: IpPools
        spine_leaf_link_ips: IpPools
        spine_asns: AsnPools
        leaf_asns: AsnPools
        virtual_network_svi_subnets: IpPools
    state: present


MAINTAINERS: jeremy@apstra.com (@jeremyschulman)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_BLUEPRINT_VIRTNET    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_blueprint_virtnet.py)

  Apstra AOS Blueprint Virtual Network module let you manage your Virtual Network easily. You can create access, define
  and delete Virtual Network by name or by using a JSON / Yaml file. This module is idempotent and support the `check'
  mode. It's using the AOS REST API.

Options (= is mandatory):

= blueprint
        Blueprint Name or Id as defined in AOS.

- content
        Datastructure of the Virtual Network to manage. The data can be in YAML / JSON or directly a variable. It's the
        same datastructure that is returned on success in `value'.
        [Default: (null)]
- name
        Name of Virtual Network as part of the Blueprint.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the Virtual Network (present or not).
        (Choices: present, absent)[Default: present]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: "Access Existing Virtual Network"
  aos_blueprint_virtnet:
    session: "{{ aos_session }}"
    blueprint: "my-blueprint-l2"
    name: "my-virtual-network"
    state: present

- name: "Delete Virtual Network with JSON File"
  aos_blueprint_virtnet:
    session: "{{ aos_session }}"
    blueprint: "my-blueprint-l2"
    content: "{{ lookup('file', 'resources/virtual-network-02.json') }}"
    state: absent

- name: "Create Virtual Network"
  aos_blueprint_virtnet:
    session: "{{ aos_session }}"
    blueprint: "my-blueprint-l2"
    content: "{{ lookup('file', 'resources/virtual-network-02.json') }}"
    state: present


MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_DEVICE    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_device.py)

  Apstra AOS Device module let you manage your devices in AOS easily. You can approve devices and define in which state
  the device should be. Currently only the state `normal' is supported but the goal is to extend this module with
  additional state. This module is idempotent and support the `check' mode. It's using the AOS REST API.

Options (= is mandatory):

- approve
        The approve argument instruct the module to convert a device in quarantine mode into approved mode.
        (Choices: yes, no)[Default: no]
- id
        The AOS internal id for a device; i.e. uniquely identifies the device in the AOS system. Only one of `name' or
        `id' can be set.
        [Default: (null)]
- location
        When approving a device using the `approve' argument, it's possible define the location of the device.
        [Default: (null)]
- name
        The device serial-number; i.e. uniquely identifies the device in the AOS system. Only one of `name' or `id' can
        be set.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Define in which state the device should be. Currently only `normal' is supported but the goal is to add `maint'
        and `decomm'.
        (Choices: normal)[Default: normal]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: Approve a new device
  aos_device:
    session: "{{ aos_session }}"
    name: D2060B2F105429GDABCD123
    state: 'normal'
    approve: true
    location: "rack-45, ru-18"


MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_EXTERNAL_ROUTER    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_external_router.py)

  Apstra AOS External Router module let you manage your External Router easily. You can create create and delete External
  Router by Name, ID or by using a JSON File. This module is idempotent and support the `check' mode. It's using the AOS
  REST API.

Options (= is mandatory):

- asn
        ASN id of the external_router.
        [Default: (null)]
- content
        Datastructure of the External Router to create. The format is defined by the `content_format' parameter. It's the
        same datastructure that is returned on success in `value'.
        [Default: (null)]
- id
        AOS Id of the External Router to manage (can't be used to create a new External Router), Only one of `name', `id'
        or `content' can be set.
        [Default: (null)]
- loopback
        IP address of the Loopback interface of the external_router.
        [Default: (null)]
- name
        Name of the External Router to manage. Only one of `name', `id' or `content' can be set.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the External Router (present or not).
        (Choices: present, absent)[Default: present]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: "Create an External Router"
  aos_external_router:
    session: "{{ aos_session }}"
    name: "my-external-router"
    loopback: 10.0.0.1
    asn: 65000
    state: present

- name: "Check if an External Router exist by ID"
  aos_external_router:
    session: "{{ aos_session }}"
    name: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: present

- name: "Delete an External Router by name"
  aos_external_router:
    session: "{{ aos_session }}"
    name: "my-external-router"
    state: absent

- name: "Delete an External Router by id"
  aos_external_router:
    session: "{{ aos_session }}"
    id: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: absent

# Save an External Router to a file
- name: "Access External Router 1/3"
  aos_external_router:
    session: "{{ aos_session }}"
    name: "my-external-router"
    state: present
  register: external_router

- name: "Save External Router into a file in JSON 2/3"
  copy:
    content: "{{ external_router.value | to_nice_json }}"
    dest: external_router_saved.json

- name: "Save External Router into a file in YAML 3/3"
  copy:
    content: "{{ external_router.value | to_nice_yaml }}"
    dest: external_router_saved.yaml

- name: "Load External Router from a JSON file"
  aos_external_router:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/external_router_saved.json') }}"
    state: present

- name: "Load External Router from a YAML file"
  aos_external_router:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/external_router_saved.yaml') }}"
    state: present


MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_IP_POOL    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_ip_pool.py)

  Apstra AOS Ip Pool module let you manage your IP Pool easily. You can create create and delete IP Pool by Name, ID or
  by using a JSON File. This module is idempotent and support the `check' mode. It's using the AOS REST API.

Options (= is mandatory):

- content
        Datastructure of the IP Pool to manage. The data can be in YAML / JSON or directly a variable. It's the same
        datastructure that is returned on success in `value'.
        [Default: (null)]
- id
        AOS Id of the IP Pool to manage (can't be used to create a new IP Pool), Only one of `name', `id' or `content'
        can be set.
        [Default: (null)]
- name
        Name of the IP Pool to manage. Only one of `name', `id' or `content' can be set.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the IP Pool (present or not).
        (Choices: present, absent)[Default: present]
- subnets
        List of subnet that needs to be part of the IP Pool.
        [Default: (null)]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: "Create an IP Pool with one subnet"
  aos_ip_pool:
    session: "{{ aos_session }}"
    name: "my-ip-pool"
    subnets: [ 172.10.0.0/16 ]
    state: present

- name: "Create an IP Pool with multiple subnets"
  aos_ip_pool:
    session: "{{ aos_session }}"
    name: "my-other-ip-pool"
    subnets: [ 172.10.0.0/16, 192.168.0.0./24 ]
    state: present

- name: "Check if an IP Pool exist with same subnets by ID"
  aos_ip_pool:
    session: "{{ aos_session }}"
    name: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    subnets: [ 172.10.0.0/16, 192.168.0.0./24 ]
    state: present

- name: "Delete an IP Pool by name"
  aos_ip_pool:
    session: "{{ aos_session }}"
    name: "my-ip-pool"
    state: absent

- name: "Delete an IP pool by id"
  aos_ip_pool:
    session: "{{ aos_session }}"
    id: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: absent

# Save an IP Pool to a file

- name: "Access IP Pool 1/3"
  aos_ip_pool:
    session: "{{ aos_session }}"
    name: "my-ip-pool"
    subnets: [ 172.10.0.0/16, 172.12.0.0/16 ]
    state: present
  register: ip_pool

- name: "Save Ip Pool into a file in JSON 2/3"
  copy:
    content: "{{ ip_pool.value | to_nice_json }}"
    dest: ip_pool_saved.json

- name: "Save Ip Pool into a file in YAML 3/3"
  copy:
    content: "{{ ip_pool.value | to_nice_yaml }}"
    dest: ip_pool_saved.yaml

- name: "Load IP Pool from a JSON file"
  aos_ip_pool:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/ip_pool_saved.json') }}"
    state: present

- name: "Load IP Pool from a YAML file"
  aos_ip_pool:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/ip_pool_saved.yaml') }}"
    state: present

- name: "Load IP Pool from a Variable"
  aos_ip_pool:
    session: "{{ aos_session }}"
    content:
      display_name: my-ip-pool
      id: 4276738d-6f86-4034-9656-4bff94a34ea7
      subnets:
        - network: 172.10.0.0/16
        - network: 172.12.0.0/16
    state: present


MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_LOGICAL_DEVICE    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_logical_device.py)

  Apstra AOS Logical Device module let you manage your Logical Devices easily. You can create create and delete Logical
  Device by Name, ID or by using a JSON File. This module is idempotent and support the `check' mode. It's using the AOS
  REST API.

Options (= is mandatory):

- content
        Datastructure of the Logical Device to create. The data can be in YAML / JSON or directly a variable. It's the
        same datastructure that is returned on success in `value'.
        [Default: (null)]
- id
        AOS Id of the Logical Device to manage (can't be used to create a new Logical Device), Only one of `name', `id'
        or `content' can be set.
        [Default: (null)]
- name
        Name of the Logical Device to manage. Only one of `name', `id' or `content' can be set.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the Logical Device (present or not).
        (Choices: present, absent)[Default: present]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: "Delete a Logical Device by name"
  aos_logical_device:
    session: "{{ aos_session }}"
    name: "my-logical-device"
    state: absent

- name: "Delete a Logical Device by id"
  aos_logical_device:
    session: "{{ aos_session }}"
    id: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: absent

# Save a Logical Device to a file

- name: "Access Logical Device 1/3"
  aos_logical_device:
    session: "{{ aos_session }}"
    name: "my-logical-device"
    state: present
  register: logical_device
- name: "Save Logical Device into a JSON file 2/3"
  copy:
    content: "{{ logical_device.value | to_nice_json }}"
    dest: logical_device_saved.json
- name: "Save Logical Device into a YAML file 3/3"
  copy:
    content: "{{ logical_device.value | to_nice_yaml }}"
    dest: logical_device_saved.yaml

- name: "Load Logical Device from a JSON file"
  aos_logical_device:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/logical_device_saved.json') }}"
    state: present

- name: "Load Logical Device from a YAML file"
  aos_logical_device:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/logical_device_saved.yaml') }}"
    state: present


MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_LOGICAL_DEVICE_MAP    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_logical_device_map.py)

  Apstra AOS Logical Device Map module let you manage your Logical Device Map easily. You can create create and delete
  Logical Device Map by Name, ID or by using a JSON File. This module is idempotent and support the `check' mode. It's
  using the AOS REST API.

Options (= is mandatory):

- content
        Datastructure of the Logical Device Map to manage. The data can be in YAML / JSON or directly a variable. It's
        the same datastructure that is returned on success in `value'. Only one of `name', `id' or `content' can be set.
        [Default: (null)]
- id
        AOS Id of the Logical Device Map to manage (can't be used to create a new Logical Device Map), Only one of
        `name', `id' or `content' can be set.
        [Default: (null)]
- name
        Name of the Logical Device Map to manage. Only one of `name', `id' or `content' can be set.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the Logical Device Map (present or not).
        (Choices: present, absent)[Default: present]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: "Create an Logical Device Map with one subnet"
  aos_logical_device_map:
    session: "{{ aos_session }}"
    name: "my-logical-device-map"
    state: present

- name: "Create an Logical Device Map with multiple subnets"
  aos_logical_device_map:
    session: "{{ aos_session }}"
    name: "my-other-logical-device-map"
    state: present

- name: "Check if an Logical Device Map exist with same subnets by ID"
  aos_logical_device_map:
    session: "{{ aos_session }}"
    name: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: present

- name: "Delete an Logical Device Map by name"
  aos_logical_device_map:
    session: "{{ aos_session }}"
    name: "my-logical-device-map"
    state: absent

- name: "Delete an Logical Device Map by id"
  aos_logical_device_map:
    session: "{{ aos_session }}"
    id: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: absent

# Save an Logical Device Map to a file

- name: "Access Logical Device Map 1/3"
  aos_logical_device_map:
    session: "{{ aos_session }}"
    name: "my-logical-device-map"
    state: present
  register: logical_device_map

- name: "Save Logical Device Map into a file in JSON 2/3"
  copy:
    content: "{{ logical_device_map.value | to_nice_json }}"
    dest: logical_device_map_saved.json

- name: "Save Logical Device Map into a file in YAML 3/3"
  copy:
    content: "{{ logical_device_map.value | to_nice_yaml }}"
    dest: logical_device_map_saved.yaml

- name: "Load Logical Device Map from a JSON file"
  aos_logical_device_map:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/logical_device_map_saved.json') }}"
    state: present

- name: "Load Logical Device Map from a YAML file"
  aos_logical_device_map:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/logical_device_map_saved.yaml') }}"
    state: present



MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_LOGIN    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_login.py)

  Obtain the AOS server session token by providing the required username and password credentials.  Upon successful
  authentication, this module will return the session-token that is required by all subsequent AOS module usage. On
  success the module will automatically populate ansible facts with the variable `aos_session' This module is not
  idempotent and do not support check mode.

Options (= is mandatory):

- passwd
        Password to use when connecting to the AOS server.
        [Default: admin]
- port
        Port number to use when connecting to the AOS server.
        [Default: 8888]
= server
        Address of the AOS Server on which you want to open a connection.

- user
        Login username to use when connecting to the AOS server.
        [Default: admin]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: Create a session with the AOS-server
  aos_login:
    server: "{{ inventory_hostname }}"
    user: admin
    passwd: admin

- name: Use the newly created session (register is not mandatory)
  aos_ip_pool:
    session: "{{ aos_session }}"
    name: my_ip_pool
    state: present


MAINTAINERS: jeremy@apstra.com (@jeremyschulman)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_RACK_TYPE    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_rack_type.py)

  Apstra AOS Rack Type module let you manage your Rack Type easily. You can create create and delete Rack Type by Name,
  ID or by using a JSON File. This module is idempotent and support the `check' mode. It's using the AOS REST API.

Options (= is mandatory):

- content
        Datastructure of the Rack Type to create. The data can be in YAML / JSON or directly a variable. It's the same
        datastructure that is returned on success in `value'.
        [Default: (null)]
- id
        AOS Id of the Rack Type to manage (can't be used to create a new Rack Type), Only one of `name', `id' or
        `content' can be set.
        [Default: (null)]
- name
        Name of the Rack Type to manage. Only one of `name', `id' or `content' can be set.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the Rack Type (present or not).
        (Choices: present, absent)[Default: present]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: "Delete a Rack Type by name"
  aos_rack_type:
    session: "{{ aos_session }}"
    name: "my-rack-type"
    state: absent

- name: "Delete a Rack Type by id"
  aos_rack_type:
    session: "{{ aos_session }}"
    id: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: absent

# Save a Rack Type to a file

- name: "Access Rack Type 1/3"
  aos_rack_type:
    session: "{{ aos_session }}"
    name: "my-rack-type"
    state: present
  register: rack_type
- name: "Save Rack Type into a JSON file 2/3"
  copy:
    content: "{{ rack_type.value | to_nice_json }}"
    dest: rack_type_saved.json
- name: "Save Rack Type into a YAML file 3/3"
  copy:
    content: "{{ rack_type.value | to_nice_yaml }}"
    dest: rack_type_saved.yaml

- name: "Load Rack Type from a JSON file"
  aos_rack_type:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/rack_type_saved.json') }}"
    state: present

- name: "Load Rack Type from a YAML file"
  aos_rack_type:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/rack_type_saved.yaml') }}"
    state: present


MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> AOS_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/aos/aos_template.py)

  Apstra AOS Template module let you manage your Template easily. You can create create and delete Template by Name, ID
  or by using a JSON File. This module is idempotent and support the `check' mode. It's using the AOS REST API.

Options (= is mandatory):

- content
        Datastructure of the Template to create. The data can be in YAML / JSON or directly a variable. It's the same
        datastructure that is returned on success in `value'.
        [Default: (null)]
- id
        AOS Id of the Template to manage (can't be used to create a new Template), Only one of `name', `id' or `src' can
        be set.
        [Default: (null)]
- name
        Name of the Template to manage. Only one of `name', `id' or `src' can be set.
        [Default: (null)]
= session
        An existing AOS session as obtained by [aos_login] module.

- state
        Indicate what is the expected state of the Template (present or not).
        (Choices: present, absent)[Default: present]
Requirements:  aos-pyez >= 0.6.0

EXAMPLES:

- name: "Check if an Template exist by name"
  aos_template:
    session: "{{ aos_session }}"
    name: "my-template"
    state: present

- name: "Check if an Template exist by ID"
  aos_template:
    session: "{{ aos_session }}"
    id: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: present

- name: "Delete an Template by name"
  aos_template:
    session: "{{ aos_session }}"
    name: "my-template"
    state: absent

- name: "Delete an Template by id"
  aos_template:
    session: "{{ aos_session }}"
    id: "45ab26fc-c2ed-4307-b330-0870488fa13e"
    state: absent

- name: "Access Template 1/3"
  aos_template:
    session: "{{ aos_session }}"
    name: "my-template"
    state: present
  register: template
- name: "Save Template into a JSON file 2/3"
  copy:
    content: "{{ template.value | to_nice_json }}"
    dest: template_saved.json
- name: "Save Template into a YAML file 2/3"
  copy:
    content: "{{ template.value | to_nice_yaml }}"
    dest: template_saved.yaml

- name: "Load Template from File (Json)"
  aos_template:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/template_saved.json') }}"
    state: present

- name: "Load Template from File (yaml)"
  aos_template:
    session: "{{ aos_session }}"
    content: "{{ lookup('file', 'resources/template_saved.yaml') }}"
    state: present


MAINTAINERS: Damien Garros (@dgarros)

METADATA:
	Status: ['preview']
	Supported_by: community
> APACHE2_MOD_PROXY    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/apache2_mod_proxy.py)

  Set and/or get members' attributes of an Apache httpd 2.4 mod_proxy balancer pool, using HTTP POST and GET requests.
  The httpd mod_proxy balancer-member status page has to be enabled and accessible, as this module relies on parsing this
  page. This module supports ansible check_mode, and requires BeautifulSoup python module.

Options (= is mandatory):

- balancer_url_suffix
        Suffix of the balancer pool url required to access the balancer pool status page (e.g.
        balancer_vhost[:port]/balancer_url_suffix).
        [Default: /balancer-manager/]
= balancer_vhost
        (ipv4|ipv6|fqdn):port of the Apache httpd 2.4 mod_proxy balancer pool.
        [Default: None]
- member_host
        (ipv4|ipv6|fqdn) of the balancer member to get or to set attributes to. Port number is autodetected and should
        not be specified here. If undefined, apache2_mod_proxy module will return a members list of dictionaries of all
        the current balancer pool members' attributes.
        [Default: None]
- state
        Desired state of the member host. (absent|disabled),drained,hot_standby,ignore_errors can be simultaneously
        invoked by separating them with a comma (e.g. state=drained,ignore_errors).
        (Choices: present, absent, enabled, disabled, drained, hot_standby, ignore_errors)[Default: None]
- tls
        Use https to access balancer management page.
        (Choices: true, false)[Default: False]
- validate_certs
        Validate ssl/tls certificates.
        (Choices: true, false)[Default: True]
EXAMPLES:
# Get all current balancer pool members' attributes:
- apache2_mod_proxy:
    balancer_vhost: 10.0.0.2

# Get a specific member's attributes:
- apache2_mod_proxy:
    balancer_vhost: myws.mydomain.org
    balancer_suffix: /lb/
    member_host: node1.myws.mydomain.org

# Enable all balancer pool members:
- apache2_mod_proxy:
    balancer_vhost: '{{ myloadbalancer_host }}'
  register: result
- apache2_mod_proxy:
    balancer_vhost: '{{ myloadbalancer_host }}'
    member_host: '{{ item.host }}'
    state: present
  with_items: '{{ result.members }}'

# Gracefully disable a member from a loadbalancer node:
- apache2_mod_proxy:
    balancer_vhost: '{{ vhost_host }}'
    member_host: '{{ member.host }}'
    state: drained
  delegate_to: myloadbalancernode
- wait_for:
    host: '{{ member.host }}'
    port: '{{ member.port }}'
    state: drained
  delegate_to: myloadbalancernode
- apache2_mod_proxy:
    balancer_vhost: '{{ vhost_host }}'
    member_host: '{{ member.host }}'
    state: absent
  delegate_to: myloadbalancernode

RETURN VALUES:
member:
    description: specific balancer member information dictionary, returned when apache2_mod_proxy module is invoked with member_host parameter.
    type: dict
    returned: success
    sample:
      {"attributes":
            {"Busy": "0",
            "Elected": "42",
            "Factor": "1",
            "From": "136K",
            "Load": "0",
            "Route": null,
            "RouteRedir": null,
            "Set": "0",
            "Status": "Init Ok ",
            "To": " 47K",
            "Worker URL": null
        },
        "balancer_url": "http://10.10.0.2/balancer-manager/",
        "host": "10.10.0.20",
        "management_url": "http://10.10.0.2/lb/?b=mywsbalancer&w=http://10.10.0.20:8080/ws&nonce=8925436c-79c6-4841-8936-e7d13b79239b",
        "path": "/ws",
        "port": 8080,
        "protocol": "http",
        "status": {
            "disabled": false,
            "drained": false,
            "hot_standby": false,
            "ignore_errors": false
        }
      }
members:
    description: list of member (defined above) dictionaries, returned when apache2_mod_proxy is invoked with no member_host and state args.
    returned: success
    type: list
    sample:
      [{"attributes": {
            "Busy": "0",
            "Elected": "42",
            "Factor": "1",
            "From": "136K",
            "Load": "0",
            "Route": null,
            "RouteRedir": null,
            "Set": "0",
            "Status": "Init Ok ",
            "To": " 47K",
            "Worker URL": null
        },
        "balancer_url": "http://10.10.0.2/balancer-manager/",
        "host": "10.10.0.20",
        "management_url": "http://10.10.0.2/lb/?b=mywsbalancer&w=http://10.10.0.20:8080/ws&nonce=8925436c-79c6-4841-8936-e7d13b79239b",
        "path": "/ws",
        "port": 8080,
        "protocol": "http",
        "status": {
            "disabled": false,
            "drained": false,
            "hot_standby": false,
            "ignore_errors": false
        }
        },
        {"attributes": {
            "Busy": "0",
            "Elected": "42",
            "Factor": "1",
            "From": "136K",
            "Load": "0",
            "Route": null,
            "RouteRedir": null,
            "Set": "0",
            "Status": "Init Ok ",
            "To": " 47K",
            "Worker URL": null
        },
        "balancer_url": "http://10.10.0.2/balancer-manager/",
        "host": "10.10.0.21",
        "management_url": "http://10.10.0.2/lb/?b=mywsbalancer&w=http://10.10.0.21:8080/ws&nonce=8925436c-79c6-4841-8936-e7d13b79239b",
        "path": "/ws",
        "port": 8080,
        "protocol": "http",
        "status": {
            "disabled": false,
            "drained": false,
            "hot_standby": false,
            "ignore_errors": false}
        }
      ]


MAINTAINERS: Olivier Boukili (@oboukili)"

METADATA:
	Status: ['preview']
	Supported_by: community
> APACHE2_MODULE    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/apache2_module.py)

  Enables or disables a specified module of the Apache2 webserver.

Options (= is mandatory):

- force
        force disabling of default modules and override Debian warnings
        (Choices: True, False)[Default: False]
- ignore_configcheck
        Ignore configuration checks about inconsistent module configuration. Especially for mpm_* modules.
        (Choices: True, False)[Default: False]
= name
        name of the module to enable/disable

- state
        indicate the desired state of the resource
        (Choices: present, absent)[Default: present]
Requirements:  a2enmod, a2dismod

EXAMPLES:
# enables the Apache2 module "wsgi"
- apache2_module:
    state: present
    name: wsgi
# disables the Apache2 module "wsgi"
- apache2_module:
    state: absent
    name: wsgi
# disable default modules for Debian
- apache2_module:
    state: absent
    name: autoindex
    force: True
# disable mpm_worker and ignore warnings about missing mpm module
- apache2_module:
    state: absent
    name: mpm_worker
    ignore_configcheck: True

RETURN VALUES:
result:
    description: message about action taken
    returned: always
    type: string
warnings:
    description: list of warning messages
    returned: when needed
    type: list
rc:
    description: return code of underlying command
    returned: failed
    type: int
stdout:
    description: stdout of underlying command
    returned: failed
    type: string
stderr:
    description: stderr of underlying command
    returned: failed
    type: string


MAINTAINERS: Robin Roth (@robinro), Christian Berendt (@berendt), Ralf Hertel (@n0trax)

METADATA:
	Status: ['preview']
	Supported_by: community
> APK    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/apk.py)

  Manages `apk' packages for Alpine Linux.

Options (= is mandatory):

- name
        A package name, like `foo', or mutliple packages, like `foo, bar'.
        [Default: None]
- state
        Indicates the desired package(s) state.
        `present' ensures the package(s) is/are present.
        `absent' ensures the package(s) is/are absent.
        `latest' ensures the package(s) is/are present and the latest version(s).
        (Choices: present, absent, latest)[Default: present]
- update_cache
        Update repository indexes. Can be run with other steps or on it's own.
        (Choices: yes, no)[Default: False]
- upgrade
        Upgrade all installed packages to their latest version.
        (Choices: yes, no)[Default: False]
Notes:
  * "name" and "upgrade" are mutually exclusive.
EXAMPLES:
# Update repositories and install "foo" package
- apk:
    name: foo
    update_cache: yes

# Update repositories and install "foo" and "bar" packages
- apk:
    name: foo,bar
    update_cache: yes

# Remove "foo" package
- apk:
    name: foo
    state: absent

# Remove "foo" and "bar" packages
- apk:
    name: foo,bar
    state: absent

# Install the package "foo"
- apk:
    name: foo
    state: present

# Install the packages "foo" and "bar"
- apk:
    name: foo,bar
    state: present

# Update repositories and update package "foo" to latest version
- apk:
    name: foo
    state: latest
    update_cache: yes

# Update repositories and update packages "foo" and "bar" to latest versions
- apk:
    name: foo,bar
    state: latest
    update_cache: yes

# Update all installed packages to the latest versions
- apk:
    upgrade: yes

# Update repositories as a separate step
- apk:
    update_cache: yes


MAINTAINERS: Kevin Brebanov (@kbrebanov)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> APT    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/apt.py)

  Manages `apt' packages (such as for Debian/Ubuntu).

Options (= is mandatory):

- allow_unauthenticated
        Ignore if packages cannot be authenticated. This is useful for bootstrapping environments that manage their own
        apt-key setup.
        (Choices: yes, no)[Default: no]
- autoremove
        If `yes', remove unused dependency packages for all module states except `build-dep'. It can also be used as the
        only option.
        (Choices: yes, no)[Default: False]
- cache_valid_time
        Update the apt cache if its older than the `cache_valid_time'. This option is set in seconds.
        [Default: 0]
- deb
        Path to a .deb package on the remote machine.
        If :// in the path, ansible will attempt to download deb before installing. (Version added 2.1)
        [Default: (null)]
- default_release
        Corresponds to the `-t' option for `apt' and sets pin priorities
        [Default: None]
- dpkg_options
        Add dpkg options to apt command. Defaults to '-o "Dpkg::Options::=--force-confdef" -o "Dpkg::Options::=--force-
        confold"'
        Options should be supplied as comma separated list
        [Default: force-confdef,force-confold]
- force
        If `yes', force installs/removes.
        (Choices: yes, no)[Default: no]
- install_recommends
        Corresponds to the `--no-install-recommends' option for `apt'. `yes' installs recommended packages.  `no' does
        not install recommended packages. By default, Ansible will use the same defaults as the operating system.
        Suggested packages are never installed.
        (Choices: yes, no)[Default: None]
- name
        A package name, like `foo', or package specifier with version, like `foo=1.0'. Name wildcards (fnmatch) like
        `apt*' and version wildcards like `foo=1.0*' are also supported.  Note that the apt-get commandline supports
        implicit regex matches here but we do not because it can let typos through easier (If you typo `foo' as `fo' apt-
        get would install packages that have "fo" in their name with a warning and a prompt for the user.  Since we don't
        have warnings and prompts before installing we disallow this.  Use an explicit fnmatch pattern if you want
        wildcarding)
        [Default: None]
- only_upgrade
        Only upgrade a package if it is already installed.
        [Default: False]
- purge
        Will force purging of configuration files if the module state is set to `absent'.
        (Choices: yes, no)[Default: False]
- state
        Indicates the desired package state. `latest' ensures that the latest version is installed. `build-dep' ensures
        the package build dependencies are installed.
        (Choices: latest, absent, present, build-dep)[Default: present]
- update_cache
        Run the equivalent of `apt-get update' before the operation. Can be run as part of the package installation or as
        a separate step.
        (Choices: yes, no)[Default: False]
- upgrade
        If yes or safe, performs an aptitude safe-upgrade.
        If full, performs an aptitude full-upgrade.
        If dist, performs an apt-get dist-upgrade.
        Note: This does not upgrade a specific package, use state=latest for that.
        (Choices: no, yes, safe, full, dist)[Default: no]
Notes:
  * Three of the upgrade modes (`full', `safe' and its alias `yes') require `aptitude', otherwise `apt-get'
        suffices.
Requirements:  python-apt (python 2), python3-apt (python 3), aptitude

EXAMPLES:
- name: Update repositories cache and install "foo" package
  apt:
    name: foo
    update_cache: yes

- name: Remove "foo" package
  apt:
    name: foo
    state: absent

- name: Install the package "foo"
  apt:
    name: foo
    state: present

- name: Install the version '1.00' of package "foo"
  apt:
    name: foo=1.00
    state: present

- name: Update the repository cache and update package "nginx" to latest version using default release squeeze-backport
  apt:
    name: nginx
    state: latest
    default_release: squeeze-backports
    update_cache: yes

- name: Install latest version of "openjdk-6-jdk" ignoring "install-recommends"
  apt:
    name: openjdk-6-jdk
    state: latest
    install_recommends: no

- name: Update all packages to the latest version
  apt:
    upgrade: dist

- name: Run the equivalent of "apt-get update" as a separate step
  apt:
    update_cache: yes

- name: Only run "update_cache=yes" if the last one is more than 3600 seconds ago
  apt:
    update_cache: yes
    cache_valid_time: 3600

- name: Pass options to dpkg on run
  apt:
    upgrade: dist
    update_cache: yes
    dpkg_options: 'force-confold,force-confdef'

- name: Install a .deb package
  apt:
    deb: /tmp/mypackage.deb

- name: Install the build dependencies for package "foo"
  apt:
    pkg: foo
    state: build-dep

- name: Install a .deb package from the internet.
  apt:
    deb: https://example.com/python-ppq_0.1-1_all.deb

RETURN VALUES:
cache_updated:
    description: if the cache was updated or not
    returned: success, in some cases
    type: boolean
    sample: True
cache_update_time:
    description: time of the last cache update (0 if unknown)
    returned: success, in some cases
    type: datetime
    sample: 1425828348000
stdout:
    description: output from apt
    returned: success, when needed
    type: string
    sample: "Reading package lists...
Building dependency tree...
Reading state information...
The following extra packages will be installed:
  apache2-bin ..."
stderr:
    description: error output from apt
    returned: success, when needed
    type: string
    sample: "AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1. Set the 'ServerName' directive globally to ..."


MAINTAINERS: Matthew Williams (@mgwilliams)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> APT_KEY    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/apt_key.py)

  Add or remove an `apt' key, optionally downloading it

Options (= is mandatory):

- data
        keyfile contents to add to the keyring
        [Default: none]
- file
        path to a keyfile on the remote server to add to the keyring
        [Default: none]
- id
        identifier of key. Including this allows check mode to correctly report the changed state.
        If specifying a subkey's id be aware that apt-key does not understand how to remove keys via a subkey id.
        Specify the primary key's id instead.
        [Default: none]
- keyring
        path to specific keyring file in /etc/apt/trusted.gpg.d
        [Default: none]
- keyserver
        keyserver to retrieve key from.
        [Default: none]
- state
        used to specify if key is being added or revoked
        (Choices: absent, present)[Default: present]
- url
        url to retrieve key from.
        [Default: none]
- validate_certs
        If `no', SSL certificates for the target url will not be validated. This should only be used on personally
        controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
Notes:
  * doesn't download the key unless it really needs it
  * as a sanity check, downloaded key id must match the one specified
  * best practice is to specify the key id and the url
EXAMPLES:
# Add an apt key by id from a keyserver
- apt_key:
    keyserver: keyserver.ubuntu.com
    id: 36A1D7869245C8950F966E92D8576A8BA88D21E9

# Add an Apt signing key, uses whichever key is at the URL
- apt_key:
    url: "https://ftp-master.debian.org/keys/archive-key-6.0.asc"
    state: present

# Add an Apt signing key, will not download if present
- apt_key:
    id: 473041FA
    url: "https://ftp-master.debian.org/keys/archive-key-6.0.asc"
    state: present

# Remove an Apt signing key, uses whichever key is at the URL
- apt_key:
    url: "https://ftp-master.debian.org/keys/archive-key-6.0.asc"
    state: absent

# Remove a Apt specific signing key, leading 0x is valid
- apt_key:
    id: 0x473041FA
    state: absent

# Add a key from a file on the Ansible server. Use armored file since utf-8 string is expected. Must be of "PGP PUBLIC KEY BLOCK" type.
- apt_key:
    data: "{{ lookup('file', 'apt.asc') }}"
    state: present

# Add an Apt signing key to a specific keyring file
- apt_key:
    id: 473041FA
    url: "https://ftp-master.debian.org/keys/archive-key-6.0.asc"
    keyring: /etc/apt/trusted.gpg.d/debian.gpg

# Add Apt signing key on remote server to keyring
- apt_key:
    id: 473041FA
    file: /tmp/apt.gpg
    state: present


MAINTAINERS: Jayson Vantuyl & others (@jvantuyl)

METADATA:
	Status: ['preview']
	Supported_by: core
> APT_REPOSITORY    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/apt_repository.py)

  Add or remove an APT repositories in Ubuntu and Debian.

Options (= is mandatory):

- codename
        Override the distribution codename to use for PPA repositories. Should usually only be set when working with a
        PPA on a non-Ubuntu target (e.g. Debian or Mint)
        [Default: (null)]
- filename
        Sets the name of the source list file in sources.list.d. Defaults to a file name based on the repository source
        url. The .list extension will be automatically added.
        [Default: (null)]
- mode
        The octal mode for newly created files in sources.list.d
        [Default: 420]
= repo
        A source string for the repository.
        [Default: none]
- state
        A source string state.
        (Choices: absent, present)[Default: present]
- update_cache
        Run the equivalent of `apt-get update' when a change occurs.  Cache updates are run after making changes.
        (Choices: yes, no)[Default: yes]
- validate_certs
        If `no', SSL certificates for the target repo will not be validated. This should only be used on personally
        controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
Notes:
  * This module works on Debian, Ubuntu and their derivatives.
  * This module supports Debian Squeeze (version 6) as well as its successors.
Requirements:  python-apt (python 2), python3-apt (python 3)

EXAMPLES:
# Add specified repository into sources list.
- apt_repository:
    repo: deb http://archive.canonical.com/ubuntu hardy partner
    state: present

# Add specified repository into sources list using specified filename.
- apt_repository:
    repo: deb http://dl.google.com/linux/chrome/deb/ stable main
    state: present
    filename: 'google-chrome'

# Add source repository into sources list.
- apt_repository:
    repo: deb-src http://archive.canonical.com/ubuntu hardy partner
    state: present

# Remove specified repository from sources list.
- apt_repository:
    repo: deb http://archive.canonical.com/ubuntu hardy partner
    state: absent

# Add nginx stable repository from PPA and install its signing key.
# On Ubuntu target:
- apt_repository:
    repo: 'ppa:nginx/stable'

# On Debian target
- apt_repository:
    repo: 'ppa:nginx/stable'
    codename: 'trusty'


MAINTAINERS: Alexander Saltanov (@sashka)

METADATA:
	Status: ['preview']
	Supported_by: core
> APT_RPM    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/apt_rpm.py)

  Manages packages with `apt-rpm'. Both low-level (`rpm') and high-level (`apt-get') package manager binaries required.

Options (= is mandatory):

= pkg
        name of package to install, upgrade or remove.
        [Default: None]
- state
        Indicates the desired package state
        (Choices: absent, present)[Default: present]
- update_cache
        update the package database first `apt-get update'.
        (Choices: yes, no)[Default: False]
EXAMPLES:
# install package foo
- apt_rpm:
    pkg: foo
    state: present

# remove package foo
- apt_rpm:
    pkg: foo
    state: absent

# description: remove packages foo and bar
- apt_rpm:
    pkg: foo,bar
    state: absent

# description: update the package database and install bar (bar will be the updated if a newer version exists)
- apt_rpm:
    name: bar
    state: present
    update_cache: yes


MAINTAINERS: Evgenii Terechkov (@evgkrsk)

METADATA:
	Status: ['preview']
	Supported_by: community
> ARCHIVE    (/usr/lib/python2.7/site-packages/ansible/modules/files/archive.py)

  Packs an archive. It is the opposite of [unarchive]. By default, it assumes the compression source exists on the
  target. It will not copy the source file from the local system to the target before archiving. Source files can be
  deleted after archival by specifying `remove=True'.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- dest
        The file name of the destination archive. This is required when `path' refers to multiple files by either
        specifying a glob, a directory or multiple paths in a list.
        [Default: None]
- format
        The type of compression to use.
        (Choices: gz, bz2, zip)[Default: gz]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
= path
        Remote absolute path, glob, or list of paths or globs for the file or files to compress or archive.

- remove
        Remove any added source files and trees after adding to archive.
        [Default: False]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
Notes:
  * requires tarfile, zipfile, gzip, and bzip2 packages on target host
  * can produce `gzip', `bzip2' and `zip' compressed files or archives
EXAMPLES:
# Compress directory /path/to/foo/ into /path/to/foo.tgz
- archive:
    path: /path/to/foo
    dest: /path/to/foo.tgz

# Compress regular file /path/to/foo into /path/to/foo.gz and remove it
- archive:
    path: /path/to/foo
    remove: True

# Create a zip archive of /path/to/foo
- archive:
    path: /path/to/foo
    format: zip

# Create a bz2 archive of multiple files, rooted at /path
- archive:
    path:
        - /path/to/foo
        - /path/wong/foo
    dest: /path/file.tar.bz2
    format: bz2

RETURN VALUES:
state:
    description:
        The current state of the archived file.
        If 'absent', then no source files were found and the archive does not exist.
        If 'compress', then the file source file is in the compressed state.
        If 'archive', then the source file or paths are currently archived.
        If 'incomplete', then an archive was created, but not all source paths were found.
    type: string
    returned: always
missing:
    description: Any files that were missing from the source.
    type: list
    returned: success
archived:
    description: Any files that were compressed or added to the archive.
    type: list
    returned: success
arcroot:
    description: The archive root.
    type: string
expanded_paths:
    description: The list of matching paths from paths argument.
    type: list


MAINTAINERS: Ben Doherty (@bendoh)

METADATA:
	Status: ['preview']
	Supported_by: community
> ASA_ACL    (/usr/lib/python2.7/site-packages/ansible/modules/network/asa/asa_acl.py)

  This module allows you to work with access-lists on a Cisco ASA device.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a changed needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuruation to use as the base config for comparison.
        [Default: None]
- context
        Specifies which context to target if you are running in the ASA in multiple context mode. Defaults to the current
        context you login to.
        [Default: None]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        (Choices: yes, no)[Default: False]
= lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.

- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  Finally if match is set to `exact', command lines must be an equal match.
        (Choices: line, strict, exact)[Default: line]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct.
        (Choices: line, block)[Default: line]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: cisco
    password: cisco
    transport: cli
    authorize: yes
    auth_pass: cisco

---
- asa_acl:
    lines:
      - access-list ACL-ANSIBLE extended permit tcp any any eq 82
      - access-list ACL-ANSIBLE extended permit tcp any any eq www
      - access-list ACL-ANSIBLE extended permit tcp any any eq 97
      - access-list ACL-ANSIBLE extended permit tcp any any eq 98
      - access-list ACL-ANSIBLE extended permit tcp any any eq 99
    before: clear configure access-list ACL-ANSIBLE
    match: strict
    replace: block
    provider: "{{ cli }}"

- asa_acl:
    lines:
      - access-list ACL-OUTSIDE extended permit tcp any any eq www
      - access-list ACL-OUTSIDE extended permit tcp any any eq https
    context: customer_a
    provider: "{{ cli }}"

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['...', '...']

responses:
  description: The set of responses from issuing the commands on the device
  returned: when not check_mode
  type: list
  sample: ['...', '...']


MAINTAINERS: Patrick Ogenstad (@ogenstad)

METADATA:
	Status: ['preview']
	Supported_by: community
> ASA_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/asa/asa_command.py)

  Sends arbitrary commands to an ASA node and returns the results read from the device. The `asa_command' module includes
  an argument that will cause the module to wait for a specific condition before returning or timing out if the condition
  is not met.

Options (= is mandatory):

- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
= commands
        List of commands to send to the remote device over the configured provider. The resulting output from the command
        is returned. If the `wait_for' argument is provided, the module is not returned until the condition is satisfied
        or the number of retires as expired.

- context
        Specifies which context to target if you are running in the ASA in multiple context mode. Defaults to the current
        context you login to.
        [Default: None]
- interval
        Configures the interval in seconds to wait between retries of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the wait_for must be satisfied.
        If the value is set to `any' then only one of the values must be satisfied.
        (Choices: any, all)[Default: all]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should by tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditions.
        [Default: 10]
- wait_for
        List of conditions to evaluate against the output of the command. The task will wait for each condition to be
        true before moving forward. If the conditional is not true within the configured number of retries, the task
        fails. See examples.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: cisco
    password: cisco
    authorize: yes
    auth_pass: cisco
    transport: cli

---
- asa_command:
    commands:
      - show version
    provider: "{{ cli }}"

- asa_command:
    commands:
      - show asp drop
      - show memory
    provider: "{{ cli }}"

- asa_command:
    commands:
      - show version
    provider: "{{ cli }}"
    context: system

RETURN VALUES:
stdout:
  description: the set of responses from the commands
  returned: always
  type: list
  sample: ['...', '...']

stdout_lines:
  description: The value of stdout split into a list
  returned: always
  type: list
  sample: [['...', '...'], ['...'], ['...']]

failed_conditions:
  description: the conditionals that failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip), Patrick Ogenstad (@ogenstad)

METADATA:
	Status: ['preview']
	Supported_by: community
> ASA_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/asa/asa_config.py)

  Cisco ASA configurations use a simple block indent file syntax for segmenting configuration into sections.  This module
  provides an implementation for working with ASA configuration sections in a deterministic way.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- backup
        This argument will cause the module to create a full backup of the current `running-config' from the remote
        device before any changes are made.  The backup file is written to the `backup' folder in the playbook root
        directory.  If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system
        [Default: None]
- commit
        This argument specifies the update method to use when applying the configuration changes to the remote node.  If
        the value is set to `merge' the configuration updates are merged with the running- config.  If the value is set
        to `check', no changes are made to the remote host.
        (Choices: merge, check)[Default: merge]
- config
        The `config' argument allows the playbook designer to supply the base configuration to be used to validate
        configuration changes necessary.  If this argument is provided, the module will not download the running-config
        from the remote node.
        [Default: None]
- context
        Specifies which context to target if you are running in the ASA in multiple context mode. Defaults to the current
        context you login to.
        [Default: None]
- defaults
        This argument specifies whether or not to collect all defaults when getting the remote device running config.
        When enabled, the module will get the current config by issuing the command `show running-config all'.
        (Choices: yes, no)[Default: False]
- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  If match is set to `exact', command lines must be an equal match.  Finally, if
        match is set to `none', the module will not attempt to compare the source configuration with the running
        configuration on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If the
        parents argument is omitted, the commands are checked against the set of top level or global commands.
        [Default: None]
- passwords
        This argument specifies to include passwords in the config when retrieving the running-config from the remote
        device.  This includes passwords related to VPN endpoints.  This argument is mutually exclusive with `defaults'.
        (Choices: yes, no)[Default: False]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running- config to the startup-config at the conclusion of
        the module running.  If check mode is specified, this argument is ignored.
        (Choices: yes, no)[Default: False]
- src
        Specifies the source path to the file that contains the configuration or configuration template to load.  The
        path to the source file can either be the full path on the Ansible control host or a relative path from the
        playbook or role root directory.  This argument is mutually exclusive with `lines'.
        [Default: None]
- update
        The `update' argument controls how the configuration statements are processed on the remote device.  Valid
        choices for the `update' argument are `merge' and `check'.  When the argument is set to `merge', the
        configuration changes are merged with the current device running configuration.  When the argument is set to
        `check' the configuration updates are determined but not actually configured on the remote device.
        (Choices: merge, check)[Default: merge]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: cisco
    password: cisco
    authorize: yes
    auth_pass: cisco
    transport: cli

---
- asa_config:
    lines:
      - network-object host 10.80.30.18
      - network-object host 10.80.30.19
      - network-object host 10.80.30.20
    parents: ['object-group network OG-MONITORED-SERVERS']
    provider: "{{ cli }}"

- asa_config:
    host: "{{ inventory_hostname }}"
    lines:
      - message-length maximum client auto
      - message-length maximum 512
    match: line
    parents: ['policy-map type inspect dns PM-DNS', 'parameters']
    authorize: yes
    auth_pass: cisco
    username: admin
    password: cisco
    context: ansible

- asa_config:
    lines:
      - ikev1 pre-shared-key MyS3cretVPNK3y
    parents: tunnel-group 1.1.1.1 ipsec-attributes
    passwords: yes
    provider: "{{ cli }}"


RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['...', '...']
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/asa_config.2016-07-16@22:28:34
responses:
  description: The set of responses from issuing the commands on the device
  returned: when not check_mode
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip), Patrick Ogenstad (@ogenstad)

METADATA:
	Status: ['preview']
	Supported_by: community
> ASSEMBLE    (/usr/lib/python2.7/site-packages/ansible/modules/files/assemble.py)

  Assembles a configuration file from fragments. Often a particular program will take a single configuration file and
  does not support a `conf.d' style structure where it is easy to build up the configuration from multiple sources.
  `assemble' will take a directory of files that can be local or have already been transferred to the system, and
  concatenate them together to produce a destination file. Files are assembled in string sorting order. Puppet calls this
  idea `fragments'.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- backup
        Create a backup file (if `yes'), including the timestamp information so you can get the original file back if you
        somehow clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- delimiter
        A delimiter to separate the file contents.
        [Default: None]
= dest
        A file to create using the concatenation of all of the source files.
        [Default: None]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- ignore_hidden
        A boolean that controls if files that start with a '.' will be included or not.
        [Default: False]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- regexp
        Assemble files only if `regex' matches the filename. If not set, all files are assembled. All "\" (backslash)
        must be escaped as "\\" to comply yaml syntax. Uses Python regular expressions; see
        http://docs.python.org/2/library/re.html.
        [Default: None]
- remote_src
        If False, it will search for src at originating/master machine, if True it will go to the remote/target machine
        for the src. Default is True.
        (Choices: True, False)[Default: True]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
= src
        An already existing directory full of source files.
        [Default: None]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- validate
        The validation command to run before copying into place.  The path to the file to validate is passed in via '%s'
        which must be present as in the sshd example below. The command is passed securely so shell features like
        expansion and pipes won't work.
        [Default: None]
EXAMPLES:
# Example from Ansible Playbooks
- assemble:
    src: /etc/someapp/fragments
    dest: /etc/someapp/someapp.conf

# When a delimiter is specified, it will be inserted in between each fragment
- assemble:
    src: /etc/someapp/fragments
    dest: /etc/someapp/someapp.conf
    delimiter: '### START FRAGMENT ###'

# Copy a new "sshd_config" file into place, after passing validation with sshd
- assemble:
    src: /etc/ssh/conf.d/
    dest: /etc/ssh/sshd_config
    validate: '/usr/sbin/sshd -t -f %s'


MAINTAINERS: Stephen Fromm (@sfromm)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> ASSERT    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/assert.py)

  This module asserts that given expressions are true with an optional custom message.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- msg
        The customized message used for a failing assertion
        [Default: (null)]
= that
        A string expression of the same form that can be passed to the 'when' statement
        Alternatively, a list of string expressions

EXAMPLES:
- assert: { that: "ansible_os_family != 'RedHat'" }

- assert:
    that:
      - "'foo' in some_command_result.stdout"
      - "number_of_the_counting == 3"

- assert:
    that:
      - "my_param <= 100"
      - "my_param >= 0"
    msg: "'my_param' must be between 0 and 100"


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> ASYNC_STATUS    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/async_status.py)

  This module gets the status of an asynchronous task.

Options (= is mandatory):

= jid
        Job or task identifier
        [Default: None]
- mode
        if `status', obtain the status; if `cleanup', clean up the async job cache located in `~/.ansible_async/' for the
        specified job `jid'.
        (Choices: status, cleanup)[Default: status]
Notes:
  * See also http://docs.ansible.com/playbooks_async.html

MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> AT    (/usr/lib/python2.7/site-packages/ansible/modules/system/at.py)

  Use this module to schedule a command or script file to run once in the future. All jobs are executed in the 'a' queue.

Options (= is mandatory):

- command
        A command to be executed in the future.
        [Default: None]
= count
        The count of units in the future to execute the command or script file.

- script_file
        An existing script file to be executed in the future.
        [Default: None]
- state
        The state dictates if the command or script file should be evaluated as present(added) or absent(deleted).
        (Choices: present, absent)[Default: present]
- unique
        If a matching job is present a new job will not be added.
        [Default: False]
= units
        The type of units in the future to execute the command or script file.
        (Choices: minutes, hours, days, weeks)
Requirements:  at

EXAMPLES:
# Schedule a command to execute in 20 minutes as root.
- at:
    command: "ls -d / > /dev/null"
    count: 20
    units: minutes

# Match a command to an existing job and delete the job.
- at:
    command: "ls -d / > /dev/null"
    state: absent

# Schedule a command to execute in 20 minutes making sure it is unique in the queue.
- at:
    command: "ls -d / > /dev/null"
    unique: true
    count: 20
    units: minutes


MAINTAINERS: Richard Isaacson (@risaacson)

METADATA:
	Status: ['preview']
	Supported_by: core
> ATOMIC_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/atomic/atomic_host.py)

  Manage the atomic host platform Rebooting of Atomic host platform should be done outside this module

Options (= is mandatory):

- revision
        The version number of the atomic host to be deployed. Providing `latest' will upgrade to the latest available
        version.
        [Default: latest]
Notes:
  * Host should be an atomic platform (verified by existence of '/run/ostree-booted' file)
Requirements:  atomic, python >= 2.6

EXAMPLES:

# Upgrade the atomic host platform to the latest version (atomic host upgrade)
- atomic_host:
    revision: latest

# Deploy a specific revision as the atomic host (atomic host deploy 23.130)
- atomic_host:
    revision: 23.130

RETURN VALUES:
msg:
    description: The command standard output
    returned: always
    type: string
    sample: 'Already on latest'


MAINTAINERS: Saravanan KR @krsacme

METADATA:
	Status: ['preview']
	Supported_by: community
> ATOMIC_IMAGE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/atomic/atomic_image.py)

  Manage the container images on the atomic host platform Allows to execute the commands on the container images

Options (= is mandatory):

= name
        Name of the container image
        [Default: None]
- started
        Start or Stop the container
        (Choices: yes, no)[Default: True]
- state
        The state of the container image.
        The state `latest' will ensure container image is upgraded to the latest version and forcefully restart
        container, if running.
        (Choices: present, absent, latest)[Default: latest]
Notes:
  * Host should be support `atomic' command
Requirements:  atomic, python >= 2.6

EXAMPLES:

# Execute the run command on rsyslog container image (atomic run rhel7/rsyslog)
- atomic_image:
    name: rhel7/rsyslog
    state: latest


RETURN VALUES:
msg:
    description: The command standard output
    returned: always
    type: string
    sample: [u'Using default tag: latest ...']


MAINTAINERS: Saravanan KR @krsacme

METADATA:
	Status: ['preview']
	Supported_by: community
> AUTHORIZED_KEY    (/usr/lib/python2.7/site-packages/ansible/modules/system/authorized_key.py)

  Adds or removes SSH authorized keys for particular user accounts

Options (= is mandatory):

- exclusive
        Whether to remove all other non-specified keys from the authorized_keys file. Multiple keys can be specified in a
        single `key' string value by separating them by newlines.
        This option is not loop aware, so if you use `with_' , it will be exclusive per iteration of the loop, if you
        want multiple keys in the file you need to pass them all to `key' in a single batch as mentioned above.
        (Choices: yes, no)[Default: no]
= key
        The SSH public key(s), as a string or (since 1.9) url (https://github.com/username.keys)

- key_options
        A string of ssh key options to be prepended to the key in the authorized_keys file
        [Default: None]
- manage_dir
        Whether this module should manage the directory of the authorized key file.  If set, the module will create the
        directory, as well as set the owner and permissions of an existing directory. Be sure to set `manage_dir=no' if
        you are using an alternate directory for authorized_keys, as set with `path', since you could lock yourself out
        of SSH access. See the example below.
        (Choices: yes, no)[Default: yes]
- path
        Alternate path to the authorized_keys file
        [Default: (homedir)+/.ssh/authorized_keys]
- state
        Whether the given key (with the given key_options) should or should not be in the file
        (Choices: present, absent)[Default: present]
= user
        The username on the remote host whose authorized_keys file will be modified

- validate_certs
        This only applies if using a https url as the source of the keys. If set to `no', the SSL certificates will not
        be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates as it avoids
        verifying the source site.
        Prior to 2.1 the code worked as if this was set to `yes'.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- name: Set authorized key took from file
  authorized_key:
    user: charlie
    state: present
    key: "{{ lookup('file', '/home/charlie/.ssh/id_rsa.pub') }}"

- name: Set authorized key took from url
  authorized_key:
    user: charlie
    state: present
    key: https://github.com/charlie.keys

- name: Set authorized key in alternate location
  authorized_key:
    user: charlie
    state: present
    key: "{{ lookup('file', '/home/charlie/.ssh/id_rsa.pub') }}"
    path: /etc/ssh/authorized_keys/charlie
    manage_dir: False

- name: Set up multiple authorized keys
  authorized_key:
    user: deploy
    state: present
    key: '{{ item }}'
  with_file:
    - public_keys/doe-jane
    - public_keys/doe-john

- name: Set authorized key defining key options
  authorized_key:
    user: charlie
    state: present
    key: "{{ lookup('file', '/home/charlie/.ssh/id_rsa.pub') }}"
    key_options: 'no-port-forwarding,from="10.0.1.1"'

- name: Set authorized key without validating the TLS/SSL certificates
  authorized_key:
    user: charlie
    state: present
    key: https://github.com/user.keys
    validate_certs: False

- name: Set authorized key, removing all the authorized key already set
  authorized_key:
    user: root
    key: '{{ item }}'
    state: present
    exclusive: True
  with_file:
    - public_keys/doe-jane

- name: Set authorized key for user ubuntu copying it from current user
  authorized_key:
    user: ubuntu
    state: present
    key: "{{ lookup('file', lookup('env','HOME') + '/.ssh/id_rsa.pub') }}"

RETURN VALUES:
exclusive:
  description: If the key has been forced to be exclusive or not.
  returned: success
  type: boolean
  sample: False
key:
  description: The key that the module was running against.
  returned: success
  type: string
  sample: https://github.com/user.keys
key_option:
  description: Key options related to the key.
  returned: success
  type: string
  sameple: null
keyfile:
  description: Path for authorzied key file.
  returned: success
  type: string
  sameple: /home/user/.ssh/authorized_keys
manage_dir:
  description: Whether this module managed the directory of the authorized key file.
  returned: success
  type: boolean
  sameple: True
path:
  description: Alternate path to the authorized_keys file
  returned: success
  type: string
  sameple: null
state:
  description: Whether the given key (with the given key_options) should or should not be in the file
  returned: success
  type: string
  sameple: present
unique:
  description: Whether the key is unique
  returned: success
  type: boolean
  sameple: false
user:
  description: The username on the remote host whose authorized_keys file will be modified
  returned: success
  type: string
  sameple: user
validate_certs:
  description: This only applies if using a https url as the source of the keys. If set to C(no), the SSL certificates will not be validated.
  returned: success
  type: boolean
  sameple: true


MAINTAINERS: Ansible Core Team

METADATA:
	Status: ['preview']
	Supported_by: core
> AVI_ANALYTICSPROFILE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_analyticsprofile.py)

  This module is used to configure AnalyticsProfile object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- apdex_response_threshold
        If a client receives an http response in less than the satisfactory latency threshold, the request is considered
        satisfied.
        It is considered tolerated if it is not satisfied and less than tolerated latency factor multiplied by the
        satisfactory latency threshold.
        Greater than this number and the client's request is considered frustrated.
        Default value when not specified in API or module is interpreted by Avi Controller as 500.
        [Default: (null)]
- apdex_response_tolerated_factor
        Client tolerated response latency factor.
        Client must receive a response within this factor times the satisfactory threshold (apdex_response_threshold) to
        be considered tolerated.
        Default value when not specified in API or module is interpreted by Avi Controller as 4.0.
        [Default: (null)]
- apdex_rtt_threshold
        Satisfactory client to avi round trip time(rtt).
        Default value when not specified in API or module is interpreted by Avi Controller as 250.
        [Default: (null)]
- apdex_rtt_tolerated_factor
        Tolerated client to avi round trip time(rtt) factor.
        It is a multiple of apdex_rtt_tolerated_factor.
        Default value when not specified in API or module is interpreted by Avi Controller as 4.0.
        [Default: (null)]
- apdex_rum_threshold
        If a client is able to load a page in less than the satisfactory latency threshold, the pageload is considered
        satisfied.
        It is considered tolerated if it is greater than satisfied but less than the tolerated latency multiplied by
        satisifed latency.
        Greater than this number and the client's request is considered frustrated.
        A pageload includes the time for dns lookup, download of all http objects, and page render time.
        Default value when not specified in API or module is interpreted by Avi Controller as 5000.
        [Default: (null)]
- apdex_rum_tolerated_factor
        Virtual service threshold factor for tolerated page load time (plt) as multiple of apdex_rum_threshold.
        Default value when not specified in API or module is interpreted by Avi Controller as 4.0.
        [Default: (null)]
- apdex_server_response_threshold
        A server http response is considered satisfied if latency is less than the satisfactory latency threshold.
        The response is considered tolerated when it is greater than satisfied but less than the tolerated latency factor
        * s_latency.
        Greater than this number and the server response is considered frustrated.
        Default value when not specified in API or module is interpreted by Avi Controller as 400.
        [Default: (null)]
- apdex_server_response_tolerated_factor
        Server tolerated response latency factor.
        Servermust response within this factor times the satisfactory threshold (apdex_server_response_threshold) to be
        considered tolerated.
        Default value when not specified in API or module is interpreted by Avi Controller as 4.0.
        [Default: (null)]
- apdex_server_rtt_threshold
        Satisfactory client to avi round trip time(rtt).
        Default value when not specified in API or module is interpreted by Avi Controller as 125.
        [Default: (null)]
- apdex_server_rtt_tolerated_factor
        Tolerated client to avi round trip time(rtt) factor.
        It is a multiple of apdex_rtt_tolerated_factor.
        Default value when not specified in API or module is interpreted by Avi Controller as 4.0.
        [Default: (null)]
- client_log_config
        Clientlogconfiguration settings for analyticsprofile.
        [Default: (null)]
- conn_lossy_ooo_threshold
        A connection between client and avi is considered lossy when more than this percentage of out of order packets
        are received.
        Default value when not specified in API or module is interpreted by Avi Controller as 50.
        [Default: (null)]
- conn_lossy_timeo_rexmt_threshold
        A connection between client and avi is considered lossy when more than this percentage of packets are
        retransmitted due to timeout.
        Default value when not specified in API or module is interpreted by Avi Controller as 20.
        [Default: (null)]
- conn_lossy_total_rexmt_threshold
        A connection between client and avi is considered lossy when more than this percentage of packets are
        retransmitted.
        Default value when not specified in API or module is interpreted by Avi Controller as 50.
        [Default: (null)]
- conn_lossy_zero_win_size_event_threshold
        A client connection is considered lossy when percentage of times a packet could not be trasmitted due to tcp zero
        window is above this threshold.
        Default value when not specified in API or module is interpreted by Avi Controller as 2.
        [Default: (null)]
- conn_server_lossy_ooo_threshold
        A connection between avi and server is considered lossy when more than this percentage of out of order packets
        are received.
        Default value when not specified in API or module is interpreted by Avi Controller as 50.
        [Default: (null)]
- conn_server_lossy_timeo_rexmt_threshold
        A connection between avi and server is considered lossy when more than this percentage of packets are
        retransmitted due to timeout.
        Default value when not specified in API or module is interpreted by Avi Controller as 20.
        [Default: (null)]
- conn_server_lossy_total_rexmt_threshold
        A connection between avi and server is considered lossy when more than this percentage of packets are
        retransmitted.
        Default value when not specified in API or module is interpreted by Avi Controller as 50.
        [Default: (null)]
- conn_server_lossy_zero_win_size_event_threshold
        A server connection is considered lossy when percentage of times a packet could not be trasmitted due to tcp zero
        window is above this threshold.
        Default value when not specified in API or module is interpreted by Avi Controller as 2.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- description
        User defined description for the object.
        [Default: (null)]
- disable_se_analytics
        Disable node (service engine) level analytics forvs metrics.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- disable_server_analytics
        Disable analytics on backend servers.
        This may be desired in container environment when there are large number of  ephemeral servers.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_client_close_before_request_as_error
        Exclude client closed connection before an http request could be completed from being classified as an error.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_gs_down_as_error
        Exclude queries to gslb services that are operationally down from the list of errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_http_error_codes
        List of http status codes to be excluded from being classified as an error.
        Error connections or responses impacts health score, are included as significant logs, and may be classified as
        part of a dos attack.
        [Default: (null)]
- exclude_invalid_dns_domain_as_error
        Exclude dns queries to domains outside the domains configured in the dns application profile from the list of
        errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_invalid_dns_query_as_error
        Exclude invalid dns queries from the list of errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_no_dns_record_as_error
        Exclude queries to domains that did not have configured services/records from the list of errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_no_valid_gs_member_as_error
        Exclude queries to gslb services that have no available members from the list of errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_persistence_change_as_error
        Exclude persistence server changed while load balancing' from the list of errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_server_dns_error_as_error
        Exclude server dns error response from the list of errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_server_tcp_reset_as_error
        Exclude server tcp reset from errors.
        It is common for applications like ms exchange.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_syn_retransmit_as_error
        Exclude 'server unanswered syns' from the list of errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_tcp_reset_as_error
        Exclude tcp resets by client from the list of potential errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- exclude_unsupported_dns_query_as_error
        Exclude unsupported dns queries from the list of errors.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- hs_event_throttle_window
        Time window (in secs) within which only unique health change events should occur.
        Default value when not specified in API or module is interpreted by Avi Controller as 1209600.
        [Default: (null)]
- hs_max_anomaly_penalty
        Maximum penalty that may be deducted from health score for anomalies.
        Default value when not specified in API or module is interpreted by Avi Controller as 10.
        [Default: (null)]
- hs_max_resources_penalty
        Maximum penalty that may be deducted from health score for high resource utilization.
        Default value when not specified in API or module is interpreted by Avi Controller as 25.
        [Default: (null)]
- hs_max_security_penalty
        Maximum penalty that may be deducted from health score based on security assessment.
        Default value when not specified in API or module is interpreted by Avi Controller as 100.
        [Default: (null)]
- hs_min_dos_rate
        Dos connection rate below which the dos security assessment will not kick in.
        Default value when not specified in API or module is interpreted by Avi Controller as 1000.
        [Default: (null)]
- hs_performance_boost
        Adds free performance score credits to health score.
        It can be used for compensating health score for known slow applications.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.
        [Default: (null)]
- hs_pscore_traffic_threshold_l4_client
        Threshold number of connections in 5min, below which apdexr, apdexc, rum_apdex, and other network quality metrics
        are not computed.
        Default value when not specified in API or module is interpreted by Avi Controller as 10.0.
        [Default: (null)]
- hs_pscore_traffic_threshold_l4_server
        Threshold number of connections in 5min, below which apdexr, apdexc, rum_apdex, and other network quality metrics
        are not computed.
        Default value when not specified in API or module is interpreted by Avi Controller as 10.0.
        [Default: (null)]
- hs_security_certscore_expired
        Score assigned when the certificate has expired.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.0.
        [Default: (null)]
- hs_security_certscore_gt30d
        Score assigned when the certificate expires in more than 30 days.
        Default value when not specified in API or module is interpreted by Avi Controller as 5.0.
        [Default: (null)]
- hs_security_certscore_le07d
        Score assigned when the certificate expires in less than or equal to 7 days.
        Default value when not specified in API or module is interpreted by Avi Controller as 2.0.
        [Default: (null)]
- hs_security_certscore_le30d
        Score assigned when the certificate expires in less than or equal to 30 days.
        Default value when not specified in API or module is interpreted by Avi Controller as 4.0.
        [Default: (null)]
- hs_security_chain_invalidity_penalty
        Penalty for allowing certificates with invalid chain.
        Default value when not specified in API or module is interpreted by Avi Controller as 1.0.
        [Default: (null)]
- hs_security_cipherscore_eq000b
        Score assigned when the minimum cipher strength is 0 bits.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.0.
        [Default: (null)]
- hs_security_cipherscore_ge128b
        Score assigned when the minimum cipher strength is greater than equal to 128 bits.
        Default value when not specified in API or module is interpreted by Avi Controller as 5.0.
        [Default: (null)]
- hs_security_cipherscore_lt128b
        Score assigned when the minimum cipher strength is less than 128 bits.
        Default value when not specified in API or module is interpreted by Avi Controller as 3.5.
        [Default: (null)]
- hs_security_encalgo_score_none
        Score assigned when no algorithm is used for encryption.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.0.
        [Default: (null)]
- hs_security_encalgo_score_rc4
        Score assigned when rc4 algorithm is used for encryption.
        Default value when not specified in API or module is interpreted by Avi Controller as 2.5.
        [Default: (null)]
- hs_security_hsts_penalty
        Penalty for not enabling hsts.
        Default value when not specified in API or module is interpreted by Avi Controller as 1.0.
        [Default: (null)]
- hs_security_nonpfs_penalty
        Penalty for allowing non-pfs handshakes.
        Default value when not specified in API or module is interpreted by Avi Controller as 1.0.
        [Default: (null)]
- hs_security_selfsignedcert_penalty
        Deprecated.
        Default value when not specified in API or module is interpreted by Avi Controller as 1.0.
        [Default: (null)]
- hs_security_ssl30_score
        Score assigned when supporting ssl3.0 encryption protocol.
        Default value when not specified in API or module is interpreted by Avi Controller as 3.5.
        [Default: (null)]
- hs_security_tls10_score
        Score assigned when supporting tls1.0 encryption protocol.
        Default value when not specified in API or module is interpreted by Avi Controller as 5.0.
        [Default: (null)]
- hs_security_tls11_score
        Score assigned when supporting tls1.1 encryption protocol.
        Default value when not specified in API or module is interpreted by Avi Controller as 5.0.
        [Default: (null)]
- hs_security_tls12_score
        Score assigned when supporting tls1.2 encryption protocol.
        Default value when not specified in API or module is interpreted by Avi Controller as 5.0.
        [Default: (null)]
- hs_security_weak_signature_algo_penalty
        Penalty for allowing weak signature algorithm(s).
        Default value when not specified in API or module is interpreted by Avi Controller as 1.0.
        [Default: (null)]
= name
        The name of the analytics profile.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- ranges
        List of http status code ranges to be excluded from being classified as an error.
        [Default: (null)]
- resp_code_block
        Block of http response codes to be excluded from being classified as an error.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Uuid of the analytics profile.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
  - name: Create a custom Analytics profile object
    avi_analyticsprofile:
      controller: ''
      username: ''
      password: ''
      apdex_response_threshold: 500
      apdex_response_tolerated_factor: 4.0
      apdex_rtt_threshold: 250
      apdex_rtt_tolerated_factor: 4.0
      apdex_rum_threshold: 5000
      apdex_rum_tolerated_factor: 4.0
      apdex_server_response_threshold: 400
      apdex_server_response_tolerated_factor: 4.0
      apdex_server_rtt_threshold: 125
      apdex_server_rtt_tolerated_factor: 4.0
      conn_lossy_ooo_threshold: 50
      conn_lossy_timeo_rexmt_threshold: 20
      conn_lossy_total_rexmt_threshold: 50
      conn_lossy_zero_win_size_event_threshold: 2
      conn_server_lossy_ooo_threshold: 50
      conn_server_lossy_timeo_rexmt_threshold: 20
      conn_server_lossy_total_rexmt_threshold: 50
      conn_server_lossy_zero_win_size_event_threshold: 2
      disable_se_analytics: false
      disable_server_analytics: false
      exclude_client_close_before_request_as_error: false
      exclude_persistence_change_as_error: false
      exclude_server_tcp_reset_as_error: false
      exclude_syn_retransmit_as_error: false
      exclude_tcp_reset_as_error: false
      hs_event_throttle_window: 1209600
      hs_max_anomaly_penalty: 10
      hs_max_resources_penalty: 25
      hs_max_security_penalty: 100
      hs_min_dos_rate: 1000
      hs_performance_boost: 20
      hs_pscore_traffic_threshold_l4_client: 10.0
      hs_pscore_traffic_threshold_l4_server: 10.0
      hs_security_certscore_expired: 0.0
      hs_security_certscore_gt30d: 5.0
      hs_security_certscore_le07d: 2.0
      hs_security_certscore_le30d: 4.0
      hs_security_chain_invalidity_penalty: 1.0
      hs_security_cipherscore_eq000b: 0.0
      hs_security_cipherscore_ge128b: 5.0
      hs_security_cipherscore_lt128b: 3.5
      hs_security_encalgo_score_none: 0.0
      hs_security_encalgo_score_rc4: 2.5
      hs_security_hsts_penalty: 0.0
      hs_security_nonpfs_penalty: 1.0
      hs_security_selfsignedcert_penalty: 1.0
      hs_security_ssl30_score: 3.5
      hs_security_tls10_score: 5.0
      hs_security_tls11_score: 5.0
      hs_security_tls12_score: 5.0
      hs_security_weak_signature_algo_penalty: 1.0
      name: jason-analytics-profile
      tenant_ref: Demo

RETURN VALUES:
obj:
    description: AnalyticsProfile (api/analyticsprofile) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_API_SESSION    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_api_session.py)

  This module can be used for calling any resources defined in Avi REST API. https://avinetworks.com/ This module is
  useful for invoking HTTP Patch methods and accessing resources that do not have an REST object associated with them.

Options (= is mandatory):

- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- data
        HTTP body in YAML or JSON format.
        [Default: (null)]
= http_method
        Allowed HTTP methods for RESTful services and are supported by Avi Controller.
        (Choices: get, put, post, patch, delete)
- params
        Query parameters passed to the HTTP API.
        [Default: (null)]
- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- path
        Path for Avi API resource. For example, `path: virtualservice' will translate to `api/virtualserivce'.
        [Default: (null)]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- timeout
        Timeout (in seconds) for Avi API calls.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:

  - name: Get Pool Information using avi_api_session
    avi_api_session:
      controller: "{{ controller }}"
      username: "{{ username }}"
      password: "{{ password }}"
      http_method: get
      path: pool
      params:
        name: "{{ pool_name }}"
    register: pool_results

  - name: Patch Pool with list of servers
    avi_api_session:
      controller: "{{ controller }}"
      username: "{{ username }}"
      password: "{{ password }}"
      http_method: patch
      path: "{{ pool_path }}"
      data:
        add:
          servers:
            - ip:
                addr: 10.10.10.10
                type: V4
            - ip:
                addr: 20.20.20.20
                type: V4
    register: updated_pool

  - name: Fetch Pool metrics bandwidth and connections rate
    avi_api_session:
      controller: "{{ controller }}"
      username: "{{ username }}"
      password: "{{ password }}"
      http_method: get
      path: analytics/metrics/pool
      params:
        name: "{{ pool_name }}"
        metric_id: l4_server.avg_bandwidth,l4_server.avg_complete_conns
        step: 300
        limit: 10
    register: pool_metrics


RETURN VALUES:
obj:
    description: Avi REST resource
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_APPLICATIONPERSISTENCEPROFILE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_applicationpersistenceprofile.py)

  This module is used to configure ApplicationPersistenceProfile object more examples at
  https://github.com/avinetworks/devops

Options (= is mandatory):

- app_cookie_persistence_profile
        Specifies the application cookie persistence profile parameters.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- description
        User defined description for the object.
        [Default: (null)]
- hdr_persistence_profile
        Specifies the custom http header persistence profile parameters.
        [Default: (null)]
- http_cookie_persistence_profile
        Specifies the http cookie persistence profile parameters.
        [Default: (null)]
- ip_persistence_profile
        Specifies the client ip persistence profile parameters.
        [Default: (null)]
= name
        A user-friendly name for the persistence profile.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
= persistence_type
        Method used to persist clients to the same server for a duration of time or a session.
        Default value when not specified in API or module is interpreted by Avi Controller as
        PERSISTENCE_TYPE_CLIENT_IP_ADDRESS.

- server_hm_down_recovery
        Specifies behavior when a persistent server has been marked down by a health monitor.
        Default value when not specified in API or module is interpreted by Avi Controller as HM_DOWN_PICK_NEW_SERVER.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Uuid of the persistence profile.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
  - name: Create an Application Persistence setting using http cookie.
    avi_applicationpersistenceprofile:
      controller: ''
      username: ''
      password: ''
      http_cookie_persistence_profile:
        always_send_cookie: false
        cookie_name: My-HTTP
        key:
        - aes_key: ShYGZdMks8j6Bpvm2sCvaXWzvXms2Z9ob+TTjRy46lQ=
          name: c1276819-550c-4adf-912d-59efa5fd7269
        - aes_key: OGsyVk84VCtyMENFOW0rMnRXVnNrb0RzdG5mT29oamJRb0dlbHZVSjR1az0=
          name: a080de57-77c3-4580-a3ea-e7a6493c14fd
        - aes_key: UVN0cU9HWmFUM2xOUzBVcmVXaHFXbnBLVUUxMU1VSktSVU5HWjJOWmVFMTBUMUV4UmxsNk4xQmFZejA9
          name: 60478846-33c6-484d-868d-bbc324fce4a5
        timeout: 15
      name: My-HTTP-Cookie
      persistence_type: PERSISTENCE_TYPE_HTTP_COOKIE
      server_hm_down_recovery: HM_DOWN_PICK_NEW_SERVER
      tenant_ref: Demo

RETURN VALUES:
obj:
    description: ApplicationPersistenceProfile (api/applicationpersistenceprofile) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_APPLICATIONPROFILE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_applicationprofile.py)

  This module is used to configure ApplicationProfile object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- description
        User defined description for the object.
        [Default: (null)]
- dns_service_profile
        Specifies various dns service related controls for virtual service.
        [Default: (null)]
- dos_rl_profile
        Specifies various security related controls for virtual service.
        [Default: (null)]
- http_profile
        Specifies the http application proxy profile parameters.
        [Default: (null)]
= name
        The name of the application profile.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- preserve_client_ip
        Specifies if client ip needs to be preserved for backend connection.
        Not compatible with connection multiplexing.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tcp_app_profile
        Specifies the tcp application proxy profile parameters.
        [Default: (null)]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
= type
        Specifies which application layer proxy is enabled for the virtual service.

- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Uuid of the application profile.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
  - name: Create an Application Profile for HTTP application enabled for SSL traffic
    avi_applicationprofile:
      controller: ''
      username: ''
      password: ''
      http_profile:
        cache_config:
          age_header: true
          aggressive: false
          date_header: true
          default_expire: 600
          enabled: false
          heuristic_expire: false
          max_cache_size: 0
          max_object_size: 4194304
          mime_types_group_refs:
          - admin:System-Cacheable-Resource-Types
          min_object_size: 100
          query_cacheable: false
          xcache_header: true
        client_body_timeout: 0
        client_header_timeout: 10000
        client_max_body_size: 0
        client_max_header_size: 12
        client_max_request_size: 48
        compression_profile:
          compressible_content_ref: admin:System-Compressible-Content-Types
          compression: false
          remove_accept_encoding_header: true
          type: AUTO_COMPRESSION
        connection_multiplexing_enabled: true
        hsts_enabled: false
        hsts_max_age: 365
        http_to_https: false
        httponly_enabled: false
        keepalive_header: false
        keepalive_timeout: 30000
        max_bad_rps_cip: 0
        max_bad_rps_cip_uri: 0
        max_bad_rps_uri: 0
        max_rps_cip: 0
        max_rps_cip_uri: 0
        max_rps_unknown_cip: 0
        max_rps_unknown_uri: 0
        max_rps_uri: 0
        post_accept_timeout: 30000
        secure_cookie_enabled: false
        server_side_redirect_to_https: false
        spdy_enabled: false
        spdy_fwd_proxy_mode: false
        ssl_client_certificate_mode: SSL_CLIENT_CERTIFICATE_NONE
        ssl_everywhere_enabled: false
        websockets_enabled: true
        x_forwarded_proto_enabled: false
        xff_alternate_name: X-Forwarded-For
        xff_enabled: true
      name: System-HTTP
      tenant_ref: admin
      type: APPLICATION_PROFILE_TYPE_HTTP

RETURN VALUES:
obj:
    description: ApplicationProfile (api/applicationprofile) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_CERTIFICATEMANAGEMENTPROFILE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_certificatemanagementprofile.py)

  This module is used to configure CertificateManagementProfile object more examples at
  https://github.com/avinetworks/devops

Options (= is mandatory):

- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
= name
        Name of the pki profile.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- script_params
        List of customparams.
        [Default: (null)]
= script_path
        Script_path of certificatemanagementprofile.

- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Unique object identifier of the object.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Example to create CertificateManagementProfile object
  avi_certificatemanagementprofile:
    controller: 10.10.25.42
    username: admin
    password: something
    state: present
    name: sample_certificatemanagementprofile

RETURN VALUES:
obj:
    description: CertificateManagementProfile (api/certificatemanagementprofile) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_HEALTHMONITOR    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_healthmonitor.py)

  This module is used to configure HealthMonitor object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- description
        User defined description for the object.
        [Default: (null)]
- dns_monitor
        Healthmonitordns settings for healthmonitor.
        [Default: (null)]
- external_monitor
        Healthmonitorexternal settings for healthmonitor.
        [Default: (null)]
- failed_checks
        Number of continuous failed health checks before the server is marked down.
        Default value when not specified in API or module is interpreted by Avi Controller as 2.
        [Default: (null)]
- http_monitor
        Healthmonitorhttp settings for healthmonitor.
        [Default: (null)]
- https_monitor
        Healthmonitorhttp settings for healthmonitor.
        [Default: (null)]
- monitor_port
        Use this port instead of the port defined for the server in the pool.
        If the monitor succeeds to this port, the load balanced traffic will still be sent to the port of the server
        defined within the pool.
        [Default: (null)]
= name
        A user friendly name for this health monitor.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- receive_timeout
        A valid response from the server is expected within the receive timeout window.
        This timeout must be less than the send interval.
        If server status is regularly flapping up and down, consider increasing this value.
        Default value when not specified in API or module is interpreted by Avi Controller as 4.
        [Default: (null)]
- send_interval
        Frequency, in seconds, that monitors are sent to a server.
        Default value when not specified in API or module is interpreted by Avi Controller as 10.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- successful_checks
        Number of continuous successful health checks before server is marked up.
        Default value when not specified in API or module is interpreted by Avi Controller as 2.
        [Default: (null)]
- tcp_monitor
        Healthmonitortcp settings for healthmonitor.
        [Default: (null)]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
= type
        Type of the health monitor.

- udp_monitor
        Healthmonitorudp settings for healthmonitor.
        [Default: (null)]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Uuid of the health monitor.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Create a HTTPS health monitor
  avi_healthmonitor:
    controller: 10.10.27.90
    username: admin
    password: AviNetworks123!
    https_monitor:
      http_request: HEAD / HTTP/1.0
      http_response_code:
        - HTTP_2XX
        - HTTP_3XX
    receive_timeout: 4
    failed_checks: 3
    send_interval: 10
    successful_checks: 3
    type: HEALTH_MONITOR_HTTPS
    name: MyWebsite-HTTPS

RETURN VALUES:
obj:
    description: HealthMonitor (api/healthmonitor) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_NETWORKPROFILE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_networkprofile.py)

  This module is used to configure NetworkProfile object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- description
        User defined description for the object.
        [Default: (null)]
= name
        The name of the network profile.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
= profile
        Networkprofileunion settings for networkprofile.

- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Uuid of the network profile.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
  - name: Create a network profile for an UDP application
    avi_networkprofile:
      controller: ''
      username: ''
      password: ''
      name: System-UDP-Fast-Path
      profile:
        type: PROTOCOL_TYPE_UDP_FAST_PATH
        udp_fast_path_profile:
          per_pkt_loadbalance: false
          session_idle_timeout: 10
          snat: true
      tenant_ref: admin

RETURN VALUES:
obj:
    description: NetworkProfile (api/networkprofile) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_PKIPROFILE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_pkiprofile.py)

  This module is used to configure PKIProfile object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- ca_certs
        List of certificate authorities (root and intermediate) trusted that is used for certificate validation.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- created_by
        Creator name.
        [Default: (null)]
- crl_check
        When enabled, avi will verify via crl checks that certificates in the trust chain have not been revoked.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
- crls
        Certificate revocation lists.
        [Default: (null)]
- ignore_peer_chain
        When enabled, avi will not trust intermediate and root certs presented by a client.
        Instead, only the chain certs configured in the certificate authority section will be used to verify trust of the
        client's cert.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
= name
        Name of the pki profile.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Unique object identifier of the object.
        [Default: (null)]
- validate_only_leaf_crl
        When enabled, avi will only validate the revocation status of the leaf certificate using crl.
        To enable validation for the entire chain, disable this option and provide all the relevant crls.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Example to create PKIProfile object
  avi_pkiprofile:
    controller: 10.10.25.42
    username: admin
    password: something
    state: present
    name: sample_pkiprofile

RETURN VALUES:
obj:
    description: PKIProfile (api/pkiprofile) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_POOL    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_pool.py)

  This module is used to configure Pool object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- a_pool
        Name of container cloud application that constitutes a pool in a a-b pool configuration, if different from vs
        app.
        [Default: (null)]
- ab_pool
        A/b pool configuration.
        [Default: (null)]
- ab_priority
        Priority of this pool in a a-b pool pair.
        Internally used.
        [Default: (null)]
- apic_epg_name
        Synchronize cisco apic epg members with pool servers.
        [Default: (null)]
- application_persistence_profile_ref
        Persistence will ensure the same user sticks to the same server for a desired duration of time.
        It is a reference to an object of type applicationpersistenceprofile.
        [Default: (null)]
- autoscale_launch_config_ref
        Reference to the launch configuration profile.
        It is a reference to an object of type autoscalelaunchconfig.
        [Default: (null)]
- autoscale_networks
        Network ids for the launch configuration.
        [Default: (null)]
- autoscale_policy_ref
        Reference to server autoscale policy.
        It is a reference to an object of type serverautoscalepolicy.
        [Default: (null)]
- capacity_estimation
        Inline estimation of capacity of servers.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- capacity_estimation_ttfb_thresh
        The maximum time-to-first-byte of a server.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.
        [Default: (null)]
- cloud_config_cksum
        Checksum of cloud configuration for pool.
        Internally set by cloud connector.
        [Default: (null)]
- cloud_ref
        It is a reference to an object of type cloud.
        [Default: (null)]
- connection_ramp_duration
        Duration for which new connections will be gradually ramped up to a server recently brought online.
        Useful for lb algorithms that are least connection based.
        Default value when not specified in API or module is interpreted by Avi Controller as 10.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- created_by
        Creator name.
        [Default: (null)]
- default_server_port
        Traffic sent to servers will use this destination server port unless overridden by the server's specific port
        attribute.
        The ssl checkbox enables avi to server encryption.
        Default value when not specified in API or module is interpreted by Avi Controller as 80.
        [Default: (null)]
- description
        A description of the pool.
        [Default: (null)]
- domain_name
        Comma separated list of domain names which will be used to verify the common names or subject alternative names
        presented by server certificates.
        It is performed only when common name check host_check_enabled is enabled.
        [Default: (null)]
- east_west
        Inherited config from virtualservice.
        [Default: (null)]
- enabled
        Enable or disable the pool.
        Disabling will terminate all open connections and pause health monitors.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
- fail_action
        Enable an action - close connection, http redirect, local http response, or backup pool - when a pool failure
        happens.
        By default, a connection will be closed, in case the pool experiences a failure.
        [Default: (null)]
- fewest_tasks_feedback_delay
        Periodicity of feedback for fewest tasks server selection algorithm.
        Default value when not specified in API or module is interpreted by Avi Controller as 10.
        [Default: (null)]
- graceful_disable_timeout
        Used to gracefully disable a server.
        Virtual service waits for the specified time before terminating the existing connections  to the servers that are
        disabled.
        Default value when not specified in API or module is interpreted by Avi Controller as 1.
        [Default: (null)]
- health_monitor_refs
        Verify server health by applying one or more health monitors.
        Active monitors generate synthetic traffic from each service engine and mark a server up or down based on the
        response.
        The passive monitor listens only to client to server communication.
        It raises or lowers the ratio of traffic destined to a server based on successful responses.
        It is a reference to an object of type healthmonitor.
        [Default: (null)]
- host_check_enabled
        Enable common name check for server certificate.
        If enabled and no explicit domain name is specified, avi will use the incoming host header to do the match.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- inline_health_monitor
        The passive monitor will monitor client to server connections and requests and adjust traffic load to servers
        based on successful responses.
        This may alter the expected behavior of the lb method, such as round robin.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
- ipaddrgroup_ref
        Use list of servers from ip address group.
        It is a reference to an object of type ipaddrgroup.
        [Default: (null)]
- lb_algorithm
        The load balancing algorithm will pick a server within the pool's list of available servers.
        Default value when not specified in API or module is interpreted by Avi Controller as
        LB_ALGORITHM_LEAST_CONNECTIONS.
        [Default: (null)]
- lb_algorithm_consistent_hash_hdr
        Http header name to be used for the hash key.
        [Default: (null)]
- lb_algorithm_hash
        Criteria used as a key for determining the hash between the client and  server.
        Default value when not specified in API or module is interpreted by Avi Controller as
        LB_ALGORITHM_CONSISTENT_HASH_SOURCE_IP_ADDRESS.
        [Default: (null)]
- max_concurrent_connections_per_server
        The maximum number of concurrent connections allowed to each server within the pool.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.
        [Default: (null)]
- max_conn_rate_per_server
        Rate limit connections to each server.
        [Default: (null)]
= name
        The name of the pool.

- networks
        (internal-use) networks designated as containing servers for this pool.
        The servers may be further narrowed down by a filter.
        This field is used internally by avi, not editable by the user.
        [Default: (null)]
- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- pki_profile_ref
        Avi will validate the ssl certificate present by a server against the selected pki profile.
        It is a reference to an object of type pkiprofile.
        [Default: (null)]
- placement_networks
        Manually select the networks and subnets used to provide reachability to the pool's servers.
        Specify the subnet using the following syntax  10-1-1-0/24.
        Use static routes in vrf configuration when pool servers are not directly connected butroutable from the service
        engine.
        [Default: (null)]
- prst_hdr_name
        Header name for custom header persistence.
        [Default: (null)]
- request_queue_depth
        Minimum number of requests to be queued when pool is full.
        Default value when not specified in API or module is interpreted by Avi Controller as 128.
        [Default: (null)]
- request_queue_enabled
        Enable request queue when pool is full.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- rewrite_host_header_to_server_name
        Rewrite incoming host header to server name of the server to which the request is proxied.
        Enabling this feature rewrites host header for requests to all servers in the pool.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- rewrite_host_header_to_sni
        If sni server name is specified, rewrite incoming host header to the sni server name.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- server_auto_scale
        Server autoscale.
        Not used anymore.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- server_count
        Number of server_count.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.
        [Default: (null)]
- server_name
        Fully qualified dns hostname which will be used in the tls sni extension in server connections if sni is enabled.
        If no value is specified, avi will use the incoming host header instead.
        [Default: (null)]
- server_reselect
        Server reselect configuration for http requests.
        [Default: (null)]
- servers
        The pool directs load balanced traffic to this list of destination servers.
        The servers can be configured by ip address, name, network or via ip address group.
        [Default: (null)]
- sni_enabled
        Enable tls sni for server connections.
        If disabled, avi will not send the sni extension as part of the handshake.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
- ssl_key_and_certificate_ref
        Service engines will present a client ssl certificate to the server.
        It is a reference to an object of type sslkeyandcertificate.
        [Default: (null)]
- ssl_profile_ref
        When enabled, avi re-encrypts traffic to the backend servers.
        The specific ssl profile defines which ciphers and ssl versions will be supported.
        It is a reference to an object of type sslprofile.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- use_service_port
        Do not translate the client's destination port when sending the connection to the server.
        The pool or servers specified service port will still be used for health monitoring.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Uuid of the pool.
        [Default: (null)]
- vrf_ref
        Virtual routing context that the pool is bound to.
        This is used to provide the isolation of the set of networks the pool is attached to.
        The pool inherits the virtual routing conext of the virtual service, and this field is used only internally, and
        is set by pb-transform.
        It is a reference to an object of type vrfcontext.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Create a Pool with two servers and HTTP monitor
  avi_pool:
    controller: 10.10.1.20
    username: avi_user
    password: avi_password
    name: testpool1
    description: testpool1
    state: present
    health_monitor_refs:
        - '/api/healthmonitor?name=System-HTTP'
    servers:
        - ip:
            addr: 10.10.2.20
            type: V4
        - ip:
            addr: 10.10.2.21
            type: V4

RETURN VALUES:
obj:
    description: Pool (api/pool) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_POOLGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_poolgroup.py)

  This module is used to configure PoolGroup object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- cloud_config_cksum
        Checksum of cloud configuration for poolgroup.
        Internally set by cloud connector.
        [Default: (null)]
- cloud_ref
        It is a reference to an object of type cloud.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- created_by
        Name of the user who created the object.
        [Default: (null)]
- deployment_policy_ref
        When setup autoscale manager will automatically promote new pools into production when deployment goals are met.
        It is a reference to an object of type poolgroupdeploymentpolicy.
        [Default: (null)]
- description
        Description of pool group.
        [Default: (null)]
- fail_action
        Enable an action - close connection, http redirect, or local http response - when a pool group failure happens.
        By default, a connection will be closed, in case the pool group experiences a failure.
        [Default: (null)]
- members
        List of pool group members object of type poolgroupmember.
        [Default: (null)]
- min_servers
        The minimum number of servers to distribute traffic to.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.
        [Default: (null)]
= name
        The name of the pool group.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- priority_labels_ref
        Uuid of the priority labels.
        If not provided, pool group member priority label will be interpreted as a number with a larger number considered
        higher priority.
        It is a reference to an object of type prioritylabels.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Uuid of the pool group.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Example to create PoolGroup object
  avi_poolgroup:
    controller: 10.10.25.42
    username: admin
    password: something
    state: present
    name: sample_poolgroup

RETURN VALUES:
obj:
    description: PoolGroup (api/poolgroup) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_role.py)

  This module is used to configure Role object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
= name
        Name of the object.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- privileges
        List of permission.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Unique object identifier of the object.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Example to create Role object
  avi_role:
    controller: 10.10.25.42
    username: admin
    password: something
    state: present
    name: sample_role

RETURN VALUES:
obj:
    description: Role (api/role) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_SSLKEYANDCERTIFICATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_sslkeyandcertificate.py)

  This module is used to configure SSLKeyAndCertificate object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- ca_certs
        Ca certificates in certificate chain.
        [Default: (null)]
= certificate
        Sslcertificate settings for sslkeyandcertificate.

- certificate_management_profile_ref
        It is a reference to an object of type certificatemanagementprofile.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- created_by
        Creator name.
        [Default: (null)]
- dynamic_params
        Dynamic parameters needed for certificate management profile.
        [Default: (null)]
- enckey_base64
        Encrypted private key corresponding to the private key (e.g.
        Those generated by an hsm such as thales nshield).
        [Default: (null)]
- enckey_name
        Name of the encrypted private key (e.g.
        Those generated by an hsm such as thales nshield).
        [Default: (null)]
- hardwaresecuritymodulegroup_ref
        It is a reference to an object of type hardwaresecuritymodulegroup.
        [Default: (null)]
- key
        Private key.
        [Default: (null)]
- key_params
        Sslkeyparams settings for sslkeyandcertificate.
        [Default: (null)]
= name
        Name of the object.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- status
        Status of sslkeyandcertificate.
        Default value when not specified in API or module is interpreted by Avi Controller as SSL_CERTIFICATE_FINISHED.
        [Default: (null)]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- type
        Type of sslkeyandcertificate.
        Default value when not specified in API or module is interpreted by Avi Controller as
        SSL_CERTIFICATE_TYPE_VIRTUALSERVICE.
        [Default: (null)]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Unique object identifier of the object.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Create a SSL Key and Certificate
  avi_sslkeyandcertificate:
    controller: 10.10.27.90
    username: admin
    password: AviNetworks123!
    key: |
        -----BEGIN PRIVATE KEY-----
        ....
        -----END PRIVATE KEY-----
    certificate:
        self_signed: true
        certificate: |
          -----BEGIN CERTIFICATE-----
          ....
          -----END CERTIFICATE-----
    type: SSL_CERTIFICATE_TYPE_VIRTUALSERVICE
    name: MyTestCert

RETURN VALUES:
obj:
    description: SSLKeyAndCertificate (api/sslkeyandcertificate) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_SSLPROFILE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_sslprofile.py)

  This module is used to configure SSLProfile object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- accepted_ciphers
        Ciphers suites represented as defined by http://www.openssl.org/docs/apps/ciphers.html.
        Default value when not specified in API or module is interpreted by Avi Controller as AES:3DES:RC4.
        [Default: (null)]
- accepted_versions
        Set of versions accepted by the server.
        [Default: (null)]
- cipher_enums
        Cipher_enums of sslprofile.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- description
        User defined description for the object.
        [Default: (null)]
- dhparam
        Dh parameters used in ssl.
        At this time, it is not configurable and is set to 2048 bits.
        [Default: (null)]
- enable_ssl_session_reuse
        Enable ssl session re-use.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
= name
        Name of the object.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- prefer_client_cipher_ordering
        Prefer the ssl cipher ordering presented by the client during the ssl handshake over the one specified in the ssl
        profile.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- send_close_notify
        Send 'close notify' alert message for a clean shutdown of the ssl connection.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
- ssl_rating
        Sslrating settings for sslprofile.
        [Default: (null)]
- ssl_session_timeout
        The amount of time before an ssl session expires.
        Default value when not specified in API or module is interpreted by Avi Controller as 86400.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tags
        List of tag.
        [Default: (null)]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Unique object identifier of the object.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
  - name: Create SSL profile with list of allowed ciphers
    avi_sslprofile:
      controller: ''
      username: ''
      password: ''
      accepted_ciphers: >
        ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA:
        ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:
        AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:
        AES256-SHA:DES-CBC3-SHA:ECDHE-RSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:
        ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA
      accepted_versions:
      - type: SSL_VERSION_TLS1
      - type: SSL_VERSION_TLS1_1
      - type: SSL_VERSION_TLS1_2
      cipher_enums:
      - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
      - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA
      - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA
      - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
      - TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256
      - TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384
      - TLS_RSA_WITH_AES_128_GCM_SHA256
      - TLS_RSA_WITH_AES_256_GCM_SHA384
      - TLS_RSA_WITH_AES_128_CBC_SHA256
      - TLS_RSA_WITH_AES_256_CBC_SHA256
      - TLS_RSA_WITH_AES_128_CBC_SHA
      - TLS_RSA_WITH_AES_256_CBC_SHA
      - TLS_RSA_WITH_3DES_EDE_CBC_SHA
      - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA
      - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384
      - TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
      - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
      - TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA
      name: PFS-BOTH-RSA-EC
      send_close_notify: true
      ssl_rating:
        compatibility_rating: SSL_SCORE_EXCELLENT
        performance_rating: SSL_SCORE_EXCELLENT
        security_score: '100.0'
      tenant_ref: Demo

RETURN VALUES:
obj:
    description: SSLProfile (api/sslprofile) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_SYSTEMCONFIGURATION    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_systemconfiguration.py)

  This module is used to configure SystemConfiguration object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- admin_auth_configuration
        Adminauthconfiguration settings for systemconfiguration.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- dns_configuration
        Dnsconfiguration settings for systemconfiguration.
        [Default: (null)]
- dns_virtualservice_refs
        Dns virtualservices hosting fqdn records for applications across avi vantage.
        If no virtualservices are provided, avi vantage will provide dns services for configured applications.
        Switching back to avi vantage from dns virtualservices is not allowed.
        It is a reference to an object of type virtualservice.
        [Default: (null)]
- docker_mode
        Boolean flag to set docker_mode.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- email_configuration
        Emailconfiguration settings for systemconfiguration.
        [Default: (null)]
- global_tenant_config
        Tenantconfiguration settings for systemconfiguration.
        [Default: (null)]
- linux_configuration
        Linuxconfiguration settings for systemconfiguration.
        [Default: (null)]
- mgmt_ip_access_control
        Configure ip access control for controller to restrict open access.
        [Default: (null)]
- ntp_configuration
        Ntpconfiguration settings for systemconfiguration.
        [Default: (null)]
- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- portal_configuration
        Portalconfiguration settings for systemconfiguration.
        [Default: (null)]
- proxy_configuration
        Proxyconfiguration settings for systemconfiguration.
        [Default: (null)]
- snmp_configuration
        Snmpconfiguration settings for systemconfiguration.
        [Default: (null)]
- ssh_ciphers
        Allowed ciphers list for ssh to the management interface on the controller and service engines.
        If this is not specified, all the default ciphers are allowed.
        Ssh -q cipher provides the list of default ciphers supported.
        [Default: (null)]
- ssh_hmacs
        Allowed hmac list for ssh to the management interface on the controller and service engines.
        If this is not specified, all the default hmacs are allowed.
        Ssh -q mac provides the list of default hmacs supported.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tech_support_uploader_configuration
        Techsupportuploaderconfiguration settings for systemconfiguration.
        [Default: (null)]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Unique object identifier of the object.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Example to create SystemConfiguration object
  avi_systemconfiguration:
    controller: 10.10.25.42
    username: admin
    password: something
    state: present
    name: sample_systemconfiguration

RETURN VALUES:
obj:
    description: SystemConfiguration (api/systemconfiguration) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_TENANT    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_tenant.py)

  This module is used to configure Tenant object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- config_settings
        Tenantconfiguration settings for tenant.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- created_by
        Creator of this tenant.
        [Default: (null)]
- description
        User defined description for the object.
        [Default: (null)]
- local
        Boolean flag to set local.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
= name
        Name of the object.

- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- url
        Avi controller URL of the object.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Unique object identifier of the object.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
  - name: Create Tenant using Service Engines in provider mode
    avi_tenant:
      controller: ''
      password: ''
      username: ''
      config_settings:
        se_in_provider_context: false
        tenant_access_to_provider_se: true
        tenant_vrf: false
      description: VCenter, Open Stack, AWS Virtual services
      local: true
      name: Demo

RETURN VALUES:
obj:
    description: Tenant (api/tenant) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AVI_VIRTUALSERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/network/avi/avi_virtualservice.py)

  This module is used to configure VirtualService object more examples at https://github.com/avinetworks/devops

Options (= is mandatory):

- active_standby_se_tag
        This configuration only applies if the virtualservice is in legacy active standby ha mode and load distribution
        among active standby is enabled.
        This field is used to tag the virtualservice so that virtualservices with the same tag will share the same active
        serviceengine.
        Virtualservices with different tags will have different active serviceengines.
        If one of the serviceengine's in the serviceenginegroup fails, all virtualservices will end up using the same
        active serviceengine.
        Redistribution of the virtualservices can be either manual or automated when the failed serviceengine recovers.
        Redistribution is based on the auto redistribute property of the serviceenginegroup.
        Default value when not specified in API or module is interpreted by Avi Controller as ACTIVE_STANDBY_SE_1.
        [Default: (null)]
- analytics_policy
        Determines analytics settings for the application.
        [Default: (null)]
- analytics_profile_ref
        Specifies settings related to analytics.
        It is a reference to an object of type analyticsprofile.
        [Default: (null)]
- application_profile_ref
        Enable application layer specific features for the virtual service.
        It is a reference to an object of type applicationprofile.
        [Default: (null)]
- auto_allocate_floating_ip
        Auto-allocate floating/elastic ip from the cloud infrastructure.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- auto_allocate_ip
        Auto-allocate vip from the provided subnet.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- availability_zone
        Availability-zone to place the virtual service.
        [Default: (null)]
- avi_allocated_fip
        (internal-use) fip allocated by avi in the cloud infrastructure.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- avi_allocated_vip
        (internal-use) vip allocated by avi in the cloud infrastructure.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- client_auth
        Http authentication configuration for protected resources.
        [Default: (null)]
- cloud_config_cksum
        Checksum of cloud configuration for vs.
        Internally set by cloud connector.
        [Default: (null)]
- cloud_ref
        It is a reference to an object of type cloud.
        [Default: (null)]
- cloud_type
        Cloud_type of virtualservice.
        Default value when not specified in API or module is interpreted by Avi Controller as CLOUD_NONE.
        [Default: (null)]
- connections_rate_limit
        Rate limit the incoming connections to this virtual service.
        [Default: (null)]
- content_rewrite
        Profile used to match and rewrite strings in request and/or response body.
        [Default: (null)]
- controller
        IP address or hostname of the controller. The default value is the environment variable `AVI_CONTROLLER'.
        [Default: (null)]
- created_by
        Creator name.
        [Default: (null)]
- delay_fairness
        Select the algorithm for qos fairness.
        This determines how multiple virtual services sharing the same service engines will prioritize traffic over a
        congested network.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- description
        User defined description for the object.
        [Default: (null)]
- discovered_network_ref
        (internal-use) discovered networks providing reachability for client facing virtual service ip.
        This field is deprecated.
        It is a reference to an object of type network.
        [Default: (null)]
- discovered_networks
        (internal-use) discovered networks providing reachability for client facing virtual service ip.
        This field is used internally by avi, not editable by the user.
        [Default: (null)]
- discovered_subnet
        (internal-use) discovered subnets providing reachability for client facing virtual service ip.
        This field is deprecated.
        [Default: (null)]
- dns_info
        Service discovery specific data including fully qualified domain name, type and time-to-live of the dns record.
        Note that only one of fqdn and dns_info setting is allowed.
        [Default: (null)]
- east_west_placement
        Force placement on all se's in service group (mesos mode only).
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- enable_autogw
        Response traffic to clients will be sent back to the source mac address of the connection, rather than statically
        sent to a default gateway.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
- enable_rhi
        Enable route health injection using the bgp config in the vrf context.
        [Default: (null)]
- enable_rhi_snat
        Enable route health injection for source nat'ted floating ip address using the bgp config in the vrf context.
        [Default: (null)]
- enabled
        Enable or disable the virtual service.
        Default value when not specified in API or module is interpreted by Avi Controller as True.
        [Default: (null)]
- floating_ip
        Floating ip to associate with this virtual service.
        [Default: (null)]
- floating_subnet_uuid
        If auto_allocate_floating_ip is true and more than one floating-ip subnets exist, then the subnet for the
        floating ip address allocation.
        This field is applicable only if the virtualservice belongs to an openstack or aws cloud.
        In openstack or aws cloud it is required when auto_allocate_floating_ip is selected.
        [Default: (null)]
- flow_dist
        Criteria for flow distribution among ses.
        Default value when not specified in API or module is interpreted by Avi Controller as LOAD_AWARE.
        [Default: (null)]
- flow_label_type
        Criteria for flow labelling.
        Default value when not specified in API or module is interpreted by Avi Controller as NO_LABEL.
        [Default: (null)]
- fqdn
        Dns resolvable, fully qualified domain name of the virtualservice.
        Only one of 'fqdn' and 'dns_info' configuration is allowed.
        [Default: (null)]
- host_name_xlate
        Translate the host name sent to the servers to this value.
        Translate the host name sent from servers back to the value used by the client.
        [Default: (null)]
- http_policies
        Http policies applied on the data traffic of the virtual service.
        [Default: (null)]
- ign_pool_net_reach
        Ignore pool servers network reachability constraints for virtual service placement.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- ip_address
        Ip address of the virtual service.
        [Default: (null)]
- ipam_network_subnet
        Subnet and/or network for allocating virtualservice ip by ipam provider module.
        [Default: (null)]
- limit_doser
        Limit potential dos attackers who exceed max_cps_per_client significantly to a fraction of max_cps_per_client for
        a while.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- max_cps_per_client
        Maximum connections per second per client ip.
        Default value when not specified in API or module is interpreted by Avi Controller as 0.
        [Default: (null)]
- microservice_ref
        Microservice representing the virtual service.
        It is a reference to an object of type microservice.
        [Default: (null)]
= name
        Name for the virtual service.

- network_profile_ref
        Determines network settings such as protocol, tcp or udp, and related options for the protocol.
        It is a reference to an object of type networkprofile.
        [Default: (null)]
- network_ref
        Manually override the network on which the virtual service is placed.
        It is a reference to an object of type network.
        [Default: (null)]
- network_security_policy_ref
        Network security policies for the virtual service.
        It is a reference to an object of type networksecuritypolicy.
        [Default: (null)]
- password
        Password of Avi user in Avi controller. The default value is the environment variable `AVI_PASSWORD'.
        [Default: (null)]
- performance_limits
        Optional settings that determine performance limits like max connections or bandwdith etc.
        [Default: (null)]
- pool_group_ref
        The pool group is an object that contains pools.
        It is a reference to an object of type poolgroup.
        [Default: (null)]
- pool_ref
        The pool is an object that contains destination servers and related attributes such as load-balancing and
        persistence.
        It is a reference to an object of type pool.
        [Default: (null)]
- port_uuid
        (internal-use) network port assigned to the virtual service ip address.
        [Default: (null)]
- remove_listening_port_on_vs_down
        Remove listening port if virtualservice is down.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- requests_rate_limit
        Rate limit the incoming requests to this virtual service.
        [Default: (null)]
- scaleout_ecmp
        Disable re-distribution of flows across service engines for a virtual service.
        Enable if the network itself performs flow hashing with ecmp in environments such as gcp.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- se_group_ref
        The service engine group to use for this virtual service.
        Moving to a new se group is disruptive to existing connections for this vs.
        It is a reference to an object of type serviceenginegroup.
        [Default: (null)]
- server_network_profile_ref
        Determines the network settings profile for the server side of tcp proxied connections.
        Leave blank to use the same settings as the client to vs side of the connection.
        It is a reference to an object of type networkprofile.
        [Default: (null)]
- service_pool_select
        Select pool based on destination port.
        [Default: (null)]
- services
        List of services defined for this virtual service.
        [Default: (null)]
- snat_ip
        Nat'ted floating source ip address(es) for upstream connection to servers.
        [Default: (null)]
- ssl_key_and_certificate_refs
        Select or create one or two certificates, ec and/or rsa, that will be presented to ssl/tls terminated
        connections.
        It is a reference to an object of type sslkeyandcertificate.
        [Default: (null)]
- ssl_profile_ref
        Determines the set of ssl versions and ciphers to accept for ssl/tls terminated connections.
        It is a reference to an object of type sslprofile.
        [Default: (null)]
- ssl_sess_cache_avg_size
        Expected number of ssl session cache entries (may be exceeded).
        Default value when not specified in API or module is interpreted by Avi Controller as 1024.
        [Default: (null)]
- state
        The state that should be applied on the entity.
        (Choices: absent, present)[Default: present]
- static_dns_records
        List of static dns records applied to this virtual service.
        These are static entries and no health monitoring is performed against the ip addresses.
        [Default: (null)]
- subnet
        Subnet providing reachability for client facing virtual service ip.
        [Default: (null)]
- subnet_uuid
        It represents subnet for the virtual service ip address allocation when auto_allocate_ip is true.it is only
        applicable in openstack or aws cloud.
        This field is required if auto_allocate_ip is true.
        [Default: (null)]
- tenant
        Name of tenant used for all Avi API calls and context of object.
        [Default: admin]
- tenant_ref
        It is a reference to an object of type tenant.
        [Default: (null)]
- tenant_uuid
        UUID of tenant used for all Avi API calls and context of object.
        [Default: ]
- type
        Specify if this is a normal virtual service, or if it is the parent or child of an sni-enabled virtual hosted
        virtual service.
        Default value when not specified in API or module is interpreted by Avi Controller as VS_TYPE_NORMAL.
        [Default: (null)]
- url
        Avi controller URL of the object.
        [Default: (null)]
- use_bridge_ip_as_vip
        Use bridge ip as vip on each host in mesos deployments.
        Default value when not specified in API or module is interpreted by Avi Controller as False.
        [Default: (null)]
- username
        Username used for accessing Avi controller. The default value is the environment variable `AVI_USERNAME'.
        [Default: (null)]
- uuid
        Uuid of the virtualservice.
        [Default: (null)]
- vh_domain_name
        The exact name requested from the client's sni-enabled tls hello domain name field.
        If this is a match, the parent vs will forward the connection to this child vs.
        [Default: (null)]
- vh_parent_vs_uuid
        Specifies the virtual service acting as virtual hosting (sni) parent.
        [Default: (null)]
- vrf_context_ref
        Virtual routing context that the virtual service is bound to.
        This is used to provide the isolation of the set of networks the application is attached to.
        It is a reference to an object of type vrfcontext.
        [Default: (null)]
- vs_datascripts
        Datascripts applied on the data traffic of the virtual service.
        [Default: (null)]
- weight
        The quality of service weight to assign to traffic transmitted from this virtual service.
        A higher weight will prioritize traffic versus other virtual services sharing the same service engines.
        Default value when not specified in API or module is interpreted by Avi Controller as 1.
        [Default: (null)]
Requirements:  avisdk

EXAMPLES:
- name: Create SSL Virtual Service using Pool testpool2
  avi_virtualservice:
    controller: 10.10.27.90
    username: admin
    password: AviNetworks123!
    name: newtestvs
    state: present
    performance_limits:
    max_concurrent_connections: 1000
    services:
        - port: 443
          enable_ssl: true
        - port: 80
    ssl_profile_ref: '/api/sslprofile?name=System-Standard'
    application_profile_ref: '/api/applicationprofile?name=System-Secure-HTTP'
    ssl_key_and_certificate_refs:
        - '/api/sslkeyandcertificate?name=System-Default-Cert'
    ip_address:
    addr: 10.90.131.103
    type: V4
    pool_ref: '/api/pool?name=testpool2'

RETURN VALUES:
obj:
    description: VirtualService (api/virtualservice) object
    returned: success, changed
    type: dict


MAINTAINERS: Gaurav Rastogi (grastogi@avinetworks.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> AWS_KMS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/aws_kms.py)

  Manage role/user access to a KMS key. Not designed for encrypting/decrypting.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- clean_invalid_entries
        If adding/removing a role and invalid grantees are found, remove them. These entries will cause an update to fail
        in all known cases.
        Only cleans if changes are being made.
        [Default: True]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- grant_types
        List of grants to give to user/role. Likely "role,role grant" or "role,role grant,admin". Required when
        `mode=grant'.
        [Default: (null)]
- key_alias
        Alias label to the key. One of `key_alias' or `key_arn' are required.
        [Default: (null)]
- key_arn
        Full ARN to the key. One of `key_alias' or `key_arn' are required.
        [Default: (null)]
= mode
        Grant or deny access.
        (Choices: grant, deny)[Default: grant]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- role_arn
        ARN of role to allow/deny access. One of `role_name' or `role_arn' are required.
        [Default: (null)]
- role_name
        Role to allow/deny access. One of `role_name' or `role_arn' are required.
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
- name: grant user-style access to production secrets
  kms:
  args:
    mode: grant
    key_alias: "alias/my_production_secrets"
    role_name: "prod-appServerRole-1R5AQG2BSEL6L"
    grant_types: "role,role grant"
- name: remove access to production secrets from role
  kms:
  args:
    mode: deny
    key_alias: "alias/my_production_secrets"
    role_name: "prod-appServerRole-1R5AQG2BSEL6L"

RETURN VALUES:
changes_needed:
  description: grant types that would be changed/were changed.
  type: dict
  returned: always
  sample: { "role": "add", "role grant": "add" }
had_invalid_entries:
  description: there are invalid (non-ARN) entries in the KMS entry. These don't count as a change, but will be removed if any changes are being made.
  type: boolean
  returned: always


MAINTAINERS: tedder

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure.py)

  Creates or terminates azure instances. When created optionally waits for it to be 'running'.

Options (= is mandatory):

- auto_updates
        Enable Auto Updates on Windows Machines
        (Choices: yes, no)[Default: no]
- enable_winrm
        Enable winrm on Windows Machines
        (Choices: yes, no)[Default: yes]
- endpoints
        a comma-separated list of TCP ports to expose on the virtual machine (e.g., "22,80")
        [Default: 22]
- hostname
        hostname to write /etc/hostname. Defaults to <name>.cloudapp.net.
        [Default: None]
= image
        system image for creating the virtual machine (e.g., b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu_DAILY_BUILD-
        precise-12_04_3-LTS-amd64-server-20131205-en-us-30GB)
        [Default: None]
= location
        the azure location to use (e.g. 'East US')
        [Default: None]
- management_cert_path
        path to an azure management certificate associated with the subscription id. Overrides the AZURE_CERT_PATH
        environment variable.
        [Default: None]
= name
        name of the virtual machine and associated cloud service.
        [Default: None]
- os_type
        The type of the os that is gettings provisioned
        (Choices: windows, linux)[Default: linux]
- password
        the unix password for the new virtual machine.
        [Default: None]
- role_size
        azure role size for the new virtual machine (e.g., Small, ExtraLarge, A6). You have to pay attention to the fact
        that instances of type G and DS are not available in all regions (locations). Make sure if you selected the size
        and type of instance available in your chosen location.
        [Default: Small]
- ssh_cert_path
        path to an X509 certificate containing the public ssh key to install in the virtual machine. See
        http://www.windowsazure.com/en-us/manage/linux/tutorials/intro-to-linux/ for more details.
        if this option is specified, password-based ssh authentication will be disabled.
        [Default: None]
- state
        create or terminate instances
        [Default: present]
= storage_account
        the azure storage account in which to store the data disks.

- subscription_id
        azure subscription id. Overrides the AZURE_SUBSCRIPTION_ID environment variable.
        [Default: None]
- user
        the unix username for the new virtual machine.
        [Default: None]
- virtual_network_name
        Name of virtual network.
        [Default: None]
- wait
        wait for the instance to be in state 'running' before returning
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 600]
- wait_timeout_redirects
        how long before wait gives up for redirects, in seconds
        [Default: 300]
Requirements:  python >= 2.6, azure >= 0.7.1

EXAMPLES:
# Note: None of these examples set subscription_id or management_cert_path
# It is assumed that their matching environment variables are set.

- name: Provision virtual machine example
  azure:
    name: my-virtual-machine
    role_size: Small
    image: b39f27a8b8c64d52b05eac6a62ebad85__Ubuntu_DAILY_BUILD-precise-12_04_3-LTS-amd64-server-20131205-en-us-30GB
    location: East US
    user: ubuntu
    ssh_cert_path: /path/to/azure_x509_cert.pem
    storage_account: my-storage-account
    wait: True
    state: present
  delegate_to: localhost

- name: Terminate virtual machine example
  azure:
    name: my-virtual-machine
    state: absent
  delegate_to: localhost

- name: Create windows machine
  azure:
    name: ben-Winows-23
    hostname: win123
    os_type: windows
    enable_winrm: True
    subscription_id: '{{ azure_sub_id }}'
    management_cert_path: '{{ azure_cert_path }}'
    role_size: Small
    image: bd507d3a70934695bc2128e3e5a255ba__RightImage-Windows-2012-x64-v13.5
    location: East Asia
    password: xxx
    storage_account: benooytes
    user: admin
    wait: True
    state: present
    virtual_network_name: '{{ vnet_name }}'
  delegate_to: localhost


MAINTAINERS: John Whitbeck (@jwhitbeck)

METADATA:
	Status: ['preview']
	Supported_by: community
> AZURE_RM_DEPLOYMENT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_deployment.py)

  Create or destroy Azure Resource Manager template deployments via the Azure SDK for Python. You can find some quick
  start templates in GitHub here https://github.com/azure/azure-quickstart-templates. For more information on Azue
  resource manager templates see https://azure.microsoft.com/en-us/documentation/articles/resource-group-template-
  deploy/.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- deployment_mode
        In incremental mode, resources are deployed without deleting existing resources that are not included in the
        template. In complete mode resources are deployed and existing resources in the resource group not included in
        the template are deleted.
        (Choices: complete, incremental)[Default: incremental]
- deployment_name
        The name of the deployment to be tracked in the resource group deployment history. Re-using a deployment name
        will overwrite the previous value in the resource group's deployment history.
        [Default: ansible-arm]
- location
        The geo-locations in which the resource group will be located.
        [Default: westus]
- parameters
        A hash of all the required template variables for the deployment template. This parameter is mutually exclusive
        with 'parameters_link'. Either one of them is required if "state" parameter is "present".
        [Default: None]
- parameters_link
        Uri of file containing the parameters body. This parameter is mutually exclusive with 'parameters'. Either one of
        them is required if "state" parameter is "present".
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
= resource_group_name
        The resource group name to use or create to host the deployed template

- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- state
        If state is "present", template will be created. If state is "present" and if deployment exists, it will be
        updated. If state is "absent", stack will be removed.
        (Choices: present, absent)[Default: present]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- template
        A hash containing the templates inline. This parameter is mutually exclusive with 'template_link'. Either one of
        them is required if "state" parameter is "present".
        [Default: None]
- template_link
        Uri of file containing the template body. This parameter is mutually exclusive with 'template'. Either one of
        them is required if "state" parameter is "present".
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
- wait_for_deployment_completion
        Whether or not to block until the deployment has completed.
        (Choices: yes, no)[Default: True]
- wait_for_deployment_polling_period
        Time (in seconds) to wait between polls when waiting for deployment completion.
        [Default: 10]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
# Destroy a template deployment
- name: Destroy Azure Deploy
  azure_rm_deployment:
    state: absent
    subscription_id: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
    resource_group_name: dev-ops-cle

# Create or update a template deployment based on uris using parameter and template links
- name: Create Azure Deploy
  azure_rm_deployment:
    state: present
    resource_group_name: dev-ops-cle
    template_link: 'https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/101-vm-simple-linux/azuredeploy.json'
    parameters_link: 'https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/101-vm-simple-linux/azuredeploy.parameters.json'

# Create or update a template deployment based on a uri to the template and parameters specified inline.
# This deploys a VM with SSH support for a given public key, then stores the result in 'azure_vms'. The result is then
# used to create a new host group. This host group is then used to wait for each instance to respond to the public IP SSH.
---
- hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - name: Destroy Azure Deploy
      azure_rm_deployment:
        state: absent
        subscription_id: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
        resource_group_name: dev-ops-cle

    - name: Create Azure Deploy
      azure_rm_deployment:
        state: present
        subscription_id: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
        resource_group_name: dev-ops-cle
        parameters:
          newStorageAccountName:
            value: devopsclestorage1
          adminUsername:
            value: devopscle
          dnsNameForPublicIP:
            value: devopscleazure
          location:
            value: West US
          vmSize:
            value: Standard_A2
          vmName:
            value: ansibleSshVm
          sshKeyData:
            value: YOUR_SSH_PUBLIC_KEY
        template_link: 'https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/101-vm-sshkey/azuredeploy.json'
      register: azure

    - name: Add new instance to host group
      add_host:
        hostname: "{{ item['ips'][0].public_ip }}"
        groupname: azure_vms
      with_items: "{{ azure.deployment.instances }}"

    - hosts: azure_vms
      user: devopscle
      tasks:
        - name: Wait for SSH to come up
          wait_for:
            port: 22
            timeout: 2000
            state: started
        - name: echo the hostname of the vm
          shell: hostname

# Deploy an Azure WebApp running a hello world'ish node app
- name: Create Azure WebApp Deployment at http://devopscleweb.azurewebsites.net/hello.js
  azure_rm_deployment:
    state: present
    subscription_id: cbbdaed0-fea9-4693-bf0c-d446ac93c030
    resource_group_name: dev-ops-cle-webapp
    parameters:
      repoURL:
        value: 'https://github.com/devigned/az-roadshow-oss.git'
      siteName:
        value: devopscleweb
      hostingPlanName:
        value: someplan
      siteLocation:
        value: westus
      sku:
        value: Standard
    template_link: 'https://raw.githubusercontent.com/azure/azure-quickstart-templates/master/201-web-app-github-deploy/azuredeploy.json'

# Create or update a template deployment based on an inline template and parameters
- name: Create Azure Deploy
  azure_rm_deployment:
    state: present
    subscription_id: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
    resource_group_name: dev-ops-cle

    template:
      $schema: "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#"
      contentVersion: "1.0.0.0"
      parameters:
        newStorageAccountName:
          type: "string"
          metadata:
            description: "Unique DNS Name for the Storage Account where the Virtual Machine's disks will be placed."
        adminUsername:
          type: "string"
          metadata:
            description: "User name for the Virtual Machine."
        adminPassword:
          type: "securestring"
          metadata:
            description: "Password for the Virtual Machine."
        dnsNameForPublicIP:
          type: "string"
          metadata:
            description: "Unique DNS Name for the Public IP used to access the Virtual Machine."
        ubuntuOSVersion:
          type: "string"
          defaultValue: "14.04.2-LTS"
          allowedValues:
            - "12.04.5-LTS"
            - "14.04.2-LTS"
            - "15.04"
          metadata:
            description: "The Ubuntu version for the VM. This will pick a fully patched image of this given Ubuntu version. Allowed values: 12.04.5-LTS, 14.04.2-LTS, 15.04."
      variables:
        location: "West US"
        imagePublisher: "Canonical"
        imageOffer: "UbuntuServer"
        OSDiskName: "osdiskforlinuxsimple"
        nicName: "myVMNic"
        addressPrefix: "192.0.2.0/24"
        subnetName: "Subnet"
        subnetPrefix: "10.0.0.0/24"
        storageAccountType: "Standard_LRS"
        publicIPAddressName: "myPublicIP"
        publicIPAddressType: "Dynamic"
        vmStorageAccountContainerName: "vhds"
        vmName: "MyUbuntuVM"
        vmSize: "Standard_D1"
        virtualNetworkName: "MyVNET"
        vnetID: "[resourceId('Microsoft.Network/virtualNetworks',variables('virtualNetworkName'))]"
        subnetRef: "[concat(variables('vnetID'),'/subnets/',variables('subnetName'))]"
      resources:
        - type: "Microsoft.Storage/storageAccounts"
          name: "[parameters('newStorageAccountName')]"
          apiVersion: "2015-05-01-preview"
          location: "[variables('location')]"
          properties:
            accountType: "[variables('storageAccountType')]"
        - apiVersion: "2015-05-01-preview"
          type: "Microsoft.Network/publicIPAddresses"
          name: "[variables('publicIPAddressName')]"
          location: "[variables('location')]"
          properties:
            publicIPAllocationMethod: "[variables('publicIPAddressType')]"
            dnsSettings:
              domainNameLabel: "[parameters('dnsNameForPublicIP')]"
        - type: "Microsoft.Network/virtualNetworks"
          apiVersion: "2015-05-01-preview"
          name: "[variables('virtualNetworkName')]"
          location: "[variables('location')]"
          properties:
            addressSpace:
              addressPrefixes:
                - "[variables('addressPrefix')]"
            subnets:
              -
                name: "[variables('subnetName')]"
                properties:
                  addressPrefix: "[variables('subnetPrefix')]"
        - type: "Microsoft.Network/networkInterfaces"
          apiVersion: "2015-05-01-preview"
          name: "[variables('nicName')]"
          location: "[variables('location')]"
          dependsOn:
            - "[concat('Microsoft.Network/publicIPAddresses/', variables('publicIPAddressName'))]"
            - "[concat('Microsoft.Network/virtualNetworks/', variables('virtualNetworkName'))]"
          properties:
            ipConfigurations:
              -
                name: "ipconfig1"
                properties:
                  privateIPAllocationMethod: "Dynamic"
                  publicIPAddress:
                    id: "[resourceId('Microsoft.Network/publicIPAddresses',variables('publicIPAddressName'))]"
                  subnet:
                    id: "[variables('subnetRef')]"
        - type: "Microsoft.Compute/virtualMachines"
          apiVersion: "2015-06-15"
          name: "[variables('vmName')]"
          location: "[variables('location')]"
          dependsOn:
            - "[concat('Microsoft.Storage/storageAccounts/', parameters('newStorageAccountName'))]"
            - "[concat('Microsoft.Network/networkInterfaces/', variables('nicName'))]"
          properties:
            hardwareProfile:
              vmSize: "[variables('vmSize')]"
            osProfile:
              computername: "[variables('vmName')]"
              adminUsername: "[parameters('adminUsername')]"
              adminPassword: "[parameters('adminPassword')]"
            storageProfile:
              imageReference:
                publisher: "[variables('imagePublisher')]"
                offer: "[variables('imageOffer')]"
                sku: "[parameters('ubuntuOSVersion')]"
                version: "latest"
              osDisk:
                name: "osdisk"
                vhd:
                  uri: "[concat('http://',parameters('newStorageAccountName'),'.blob.core.windows.net/',variables('vmStorageAccountContainerName'),'/',variables('OSDiskName'),'.vhd')]"
                caching: "ReadWrite"
                createOption: "FromImage"
            networkProfile:
              networkInterfaces:
                -
                  id: "[resourceId('Microsoft.Network/networkInterfaces',variables('nicName'))]"
            diagnosticsProfile:
              bootDiagnostics:
                enabled: "true"
                storageUri: "[concat('http://',parameters('newStorageAccountName'),'.blob.core.windows.net')]"
    parameters:
      newStorageAccountName:
        value: devopsclestorage
      adminUsername:
        value: devopscle
      adminPassword:
        value: Password1!
      dnsNameForPublicIP:
        value: devopscleazure

RETURN VALUES:
deployment:
  description: Deployment details
  type: dict
  returned: always
  sample:
      group_name:
        description: Name of the resource group
        type: string
        returned: always
      id:
        description: The Azure ID of the deployment
        type: string
        returned: always
      instances:
        description: Provides the public IP addresses for each VM instance.
        type: list
        returned: always
      name:
        description: Name of the deployment
        type: string
        returned: always
      outputs:
        description: Dictionary of outputs received from the deployment
        type: dict
        returned: always


MAINTAINERS: Andre Price (@obsoleted), David Justice (@devigned), Laurent Mazuel (@lmazuel)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_NETWORKINTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_networkinterface.py)

  Create, update or delete a network interface. When creating a network interface you must provide the name of an
  existing virtual network, the name of an existing subnet within the virtual network. A default security group and
  public IP address will be created automatically, or you can provide the name of an existing security group and public
  IP address. See the examples below for more details.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- append_tags
        Use to control if tags field is canonical or just appends to existing tags. When canonical, any tags not found in
        the tags parameter will be removed from the object's metadata.
        [Default: True]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- location
        Valid azure location. Defaults to location of the resource group.
        [Default: resource_group location]
= name
        Name of the network interface.

- open_ports
        When a default security group is created for a Linux host a rule will be added allowing inbound TCP connections
        to the default SSH port 22, and for a Windows host rules will be added allowing inbound access to RDP ports 3389
        and 5986. Override the default ports by providing a list of open ports.
        [Default: None]
- os_type
        Determines any rules to be added to a default security group. When creating a network interface, if no security
        group name is provided, a default security group will be created. If the os_type is 'Windows', a rule will be
        added allowing RDP access. If the os_type is 'Linux', a rule allowing SSH access will be added.
        (Choices: Windows, Linux)[Default: Linux]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- private_ip_address
        Valid IPv4 address that falls within the specified subnet.
        [Default: (null)]
- private_ip_allocation_method
        Specify whether or not the assigned IP address is permanent. NOTE: when creating a network interface specifying a
        value of 'Static' requires that a private_ip_address value be provided. You can update the allocation method to
        'Static' after a dynamic private ip address has been assigned.
        (Choices: Dynamic, Static)[Default: Dynamic]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- public_ip
        When creating a network interface, if no public IP address name is provided a default public IP address will be
        created. Set to false, if you do not want a public IP address automatically created.
        [Default: True]
- public_ip_address_name
        Name of an existing public IP address object to associate with the security group.
        [Default: None]
- public_ip_allocation_method
        If a public_ip_address_name is not provided, a default public IP address will be created. The allocation method
        determines whether or not the public IP address assigned to the network interface is permanent.
        (Choices: Dynamic, Static)[Default: Dynamic]
= resource_group
        Name of a resource group where the network interface exists or will be created.

- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- security_group_name
        Name of an existing security group with which to associate the network interface. If not provided, a default
        security group will be created.
        [Default: None]
- state
        Assert the state of the network interface. Use 'present' to create or update an interface and 'absent' to delete
        an interface.
        (Choices: absent, present)[Default: present]
- subnet_name
        Name of an existing subnet within the specified virtual network. Required when creating a network interface
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Dictionary of string:string pairs to assign as metadata to the object. Metadata tags on the object will be
        updated with any provided values. To remove tags set append_tags option to false.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
- virtual_network_name
        Name of an existing virtual network with which the network interface will be associated. Required when creating a
        network interface.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Create a network interface with minimal parameters
      azure_rm_networkinterface:
            name: nic001
            resource_group: Testing
            virtual_network_name: vnet001
            subnet_name: subnet001

    - name: Create a network interface with private IP address only (no Public IP)
      azure_rm_networkinterface:
            name: nic001
            resource_group: Testing
            virtual_network_name: vnet001
            subnet_name: subnet001
            public_ip: no

    - name: Create a network interface for use in a Windows host (opens RDP port) with custom RDP port
      azure_rm_networkinterface:
            name: nic002
            resource_group: Testing
            virtual_network_name: vnet001
            subnet_name: subnet001
            os_type: Windows
            rdp_port: 3399

    - name: Create a network interface using existing security group and public IP
      azure_rm_networkinterface:
            name: nic003
            resource_group: Testing
            virtual_network_name: vnet001
            subnet_name: subnet001
            security_group_name: secgroup001
            public_ip_address_name: publicip001

    - name: Delete network interface
      azure_rm_networkinterface:
            resource_group: Testing
            name: nic003
            state: absent

RETURN VALUES:
state:
    description: The current state of the network interface.
    returned: always
    type: dict
    sample: {
        "dns_settings": {
            "applied_dns_servers": [],
            "dns_servers": [],
            "internal_dns_name_label": null,
            "internal_fqdn": null
        },
        "enable_ip_forwarding": false,
        "etag": 'W/"be115a43-2148-4545-a324-f33ad444c926"',
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkInterfaces/nic003",
        "ip_configuration": {
            "name": "default",
            "private_ip_address": "10.1.0.10",
            "private_ip_allocation_method": "Static",
            "public_ip_address": {
                "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/publicIPAddresses/publicip001",
                "name": "publicip001"
            },
            "subnet": {}
        },
        "location": "eastus2",
        "mac_address": null,
        "name": "nic003",
        "network_security_group": {},
        "primary": null,
        "provisioning_state": "Succeeded",
        "tags": null,
        "type": "Microsoft.Network/networkInterfaces"
    }


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_NETWORKINTERFACE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_networkinterface_facts.py)

  Get facts for a specific network interface or all network interfaces within a resource group.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- name
        Only show results for a specific network interface.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- resource_group
        Name of the resource group containing the network interface(s). Required when searching by name.
        [Default: None]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Limit results by providing a list of tags. Format tags as 'key' or 'key:value'.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Get facts for one network interface
      azure_rm_networkinterface_facts:
        resource_group: Testing
        name: nic001

    - name: Get network interfaces within a resource group
      azure_rm_networkinterface_facts:
        resource_group: Testing

    - name: Get network interfaces by tag
      azure_rm_networkinterface_facts:
        resource_group: Testing
        tags:
          - testing
          - foo:bar

RETURN VALUES:
azure_networkinterfaces:
    description: List of network interface dicts.
    returned: always
    type: list
    example: [{
        "dns_settings": {
            "applied_dns_servers": [],
            "dns_servers": [],
            "internal_dns_name_label": null,
            "internal_fqdn": null
        },
        "enable_ip_forwarding": false,
        "etag": 'W/"59726bfc-08c4-44ed-b900-f6a559876a9d"',
        "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkInterfaces/nic003",
        "ip_configuration": {
            "name": "default",
            "private_ip_address": "10.10.0.4",
            "private_ip_allocation_method": "Dynamic",
            "public_ip_address": {
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/publicIPAddresses/publicip001",
                "name": "publicip001"
            },
            "subnet": {
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/virtualNetworks/vnet001/subnets/subnet001",
                "name": "subnet001",
                "virtual_network_name": "vnet001"
            }
        },
        "location": "westus",
        "mac_address": null,
        "name": "nic003",
        "network_security_group": {
            "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroup001",
            "name": "secgroup001"
        },
        "primary": null,
        "provisioning_state": "Succeeded",
        "tags": {},
        "type": "Microsoft.Network/networkInterfaces"
    }]


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_PUBLICIPADDRESS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_publicipaddress.py)

  Create, update and delete a Public IP address. Allows setting and updating the address allocation method and domain
  name label. Use the azure_rm_networkinterface module to associate a Public IP with a network interface.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- allocation_method
        Control whether the assigned Public IP remains permanently assigned to the object. If not set to 'Static', the IP
        address my changed anytime an associated virtual machine is power cycled.
        (Choices: Dynamic, Static)[Default: Dynamic]
- append_tags
        Use to control if tags field is canonical or just appends to existing tags. When canonical, any tags not found in
        the tags parameter will be removed from the object's metadata.
        [Default: True]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- domain_name_label
        The customizable portion of the FQDN assigned to public IP address. This is an explicit setting. If no value is
        provided, any existing value will be removed on an existing public IP.
        [Default: None]
- location
        Valid azure location. Defaults to location of the resource group.
        [Default: resource_group location]
= name
        Name of the Public IP.

- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
= resource_group
        Name of resource group with which the Public IP is associated.

- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- state
        Assert the state of the Public IP. Use 'present' to create or update a and 'absent' to delete.
        (Choices: absent, present)[Default: present]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Dictionary of string:string pairs to assign as metadata to the object. Metadata tags on the object will be
        updated with any provided values. To remove tags set append_tags option to false.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Create a public ip address
      azure_rm_publicipaddress:
        resource_group: testing
        name: my_public_ip
        allocation_method: Static
        domain_name: foobar

    - name: Delete public ip
      azure_rm_publicipaddress:
        resource_group: testing
        name: my_public_ip
        state: absent

RETURN VALUES:
state:
    description: Facts about the current state of the object.
    returned: always
    type: dict
    sample: {
        "dns_settings": {},
        "etag": '"/"a5e56955-12df-445a-bda4-dc129d22c12f"',
        "idle_timeout_in_minutes": 4,
        "ip_address": "52.160.103.93",
        "location": "westus",
        "name": "publicip002",
        "provisioning_state": "Succeeded",
        "public_ip_allocation_method": "Static",
        "tags": {},
        "type": "Microsoft.Network/publicIPAddresses"
    }


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_PUBLICIPADDRESS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_publicipaddress_facts.py)

  Get facts for a specific public IP or all public IPs within a resource group.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- name
        Only show results for a specific Public IP.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- resource_group
        Limit results by resource group. Required when using name parameter.
        [Default: None]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Limit results by providing a list of tags. Format tags as 'key' or 'key:value'.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Get facts for one Public IP
      azure_rm_publicip_facts:
        resource_group: Testing
        name: publicip001

    - name: Get facts for all Public IPs within a resource groups
      azure_rm_publicip_facts:
        resource_group: Testing

RETURN VALUES:
azure_publicipaddresses:
    description: List of public IP address dicts.
    returned: always
    type: list
    example: [{
        "etag": 'W/"a31a6d7d-cb18-40a5-b16d-9f4a36c1b18a"',
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/publicIPAddresses/pip2001",
        "location": "eastus2",
        "name": "pip2001",
        "properties": {
            "idleTimeoutInMinutes": 4,
            "provisioningState": "Succeeded",
            "publicIPAllocationMethod": "Dynamic",
            "resourceGuid": "29de82f4-a7da-440e-bd3d-9cabb79af95a"
        },
        "type": "Microsoft.Network/publicIPAddresses"
    }]


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_RESOURCEGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_resourcegroup.py)

  Create, update and delete a resource group.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- append_tags
        Use to control if tags field is canonical or just appends to existing tags. When canonical, any tags not found in
        the tags parameter will be removed from the object's metadata.
        [Default: True]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- force
        Remove a resource group and all associated resources. Use with state 'absent' to delete a resource group that
        contains resources.
        [Default: False]
- location
        Azure location for the resource group. Required when creating a new resource group. Cannot be changed once
        resource group is created.
        [Default: None]
= name
        Name of the resource group.

- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- state
        Assert the state of the resource group. Use 'present' to create or update and 'absent' to delete. When 'absent' a
        resource group containing resources will not be removed unless the force option is used.
        (Choices: absent, present)[Default: present]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Dictionary of string:string pairs to assign as metadata to the object. Metadata tags on the object will be
        updated with any provided values. To remove tags set append_tags option to false.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Create a resource group
      azure_rm_resourcegroup:
        name: Testing
        location: westus
        tags:
            testing: testing
            delete: never

    - name: Delete a resource group
      azure_rm_resourcegroup:
        name: Testing
        state: absent

RETURN VALUES:
contains_resources:
    description: Whether or not the resource group contains associated resources.
    type: bool
    sample: True
state:
    description: Current state of the resource group.
    returned: always
    type: dict
    sample: {
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing",
        "location": "westus",
        "name": "Testing",
        "provisioning_state": "Succeeded",
        "tags": {
            "delete": "on-exit",
            "testing": "no"
        }
    }


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_RESOURCEGROUP_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_resourcegroup_facts.py)

  Get facts for a specific resource group or all resource groups.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- name
        Limit results to a specific resource group.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Limit results by providing a list of tags. Format tags as 'key' or 'key:value'.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Get facts for one resource group
      azure_rm_resourcegroup_facts:
        name: Testing

    - name: Get facts for all resource groups
      azure_rm_securitygroup_facts:

    - name: Get facts by tags
      azure_rm_resourcegroup_facts:
        tags:
          - testing
          - foo:bar

RETURN VALUES:
azure_resourcegroups:
    description: List of resource group dicts.
    returned: always
    type: list
    example: [{
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing",
        "location": "westus",
        "name": "Testing",
        "properties": {
            "provisioningState": "Succeeded"
        },
        "tags": {
            "delete": "never",
            "testing": "testing"
        }
    }]


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_SECURITYGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_securitygroup.py)

  Create, update or delete a network security group. A security group contains Access Control List (ACL) rules that allow
  or deny network traffic to subnets or individual network interfaces. A security group is created with a set of default
  security rules and an empty set of security rules. Shape traffic flow by adding rules to the empty set of security
  rules.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- append_tags
        Use to control if tags field is canonical or just appends to existing tags. When canonical, any tags not found in
        the tags parameter will be removed from the object's metadata.
        [Default: True]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- default_rules
        The set of default rules automatically added to a security group at creation. In general default rules will not
        be modified. Modify rules to shape the flow of traffic to or from a subnet or NIC. See rules below for the makeup
        of a rule dict.
        [Default: None]
- location
        Valid azure location. Defaults to location of the resource group.
        [Default: resource_group location]
- name
        Name of the security group to operate on.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- purge_default_rules
        Remove any existing rules not matching those defined in the default_rules parameter.
        [Default: False]
- purge_rules
        Remove any existing rules not matching those defined in the rules parameters.
        [Default: False]
= resource_group
        Name of the resource group the security group belongs to.

- rules
        Set of rules shaping traffic flow to or from a subnet or NIC. Each rule is a dictionary.
        [Default: None]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- state
        Assert the state of the security group. Set to 'present' to create or update a security group. Set to 'absent' to
        remove a security group.
        (Choices: absent, present)[Default: present]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Dictionary of string:string pairs to assign as metadata to the object. Metadata tags on the object will be
        updated with any provided values. To remove tags set append_tags option to false.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:

# Create a security group
- azure_rm_securitygroup:
      resource_group: mygroup
      name: mysecgroup
      purge_rules: yes
      rules:
          - name: DenySSH
            protocol: TCP
            destination_port_range: 22
            access: Deny
            priority: 100
            direction: Inbound
          - name: 'AllowSSH'
            protocol: TCP
            source_address_prefix: '174.109.158.0/24'
            destination_port_range: 22
            access: Allow
            priority: 101
            direction: Inbound

# Update rules on existing security group
- azure_rm_securitygroup:
      resource_group: mygroup
      name: mysecgroup
      rules:
          - name: DenySSH
            protocol: TCP
            destination_port_range: 22-23
            access: Deny
            priority: 100
            direction: Inbound
          - name: AllowSSHFromHome
            protocol: TCP
            source_address_prefix: '174.109.158.0/24'
            destination_port_range: 22-23
            access: Allow
            priority: 102
            direction: Inbound
      tags:
          testing: testing
          delete: on-exit

# Delete security group
- azure_rm_securitygroup:
      resource_group: mygroup
      name: mysecgroup
      state: absent

RETURN VALUES:
state:
    description: Current state of the security group.
    returned: always
    type: dict
    sample: {
        "default_rules": [
            {
                "access": "Allow",
                "description": "Allow inbound traffic from all VMs in VNET",
                "destination_address_prefix": "VirtualNetwork",
                "destination_port_range": "*",
                "direction": "Inbound",
                "etag": 'W/"edf48d56-b315-40ca-a85d-dbcb47f2da7d"',
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup/defaultSecurityRules/AllowVnetInBound",
                "name": "AllowVnetInBound",
                "priority": 65000,
                "protocol": "*",
                "provisioning_state": "Succeeded",
                "source_address_prefix": "VirtualNetwork",
                "source_port_range": "*"
            },
            {
                "access": "Allow",
                "description": "Allow inbound traffic from azure load balancer",
                "destination_address_prefix": "*",
                "destination_port_range": "*",
                "direction": "Inbound",
                "etag": 'W/"edf48d56-b315-40ca-a85d-dbcb47f2da7d"',
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup/defaultSecurityRules/AllowAzureLoadBalancerInBound",
                "name": "AllowAzureLoadBalancerInBound",
                "priority": 65001,
                "protocol": "*",
                "provisioning_state": "Succeeded",
                "source_address_prefix": "AzureLoadBalancer",
                "source_port_range": "*"
            },
            {
                "access": "Deny",
                "description": "Deny all inbound traffic",
                "destination_address_prefix": "*",
                "destination_port_range": "*",
                "direction": "Inbound",
                "etag": 'W/"edf48d56-b315-40ca-a85d-dbcb47f2da7d"',
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup/defaultSecurityRules/DenyAllInBound",
                "name": "DenyAllInBound",
                "priority": 65500,
                "protocol": "*",
                "provisioning_state": "Succeeded",
                "source_address_prefix": "*",
                "source_port_range": "*"
            },
            {
                "access": "Allow",
                "description": "Allow outbound traffic from all VMs to all VMs in VNET",
                "destination_address_prefix": "VirtualNetwork",
                "destination_port_range": "*",
                "direction": "Outbound",
                "etag": 'W/"edf48d56-b315-40ca-a85d-dbcb47f2da7d"',
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup/defaultSecurityRules/AllowVnetOutBound",
                "name": "AllowVnetOutBound",
                "priority": 65000,
                "protocol": "*",
                "provisioning_state": "Succeeded",
                "source_address_prefix": "VirtualNetwork",
                "source_port_range": "*"
            },
            {
                "access": "Allow",
                "description": "Allow outbound traffic from all VMs to Internet",
                "destination_address_prefix": "Internet",
                "destination_port_range": "*",
                "direction": "Outbound",
                "etag": 'W/"edf48d56-b315-40ca-a85d-dbcb47f2da7d"',
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup/defaultSecurityRules/AllowInternetOutBound",
                "name": "AllowInternetOutBound",
                "priority": 65001,
                "protocol": "*",
                "provisioning_state": "Succeeded",
                "source_address_prefix": "*",
                "source_port_range": "*"
            },
            {
                "access": "Deny",
                "description": "Deny all outbound traffic",
                "destination_address_prefix": "*",
                "destination_port_range": "*",
                "direction": "Outbound",
                "etag": 'W/"edf48d56-b315-40ca-a85d-dbcb47f2da7d"',
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup/defaultSecurityRules/DenyAllOutBound",
                "name": "DenyAllOutBound",
                "priority": 65500,
                "protocol": "*",
                "provisioning_state": "Succeeded",
                "source_address_prefix": "*",
                "source_port_range": "*"
            }
        ],
        "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup",
        "location": "westus",
        "name": "mysecgroup",
        "network_interfaces": [],
        "rules": [
            {
                "access": "Deny",
                "description": null,
                "destination_address_prefix": "*",
                "destination_port_range": "22",
                "direction": "Inbound",
                "etag": 'W/"edf48d56-b315-40ca-a85d-dbcb47f2da7d"',
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup/securityRules/DenySSH",
                "name": "DenySSH",
                "priority": 100,
                "protocol": "Tcp",
                "provisioning_state": "Succeeded",
                "source_address_prefix": "*",
                "source_port_range": "*"
            },
            {
                "access": "Allow",
                "description": null,
                "destination_address_prefix": "*",
                "destination_port_range": "22",
                "direction": "Inbound",
                "etag": 'W/"edf48d56-b315-40ca-a85d-dbcb47f2da7d"',
                "id": "/subscriptions/3f7e29ba-24e0-42f6-8d9c-5149a14bda37/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/mysecgroup/securityRules/AllowSSH",
                "name": "AllowSSH",
                "priority": 101,
                "protocol": "Tcp",
                "provisioning_state": "Succeeded",
                "source_address_prefix": "174.109.158.0/24",
                "source_port_range": "*"
            }
        ],
        "subnets": [],
        "tags": {
            "delete": "on-exit",
            "foo": "bar",
            "testing": "testing"
        },
        "type": "Microsoft.Network/networkSecurityGroups"
    }


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_SECURITYGROUP_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_securitygroup_facts.py)

  Get facts for a specific security group or all security groups within a resource group.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- name
        Only show results for a specific security group.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
= resource_group
        Name of the resource group to use.

- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Limit results by providing a list of tags. Format tags as 'key' or 'key:value'.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Get facts for one security group
      azure_rm_securitygroup_facts:
        resource_group: Testing
        name: secgroup001

    - name: Get facts for all security groups
      azure_rm_securitygroup_facts:
        resource_group: Testing


RETURN VALUES:
azure_securitygroups:
    description: List containing security group dicts.
    returned: always
    type: list
    example: [{
        "etag": 'W/"d036f4d7-d977-429a-a8c6-879bc2523399"',
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroup001",
        "location": "eastus2",
        "name": "secgroup001",
        "properties": {
            "defaultSecurityRules": [
                {
                    "etag": 'W/"d036f4d7-d977-429a-a8c6-879bc2523399"',
                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroup001/defaultSecurityRules/AllowVnetInBound",
                    "name": "AllowVnetInBound",
                    "properties": {
                        "access": "Allow",
                        "description": "Allow inbound traffic from all VMs in VNET",
                        "destinationAddressPrefix": "VirtualNetwork",
                        "destinationPortRange": "*",
                        "direction": "Inbound",
                        "priority": 65000,
                        "protocol": "*",
                        "provisioningState": "Succeeded",
                        "sourceAddressPrefix": "VirtualNetwork",
                        "sourcePortRange": "*"
                    }
                },
                {
                    "etag": 'W/"d036f4d7-d977-429a-a8c6-879bc2523399"',
                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroup001/defaultSecurityRules/AllowAzureLoadBalancerInBound",
                    "name": "AllowAzureLoadBalancerInBound",
                    "properties": {
                        "access": "Allow",
                        "description": "Allow inbound traffic from azure load balancer",
                        "destinationAddressPrefix": "*",
                        "destinationPortRange": "*",
                        "direction": "Inbound",
                        "priority": 65001,
                        "protocol": "*",
                        "provisioningState": "Succeeded",
                        "sourceAddressPrefix": "AzureLoadBalancer",
                        "sourcePortRange": "*"
                    }
                },
                {
                    "etag": 'W/"d036f4d7-d977-429a-a8c6-879bc2523399"',
                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroup001/defaultSecurityRules/DenyAllInBound",
                    "name": "DenyAllInBound",
                    "properties": {
                        "access": "Deny",
                        "description": "Deny all inbound traffic",
                        "destinationAddressPrefix": "*",
                        "destinationPortRange": "*",
                        "direction": "Inbound",
                        "priority": 65500,
                        "protocol": "*",
                        "provisioningState": "Succeeded",
                        "sourceAddressPrefix": "*",
                        "sourcePortRange": "*"
                    }
                },
                {
                    "etag": 'W/"d036f4d7-d977-429a-a8c6-879bc2523399"',
                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroup001/defaultSecurityRules/AllowVnetOutBound",
                    "name": "AllowVnetOutBound",
                    "properties": {
                        "access": "Allow",
                        "description": "Allow outbound traffic from all VMs to all VMs in VNET",
                        "destinationAddressPrefix": "VirtualNetwork",
                        "destinationPortRange": "*",
                        "direction": "Outbound",
                        "priority": 65000,
                        "protocol": "*",
                        "provisioningState": "Succeeded",
                        "sourceAddressPrefix": "VirtualNetwork",
                        "sourcePortRange": "*"
                    }
                },
                {
                    "etag": 'W/"d036f4d7-d977-429a-a8c6-879bc2523399"',
                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroup001/defaultSecurityRules/AllowInternetOutBound",
                    "name": "AllowInternetOutBound",
                    "properties": {
                        "access": "Allow",
                        "description": "Allow outbound traffic from all VMs to Internet",
                        "destinationAddressPrefix": "Internet",
                        "destinationPortRange": "*",
                        "direction": "Outbound",
                        "priority": 65001,
                        "protocol": "*",
                        "provisioningState": "Succeeded",
                        "sourceAddressPrefix": "*",
                        "sourcePortRange": "*"
                    }
                },
                {
                    "etag": 'W/"d036f4d7-d977-429a-a8c6-879bc2523399"',
                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroup001/defaultSecurityRules/DenyAllOutBound",
                    "name": "DenyAllOutBound",
                    "properties": {
                        "access": "Deny",
                        "description": "Deny all outbound traffic",
                        "destinationAddressPrefix": "*",
                        "destinationPortRange": "*",
                        "direction": "Outbound",
                        "priority": 65500,
                        "protocol": "*",
                        "provisioningState": "Succeeded",
                        "sourceAddressPrefix": "*",
                        "sourcePortRange": "*"
                    }
                }
            ],
            "networkInterfaces": [
                {
                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkInterfaces/nic004"
                }
            ],
            "provisioningState": "Succeeded",
            "resourceGuid": "ebd00afa-5dc8-446f-810a-50dd6f671588",
            "securityRules": []
        },
        "tags": {},
        "type": "Microsoft.Network/networkSecurityGroups"
    }]



MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_STORAGEACCOUNT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_storageaccount.py)

  Create, update or delete a storage account.

Options (= is mandatory):

- account_type
        Type of storage account. Required when creating a storage account. NOTE: Standard_ZRS and Premium_LRS accounts
        cannot be changed to other account types, and other account types cannot be changed to Standard_ZRS or
        Premium_LRS.
        (Choices: Premium_LRS, Standard_GRS, Standard_LRS, Standard_RAGRS, Standard_ZRS)[Default: None]
- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- append_tags
        Use to control if tags field is canonical or just appends to existing tags. When canonical, any tags not found in
        the tags parameter will be removed from the object's metadata.
        [Default: True]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- custom_domain
        User domain assigned to the storage account. Must be a dictionary with 'name' and 'use_sub_domain' keys where
        'name' is the CNAME source. Only one custom domain is supported per storage account at this time. To clear the
        existing custom domain, use an empty string for the custom domain name property.
        Can be added to an existing storage account. Will be ignored during storage account creation.
        [Default: None]
- kind
        The 'kind' of storage.
        (Choices: Storage, StorageBlob)[Default: Storage]
- location
        Valid azure location. Defaults to location of the resource group.
        [Default: resource_group location]
- name
        Name of the storage account to update or create.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
= resource_group
        Name of the resource group to use.

- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- state
        Assert the state of the storage account. Use 'present' to create or update a storage account and 'absent' to
        delete an account.
        (Choices: absent, present)[Default: present]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Dictionary of string:string pairs to assign as metadata to the object. Metadata tags on the object will be
        updated with any provided values. To remove tags set append_tags option to false.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: remove account, if it exists
      azure_rm_storageaccount:
        resource_group: Testing
        name: clh0002
        state: absent

    - name: create an account
      azure_rm_storageaccount:
        resource_group: Testing
        name: clh0002
        type: Standard_RAGRS
        tags:
          - testing: testing
          - delete: on-exit

RETURN VALUES:
state:
    description: Current state of the storage account.
    returned: always
    type: dict
    sample: {
        "account_type": "Standard_RAGRS",
        "custom_domain": null,
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/testing/providers/Microsoft.Storage/storageAccounts/clh0003",
        "location": "eastus2",
        "name": "clh0003",
        "primary_endpoints": {
            "blob": "https://clh0003.blob.core.windows.net/",
            "queue": "https://clh0003.queue.core.windows.net/",
            "table": "https://clh0003.table.core.windows.net/"
        },
        "primary_location": "eastus2",
        "provisioning_state": "Succeeded",
        "resource_group": "Testing",
        "secondary_endpoints": {
            "blob": "https://clh0003-secondary.blob.core.windows.net/",
            "queue": "https://clh0003-secondary.queue.core.windows.net/",
            "table": "https://clh0003-secondary.table.core.windows.net/"
        },
        "secondary_location": "centralus",
        "status_of_primary": "Available",
        "status_of_secondary": "Available",
        "tags": null,
        "type": "Microsoft.Storage/storageAccounts"
    }


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_STORAGEACCOUNT_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_storageaccount_facts.py)

  Get facts for one storage account or all storage accounts within a resource group.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- name
        Only show results for a specific account.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- resource_group
        Limit results to a resource group. Required when filtering by name.
        [Default: None]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Limit results by providing a list of tags. Format tags as 'key' or 'key:value'.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Get facts for one account
      azure_rm_storageaccount_facts:
        resource_group: Testing
        name: clh0002

    - name: Get facts for all accounts in a resource group
      azure_rm_storageaccount_facts:
        resource_group: Testing

    - name: Get facts for all accounts by tags
      azure_rm_storageaccount_facts:
        tags:
          - testing
          - foo:bar

RETURN VALUES:
azure_storageaccounts:
    description: List of storage account dicts.
    returned: always
    type: list
    example: [{
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/testing/providers/Microsoft.Storage/storageAccounts/testaccount001",
        "location": "eastus2",
        "name": "testaccount001",
        "properties": {
            "accountType": "Standard_LRS",
            "creationTime": "2016-03-28T02:46:58.290113Z",
            "primaryEndpoints": {
                "blob": "https://testaccount001.blob.core.windows.net/",
                "file": "https://testaccount001.file.core.windows.net/",
                "queue": "https://testaccount001.queue.core.windows.net/",
                "table": "https://testaccount001.table.core.windows.net/"
            },
            "primaryLocation": "eastus2",
            "provisioningState": "Succeeded",
            "statusOfPrimary": "Available"
        },
        "tags": {},
        "type": "Microsoft.Storage/storageAccounts"
    }]


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_STORAGEBLOB    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_storageblob.py)

  Create, update and delete blob containers and blob objects. Use to upload a file and store it as a blob object, or
  download a blob object to a file.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- append_tags
        Use to control if tags field is canonical or just appends to existing tags. When canonical, any tags not found in
        the tags parameter will be removed from the object's metadata.
        [Default: True]
- blob
        Name of a blob object within the container.
        [Default: None]
- cache_control
        Set the blob cache-control header.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
= container
        Name of a blob container within the storage account.

- content_disposition
        Set the blob content-disposition header.
        [Default: None]
- content_encoding
        Set the blob encoding header.
        [Default: None]
- content_language
        Set the blob content-language header.
        [Default: None]
- content_md5
        Set the blob md5 hash value.
        [Default: None]
- content_type
        Set the blob content-type header. For example, 'image/png'.
        [Default: None]
- dest
        Destination file path. Use with state 'present' to download a blob.
        [Default: None]
- force
        Overwrite existing blob or file when uploading or downloading. Force deletion of a container that contains blobs.
        [Default: False]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- public_access
        Determine a container's level of public access. By default containers are private. Can only be set at time of
        container creation.
        (Choices: container, blob)[Default: None]
= resource_group
        Name of the resource group to use.

- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- src
        Source file path. Use with state 'present' to upload a blob.
        [Default: None]
- state
        Assert the state of a container or blob.
        Use state 'absent' with a container value only to delete a container. Include a blob value to remove a specific
        blob. A container will not be deleted, if it contains blobs. Use the force option to override, deleting the
        container and all associated blobs.
        Use state 'present' to create or update a container and upload or download a blob. If the container does not
        exist, it will be created. If it exists, it will be updated with configuration options. Provide a blob name and
        either src or dest to upload or download. Provide a src path to upload and a dest path to download. If a blob
        (uploading) or a file (downloading) already exists, it will not be overwritten unless the force parameter is
        true.
        (Choices: absent, present)[Default: present]
= storage_account_name
        Name of the storage account to use.

- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Dictionary of string:string pairs to assign as metadata to the object. Metadata tags on the object will be
        updated with any provided values. To remove tags set append_tags option to false.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
- name: Remove container foo
  azure_rm_storageblob:
    resource_group: testing
    storage_account_name: clh0002
    container: foo
    state: absent

- name: Create container foo and upload a file
  azure_rm_storageblob:
    resource_group: Testing
    storage_account_name: clh0002
    container: foo
    blob: graylog.png
    src: ./files/graylog.png
    public_access: container
    content_type: 'application/image'

- name: Download the file
  azure_rm_storageblob:
    resource_group: Testing
    storage_account_name: clh0002
    container: foo
    blob: graylog.png
    dest: ~/tmp/images/graylog.png

RETURN VALUES:
blob:
    description: Facts about the current state of the blob.
    returned: when a blob is operated on
    type: dict
    sample: {
        "content_length": 136532,
        "content_settings": {
            "cache_control": null,
            "content_disposition": null,
            "content_encoding": null,
            "content_language": null,
            "content_md5": null,
            "content_type": "application/image"
        },
        "last_modified": "09-Mar-2016 22:08:25 +0000",
        "name": "graylog.png",
        "tags": {},
        "type": "BlockBlob"
    }
container:
    description: Facts about the current state of the selected container.
    returned: always
    type: dict
    sample: {
        "last_mdoified": "09-Mar-2016 19:28:26 +0000",
        "name": "foo",
        "tags": {}
    }


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_SUBNET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_subnet.py)

  Create, update or delete a subnet within a given virtual network. Allows setting and updating the address prefix CIDR,
  which must be valid within the context of the virtual network. Use the azure_rm_networkinterface module to associate
  interfaces with the subnet and assign specific IP addresses.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
= address_prefix_cidr
        CIDR defining the IPv4 address space of the subnet. Must be valid within the context of the virtual network.

- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
= name
        Name of the subnet.

- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
= resource_group
        Name of resource group.

- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- security_group_name
        Name of an existing security group with which to associate the subnet.
        [Default: None]
= state
        Assert the state of the subnet. Use 'present' to create or update a subnet and 'absent' to delete a subnet.
        (Choices: absent, present)[Default: present]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
= virtual_network_name
        Name of an existing virtual network with which the subnet is or will be associated.

Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Create a subnet
      azure_rm_subnet:
        name: foobar
        virtual_network_name: My_Virtual_Network
        resource_group: Testing
        address_prefix_cidr: "10.1.0.0/24"

    - name: Delete a subnet
      azure_rm_subnet:
        name: foobar
        virtual_network_name: My_Virtual_Network
        resource_group: Testing
        state: absent

RETURN VALUES:
state:
    description: Current state of the subnet.
    returned: success
    type: complex
    contains:
        address_prefix:
          description: IP address CIDR.
          type: str
          example: "10.1.0.0/16"
        id:
          description: Subnet resource path.
          type: str
          example: "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/virtualNetworks/My_Virtual_Network/subnets/foobar"
        name:
          description: Subnet name.
          type: str
          example: "foobar"
        network_security_group:
          type: complex
          contains:
            id:
              description: Security group resource identifier.
              type: str
              example: "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkSecurityGroups/secgroupfoo"
            name:
              description: Name of the security group.
              type: str
              example: "secgroupfoo"
        provisioning_state:
          description: Success or failure of the provisioning event.
          type: str
          example: "Succeeded"


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_VIRTUALMACHINE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_virtualmachine.py)

  Create, update, stop and start a virtual machine. Provide an existing storage account and network interface or allow
  the module to create these for you. If you choose not to provide a network interface, the resource group must contain a
  virtual network with at least one subnet. Currently requires an image found in the Azure Marketplace. Use
  azure_rm_virtualmachineimage_facts module to discover the publisher, offer, sku and version of a particular image.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- admin_password
        Password for the admin username. Not required if the os_type is Linux and SSH password authentication is disabled
        by setting ssh_password_enabled to false.
        [Default: None]
- admin_username
        Admin username used to access the host after it is created. Required when creating a VM.
        [Default: None]
- allocated
        Toggle that controls if the machine is allocated/deallocated, only useful with state='present'.
        [Default: True]
- append_tags
        Use to control if tags field is canonical or just appends to existing tags. When canonical, any tags not found in
        the tags parameter will be removed from the object's metadata.
        [Default: True]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
= image
        A dictionary describing the Marketplace image used to build the VM. Will contain keys: publisher, offer, sku and
        version. NOTE: set image.version to 'latest' to get the most recent version of a given image.

- location
        Valid Azure location. Defaults to location of the resource group.
        [Default: None]
= name
        Name of the virtual machine.

- network_interface_names
        List of existing network interface names to add to the VM. If a network interface name is not provided when the
        VM is created, a default network interface will be created. In order for the module to create a network
        interface, at least one Virtual Network with one Subnet must exist.
        [Default: None]
- open_ports
        If a network interface is created when creating the VM, a security group will be created as well. For Linux hosts
        a rule will be added to the security group allowing inbound TCP connections to the default SSH port 22, and for
        Windows hosts ports 3389 and 5986 will be opened. Override the default open ports by providing a list of ports.
        [Default: None]
- os_disk_caching
        Type of OS disk caching.
        (Choices: ReadOnly, ReadWrite)[Default: ReadOnly]
- os_type
        Base type of operating system.
        (Choices: Windows, Linux)[Default: [u'Linux']]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- public_ip_allocation_method
        If a public IP address is created when creating the VM (because a Network Interface was not provided), determines
        if the public IP address remains permanently associated with the Network Interface. If set to 'Dynamic' the
        public IP address may change any time the VM is rebooted or power cycled.
        (Choices: Dynamic, Static)[Default: [u'Static']]
- remove_on_absent
        When removing a VM using state 'absent', also remove associated resources
        It can be 'all' or a list with any of the following: ['network_interfaces', 'virtual_storage', 'public_ips']
        Any other input will be ignored
        [Default: [u'all']]
= resource_group
        Name of the resource group containing the virtual machine.

- restarted
        Use with state 'present' to restart a running VM.
        [Default: False]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- short_hostname
        Name assigned internally to the host. On a linux VM this is the name returned by the `hostname` command. When
        creating a virtual machine, short_hostname defaults to name.
        [Default: None]
- ssh_password_enabled
        When the os_type is Linux, setting ssh_password_enabled to false will disable SSH password authentication and
        require use of SSH keys.
        [Default: True]
- ssh_public_keys
        For os_type Linux provide a list of SSH keys. Each item in the list should be a dictionary where the dictionary
        contains two keys: path and key_data. Set the path to the default location of the authorized_keys files. On an
        Enterprise Linux host, for example, the path will be /home/<admin username>/.ssh/authorized_keys. Set key_data to
        the actual value of the public key.
        [Default: None]
- started
        Use with state 'present' to start the machine. Set to false to have the machine be 'stopped'.
        [Default: True]
- state
        Assert the state of the virtual machine.
        State 'present' will check that the machine exists with the requested configuration. If the configuration of the
        existing machine does not match, the machine will be updated. Use options started, allocated and restarted to
        change the machine's power state.
        State 'absent' will remove the virtual machine.
        (Choices: absent, present)[Default: present]
- storage_account_name
        Name of an existing storage account that supports creation of VHD blobs. If not specified for a new VM, a new
        storage account named <vm name>01 will be created using storage type 'Standard_LRS'.
        [Default: None]
- storage_blob_name
        Name fo the storage blob used to hold the VM's OS disk image. If no name is provided, defaults to the VM name +
        '.vhd'. If you provide a name, it must end with '.vhd'
        [Default: None]
- storage_container_name
        Name of the container to use within the storage account to store VHD blobs. If no name is specified a default
        container will created.
        [Default: vhds]
- subnet_name
        When creating a virtual machine, if a network interface name is not provided, one will be created. The new
        network interface will be assigned to the first subnet found in the virtual network. Use this parameter to
        provide a specific subnet instead.
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Dictionary of string:string pairs to assign as metadata to the object. Metadata tags on the object will be
        updated with any provided values. To remove tags set append_tags option to false.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
- virtual_network_name
        When creating a virtual machine, if a network interface name is not provided, one will be created. The new
        network interface will be assigned to the first virtual network found in the resource group. Use this parameter
        to provide a specific virtual network instead.
        [Default: None]
- vm_size
        A valid Azure VM size value. For example, 'Standard_D4'. The list of choices varies depending on the subscription
        and location. Check your subscription for available choices.
        [Default: Standard_D1]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:

- name: Create VM with defaults
  azure_rm_virtualmachine:
    resource_group: Testing
    name: testvm10
    admin_username: chouseknecht
    admin_password: <your password here>
    image:
      offer: CentOS
      publisher: OpenLogic
      sku: '7.1'
      version: latest

- name: Create a VM with exiting storage account and NIC
  azure_rm_virtualmachine:
    resource_group: Testing
    name: testvm002
    vm_size: Standard_D4
    storage_account: testaccount001
    admin_username: adminUser
    ssh_public_keys:
      - path: /home/adminUser/.ssh/authorized_keys
        key_data: < insert yor ssh public key here... >
    network_interfaces: testvm001
    image:
      offer: CentOS
      publisher: OpenLogic
      sku: '7.1'
      version: latest

- name: Power Off
  azure_rm_virtualmachine:
    resource_group: Testing
    name: testvm002
    started: no

- name: Deallocate
  azure_rm_virtualmachine:
    resource_group: Testing
    name: testvm002
    allocated: no

- name: Power On
  azure_rm_virtualmachine:
    resource_group:
    name: testvm002

- name: Restart
  azure_rm_virtualmachine:
    resource_group:
    name: testvm002
    restarted: yes

- name: remove vm and all resources except public ips
  azure_rm_virtualmachine:
    resource_group: Testing
    name: testvm002
    state: absent
    remove_on_absent:
        - network_interfaces
        - virtual_storage

RETURN VALUES:
powerstate:
    description: Indicates if the state is running, stopped, deallocated
    returned: always
    type: string
    example: running
deleted_vhd_uris:
    description: List of deleted Virtual Hard Disk URIs.
    returned: 'on delete'
    type: list
    example: ["https://testvm104519.blob.core.windows.net/vhds/testvm10.vhd"]
deleted_network_interfaces:
    description: List of deleted NICs.
    returned: 'on delete'
    type: list
    example: ["testvm1001"]
deleted_public_ips:
    description: List of deleted public IP address names.
    returned: 'on delete'
    type: list
    example: ["testvm1001"]
azure_vm:
    description: Facts about the current state of the object. Note that facts are not part of the registered output but available directly.
    returned: always
    type: complex
    example: {
        "properties": {
            "hardwareProfile": {
                "vmSize": "Standard_D1"
            },
            "instanceView": {
                "disks": [
                    {
                        "name": "testvm10.vhd",
                        "statuses": [
                            {
                                "code": "ProvisioningState/succeeded",
                                "displayStatus": "Provisioning succeeded",
                                "level": "Info",
                                "time": "2016-03-30T07:11:16.187272Z"
                            }
                        ]
                    }
                ],
                "statuses": [
                    {
                        "code": "ProvisioningState/succeeded",
                        "displayStatus": "Provisioning succeeded",
                        "level": "Info",
                        "time": "2016-03-30T20:33:38.946916Z"
                    },
                    {
                        "code": "PowerState/running",
                        "displayStatus": "VM running",
                        "level": "Info"
                    }
                ],
                "vmAgent": {
                    "extensionHandlers": [],
                    "statuses": [
                        {
                            "code": "ProvisioningState/succeeded",
                            "displayStatus": "Ready",
                            "level": "Info",
                            "message": "GuestAgent is running and accepting new configurations.",
                            "time": "2016-03-30T20:31:16.000Z"
                        }
                    ],
                    "vmAgentVersion": "WALinuxAgent-2.0.16"
                }
            },
            "networkProfile": {
                "networkInterfaces": [
                    {
                        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkInterfaces/testvm10_NIC01",
                        "name": "testvm10_NIC01",
                        "properties": {
                            "dnsSettings": {
                                "appliedDnsServers": [],
                                "dnsServers": []
                            },
                            "enableIPForwarding": false,
                            "ipConfigurations": [
                                {
                                    "etag": 'W/"041c8c2a-d5dd-4cd7-8465-9125cfbe2cf8"',
                                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkInterfaces/testvm10_NIC01/ipConfigurations/default",
                                    "name": "default",
                                    "properties": {
                                        "privateIPAddress": "10.10.0.5",
                                        "privateIPAllocationMethod": "Dynamic",
                                        "provisioningState": "Succeeded",
                                        "publicIPAddress": {
                                            "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/publicIPAddresses/testvm10_PIP01",
                                            "name": "testvm10_PIP01",
                                            "properties": {
                                                "idleTimeoutInMinutes": 4,
                                                "ipAddress": "13.92.246.197",
                                                "ipConfiguration": {
                                                    "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/networkInterfaces/testvm10_NIC01/ipConfigurations/default"
                                                },
                                                "provisioningState": "Succeeded",
                                                "publicIPAllocationMethod": "Static",
                                                "resourceGuid": "3447d987-ca0d-4eca-818b-5dddc0625b42"
                                            }
                                        }
                                    }
                                }
                            ],
                            "macAddress": "00-0D-3A-12-AA-14",
                            "primary": true,
                            "provisioningState": "Succeeded",
                            "resourceGuid": "10979e12-ccf9-42ee-9f6d-ff2cc63b3844",
                            "virtualMachine": {
                                "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Compute/virtualMachines/testvm10"
                            }
                        }
                    }
                ]
            },
            "osProfile": {
                "adminUsername": "chouseknecht",
                "computerName": "test10",
                "linuxConfiguration": {
                    "disablePasswordAuthentication": false
                },
                "secrets": []
            },
            "provisioningState": "Succeeded",
            "storageProfile": {
                "dataDisks": [],
                "imageReference": {
                    "offer": "CentOS",
                    "publisher": "OpenLogic",
                    "sku": "7.1",
                    "version": "7.1.20160308"
                },
                "osDisk": {
                    "caching": "ReadOnly",
                    "createOption": "fromImage",
                    "name": "testvm10.vhd",
                    "osType": "Linux",
                    "vhd": {
                        "uri": "https://testvm10sa1.blob.core.windows.net/vhds/testvm10.vhd"
                    }
                }
            }
        },
        "type": "Microsoft.Compute/virtualMachines"
    }


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_VIRTUALMACHINEIMAGE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_virtualmachineimage_facts.py)

  Get facts for virtual machine images.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
= location
        Azure location value (ie. westus, eastus, eastus2, northcentralus, etc.). Supplying only a location value will
        yield a list of available publishers for the location.

- name
        Only show results for a specific security group.
        [Default: None]
- offer
        Name of an image offering. Combine with sku to see a list of available image versions.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- publisher
        Name of an image publisher. List image offerings associated with a particular publisher.
        [Default: None]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- sku
        Image offering SKU. Combine with offer to see a list of available versions.
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
- version
        Specific version number of an image.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Get facts for a specific image
      azure_rm_virtualmachineimage_facts:
        location: eastus
        publisher: OpenLogic
        offer: CentOS
        sku: '7.1'
        version: '7.1.20160308'

    - name: List available versions
      azure_rm_virtualmachineimage_facts:
        location: eastus
        publisher: OpenLogic
        offer: CentOS
        sku: '7.1'

    - name: List available offers
      azure_rm_virtualmachineimage_facts:
        location: eastus
        publisher: OpenLogic

    - name: List available publishers
      azure_rm_virtualmachineimage_facts:
        location: eastus


RETURN VALUES:
azure_vmimages:
    description: List of image dicts.
    returned: always
    type: list
    example: []


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_VIRTUALNETWORK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_virtualnetwork.py)

  Create, update or delete a virtual networks. Allows setting and updating the available IPv4 address ranges and setting
  custom DNS servers. Use the azure_rm_subnet module to associate subnets with a virtual network.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- address_prefixes_cidr
        List of IPv4 address ranges where each is formatted using CIDR notation. Required when creating a new virtual
        network or using purge_address_prefixes.
        [Default: None]
- append_tags
        Use to control if tags field is canonical or just appends to existing tags. When canonical, any tags not found in
        the tags parameter will be removed from the object's metadata.
        [Default: True]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- dns_servers
        Custom list of DNS servers. Maximum length of two. The first server in the list will be treated as the Primary
        server. This is an explicit list. Existing DNS servers will be replaced with the specified list. Use the
        purge_dns_servers option to remove all custom DNS servers and revert to default Azure servers.
        [Default: None]
- location
        Valid azure location. Defaults to location of the resource group.
        [Default: resource_group location]
= name
        name of the virtual network.

- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- purge_address_prefixes
        Use with state present to remove any existing address_prefixes.
        [Default: False]
- purge_dns_servers
        Use with state present to remove existing DNS servers, reverting to default Azure servers. Mutually exclusive
        with dns_servers.
        [Default: False]
= resource_group
        name of resource group.

- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- state
        Assert the state of the virtual network. Use 'present' to create or update and 'absent' to delete.
        (Choices: absent, present)[Default: present]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Dictionary of string:string pairs to assign as metadata to the object. Metadata tags on the object will be
        updated with any provided values. To remove tags set append_tags option to false.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Create a virtual network
      azure_rm_virtualnetwork:
        name: foobar
        resource_group: Testing
        address_prefixes_cidr:
            - "10.1.0.0/16"
            - "172.100.0.0/16"
        dns_servers:
            - "127.0.0.1"
            - "127.0.0.2"
        tags:
            testing: testing
            delete: on-exit

    - name: Delete a virtual network
      azure_rm_virtualnetwork:
        name: foobar
        resource_group: Testing
        state: absent

RETURN VALUES:
state:
    description: Current state of the virtual network.
    returned: always
    type: dict
    sample: {
        "address_prefixes": [
            "10.1.0.0/16",
            "172.100.0.0/16"
        ],
        "dns_servers": [
            "127.0.0.1",
            "127.0.0.3"
        ],
        "etag": 'W/"0712e87c-f02f-4bb3-8b9e-2da0390a3886"',
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/virtualNetworks/my_test_network",
        "location": "eastus",
        "name": "my_test_network",
        "provisioning_state": "Succeeded",
        "tags": null,
        "type": "Microsoft.Network/virtualNetworks"
    }


MAINTAINERS: Chris Houseknecht (@chouseknecht), Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: curated
> AZURE_RM_VIRTUALNETWORK_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/azure/azure_rm_virtualnetwork_facts.py)

  Get facts for a specific virtual network or all virtual networks within a resource group.

Options (= is mandatory):

- ad_user
        Active Directory username. Use when authenticating with an Active Directory user rather than service principal.
        [Default: None]
- client_id
        Azure client ID. Use when authenticating with a Service Principal.
        [Default: None]
- name
        Only show results for a specific security group.
        [Default: None]
- password
        Active Directory user password. Use when authenticating with an Active Directory user rather than service
        principal.
        [Default: None]
- profile
        Security profile found in ~/.azure/credentials file.
        [Default: None]
- resource_group
        Limit results by resource group. Required when filtering by name.
        [Default: None]
- secret
        Azure client secret. Use when authenticating with a Service Principal.
        [Default: None]
- subscription_id
        Your Azure subscription Id.
        [Default: None]
- tags
        Limit results by providing a list of tags. Format tags as 'key' or 'key:value'.
        [Default: None]
- tenant
        Azure tenant ID. Use when authenticating with a Service Principal.
        [Default: None]
Notes:
  * For authentication with Azure you can pass parameters, set environment variables or use a profile stored in
        ~/.azure/credentials. Authentication is possible using a service principal or Active Directory user. To
        authenticate via service principal pass subscription_id, client_id, secret and tenant or set set
        environment variables AZURE_SUBSCRIPTION_ID, AZURE_CLIENT_ID, AZURE_SECRET and AZURE_TENANT.
  * To Authentication via Active Directory user pass ad_user and password, or set AZURE_AD_USER and AZURE_PASSWORD
        in the environment.
  * Alternatively, credentials can be stored in ~/.azure/credentials. This is an ini file containing a [default]
        section and the following keys: subscription_id, client_id, secret and tenant or subscription_id, ad_user
        and password. It is also possible to add additional profiles. Specify the profile by passing profile or
        setting AZURE_PROFILE in the environment.
Requirements:  python >= 2.7, azure == 2.0.0rc5

EXAMPLES:
    - name: Get facts for one virtual network
      azure_rm_virtualnetwork_facts:
        resource_group: Testing
        name: secgroup001

    - name: Get facts for all virtual networks
      azure_rm_virtualnetwork_facts:
        resource_group: Testing

    - name: Get facts by tags
      azure_rm_virtualnetwork_facts:
        tags:
          - testing

RETURN VALUES:
azure_virtualnetworks:
    description: List of virtual network dicts.
    returned: always
    type: list
    example: [{
        "etag": 'W/"532ba1be-ae71-40f2-9232-3b1d9cf5e37e"',
        "id": "/subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXX/resourceGroups/Testing/providers/Microsoft.Network/virtualNetworks/vnet2001",
        "location": "eastus2",
        "name": "vnet2001",
        "properties": {
            "addressSpace": {
                "addressPrefixes": [
                    "10.10.0.0/16"
                ]
            },
            "provisioningState": "Succeeded",
            "resourceGuid": "a7ba285f-f7e7-4e17-992a-de4d39f28612",
            "subnets": []
        },
        "type": "Microsoft.Network/virtualNetworks"
    }]


MAINTAINERS: Chris Houseknecht house@redhat.com, Matt Davis mdavis@redhat.com

METADATA:
	Status: ['preview']
	Supported_by: curated
> BEADM    (/usr/lib/python2.7/site-packages/ansible/modules/system/beadm.py)

  Create, delete or activate ZFS boot environments. Mount and unmount ZFS boot environments.

Options (= is mandatory):

- description
        Associate a description with a new boot environment. This option is available only on Solarish platforms.
        [Default: False]
- force
        Specifies if the unmount should be forced.
        (Choices: true, false)[Default: False]
- mountpoint
        Path where to mount the ZFS boot environment
        [Default: False]
= name
        ZFS boot environment name.

- options
        Create the datasets for new BE with specific ZFS properties. Multiple options can be specified. This option is
        available only on Solarish platforms.
        [Default: False]
- snapshot
        If specified, the new boot environment will be cloned from the given snapshot or inactive boot environment.
        [Default: False]
- state
        Create or delete ZFS boot environment.
        (Choices: present, absent, activated, mounted, unmounted)[Default: present]
EXAMPLES:
- name: Create ZFS boot environment
  beadm:
    name: upgrade-be
    state: present

- name: Create ZFS boot environment from existing inactive boot environment
  beadm:
    name: upgrade-be
    snapshot: be@old
    state: present

- name: Create ZFS boot environment with compression enabled and description "upgrade"
  beadm:
    name: upgrade-be
    options: "compression=on"
    description: upgrade
    state: present

- name: Delete ZFS boot environment
  beadm:
    name: old-be
    state: absent

- name: Mount ZFS boot environment on /tmp/be
  beadm:
    name: BE
    mountpoint: /tmp/be
    state: mounted

- name: Unmount ZFS boot environment
  beadm:
    name: BE
    state: unmounted

- name: Activate ZFS boot environment
  beadm:
    name: upgrade-be
    state: activated

RETURN VALUES:
name:
    description: BE name
    returned: always
    type: string
    sample: pre-upgrade
snapshot:
    description: ZFS snapshot to create BE from
    returned: always
    type: string
    sample: rpool/ROOT/oi-hipster@fresh
description:
    description: BE description
    returned: always
    type: string
    sample: Upgrade from 9.0 to 10.0
options:
    description: BE additional options
    returned: always
    type: string
    sample: compression=on
mountpoint:
    description: BE mountpoint
    returned: always
    type: string
    sample: /mnt/be
state:
    description: state of the target
    returned: always
    type: string
    sample: present
force:
    description: if forced action is wanted
    returned: always
    type: boolean
    sample: False


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_DEVICE_DNS    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_device_dns.py)

  Manage BIG-IP device DNS settings

Options (= is mandatory):

- cache
        Specifies whether the system caches DNS lookups or performs the operation each time a lookup is needed. Please
        note that this applies only to Access Policy Manager features, such as ACLs, web application rewrites, and
        authentication.
        (Choices: enable, disable)[Default: disable]
- forwarders
        A list of BIND servers that the system can use to perform DNS lookups
        [Default: (null)]
- ip_version
        Specifies whether the DNS specifies IP addresses using IPv4 or IPv6.
        (Choices: 4, 6)[Default: (null)]
- name_servers
        A list of name serverz that the system uses to validate DNS lookups
        [Default: (null)]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- search
        A list of domains that the system searches for local domain lookups, to resolve local host names.
        [Default: (null)]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        The state of the variable on the system. When `present', guarantees that an existing variable is set to `value'.
        (Choices: absent, present)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install requests
Requirements:  f5-sdk

EXAMPLES:
- name: Set the DNS settings on the BIG-IP
  bigip_device_dns:
      name_servers:
          - 208.67.222.222
          - 208.67.220.220
      search:
          - localdomain
          - lab.local
      state: present
      password: "secret"
      server: "lb.mydomain.com"
      user: "admin"
      validate_certs: "no"
  delegate_to: localhost

RETURN VALUES:
cache:
    description: The new value of the DNS caching
    returned: changed
    type: string
    sample: "enabled"
name_servers:
    description: List of name servers that were added or removed
    returned: changed
    type: list
    sample: "['192.0.2.10', '172.17.12.10']"
forwarders:
    description: List of forwarders that were added or removed
    returned: changed
    type: list
    sample: "['192.0.2.10', '172.17.12.10']"
search:
    description: List of search domains that were added or removed
    returned: changed
    type: list
    sample: "['192.0.2.10', '172.17.12.10']"
ip_version:
    description: IP version that was set that DNS will specify IP addresses in
    returned: changed
    type: int
    sample: 4


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_DEVICE_NTP    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_device_ntp.py)

  Manage NTP servers on a BIG-IP

Options (= is mandatory):

- ntp_servers
        A list of NTP servers to set on the device. At least one of `ntp_servers' or `timezone' is required.
        [Default: []]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        The state of the NTP servers on the system. When `present', guarantees that the NTP servers are set on the
        system. When `absent', removes the specified NTP servers from the device configuration.
        (Choices: absent, present)[Default: present]
- timezone
        The timezone to set for NTP lookups. At least one of `ntp_servers' or `timezone' is required.
        [Default: UTC]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
Requirements:  f5-sdk

EXAMPLES:
- name: Set NTP server
  bigip_device_ntp:
      ntp_servers:
          - "192.0.2.23"
      password: "secret"
      server: "lb.mydomain.com"
      user: "admin"
      validate_certs: "no"
  delegate_to: localhost

- name: Set timezone
  bigip_device_ntp:
      password: "secret"
      server: "lb.mydomain.com"
      timezone: "America/Los_Angeles"
      user: "admin"
      validate_certs: "no"
  delegate_to: localhost

RETURN VALUES:
ntp_servers:
    description: The NTP servers that were set on the device
    returned: changed
    type: list
    sample: ["192.0.2.23", "192.0.2.42"]
timezone:
    description: The timezone that was set on the device
    returned: changed
    type: string
    sample: "true"


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_DEVICE_SSHD    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_device_sshd.py)

  Manage the SSHD settings of a BIG-IP

Options (= is mandatory):

- allow
        Specifies, if you have enabled SSH access, the IP address or address range for other systems that can use SSH to
        communicate with this system.
        (Choices: all, IP address, such as 172.27.1.10, IP range, such as 172.27.*.* or 172.27.0.0/255.255.0.0)[Default:
        (null)]
- banner
        Whether to enable the banner or not.
        (Choices: enabled, disabled)[Default: (null)]
- banner_text
        Specifies the text to include on the pre-login banner that displays when a user attempts to login to the system
        using SSH.
        [Default: (null)]
- inactivity_timeout
        Specifies the number of seconds before inactivity causes an SSH session to log out.
        [Default: (null)]
- log_level
        Specifies the minimum SSHD message level to include in the system log.
        (Choices: debug, debug1, debug2, debug3, error, fatal, info, quiet, verbose)[Default: (null)]
- login
        Specifies, when checked `enabled', that the system accepts SSH communications.
        (Choices: enabled, disabled)[Default: (null)]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- port
        Port that you want the SSH daemon to run on.
        [Default: (null)]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host This is as easy as pip install f5-sdk.
  * Requires BIG-IP version 12.0.0 or greater
Requirements:  f5-sdk

EXAMPLES:
- name: Set the banner for the SSHD service from a string
  bigip_device_sshd:
      banner: "enabled"
      banner_text: "banner text goes here"
      password: "secret"
      server: "lb.mydomain.com"
      user: "admin"
  delegate_to: localhost

- name: Set the banner for the SSHD service from a file
  bigip_device_sshd:
      banner: "enabled"
      banner_text: "{{ lookup('file', '/path/to/file') }}"
      password: "secret"
      server: "lb.mydomain.com"
      user: "admin"
  delegate_to: localhost

- name: Set the SSHD service to run on port 2222
  bigip_device_sshd:
      password: "secret"
      port: 2222
      server: "lb.mydomain.com"
      user: "admin"
  delegate_to: localhost

RETURN VALUES:
allow:
    description: >
        Specifies, if you have enabled SSH access, the IP address or address
        range for other systems that can use SSH to communicate with this
        system.
    returned: changed
    type: string
    sample: "192.0.2.*"
banner:
    description: Whether the banner is enabled or not.
    returned: changed
    type: string
    sample: "true"
banner_text:
    description: >
        Specifies the text included on the pre-login banner that
        displays when a user attempts to login to the system using SSH.
    returned: changed and success
    type: string
    sample: "This is a corporate device. Connecting to it without..."
inactivity_timeout:
    description: >
        The number of seconds before inactivity causes an SSH.
        session to log out.
    returned: changed
    type: int
    sample: "10"
log_level:
    description: The minimum SSHD message level to include in the system log.
    returned: changed
    type: string
    sample: "debug"
login:
    description: Specifies that the system accepts SSH communications or not.
    returned: changed
    type: bool
    sample: true
port:
    description: Port that you want the SSH daemon to run on.
    returned: changed
    type: int
    sample: 22


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_facts.py)

  Collect facts from F5 BIG-IP devices via iControl SOAP API

Options (= is mandatory):

- filter
        Shell-style glob matching string used to filter fact keys. Not applicable for software, provision, and
        system_info fact categories.
        (Choices: )[Default: None]
= include
        Fact category or list of categories to collect
        (Choices: address_class, certificate, client_ssl_profile, device, device_group, interface, key, node, pool,
        provision, rule, self_ip, software, system_info, traffic_group, trunk, virtual_address, virtual_server,
        vlan)[Default: None]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- session
        BIG-IP session support; may be useful to avoid concurrency issues in certain circumstances.
        (Choices: )[Default: True]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires BIG-IP software version >= 11.4
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
  * Tested with manager and above account privilege level
  * `provision' facts were added in 2.2
Requirements:  bigsuds

EXAMPLES:
- name: Collect BIG-IP facts
  bigip_facts:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      include: "interface,vlan"
  delegate_to: localhost


MAINTAINERS: Matt Hite (@mhite), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_GTM_DATACENTER    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_gtm_datacenter.py)

  Manage BIG-IP data center configuration. A data center defines the location where the physical network components
  reside, such as the server and link objects that share the same subnet on the network. This module is able to
  manipulate the data center definitions in a BIG-IP

Options (= is mandatory):

- contact
        The name of the contact for the data center.
        [Default: (null)]
- description
        The description of the data center.
        [Default: (null)]
- enabled
        Whether the data center should be enabled. At least one of `state' and `enabled' are required.
        (Choices: True, False)[Default: (null)]
- location
        The location of the data center.
        [Default: (null)]
= name
        The name of the data center.

= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        The state of the datacenter on the BIG-IP. When `present', guarantees that the data center exists. When `absent'
        removes the data center from the BIG-IP. `enabled' will enable the data center and `disabled' will ensure the
        data center is disabled. At least one of state and enabled are required.
        (Choices: present, absent)[Default: (null)]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
Requirements:  f5-sdk

EXAMPLES:
- name: Create data center "New York"
  bigip_gtm_datacenter:
      server: "big-ip"
      name: "New York"
      location: "222 West 23rd"
  delegate_to: localhost

RETURN VALUES:
contact:
    description: The contact that was set on the datacenter
    returned: changed
    type: string
    sample: "admin@root.local"
description:
    description: The description that was set for the datacenter
    returned: changed
    type: string
    sample: "Datacenter in NYC"
enabled:
    description: Whether the datacenter is enabled or not
    returned: changed
    type: bool
    sample: true
location:
    description: The location that is set for the datacenter
    returned: changed
    type: string
    sample: "222 West 23rd"
name:
    description: Name of the datacenter being manipulated
    returned: changed
    type: string
    sample: "foo"


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_GTM_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_gtm_facts.py)

  Collect facts from F5 BIG-IP GTM devices.

Options (= is mandatory):

- filter
        Perform regex filter of response. Filtering is done on the name of the resource. Valid filters are anything that
        can be provided to Python's `re' module.
        [Default: None]
= include
        Fact category to collect
        (Choices: pool, wide_ip, virtual_server)
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk
Requirements:  f5-sdk

EXAMPLES:
- name: Get pool facts
  bigip_gtm_facts:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      include: "pool"
      filter: "my_pool"
  delegate_to: localhost

RETURN VALUES:
wide_ip:
    description:
        Contains the lb method for the wide ip and the pools
        that are within the wide ip.
    returned: changed
    type: dict
    sample:
        wide_ip:
            - enabled: "True"
              failure_rcode: "noerror"
              failure_rcode_response: "disabled"
              failure_rcode_ttl: "0"
              full_path: "/Common/foo.ok.com"
              last_resort_pool: ""
              minimal_response: "enabled"
              name: "foo.ok.com"
              partition: "Common"
              persist_cidr_ipv4: "32"
              persist_cidr_ipv6: "128"
              persistence: "disabled"
              pool_lb_mode: "round-robin"
              pools:
                  - name: "d3qw"
                    order: "0"
                    partition: "Common"
                    ratio: "1"
              ttl_persistence: "3600"
              type: "naptr"
pool:
    description: Contains the pool object status and enabled status.
    returned: changed
    type: dict
    sample:
        pool:
            - alternate_mode: "round-robin"
              dynamic_ratio: "disabled"
              enabled: "True"
              fallback_mode: "return-to-dns"
              full_path: "/Common/d3qw"
              load_balancing_mode: "round-robin"
              manual_resume: "disabled"
              max_answers_returned: "1"
              members:
                  - disabled: "True"
                    flags: "a"
                    full_path: "ok3.com"
                    member_order: "0"
                    name: "ok3.com"
                    order: "10"
                    preference: "10"
                    ratio: "1"
                    service: "80"
              name: "d3qw"
              partition: "Common"
              qos_hit_ratio: "5"
              qos_hops: "0"
              qos_kilobytes_second: "3"
              qos_lcs: "30"
              qos_packet_rate: "1"
              qos_rtt: "50"
              qos_topology: "0"
              qos_vs_capacity: "0"
              qos_vs_score: "0"
              ttl: "30"
              type: "naptr"
              verify_member_availability: "disabled"
virtual_server:
    description:
        Contains the virtual server enabled and availability
        status, and address
    returned: changed
    type: dict
    sample:
        virtual_server:
            - addresses:
                  - device_name: "/Common/qweqwe"
                    name: "10.10.10.10"
                    translation: "none"
              datacenter: "/Common/xfxgh"
              enabled: "True"
              expose_route_domains: "no"
              full_path: "/Common/qweqwe"
              iq_allow_path: "yes"
              iq_allow_service_check: "yes"
              iq_allow_snmp: "yes"
              limit_cpu_usage: "0"
              limit_cpu_usage_status: "disabled"
              limit_max_bps: "0"
              limit_max_bps_status: "disabled"
              limit_max_connections: "0"
              limit_max_connections_status: "disabled"
              limit_max_pps: "0"
              limit_max_pps_status: "disabled"
              limit_mem_avail: "0"
              limit_mem_avail_status: "disabled"
              link_discovery: "disabled"
              monitor: "/Common/bigip "
              name: "qweqwe"
              partition: "Common"
              product: "single-bigip"
              virtual_server_discovery: "disabled"
              virtual_servers:
                  - destination: "10.10.10.10:0"
                    enabled: "True"
                    full_path: "jsdfhsd"
                    limit_max_bps: "0"
                    limit_max_bps_status: "disabled"
                    limit_max_connections: "0"
                    limit_max_connections_status: "disabled"
                    limit_max_pps: "0"
                    limit_max_pps_status: "disabled"
                    name: "jsdfhsd"
                    translation_address: "none"
                    translation_port: "0"


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_GTM_VIRTUAL_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_gtm_virtual_server.py)

  Manages F5 BIG-IP GTM virtual servers

Options (= is mandatory):

- host
        Virtual server host
        [Default: None]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- port
        Virtual server port
        [Default: None]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        Virtual server state
        (Choices: present, absent, enabled, disabled)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
= virtual_server_name
        Virtual server name

= virtual_server_server
        Virtual server server

Notes:
  * Requires BIG-IP software version >= 11.4
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
  * Tested with manager and above account privilege level
Requirements:  bigsuds

EXAMPLES:
  - name: Enable virtual server
    local_action: >
      bigip_gtm_virtual_server
      server=192.0.2.1
      user=admin
      password=mysecret
      virtual_server_name=myname
      virtual_server_server=myserver
      state=enabled

RETURN VALUES:
 

MAINTAINERS: Michael Perzel (@perzizzle), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_GTM_WIDE_IP    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_gtm_wide_ip.py)

  Manages F5 BIG-IP GTM wide ip

Options (= is mandatory):

= lb_method
        LB method of wide ip
        (Choices: return_to_dns, null, round_robin, ratio, topology, static_persist, global_availability, vs_capacity,
        least_conn, lowest_rtt, lowest_hops, packet_rate, cpu, hit_ratio, qos, bps, drop_packet, explicit_ip,
        connection_rate, vs_score)
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
= wide_ip
        Wide IP name

Notes:
  * Requires BIG-IP software version >= 11.4
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
  * Tested with manager and above account privilege level
Requirements:  bigsuds

EXAMPLES:
  - name: Set lb method
    local_action: >
      bigip_gtm_wide_ip
      server=192.0.2.1
      user=admin
      password=mysecret
      lb_method=round_robin
      wide_ip=my-wide-ip.example.com


MAINTAINERS: Michael Perzel (@perzizzle), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_HOSTNAME    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_hostname.py)

  Manage the hostname of a BIG-IP.

Options (= is mandatory):

= hostname
        Hostname of the BIG-IP host.

= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
Requirements:  f5-sdk

EXAMPLES:
- name: Set the hostname of the BIG-IP
  bigip_hostname:
      hostname: "bigip.localhost.localdomain"
      password: "admin"
      server: "bigip.localhost.localdomain"
      user: "admin"
  delegate_to: localhost

RETURN VALUES:
hostname:
    description: The new hostname of the device
    returned: changed
    type: string
    sample: "big-ip01.internal"


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_IRULE    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_irule.py)

  Manage iRules across different modules on a BIG-IP.

Options (= is mandatory):

- content
        When used instead of 'src', sets the contents of an iRule directly to the specified value. This is for simple
        values, but can be used with lookup plugins for anything complex or with formatting. Either one of `src' or
        `content' must be provided.
        [Default: (null)]
= module
        The BIG-IP module to add the iRule to.
        (Choices: ltm, gtm)
= name
        The name of the iRule.

- partition
        The partition to create the iRule on.
        [Default: Common]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
= src
        The iRule file to interpret and upload to the BIG-IP. Either one of `src' or `content' must be provided.

- state
        Whether the iRule should exist or not.
        (Choices: present, absent)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
Requirements:  f5-sdk

EXAMPLES:
- name: Add the iRule contained in templated irule.tcl to the LTM module
  bigip_irule:
      content: "{{ lookup('template', 'irule-template.tcl') }}"
      module: "ltm"
      name: "MyiRule"
      password: "secret"
      server: "lb.mydomain.com"
      state: "present"
      user: "admin"
  delegate_to: localhost

- name: Add the iRule contained in static file irule.tcl to the LTM module
  bigip_irule:
      module: "ltm"
      name: "MyiRule"
      password: "secret"
      server: "lb.mydomain.com"
      src: "irule-static.tcl"
      state: "present"
      user: "admin"
  delegate_to: localhost

RETURN VALUES:
module:
    description: The module that the iRule was added to
    returned: changed and success
    type: string
    sample: "gtm"
src:
    description: The filename that included the iRule source
    returned: changed and success, when provided
    type: string
    sample: "/opt/src/irules/example1.tcl"
name:
    description: The name of the iRule that was managed
    returned: changed and success
    type: string
    sample: "my-irule"
content:
    description: The content of the iRule that was managed
    returned: changed and success
    type: string
    sample: "when LB_FAILED { set wipHost [LB::server addr] }"
partition:
    description: The partition in which the iRule was managed
    returned: changed and success
    type: string
    sample: "Common"


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_MONITOR_HTTP    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_monitor_http.py)

  Manages F5 BIG-IP LTM monitors via iControl SOAP API

Options (= is mandatory):

- interval
        The interval specifying how frequently the monitor instance of this template will run. By default, this interval
        is used for up and down states. The default API setting is 5.
        [Default: none]
- ip
        IP address part of the ipport definition. The default API setting is "0.0.0.0".
        [Default: none]
= name
        Monitor name
        [Default: None]
- parent
        The parent template of this monitor template
        [Default: http]
- parent_partition
        Partition for the parent monitor
        [Default: Common]
- partition
        Partition for the monitor
        [Default: Common]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- port
        Port address part of the ip/port definition. The default API setting is 0.
        [Default: none]
= receive
        The receive string for the monitor call
        [Default: none]
= receive_disable
        The receive disable string for the monitor call
        [Default: none]
= send
        The send string for the monitor call
        [Default: none]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        Monitor state
        (Choices: present, absent)[Default: present]
- time_until_up
        Specifies the amount of time in seconds after the first successful response before a node will be marked up. A
        value of 0 will cause a node to be marked up immediately after a valid response is received from the node. The
        default API setting is 0.
        [Default: none]
- timeout
        The number of seconds in which the node or service must respond to the monitor request. If the target responds
        within the set time period, it is considered up. If the target does not respond within the set time period, it is
        considered down. You can change this number to any number you want, however, it should be 3 times the interval
        number of seconds plus 1 second. The default API setting is 16.
        [Default: none]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires BIG-IP software version >= 11
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
  * Monitor API documentation: https://devcentral.f5.com/wiki/iControl.LocalLB__Monitor.ashx
Requirements:  bigsuds

EXAMPLES:
- name: BIGIP F5 | Create HTTP Monitor
  bigip_monitor_http:
      state: "present"
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      name: "my_http_monitor"
      send: "http string to send"
      receive: "http string to receive"
  delegate_to: localhost

- name: BIGIP F5 | Remove HTTP Monitor
  bigip_monitor_http:
    state: "absent"
    server: "lb.mydomain.com"
    user: "admin"
    password: "secret"
    name: "my_http_monitor"
  delegate_to: localhost


MAINTAINERS: Serge van Ginderachter (@srvg), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_MONITOR_TCP    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_monitor_tcp.py)

  Manages F5 BIG-IP LTM tcp monitors via iControl SOAP API

Options (= is mandatory):

- interval
        The interval specifying how frequently the monitor instance of this template will run. By default, this interval
        is used for up and down states. The default API setting is 5.
        [Default: none]
- ip
        IP address part of the ipport definition. The default API setting is "0.0.0.0".
        [Default: none]
= name
        Monitor name
        [Default: None]
- parent
        The parent template of this monitor template
        (Choices: tcp, tcp_echo, tcp_half_open)[Default: tcp]
- parent_partition
        Partition for the parent monitor
        [Default: Common]
- partition
        Partition for the monitor
        [Default: Common]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- port
        Port address part op the ipport definition. The default API setting is 0.
        [Default: none]
= receive
        The receive string for the monitor call
        [Default: none]
= send
        The send string for the monitor call
        [Default: none]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        Monitor state
        (Choices: present, absent)[Default: present]
- time_until_up
        Specifies the amount of time in seconds after the first successful response before a node will be marked up. A
        value of 0 will cause a node to be marked up immediately after a valid response is received from the node. The
        default API setting is 0.
        [Default: none]
- timeout
        The number of seconds in which the node or service must respond to the monitor request. If the target responds
        within the set time period, it is considered up. If the target does not respond within the set time period, it is
        considered down. You can change this number to any number you want, however, it should be 3 times the interval
        number of seconds plus 1 second. The default API setting is 16.
        [Default: none]
- type
        The template type of this monitor template
        (Choices: TTYPE_TCP, TTYPE_TCP_ECHO, TTYPE_TCP_HALF_OPEN)[Default: tcp]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires BIG-IP software version >= 11
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
  * Monitor API documentation: https://devcentral.f5.com/wiki/iControl.LocalLB__Monitor.ashx
Requirements:  bigsuds

EXAMPLES:
- name: Create TCP Monitor
  bigip_monitor_tcp:
    state: "present"
    server: "lb.mydomain.com"
    user: "admin"
    password: "secret"
    name: "my_tcp_monitor"
    type: "tcp"
    send: "tcp string to send"
    receive: "tcp string to receive"
  delegate_to: localhost

- name: Create TCP half open Monitor
  bigip_monitor_tcp:
    state: "present"
    server: "lb.mydomain.com"
    user: "admin"
    password: "secret"
    name: "my_tcp_monitor"
    type: "tcp"
    send: "tcp string to send"
    receive: "http string to receive"
  delegate_to: localhost

- name: Remove TCP Monitor
  bigip_monitor_tcp:
      state: "absent"
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      name: "my_tcp_monitor"


MAINTAINERS: Serge van Ginderachter (@srvg), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_NODE    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_node.py)

  Manages F5 BIG-IP LTM nodes via iControl SOAP API

Options (= is mandatory):

- description
        Node description.
        (Choices: )[Default: None]
= host
        Node IP. Required when state=present and node does not exist. Error when state=absent.
        (Choices: )[Default: None]
- monitor_state
        Set monitor availability status for node
        (Choices: enabled, disabled)[Default: None]
- monitor_type
        Monitor rule type when monitors > 1
        (Choices: and_list, m_of_n)[Default: None]
- monitors
        Monitor template name list. Always use the full path to the monitor.
        (Choices: )[Default: None]
- name
        Node name
        (Choices: )[Default: None]
- partition
        Partition
        (Choices: )[Default: Common]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- quorum
        Monitor quorum value when monitor_type is m_of_n
        (Choices: )[Default: None]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- session_state
        Set new session availability status for node
        (Choices: enabled, disabled)[Default: None]
= state
        Pool member state
        (Choices: present, absent)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires BIG-IP software version >= 11
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
Requirements:  bigsuds

EXAMPLES:
- name: Add node
  bigip_node:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      partition: "Common"
      host: "10.20.30.40"
      name: "10.20.30.40"

# Note that the BIG-IP automatically names the node using the
# IP address specified in previous play's host parameter.
# Future plays referencing this node no longer use the host
# parameter but instead use the name parameter.
# Alternatively, you could have specified a name with the
# name parameter when state=present.

- name: Add node with a single 'ping' monitor
  bigip_node:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      partition: "Common"
      host: "10.20.30.40"
      name: "mytestserver"
      monitors:
        - /Common/icmp
  delegate_to: localhost

- name: Modify node description
  bigip_node:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      partition: "Common"
      name: "10.20.30.40"
      description: "Our best server yet"
  delegate_to: localhost

- name: Delete node
  bigip_node:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "absent"
      partition: "Common"
      name: "10.20.30.40"

# The BIG-IP GUI doesn't map directly to the API calls for "Node ->
# General Properties -> State". The following states map to API monitor
# and session states.
#
# Enabled (all traffic allowed):
# monitor_state=enabled, session_state=enabled
# Disabled (only persistent or active connections allowed):
# monitor_state=enabled, session_state=disabled
# Forced offline (only active connections allowed):
# monitor_state=disabled, session_state=disabled
#
# See https://devcentral.f5.com/questions/icontrol-equivalent-call-for-b-node-down

- name: Force node offline
  bigip_node:
      server: "lb.mydomain.com"
      user: "admin"
      password: "mysecret"
      state: "present"
      session_state: "disabled"
      monitor_state: "disabled"
      partition: "Common"
      name: "10.20.30.40"


MAINTAINERS: Matt Hite (@mhite), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_POOL    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_pool.py)

  Manages F5 BIG-IP LTM pools via iControl SOAP API

Options (= is mandatory):

- description
        Specifies descriptive text that identifies the pool.
        [Default: (null)]
- host
        Pool member IP
        (Choices: )[Default: None]
- lb_method
        Load balancing method
        (Choices: round_robin, ratio_member, least_connection_member, observed_member, predictive_member,
        ratio_node_address, least_connection_node_address, fastest_node_address, observed_node_address,
        predictive_node_address, dynamic_ratio, fastest_app_response, least_sessions, dynamic_ratio_member, l3_addr,
        weighted_least_connection_member, weighted_least_connection_node_address, ratio_session,
        ratio_least_connection_member, ratio_least_connection_node_address)[Default: round_robin]
- monitor_type
        Monitor rule type when monitors > 1
        (Choices: and_list, m_of_n)[Default: None]
- monitors
        Monitor template name list. Always use the full path to the monitor.
        (Choices: )[Default: None]
= name
        Pool name
        (Choices: )[Default: None]
- partition
        Partition of pool/pool member
        (Choices: )[Default: Common]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- port
        Pool member port
        (Choices: )[Default: None]
- quorum
        Monitor quorum value when monitor_type is m_of_n
        (Choices: )[Default: None]
- reselect_tries
        Sets the number of times the system tries to contact a pool member after a passive failure
        (Choices: )[Default: None]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- service_down_action
        Sets the action to take when node goes down in pool
        (Choices: none, reset, drop, reselect)[Default: None]
- slow_ramp_time
        Sets the ramp-up time (in seconds) to gradually ramp up the load on newly added or freshly detected up pool
        members
        (Choices: )[Default: None]
- state
        Pool/pool member state
        (Choices: present, absent)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires BIG-IP software version >= 11
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
Requirements:  bigsuds

EXAMPLES:
- name: Create pool
  bigip_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      name: "my-pool"
      partition: "Common"
      lb_method: "least_connection_member"
      slow_ramp_time: 120
  delegate_to: localhost

- name: Modify load balancer method
  bigip_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      name: "my-pool"
      partition: "Common"
      lb_method: "round_robin"

- name: Add pool member
  bigip_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      name: "my-pool"
      partition: "Common"
      host: "{{ ansible_default_ipv4['address'] }}"
      port: 80

- name: Remove pool member from pool
  bigip_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "absent"
      name: "my-pool"
      partition: "Common"
      host: "{{ ansible_default_ipv4['address'] }}"
      port: 80

- name: Delete pool
  bigip_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "absent"
      name: "my-pool"
      partition: "Common"

RETURN VALUES:


MAINTAINERS: Matt Hite (@mhite), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_POOL_MEMBER    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_pool_member.py)

  Manages F5 BIG-IP LTM pool members via iControl SOAP API

Options (= is mandatory):

- connection_limit
        Pool member connection limit. Setting this to 0 disables the limit.
        [Default: None]
- description
        Pool member description
        [Default: None]
= host
        Pool member IP

- monitor_state
        Set monitor availability status for pool member
        (Choices: enabled, disabled)[Default: None]
- partition
        Partition
        [Default: Common]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= pool
        Pool name. This pool must exist.

= port
        Pool member port

- preserve_node
        When state is absent and the pool member is no longer referenced in other pools, the default behavior removes the
        unused node o bject. Setting this to 'yes' disables this behavior.
        (Choices: True, False)[Default: no]
- rate_limit
        Pool member rate limit (connections-per-second). Setting this to 0 disables the limit.
        [Default: None]
- ratio
        Pool member ratio weight. Valid values range from 1 through 100. New pool members -- unless overridden with this
        value -- default to 1.
        [Default: None]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- session_state
        Set new session availability status for pool member
        (Choices: enabled, disabled)[Default: None]
= state
        Pool member state
        (Choices: present, absent)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires BIG-IP software version >= 11
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
  * Supersedes bigip_pool for managing pool members
Requirements:  bigsuds

EXAMPLES:
- name: Add pool member
  bigip_pool_member:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      pool: "my-pool"
      partition: "Common"
      host: "{{ ansible_default_ipv4['address'] }}"
      port: 80
      description: "web server"
      connection_limit: 100
      rate_limit: 50
      ratio: 2
  delegate_to: localhost

- name: Modify pool member ratio and description
  bigip_pool_member:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      pool: "my-pool"
      partition: "Common"
      host: "{{ ansible_default_ipv4['address'] }}"
      port: 80
      ratio: 1
      description: "nginx server"
  delegate_to: localhost

- name: Remove pool member from pool
  bigip_pool_member:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "absent"
      pool: "my-pool"
      partition: "Common"
      host: "{{ ansible_default_ipv4['address'] }}"
      port: 80
  delegate_to: localhost


# The BIG-IP GUI doesn't map directly to the API calls for "Pool ->
# Members -> State". The following states map to API monitor
# and session states.
#
# Enabled (all traffic allowed):
# monitor_state=enabled, session_state=enabled
# Disabled (only persistent or active connections allowed):
# monitor_state=enabled, session_state=disabled
# Forced offline (only active connections allowed):
# monitor_state=disabled, session_state=disabled
#
# See https://devcentral.f5.com/questions/icontrol-equivalent-call-for-b-node-down

- name: Force pool member offline
  bigip_pool_member:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      session_state: "disabled"
      monitor_state: "disabled"
      pool: "my-pool"
      partition: "Common"
      host: "{{ ansible_default_ipv4['address'] }}"
      port: 80
  delegate_to: localhost


MAINTAINERS: Matt Hite (@mhite), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_ROUTEDOMAIN    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_routedomain.py)

  Manage route domains on a BIG-IP

Options (= is mandatory):

- bwc_policy
        The bandwidth controller for the route domain.
        [Default: (null)]
- connection_limit
        The maximum number of concurrent connections allowed for the route domain. Setting this to `0' turns off
        connection limits.
        [Default: (null)]
- description
        Specifies descriptive text that identifies the route domain.
        [Default: (null)]
- flow_eviction_policy
        The eviction policy to use with this route domain. Apply an eviction policy to provide customized responses to
        flow overflows and slow flows on the route domain.
        [Default: (null)]
= id
        The unique identifying integer representing the route domain.

- parent
        Specifies the route domain the system searches when it cannot find a route in the configured domain.
        [Default: (null)]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- routing_protocol
        Dynamic routing protocols for the system to use in the route domain.
        (Choices: BFD, BGP, IS-IS, OSPFv2, OSPFv3, PIM, RIP, RIPng)[Default: (null)]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- service_policy
        Service policy to associate with the route domain.
        [Default: (null)]
- state
        Whether the route domain should exist or not.
        (Choices: present, absent)[Default: present]
- strict
        Specifies whether the system enforces cross-routing restrictions or not.
        (Choices: enabled, disabled)[Default: (null)]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
- vlans
        VLANs for the system to use in the route domain
        [Default: (null)]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
Requirements:  f5-sdk

EXAMPLES:
- name: Create a route domain
  bigip_routedomain:
      id: "1234"
      password: "secret"
      server: "lb.mydomain.com"
      state: "present"
      user: "admin"
  delegate_to: localhost

- name: Set VLANs on the route domain
  bigip_routedomain:
      id: "1234"
      password: "secret"
      server: "lb.mydomain.com"
      state: "present"
      user: "admin"
      vlans:
          - net1
          - foo
  delegate_to: localhost

RETURN VALUES:
id:
    description: The ID of the route domain that was changed
    returned: changed
    type: int
    sample: 2
description:
    description: The description of the route domain
    returned: changed
    type: string
    sample: "route domain foo"
strict:
    description: The new strict isolation setting
    returned: changed
    type: string
    sample: "enabled"
parent:
    description: The new parent route domain
    returned: changed
    type: int
    sample: 0
vlans:
    description: List of new VLANs the route domain is applied to
    returned: changed
    type: list
    sample: ['/Common/http-tunnel', '/Common/socks-tunnel']
routing_protocol:
    description: List of routing protocols applied to the route domain
    returned: changed
    type: list
    sample: ['bfd', 'bgp']
bwc_policy:
    description: The new bandwidth controller
    returned: changed
    type: string
    sample: /Common/foo
connection_limit:
    description: The new connection limit for the route domain
    returned: changed
    type: int
    sample: 100
flow_eviction_policy:
    description: The new eviction policy to use with this route domain
    returned: changed
    type: string
    sample: /Common/default-eviction-policy
service_policy:
    description: The new service policy to use with this route domain
    returned: changed
    type: string
    sample: /Common-my-service-policy


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_SELFIP    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_selfip.py)

  Manage Self-IPs on a BIG-IP system

Options (= is mandatory):

- address
        The IP addresses for the new self IP. This value is ignored upon update as addresses themselves cannot be changed
        after they are created.
        [Default: (null)]
- allow_service
        Configure port lockdown for the Self IP. By default, the Self IP has a "default deny" policy. This can be changed
        to allow TCP and UDP ports as well as specific protocols. This list should contain `protocol':`port' values.
        [Default: (null)]
= name
        The self IP to create.
        [Default: Value of `address']
= netmask
        The netmasks for the self IP.

= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- route_domain
        The route domain id of the system. If none, id of the route domain will be "0" (default route domain)
        [Default: none]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        The state of the variable on the system. When `present', guarantees that the Self-IP exists with the provided
        attributes. When `absent', removes the Self-IP from the system.
        (Choices: absent, present)[Default: present]
- traffic_group
        The traffic group for the self IP addresses in an active-active, redundant load balancer configuration.
        [Default: (null)]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
= vlan
        The VLAN that the new self IPs will be on.

Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
  * Requires the netaddr Python package on the host.
Requirements:  netaddr, f5-sdk

EXAMPLES:
- name: Create Self IP
  bigip_selfip:
      address: "10.10.10.10"
      name: "self1"
      netmask: "255.255.255.0"
      password: "secret"
      server: "lb.mydomain.com"
      user: "admin"
      validate_certs: "no"
      vlan: "vlan1"
  delegate_to: localhost

- name: Create Self IP with a Route Domain
  bigip_selfip:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      validate_certs: "no"
      name: "self1"
      address: "10.10.10.10"
      netmask: "255.255.255.0"
      vlan: "vlan1"
      route_domain: "10"
      allow_service: "default"
  delegate_to: localhost

- name: Delete Self IP
  bigip_selfip:
      name: "self1"
      password: "secret"
      server: "lb.mydomain.com"
      state: "absent"
      user: "admin"
      validate_certs: "no"
  delegate_to: localhost

- name: Allow management web UI to be accessed on this Self IP
  bigip_selfip:
      name: "self1"
      password: "secret"
      server: "lb.mydomain.com"
      state: "absent"
      user: "admin"
      validate_certs: "no"
      allow_service:
          - "tcp:443"
  delegate_to: localhost

- name: Allow HTTPS and SSH access to this Self IP
  bigip_selfip:
      name: "self1"
      password: "secret"
      server: "lb.mydomain.com"
      state: "absent"
      user: "admin"
      validate_certs: "no"
      allow_service:
          - "tcp:443"
          - "tpc:22"
  delegate_to: localhost

- name: Allow all services access to this Self IP
  bigip_selfip:
      name: "self1"
      password: "secret"
      server: "lb.mydomain.com"
      state: "absent"
      user: "admin"
      validate_certs: "no"
      allow_service:
          - all
  delegate_to: localhost

- name: Allow only GRE and IGMP protocols access to this Self IP
  bigip_selfip:
      name: "self1"
      password: "secret"
      server: "lb.mydomain.com"
      state: "absent"
      user: "admin"
      validate_certs: "no"
      allow_service:
          - gre:0
          - igmp:0
  delegate_to: localhost

- name: Allow all TCP, but no other protocols access to this Self IP
  bigip_selfip:
      name: "self1"
      password: "secret"
      server: "lb.mydomain.com"
      state: "absent"
      user: "admin"
      validate_certs: "no"
      allow_service:
          - tcp:0
  delegate_to: localhost

RETURN VALUES:
allow_service:
    description: Services that allowed via this Self IP
    returned: changed
    type: list
    sample: ['igmp:0','tcp:22','udp:53']
address:
    description: The address for the Self IP
    returned: created
    type: string
    sample: "192.0.2.10"
name:
    description: The name of the Self IP
    returned: created, changed or deleted
    type: string
    sample: "self1"
netmask:
    description: The netmask of the Self IP
    returned: created or changed
    type: string
    sample: "255.255.255.0"
traffic_group:
    description: The traffic group that the Self IP is a member of
    returned: changed or created
    type: string
    sample: "traffic-group-local-only"
vlan:
    description: The VLAN set on the Self IP
    returned: created or changed
    type: string
    sample: "vlan1"


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_SNAT_POOL    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_snat_pool.py)

  Manage SNAT pools on a BIG-IP.

Options (= is mandatory):

- append
        When `yes', will only add members to the SNAT pool. When `no', will replace the existing member list with the
        provided member list.
        (Choices: True, False)[Default: False]
- members
        List of members to put in the SNAT pool. When a `state' of present is provided, this parameter is required.
        Otherwise, it is optional.
        [Default: None]
= name
        The name of the SNAT pool.

= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        Whether the SNAT pool should exist or not.
        (Choices: present, absent)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk
  * Requires the netaddr Python package on the host. This is as easy as pip install netaddr
Requirements:  f5-sdk

EXAMPLES:
- name: Add the SNAT pool 'my-snat-pool'
  bigip_snat_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      name: "my-snat-pool"
      state: "present"
      members:
          - 10.10.10.10
          - 20.20.20.20
  delegate_to: localhost

- name: Change the SNAT pool's members to a single member
  bigip_snat_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      name: "my-snat-pool"
      state: "present"
      member: "30.30.30.30"
  delegate_to: localhost

- name: Append a new list of members to the existing pool
  bigip_snat_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      name: "my-snat-pool"
      state: "present"
      members:
          - 10.10.10.10
          - 20.20.20.20
  delegate_to: localhost

- name: Remove the SNAT pool 'my-snat-pool'
  bigip_snat_pool:
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      name: "johnd"
      state: "absent"
  delegate_to: localhost

RETURN VALUES:
members:
    description:
      - List of members that are part of the SNAT pool.
    returned: changed and success
    type: list
    sample: "['10.10.10.10']"


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_SSL_CERTIFICATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_ssl_certificate.py)

  This module will import/delete SSL certificates on BIG-IP LTM. Certificates can be imported from certificate and key
  files on the local disk, in PEM format.

Options (= is mandatory):

- cert_content
        When used instead of 'cert_src', sets the contents of a certificate directly to the specified value. This is used
        with lookup plugins or for anything with formatting or templating. Either one of `key_src', `key_content',
        `cert_src' or `cert_content' must be provided when `state' is `present'.
        [Default: (null)]
- cert_src
        This is the local filename of the certificate. Either one of `key_src', `key_content', `cert_src' or
        `cert_content' must be provided when `state' is `present'.
        [Default: (null)]
- key_content
        When used instead of 'key_src', sets the contents of a certificate key directly to the specified value. This is
        used with lookup plugins or for anything with formatting or templating. Either one of `key_src', `key_content',
        `cert_src' or `cert_content' must be provided when `state' is `present'.
        [Default: (null)]
- key_src
        This is the local filename of the private key. Either one of `key_src', `key_content', `cert_src' or
        `cert_content' must be provided when `state' is `present'.
        [Default: (null)]
= name
        SSL Certificate Name.  This is the cert/key pair name used when importing a certificate/key into the F5. It also
        determines the filenames of the objects on the LTM (:Partition:name.cer_11111_1 and :Partition_name.key_11111_1).

- partition
        BIG-IP partition to use when adding/deleting certificate.
        [Default: Common]
- passphrase
        Passphrase on certificate private key
        [Default: (null)]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
= state
        Certificate and key state. This determines if the provided certificate and key is to be made `present' on the
        device or `absent'.
        (Choices: present, absent)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
  * Requires the netaddr Python package on the host.
  * If you use this module, you will not be able to remove the certificates and keys that are managed, via the web
        UI. You can only remove them via tmsh or these modules.
Requirements:  f5-sdk >= 1.5.0, BigIP >= v12

EXAMPLES:
- name: Import PEM Certificate from local disk
  bigip_ssl_certificate:
      name: "certificate-name"
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      cert_src: "/path/to/cert.crt"
      key_src: "/path/to/key.key"
  delegate_to: localhost

- name: Use a file lookup to import PEM Certificate
  bigip_ssl_certificate:
      name: "certificate-name"
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "present"
      cert_content: "{{ lookup('file', '/path/to/cert.crt') }}"
      key_content: "{{ lookup('file', '/path/to/key.key') }}"
  delegate_to: localhost

- name: "Delete Certificate"
  bigip_ssl_certificate:
      name: "certificate-name"
      server: "lb.mydomain.com"
      user: "admin"
      password: "secret"
      state: "absent"
  delegate_to: localhost

RETURN VALUES:
cert_name:
    description: >
        The name of the SSL certificate. The C(cert_name) and
        C(key_name) will be equal to each other.
    returned: created, changed or deleted
    type: string
    sample: "cert1"
key_name:
    description: >
        The name of the SSL certificate key. The C(key_name) and
        C(cert_name) will be equal to each other.
    returned: created, changed or deleted
    type: string
    sample: "key1"
partition:
    description: Partition in which the cert/key was created
    returned: created, changed or deleted
    type: string
    sample: "Common"
key_checksum:
    description: SHA1 checksum of the key that was provided
    returned: created or changed
    type: string
    sample: "cf23df2207d99a74fbe169e3eba035e633b65d94"
cert_checksum:
    description: SHA1 checksum of the cert that was provided
    returned: created or changed
    type: string
    sample: "f7ff9e8b7bb2e09b70935a5d785e0cc5d9d0abf0"


MAINTAINERS: Tim Rupp (@caphrim007), Kevin Coming (@waffie1)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_SYS_DB    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_sys_db.py)

  Manage BIG-IP system database variables

Options (= is mandatory):

= key
        The database variable to manipulate.

= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        The state of the variable on the system. When `present', guarantees that an existing variable is set to `value'.
        When `reset' sets the variable back to the default value. At least one of value and state `reset' are required.
        (Choices: present, reset)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
- value
        The value to set the key to. At least one of value and state `reset' are required.
        [Default: (null)]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
  * Requires BIG-IP version 12.0.0 or greater
Requirements:  f5-sdk

EXAMPLES:
- name: Set the boot.quiet DB variable on the BIG-IP
  bigip_sys_db:
      user: "admin"
      password: "secret"
      server: "lb.mydomain.com"
      key: "boot.quiet"
      value: "disable"
  delegate_to: localhost

- name: Disable the initial setup screen
  bigip_sys_db:
      user: "admin"
      password: "secret"
      server: "lb.mydomain.com"
      key: "setup.run"
      value: "false"
  delegate_to: localhost

- name: Reset the initial setup screen
  bigip_sys_db:
      user: "admin"
      password: "secret"
      server: "lb.mydomain.com"
      key: "setup.run"
      state: "reset"
  delegate_to: localhost

RETURN VALUES:
name:
    description: The key in the system database that was specified
    returned: changed and success
    type: string
    sample: "setup.run"
default_value:
    description: The default value of the key
    returned: changed and success
    type: string
    sample: "true"
value:
    description: The value that you set the key to
    returned: changed and success
    type: string
    sample: "false"


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_SYS_GLOBAL    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_sys_global.py)

  Manage BIG-IP global settings.

Options (= is mandatory):

- banner_text
        Specifies the text to present in the advisory banner.
        [Default: (null)]
- console_timeout
        Specifies the number of seconds of inactivity before the system logs off a user that is logged on.
        [Default: (null)]
- gui_setup
        `enable' or `disabled' the Setup utility in the browser-based Configuration utility
        (Choices: enabled, disabled)[Default: (null)]
- lcd_display
        Specifies, when `enabled', that the system menu displays on the LCD screen on the front of the unit. This setting
        has no effect when used on the VE platform.
        (Choices: enabled, disabled)[Default: (null)]
- mgmt_dhcp
        Specifies whether or not to enable DHCP client on the management interface
        (Choices: enabled, disabled)[Default: (null)]
- net_reboot
        Specifies, when `enabled', that the next time you reboot the system, the system boots to an ISO image on the
        network, rather than an internal media drive.
        (Choices: enabled, disabled)[Default: (null)]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- quiet_boot
        Specifies, when `enabled', that the system suppresses informational text on the console during the boot cycle.
        When `disabled', the system presents messages and informational text on the console during the boot cycle.
        [Default: (null)]
- security_banner
        Specifies whether the system displays an advisory message on the login screen.
        (Choices: enabled, disabled)[Default: (null)]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        The state of the variable on the system. When `present', guarantees that an existing variable is set to `value'.
        (Choices: present)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
Requirements:  f5-sdk

EXAMPLES:
- name: Disable the setup utility
  bigip_sys_global:
      gui_setup: "disabled"
      password: "secret"
      server: "lb.mydomain.com"
      user: "admin"
      state: "present"
  delegate_to: localhost

RETURN VALUES:
banner_text:
    description: The new text to present in the advisory banner.
    returned: changed
    type: string
    sample: "This is a corporate device. Do not touch."
console_timeout:
    description: >
      The new number of seconds of inactivity before the system
      logs off a user that is logged on.
    returned: changed
    type: int
    sample: 600
gui_setup:
    description: The new setting for the Setup utility.
    returned: changed
    type: string
    sample: enabled
lcd_display:
    description: The new setting for displaying the system menu on the LCD.
    returned: changed
    type: string
    sample: enabled
mgmt_dhcp:
    description: >
      The new setting for whether the mgmt interface should DHCP
      or not
    returned: changed
    type: string
    sample: enabled
net_reboot:
    description: >
      The new setting for whether the system should boot to an ISO on the
      network or not
    returned: changed
    type: string
    sample: enabled
quiet_boot:
    description: >
      The new setting for whether the system should suppress information to
      the console during boot or not.
    returned: changed
    type: string
    sample: enabled
security_banner:
    description: >
      The new setting for whether the system should display an advisory message
      on the login screen or not
    returned: changed
    type: string
    sample: enabled


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_VIRTUAL_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_virtual_server.py)

  Manages F5 BIG-IP LTM virtual servers via iControl SOAP API

Options (= is mandatory):

- all_policies
        List of all policies enabled for the virtual server.
        [Default: None]
- all_profiles
        List of all Profiles (HTTP,ClientSSL,ServerSSL,etc) that must be used by the virtual server
        [Default: None]
- all_rules
        List of rules to be applied in priority order
        [Default: None]
- default_persistence_profile
        Default Profile which manages the session persistence
        [Default: None]
- description
        Virtual server description
        [Default: None]
= destination
        Destination IP of the virtual server (only host is currently supported). Required when state=present and vs does
        not exist.

- enabled_vlans
        List of vlans to be enabled. When a VLAN named `ALL' is used, all VLANs will be allowed.
        [Default: None]
- fallback_persistence_profile
        Specifies the persistence profile you want the system to use if it cannot use the specified default persistence
        profile.
        [Default: None]
= name
        Virtual server name

- partition
        Partition
        [Default: Common]
= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

- pool
        Default pool for the virtual server
        [Default: None]
- port
        Port of the virtual server. Required when state=present and vs does not exist. If you specify a value for this
        field, it must be a number between 0 and 65535.
        [Default: None]
- route_advertisement_state
        Enable route advertisement for destination
        [Default: disabled]
= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- snat
        Source network address policy
        (Choices: None, Automap, Name of a SNAT pool (eg "/Common/snat_pool_name") to enable SNAT with the specific
        pool)[Default: None]
- state
        Virtual Server state
        Absent, delete the VS if present
        `present' (and its synonym enabled), create if needed the VS and set state to enabled
        `disabled', create if needed the VS and set state to disabled
        (Choices: present, absent, enabled, disabled)[Default: present]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires BIG-IP software version >= 11
  * F5 developed module 'bigsuds' required (see http://devcentral.f5.com)
  * Best run as a local_action in your playbook
Requirements:  bigsuds

EXAMPLES:
- name: Add virtual server
  bigip_virtual_server:
      server: lb.mydomain.net
      user: admin
      password: secret
      state: present
      partition: MyPartition
      name: myvirtualserver
      destination: "{{ ansible_default_ipv4['address'] }}"
      port: 443
      pool: "{{ mypool }}"
      snat: Automap
      description: Test Virtual Server
      all_profiles:
          - http
          - clientssl
      enabled_vlans:
          - /Common/vlan2
  delegate_to: localhost

- name: Modify Port of the Virtual Server
  bigip_virtual_server:
      server: lb.mydomain.net
      user: admin
      password: secret
      state: present
      partition: MyPartition
      name: myvirtualserver
      port: 8080
  delegate_to: localhost

- name: Delete virtual server
  bigip_virtual_server:
      server: lb.mydomain.net
      user: admin
      password: secret
      state: absent
      partition: MyPartition
      name: myvirtualserver
  delegate_to: localhost

RETURN VALUES:
---
deleted:
    description: Name of a virtual server that was deleted
    returned: changed
    type: string
    sample: "my-virtual-server"


MAINTAINERS: Etienne Carriere (@Etienne-Carriere), Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGIP_VLAN    (/usr/lib/python2.7/site-packages/ansible/modules/network/f5/bigip_vlan.py)

  Manage VLANs on a BIG-IP system

Options (= is mandatory):

- description
        The description to give to the VLAN.
        [Default: (null)]
= name
        The VLAN to manage. If the special VLAN `ALL' is specified with the `state' value of `absent' then all VLANs will
        be removed.

= password
        The password for the user account used to connect to the BIG-IP. This option can be omitted if the environment
        variable `F5_PASSWORD' is set.

= server
        The BIG-IP host. This option can be omitted if the environment variable `F5_SERVER' is set.

- server_port
        The BIG-IP server port. This option can be omitted if the environment variable `F5_SERVER_PORT' is set.
        [Default: 443]
- state
        The state of the VLAN on the system. When `present', guarantees that the VLAN exists with the provided
        attributes. When `absent', removes the VLAN from the system.
        (Choices: absent, present)[Default: present]
- tag
        Tag number for the VLAN. The tag number can be any integer between 1 and 4094. The system automatically assigns a
        tag number if you do not specify a value.
        [Default: (null)]
- tagged_interfaces
        Specifies a list of tagged interfaces and trunks that you want to configure for the VLAN. Use tagged interfaces
        or trunks when you want to assign a single interface or trunk to multiple VLANs.
        [Default: (null)]
- untagged_interfaces
        Specifies a list of untagged interfaces and trunks that you want to configure for the VLAN.
        [Default: (null)]
= user
        The username to connect to the BIG-IP with. This user must have administrative privileges on the device. This
        option can be omitted if the environment variable `F5_USER' is set.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates. This option can be omitted if the environment variable `F5_VALIDATE_CERTS' is set.
        (Choices: True, False)[Default: True]
Notes:
  * Requires the f5-sdk Python package on the host. This is as easy as pip install f5-sdk.
  * Requires BIG-IP versions >= 12.0.0
Requirements:  f5-sdk

EXAMPLES:
- name: Create VLAN
  bigip_vlan:
      name: "net1"
      password: "secret"
      server: "lb.mydomain.com"
      user: "admin"
      validate_certs: "no"
  delegate_to: localhost

- name: Set VLAN tag
  bigip_vlan:
      name: "net1"
      password: "secret"
      server: "lb.mydomain.com"
      tag: "2345"
      user: "admin"
      validate_certs: "no"
  delegate_to: localhost

- name: Add VLAN 2345 as tagged to interface 1.1
  bigip_vlan:
      tagged_interface: 1.1
      name: "net1"
      password: "secret"
      server: "lb.mydomain.com"
      tag: "2345"
      user: "admin"
      validate_certs: "no"
  delegate_to: localhost

- name: Add VLAN 1234 as tagged to interfaces 1.1 and 1.2
  bigip_vlan:
      tagged_interfaces:
          - 1.1
          - 1.2
      name: "net1"
      password: "secret"
      server: "lb.mydomain.com"
      tag: "1234"
      user: "admin"
      validate_certs: "no"
  delegate_to: localhost

RETURN VALUES:
description:
    description: The description set on the VLAN
    returned: changed
    type: string
    sample: foo VLAN
interfaces:
    description: Interfaces that the VLAN is assigned to
    returned: changed
    type: list
    sample: ['1.1','1.2']
name:
    description: The name of the VLAN
    returned: changed
    type: string
    sample: net1
partition:
    description: The partition that the VLAN was created on
    returned: changed
    type: string
    sample: Common
tag:
    description: The ID of the VLAN
    returned: changed
    type: int
    sample: 2345


MAINTAINERS: Tim Rupp (@caphrim007)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGMON_CHAIN    (/usr/lib/python2.7/site-packages/ansible/modules/network/bigswitch/bigmon_chain.py)

  Create and remove a bigmon inline service chain.

Options (= is mandatory):

- access_token
        Bigmon access token. If this isn't set the the environment variable `BIGSWITCH_ACCESS_TOKEN' is used.
        [Default: (null)]
= controller
        The controller IP address.

= name
        The name of the chain.

- state
        Whether the service chain should be present or absent.
        (Choices: present, absent)[Default: present]
- validate_certs
        If `false', SSL certificates will not be validated. This should only be used on personally controlled devices
        using self-signed certificates.
        (Choices: True, False)[Default: True]
EXAMPLES:
- name: bigmon inline service chain
  bigmon_chain:
    name: MyChain
    controller: '{{ inventory_hostname }}'
    state: present
    validate_certs: false

RETURN VALUES:
# 

MAINTAINERS: Ted (@tedelhourani)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGMON_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/network/bigswitch/bigmon_policy.py)

  Create and remove a bigmon out-of-band policy.

Options (= is mandatory):

- access_token
        Bigmon access token. If this isn't set the the environment variable `BIGSWITCH_ACCESS_TOKEN' is used.
        [Default: (null)]
- action
        Forward matching packets to delivery interfaces, Drop is for measure rate of matching packets, but do not forward
        to delivery interfaces, capture packets and write to a PCAP file, or enable NetFlow generation.
        (Choices: forward, drop, flow-gen)[Default: forward]
= controller
        The controller address.

- delivery_packet_count
        Run policy until delivery_packet_count packets are delivered.
        [Default: 0]
- duration
        Run policy for duration duration or until delivery_packet_count packets are delivered, whichever comes first.
        [Default: 0]
= name
        The name of the policy.

- policy_description
        Description of policy.
        [Default: (null)]
- priority
        A priority associated with this policy. The higher priority policy takes precedence over a lower priority.
        [Default: 100]
- start_time
        Date the policy becomes active
        [Default: ansible_date_time.iso8601]
- state
        Whether the policy should be present or absent.
        (Choices: present, absent)[Default: present]
- validate_certs
        If `false', SSL certificates will not be validated. This should only be used on personally controlled devices
        using self-signed certificates.
        (Choices: True, False)[Default: True]
EXAMPLES:
- name: policy to aggregate filter and deliver data center (DC) 1 traffic
  bigmon_policy:
    name: policy1
    policy_description: DC 1 traffic policy
    action: drop
    controller: '{{ inventory_hostname }}'
    state: present
    validate_certs: false

RETURN VALUES:
# 

MAINTAINERS: Ted (@tedelhourani)

METADATA:
	Status: ['preview']
	Supported_by: community
> BIGPANDA    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/bigpanda.py)

  Notify BigPanda when deployments start and end (successfully or not). Returns a deployment object containing all the
  parameters for future module calls.

Options (= is mandatory):

= component
        The name of the component being deployed. Ex: billing

- description
        Free text description of the deployment.
        [Default: (null)]
- env
        The environment name, typically 'production', 'staging', etc.
        [Default: (null)]
- hosts
        Name of affected host name. Can be a list.
        [Default: machine's hostname]
- owner
        The person responsible for the deployment.
        [Default: (null)]
= state
        State of the deployment.
        (Choices: started, finished, failed)
= token
        API token.

- url
        Base URL of the API server.
        [Default: https://api.bigpanda.io]
- validate_certs
        If `no', SSL certificates for the target url will not be validated. This should only be used on personally
        controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
= version
        The deployment version.

EXAMPLES:
- bigpanda:
    component: myapp
    version: '1.3'
    token: '{{ bigpanda_token }}'
    state: started

- bigpanda:
    component: myapp
    version: '1.3'
    token: '{{ bigpanda_token }}'
    state: finished

# If outside servers aren't reachable from your machine, use delegate_to and override hosts:
- bigpanda:
    component: myapp
    version: '1.3'
    token: '{{ bigpanda_token }}'
    hosts: '{{ ansible_hostname }}'
    state: started
  delegate_to: localhost
  register: deployment

- bigpanda:
    component: '{{ deployment.component }}'
    version: '{{ deployment.version }}'
    token: '{{ deployment.token }}'
    state: finished
  delegate_to: localhost


MAINTAINERS: Hagai Kariti (@hkariti)

METADATA:
	Status: ['preview']
	Supported_by: community
> BLOCKINFILE    (/usr/lib/python2.7/site-packages/ansible/modules/files/blockinfile.py)

  This module will insert/update/remove a block of multi-line text surrounded by customizable marker lines.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- block
        The text to insert inside the marker lines. If it's missing or an empty string, the block will be removed as if
        `state' were specified to `absent'.
        [Default: ]
- create
        Create a new file if it doesn't exist.
        (Choices: yes, no)[Default: no]
- follow
        This flag indicates that filesystem links, if they exist, should be followed.
        (Choices: yes, no)[Default: no]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- insertafter
        If specified, the block will be inserted after the last match of specified regular expression. A special value is
        available; `EOF' for inserting the block at the end of the file.  If specified regular expresion has no matches,
        `EOF' will be used instead.
        (Choices: EOF, *regex*)[Default: EOF]
- insertbefore
        If specified, the block will be inserted before the last match of specified regular expression. A special value
        is available; `BOF' for inserting the block at the beginning of the file.  If specified regular expresion has no
        matches, the block will be inserted at the end of the file.
        (Choices: BOF, *regex*)[Default: None]
- marker
        The marker line template. "{mark}" will be replaced with "BEGIN" or "END".
        [Default: # {mark} ANSIBLE MANAGED BLOCK]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
= path
        The file to modify.
        Before 2.3 this option was only usable as `dest', `destfile' and `name'.

- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- state
        Whether the block should be there or not.
        (Choices: present, absent)[Default: present]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- validate
        The validation command to run before copying into place. The path to the file to validate is passed in via '%s'
        which must be present as in the example below. The command is passed securely so shell features like expansion
        and pipes won't work.
        [Default: None]
Notes:
  * This module supports check mode.
  * When using 'with_*' loops be aware that if you do not set a unique mark the block will be overwritten on each
        iteration.
  * As of Ansible 2.3, the `dest' option has been changed to `path' as default, but `dest' still works as well.
EXAMPLES:
# Before 2.3, option 'dest' or 'name' was used instead of 'path'
- name: insert/update "Match User" configuration block in /etc/ssh/sshd_config
  blockinfile:
    path: /etc/ssh/sshd_config
    block: |
      Match User ansible-agent
      PasswordAuthentication no

- name: insert/update eth0 configuration stanza in /etc/network/interfaces
        (it might be better to copy files into /etc/network/interfaces.d/)
  blockinfile:
    path: /etc/network/interfaces
    block: |
      iface eth0 inet static
          address 192.0.2.23
          netmask 255.255.255.0

- name: insert/update configuration using a local file
  blockinfile:
    block: "{{ lookup('file', './local/ssh_config') }}"
    dest: "/etc/ssh/ssh_config"
    backup: yes

- name: insert/update HTML surrounded by custom markers after <body> line
  blockinfile:
    path: /var/www/html/index.html
    marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
    insertafter: "<body>"
    content: |
      <h1>Welcome to {{ ansible_hostname }}</h1>
      <p>Last updated on {{ ansible_date_time.iso8601 }}</p>

- name: remove HTML as well as surrounding markers
  blockinfile:
    path: /var/www/html/index.html
    marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
    content: ""

- name: Add mappings to /etc/hosts
  blockinfile:
    path: /etc/hosts
    block: |
      {{ item.ip }} {{ item.name }}
    marker: "# {mark} ANSIBLE MANAGED BLOCK {{ item.name }}"
  with_items:
    - { name: host1, ip: 10.10.1.10 }
    - { name: host2, ip: 10.10.1.11 }
    - { name: host3, ip: 10.10.1.12 }


MAINTAINERS: YAEGASHI Takeshi (@yaegashi)

METADATA:
	Status: ['preview']
	Supported_by: core
> BOUNDARY_METER    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/boundary_meter.py)

  This module manages boundary meters

Options (= is mandatory):

= apiid
        Organizations boundary API ID

= apikey
        Organizations boundary API KEY

= name
        meter name

- state
        Whether to create or remove the client from boundary
        (Choices: present, absent)[Default: True]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
Notes:
  * This module does not yet support boundary tags.
Requirements:  Boundary API access, bprobe is required to send data, but not to register a meter

EXAMPLES:
- name: Create meter
  boundary_meter:
    apiid: AAAAAA
    apikey: BBBBBB
    state: present
    name: '{{ inventory_hostname }}'

- name: Delete meter
  boundary_meter:
    apiid: AAAAAA
    apikey: BBBBBB
    state: absent
    name: '{{ inventory_hostname }}'


MAINTAINERS: curtis (@ccollicutt)

METADATA:
	Status: ['preview']
	Supported_by: community
> BOWER    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/bower.py)

  Manage bower packages with bower

Options (= is mandatory):

- name
        The name of a bower package to install
        [Default: (null)]
- offline
        Install packages from local cache, if the packages were installed before
        (Choices: yes, no)[Default: False]
= path
        The base path where to install the bower packages

- production
        Install with --production flag
        (Choices: yes, no)[Default: False]
- relative_execpath
        Relative path to bower executable from install path
        [Default: None]
- state
        The state of the bower package
        (Choices: present, absent, latest)[Default: present]
- version
        The version to be installed
        [Default: (null)]
EXAMPLES:
- name: Install "bootstrap" bower package.
  bower:
    name: bootstrap

- name: Install "bootstrap" bower package on version 3.1.1.
  bower:
    name: bootstrap
    version: '3.1.1'

- name: Remove the "bootstrap" bower package.
  bower:
    name: bootstrap
    state: absent

- name: Install packages based on bower.json.
  bower:
    path: /app/location

- name: Update packages based on bower.json to their latest version.
  bower:
    path: /app/location
    state: latest

# install bower locally and run from there
- npm:
    path: /app/location
    name: bower
    global: no
- bower:
    path: /app/location
    relative_execpath: node_modules/.bin


MAINTAINERS: Michael Warkentin (@mwarkentin)

METADATA:
	Status: ['preview']
	Supported_by: community
> BUNDLER    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/bundler.py)

  Manage installation and Gem version dependencies for Ruby using the Bundler gem

Options (= is mandatory):

- binstub_directory
        Only applies if state is `present'. Specifies the directory to install any gem bins files to. When executed the
        bin files will run within the context of the Gemfile and fail if any required gem dependencies are not installed.
        If `chdir' is set then this path is relative to `chdir'
        [Default: None]
- chdir
        The directory to execute the bundler commands from. This directoy needs to contain a valid Gemfile or .bundle/
        directory
        [Default: temporary working directory]
- clean
        Only applies if state is `present'. If set removes any gems on the target host that are not in the gemfile
        (Choices: True, False)[Default: no]
- deployment_mode
        Only applies if state is `present'. If set it will only install gems that are in the default or production
        groups. Requires a Gemfile.lock file to have been created prior
        (Choices: True, False)[Default: no]
- exclude_groups
        A list of Gemfile groups to exclude during operations. This only applies when state is `present'. Bundler
        considers this a 'remembered' property for the Gemfile and will automatically exclude groups in future operations
        even if `exclude_groups' is not set
        [Default: None]
- executable
        The path to the bundler executable
        [Default: None]
- extra_args
        A space separated string of additional commands that can be applied to the Bundler command. Refer to the Bundler
        documentation for more information
        [Default: None]
- gem_path
        Only applies if state is `present'. Specifies the directory to install the gems into. If `chdir' is set then this
        path is relative to `chdir'
        [Default: RubyGems gem paths]
- gemfile
        Only applies if state is `present'. The path to the gemfile to use to install gems.
        [Default: Gemfile in current directory]
- local
        If set only installs gems from the cache on the target host
        (Choices: True, False)[Default: no]
- state
        The desired state of the Gem bundle. `latest' updates gems to the most recent, acceptable version
        (Choices: present, latest)[Default: present]
- user_install
        Only applies if state is `present'. Installs gems in the local user's cache or for all users
        (Choices: True, False)[Default: yes]
EXAMPLES:
# Installs gems from a Gemfile in the current directory
- bundler:
    state: present
    executable: ~/.rvm/gems/2.1.5/bin/bundle

# Excludes the production group from installing
- bundler:
    state: present
    exclude_groups: production

# Only install gems from the default and production groups
- bundler:
    state: present
    deployment_mode: yes

# Installs gems using a Gemfile in another directory
- bundler:
    state: present
    gemfile: ../rails_project/Gemfile

# Updates Gemfile in another directory
- bundler:
    state: latest
    chdir: ~/rails_project


MAINTAINERS: Tim Hoiberg (@thoiberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> BZR    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/bzr.py)

  Manage `bzr' branches to deploy files or software.

Options (= is mandatory):

= dest
        Absolute path of where the branch should be cloned to.

- executable
        Path to bzr executable to use. If not supplied, the normal mechanism for resolving binary paths will be used.
        [Default: None]
- force
        If `yes', any modified files in the working tree will be discarded.  Before 1.9 the default value was "yes".
        (Choices: yes, no)[Default: no]
= name
        SSH or HTTP protocol address of the parent branch.

- version
        What version of the branch to clone.  This can be the bzr revno or revid.
        [Default: head]
EXAMPLES:
# Example bzr checkout from Ansible Playbooks
- bzr:
    name: bzr+ssh://foosball.example.org/path/to/branch
    dest: /srv/checkout
    version: 22


MAINTAINERS: André Paramés (@andreparames)

METADATA:
	Status: ['preview']
	Supported_by: community
> CAMPFIRE    (/usr/lib/python2.7/site-packages/ansible/modules/notification/campfire.py)

  Send a message to Campfire. Messages with newlines will result in a "Paste" message being sent.

Options (= is mandatory):

= msg
        The message body.

- notify
        Send a notification sound before the message.
        (Choices: 56k, bell, bezos, bueller, clowntown, cottoneyejoe, crickets, dadgummit, dangerzone, danielsan, deeper,
        drama, greatjob, greyjoy, guarantee, heygirl, horn, horror, inconceivable, live, loggins, makeitso, noooo, nyan,
        ohmy, ohyeah, pushit, rimshot, rollout, rumble, sax, secret, sexyback, story, tada, tmyk, trololo, trombone,
        unix, vuvuzela, what, whoomp, yeah, yodel)[Default: (null)]
= room
        Room number to which the message should be sent.

= subscription
        The subscription name to use.

= token
        API token.

EXAMPLES:
- campfire:
    subscription: foo
    token: 12345
    room: 123
    msg: Task completed.

- campfire:
    subscription: foo
    token: 12345
    room: 123
    notify: loggins
    msg: Task completed ... with feeling.


MAINTAINERS: Adam Garside (@fabulops)

METADATA:
	Status: ['preview']
	Supported_by: community
> CAPABILITIES    (/usr/lib/python2.7/site-packages/ansible/modules/system/capabilities.py)

  This module manipulates files privileges using the Linux capabilities(7) system.

Options (= is mandatory):

= capability
        Desired capability to set (with operator and flags, if state is `present') or remove (if state is `absent')
        [Default: None]
= path
        Specifies the path to the file to be managed.
        [Default: None]
- state
        Whether the entry should be present or absent in the file's capabilities.
        (Choices: present, absent)[Default: present]
Notes:
  * The capabilities system will automatically transform operators and flags into the effective set, so (for
        example, cap_foo=ep will probably become cap_foo+ep). This module does not attempt to determine the final
        operator and flags to compare, so you will want to ensure that your capabilities argument matches the final
        capabilities.
EXAMPLES:
# Set cap_sys_chroot+ep on /foo
- capabilities:
    path: /foo
    capability: cap_sys_chroot+ep
    state: present

# Remove cap_net_bind_service from /bar
- capabilities:
    path: /bar
    capability: cap_net_bind_service
    state: absent


MAINTAINERS: Nate Coraor (@natefoo)

METADATA:
	Status: ['preview']
	Supported_by: community
> CE_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/cloudengine/ce_command.py)

  Sends an arbitrary command to an HUAWEI CloudEngine node and returns the results read from the device.  The ce_command
  module includes an argument that will cause the module to wait for a specific condition before returning or timing out
  if the condition is not met.

Options (= is mandatory):

= commands
        The commands to send to the remote HUAWEI CloudEngine device over the configured provider.  The resulting output
        from the command is returned. If the `wait_for' argument is provided, the module is not returned until the
        condition is satisfied or the number of `retries' has been exceeded.

- interval
        Configures the interval in seconds to wait between retries of the command.  If the command does not pass the
        specified conditional, the interval indicates how to long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the `wait_for' must be
        satisfied.  If the value is set to `any' then only one of the values must be satisfied.
        [Default: all]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should by tried before it is considered failed.  The command is run on
        the target device every retry and evaluated against the `wait_for' conditionals.
        [Default: 10]
- wait_for
        Specifies what to evaluate from the output of the command and what conditionals to apply.  This argument will
        cause the task to wait for a particular conditional to be true before moving forward.   If the conditional is not
        true by the configured retries, the task fails.  See examples.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

---
- name: run display version on remote devices
  ce_command:
    commands: display version
    provider: "{{ cli }}"

- name: run display version and check to see if output contains HUAWEI
  ce_command:
    commands: display version
    wait_for: result[0] contains HUAWEI
    provider: "{{ cli }}"

- name: run multiple commands on remote nodes
  ce_command:
    commands:
      - display version
      - display device
    provider: "{{ cli }}"

- name: run multiple commands and evaluate the output
  ce_command:
    commands:
      - display version
      - display device
    wait_for:
      - result[0] contains HUAWEI
      - result[1] contains Device
    provider: "{{ cli }}"

- name: run commands and specify the output format
  ce_command:
    commands:
      - command: display version
        output: json
    provider: "{{ cli }}"

RETURN VALUES:
stdout:
  description: the set of responses from the commands
  returned: always
  type: list
  sample: ['...', '...']

stdout_lines:
  description: The value of stdout split into a list
  returned: always
  type: list
  sample: [['...', '...'], ['...'], ['...']]

failed_conditions:
  description: the conditionals that failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: JackyGao2016 (@CloudEngine-Ansible)

METADATA:
	Status: ['preview']
	Supported_by: community
> CIRCONUS_ANNOTATION    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/circonus_annotation.py)

  Create an annotation event with a given category, title and description. Optionally start, end or durations can be
  provided

Options (= is mandatory):

= api_key
        Circonus API key

= category
        Annotation Category

= description
        Description of annotation

- duration
        Duration in seconds of annotation, defaults to 0
        [Default: (null)]
- start
        Unix timestamp of event start, defaults to now
        [Default: (null)]
- stop
        Unix timestamp of event end, defaults to now + duration
        [Default: (null)]
= title
        Title of annotation

Requirements:  urllib3, requests, time

EXAMPLES:
# Create a simple annotation event with a source, defaults to start and end time of now
- circonus_annotation:
    api_key: XXXXXXXXXXXXXXXXX
    title: App Config Change
    description: This is a detailed description of the config change
    category: This category groups like annotations
# Create an annotation with a duration of 5 minutes and a default start time of now
- circonus_annotation:
    api_key: XXXXXXXXXXXXXXXXX
    title: App Config Change
    description: This is a detailed description of the config change
    category: This category groups like annotations
    duration: 300
# Create an annotation with a start_time and end_time
- circonus_annotation:
    api_key: XXXXXXXXXXXXXXXXX
    title: App Config Change
    description: This is a detailed description of the config change
    category: This category groups like annotations
    start_time: 1395940006
    end_time: 1395954407


MAINTAINERS: Nick Harring (@NickatEpic)

METADATA:
	Status: ['preview']
	Supported_by: community
> CISCO_SPARK    (/usr/lib/python2.7/site-packages/ansible/modules/notification/cisco_spark.py)

  Send a message to a Cisco Spark Room or Individual with options to control the formatting.

Options (= is mandatory):

= message
        The message you would like to send.

- message_type
        Specifies how you would like the message formatted.
        (Choices: text, markdown)[Default: text]
= personal_token
        Your personal access token required to validate the Spark API.

= recipient_id
        The unique identifier associated with the supplied `recipient_type'.

= recipient_type
        The request parameter you would like to send the message to.
        Messages can be sent to either a room or individual (by ID or E-Mail).
        (Choices: roomId, toPersonEmail, toPersonId)
Notes:
  * The `recipient_id' type must be valid for the supplied `recipient_id'.
  * Full API documentation can be found at https://developer.ciscospark.com/endpoint-messages-post.html.
EXAMPLES:
# Note: The following examples assume a variable file has been imported
# that contains the appropriate information.

- name: Cisco Spark - Markdown Message to a Room
  cisco_spark:
    recipient_type: roomId
    recipient_id: "{{ room_id }}"
    message_type: markdown
    personal_token: "{{ token }}"
    message: "**Cisco Spark Ansible Module - Room Message in Markdown**"

- name: Cisco Spark - Text Message to a Room
  cisco_spark:
    recipient_type: roomId
    recipient_id: "{{ room_id }}"
    message_type: text
    personal_token: "{{ token }}"
    message: "Cisco Spark Ansible Module - Room Message in Text"

- name: Cisco Spark - Text Message by an Individuals ID
  cisco_spark:
    recipient_type: toPersonId
    recipient_id: "{{ person_id}}"
    message_type: text
    personal_token: "{{ token }}"
    message: "Cisco Spark Ansible Module - Text Message to Individual by ID"

- name: Cisco Spark - Text Message by an Individuals E-Mail Address
  cisco_spark:
    recipient_type: toPersonEmail
    recipient_id: "{{ person_email }}"
    message_type: text
    personal_token: "{{ token }}"
    message: "Cisco Spark Ansible Module - Text Message to Individual by E-Mail"


RETURN VALUES:
status_code:
  description:
    - The Response Code returned by the Spark API.
    - Full Responsde Code explanations can be found at U(https://developer.ciscospark.com/endpoint-messages-post.html).
  returned: always
  type: int
  sample: 200

message:
    description:
      - The Response Message returned by the Spark API.
      - Full Responsde Code explanations can be found at U(https://developer.ciscospark.com/endpoint-messages-post.html.
    returned: always
    type: string
    sample: OK (585 bytes)


MAINTAINERS: Drew Rusell (@drusse11)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CL_BOND    (/usr/lib/python2.7/site-packages/ansible/modules/network/cumulus/_cl_bond.py)

  Configures a bond interface on Cumulus Linux To configure a bridge port use the cl_bridge module. To configure any
  other type of interface use the cl_interface module. Follow the guidelines for bonding found in the Cumulus User Guide
  at http://docs.cumulusnetworks.com.

DEPRECATED: 
Deprecated in 2.3. Use M(nclu) instead.

Options (= is mandatory):

- addr_method
        Configures the port to use DHCP. To enable this feature use the option `dhcp'.
        (Choices: dhcp)[Default: (null)]
- alias_name
        Description of the port.
        [Default: (null)]
- clag_id
        Specify a unique clag_id for every dual connected bond on each peer switch. The value must be between 1 and 65535
        and must be the same on both peer switches in order for the bond to be considered dual-connected.
        [Default: (null)]
- ipv4
        List of IPv4 addresses to configure on the interface. In the form `X.X.X.X/YY'.
        [Default: (null)]
- ipv6
        List of IPv6 addresses to configure on the interface. In the form `X:X:X::X/YYY'.
        [Default: (null)]
- lacp_bypass_all_active
        Activate all interfaces for bypass. It is recommended to configure all_active instead of using bypass_priority.
        [Default: (null)]
- lacp_bypass_allow
        Enable LACP bypass.
        [Default: (null)]
- lacp_bypass_period
        Period for enabling LACP bypass. Max value is 900.
        [Default: (null)]
- lacp_bypass_priority
        List of ports and priorities. Example `"swp1=10, swp2=20"'.
        [Default: (null)]
- lacp_rate
        The lacp rate.
        [Default: 1]
- location
        Interface directory location.
        [Default: [u'/etc/network/interfaces.d']]
- miimon
        The mii link monitoring interval.
        [Default: 100]
- min_links
        Minimum number of links.
        [Default: 1]
- mode
        The bond mode, as of Cumulus Linux 2.5 only LACP bond mode is supported.
        [Default: 802.3ad]
- mstpctl_bpduguard
        Enables BPDU Guard on a port in vlan-aware mode.
        (Choices: True, False)[Default: (null)]
- mstpctl_portadminedge
        Enables admin edge port.
        (Choices: True, False)[Default: (null)]
- mstpctl_portnetwork
        Enables bridge assurance in vlan-aware mode.
        (Choices: True, False)[Default: (null)]
- mtu
        Set MTU. Configure Jumbo Frame by setting MTU to `9000'.
        [Default: (null)]
= name
        Name of the interface.

- pvid
        In vlan-aware mode, defines vlan that is the untagged vlan.
        [Default: (null)]
= slaves
        Bond members.

- vids
        In vlan-aware mode, lists VLANs defined under the interface.
        [Default: (null)]
- virtual_ip
        Define IPv4 virtual IP used by the Cumulus Linux VRR feature.
        [Default: (null)]
- virtual_mac
        Define Ethernet mac associated with Cumulus Linux VRR feature.
        [Default: (null)]
- xmit_hash_policy
        Transmit load balancing algorithm. As of Cumulus Linux 2.5 only `layer3+4' policy is supported.
        [Default: layer3+4]
Notes:
  * As this module writes the interface directory location, ensure that ``/etc/network/interfaces`` has a 'source
        /etc/network/interfaces.d/\*' or whatever path is mentioned in the ``location`` attribute.
  * For the config to be activated, i.e installed in the kernel, "service networking reload" needs be be executed.
        See EXAMPLES section.
Requirements:  Alternate Debian network interface manager - ifupdown2 @ github.com/CumulusNetworks/ifupdown2

EXAMPLES:
# Options ['virtual_mac', 'virtual_ip'] are required together
# configure a bond interface with IP address
- cl_bond:
    name: bond0
    slaves:
      - swp4-5
    ipv4: 10.1.1.1/24

# configure bond as a dual-connected clag bond
- cl_bond:
    name: bond1
    slaves:
      - swp1s0
      - swp2s0
    clag_id: 1

# define cl_bond once in tasks file
# then write interface config in variables file
# with just the options you want.
- cl_bond:
    name: "{{ item.key }}"
    slaves: "{{ item.value.slaves }}"
    clag_id: "{{ item.value.clag_id|default(omit) }}"
    ipv4:  "{{ item.value.ipv4|default(omit) }}"
    ipv6: "{{ item.value.ipv6|default(omit) }}"
    alias_name: "{{ item.value.alias_name|default(omit) }}"
    addr_method: "{{ item.value.addr_method|default(omit) }}"
    mtu: "{{ item.value.mtu|default(omit) }}"
    vids: "{{ item.value.vids|default(omit) }}"
    virtual_ip: "{{ item.value.virtual_ip|default(omit) }}"
    virtual_mac: "{{ item.value.virtual_mac|default(omit) }}"
    mstpctl_portnetwork: "{{ item.value.mstpctl_portnetwork|default('no') }}"
    mstpctl_portadminedge: "{{ item.value.mstpctl_portadminedge|default('no') }}"
    mstpctl_bpduguard: "{{ item.value.mstpctl_bpduguard|default('no') }}"
  with_dict: "{{ cl_bonds }}"

# In vars file
# ============
---
cl_bonds:
  bond0:
    alias_name: uplink to isp
    slaves:
      - swp1
      - swp3
    ipv4: 10.1.1.1/24'
  bond2:
    vids:
      - 1
      - 50
    clag_id: 1

RETURN VALUES:
changed:
    description: whether the interface was changed
    returned: changed
    type: bool
    sample: True
msg:
    description: human-readable report of success or failure
    returned: always
    type: string
    sample: "interface bond0 config updated"


MAINTAINERS: Cumulus Networks (@CumulusNetworks)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> CL_BRIDGE    (/usr/lib/python2.7/site-packages/ansible/modules/network/cumulus/_cl_bridge.py)

  Configures a bridge interface on Cumulus Linux To configure a bond port use the cl_bond module. To configure any other
  type of interface use the cl_interface module. Follow the guidelines for bridging found in the Cumulus User Guide at
  http://docs.cumulusnetworks.com

DEPRECATED: 
Deprecated in 2.3. Use M(nclu) instead.

Options (= is mandatory):

- addr_method
        Configures the port to use DHCP. To enable this feature use the option `dhcp'.
        (Choices: dhcp)[Default: (null)]
- alias_name
        Description of the port.
        [Default: (null)]
- ipv4
        List of IPv4 addresses to configure on the interface. In the form `X.X.X.X/YY'.
        [Default: (null)]
- ipv6
        List of IPv6 addresses to configure on the interface. In the form `X:X:X::X/YYY'.
        [Default: (null)]
- location
        Interface directory location.
        [Default: [u'/etc/network/interfaces.d']]
- mstpctl_treeprio
        Set spanning tree root priority. Must be a multiple of 4096.
        [Default: (null)]
- mtu
        Set MTU. Configure Jumbo Frame by setting MTU to `9000'.
        [Default: (null)]
= name
        Name of the interface.

= ports
        List of bridge members.

- pvid
        In vlan-aware mode, defines vlan that is the untagged vlan.
        [Default: (null)]
- stp
        Enables spanning tree Protocol. As of Cumulus Linux 2.5 the default bridging mode, only per vlan RSTP or 802.1d
        is supported. For the vlan aware mode, only common instance STP is supported
        (Choices: yes, no)[Default: yes]
- vids
        In vlan-aware mode, lists VLANs defined under the interface.
        [Default: (null)]
- virtual_ip
        Define IPv4 virtual IP used by the Cumulus Linux VRR feature.
        [Default: (null)]
- virtual_mac
        Define Ethernet mac associated with Cumulus Linux VRR feature.
        [Default: (null)]
- vlan_aware
        Enables vlan-aware mode.
        (Choices: yes, no)[Default: (null)]
Notes:
  * As this module writes the interface directory location, ensure that ``/etc/network/interfaces`` has a 'source
        /etc/network/interfaces.d/\*' or whatever path is mentioned in the ``location`` attribute.
  * For the config to be activated, i.e installed in the kernel, "service networking reload" needs be be executed.
        See EXAMPLES section.
Requirements:  Alternate Debian network interface manager ifupdown2 @ github.com/CumulusNetworks/ifupdown2

EXAMPLES:
# Options ['virtual_mac', 'virtual_ip'] are required together
# configure a bridge vlan aware bridge.
- cl_bridge:
    name: br0
    ports: 'swp1-12'
    vlan_aware: 'yes'
  notify: reload networking

# configure bridge interface to define a default set of vlans
- cl_bridge:
    name: bridge
    ports: 'swp1-12'
    vlan_aware: 'yes'
    vids: '1-100'
  notify: reload networking

# define cl_bridge once in tasks file
# then write interface config in variables file
# with just the options you want.
- cl_bridge:
    name: "{{ item.key }}"
    ports: "{{ item.value.ports }}"
    vlan_aware: "{{ item.value.vlan_aware|default(omit) }}"
    ipv4:  "{{ item.value.ipv4|default(omit) }}"
    ipv6: "{{ item.value.ipv6|default(omit) }}"
    alias_name: "{{ item.value.alias_name|default(omit) }}"
    addr_method: "{{ item.value.addr_method|default(omit) }}"
    mtu: "{{ item.value.mtu|default(omit) }}"
    vids: "{{ item.value.vids|default(omit) }}"
    virtual_ip: "{{ item.value.virtual_ip|default(omit) }}"
    virtual_mac: "{{ item.value.virtual_mac|default(omit) }}"
    mstpctl_treeprio: "{{ item.value.mstpctl_treeprio|default(omit) }}"
  with_dict: "{{ cl_bridges }}"
  notify: reload networking

# In vars file
# ============
---
cl_bridge:
  br0:
    alias_name: 'vlan aware bridge'
    ports: ['swp1', 'swp3']
    vlan_aware: true
    vids: ['1-100']

RETURN VALUES:
changed:
    description: whether the interface was changed
    returned: changed
    type: bool
    sample: True
msg:
    description: human-readable report of success or failure
    returned: always
    type: string
    sample: "interface bond0 config updated"


MAINTAINERS: Cumulus Networks (@CumulusNetworks)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> CL_IMG_INSTALL    (/usr/lib/python2.7/site-packages/ansible/modules/network/cumulus/_cl_img_install.py)

  install a different version of Cumulus Linux in the inactive slot. For more details go the Image Management User Guide
  at http://docs.cumulusnetworks.com/.

DEPRECATED: 
Deprecated in 2.3. The image slot system no longer exists in Cumulus Linux.

Options (= is mandatory):

= src
        The full path to the Cumulus Linux binary image. Can be a local path, http or https URL. If the code version is
        in the name of the file, the module will assume this is the version of code you wish to install.

- switch_slot
        Switch slots after installing the image. To run the installed code, reboot the switch.
        (Choices: yes, no)[Default: no]
- version
        Inform the module of the exact version one is installing. This overrides the automatic check of version in the
        file name. For example, if the binary file name is called CumulusLinux-2.2.3.bin, and version is set to '2.5.0',
        then the module will assume it is installing '2.5.0' not '2.2.3'. If version is not included, then the module
        will assume '2.2.3' is the version to install.
        [Default: None]
Requirements:  Cumulus Linux OS

EXAMPLES:
## Download and install the image from a webserver.
- name: Install image using using http url. Switch slots so the subsequent will load the new version
  cl_img_install:
    version: 2.0.1
    src: http://10.1.1.1/CumulusLinux-2.0.1.bin
    switch_slot: yes

## Copy the software from the ansible server to the switch.
## The module will get the code version from the filename
## The code will be installed in the alternate slot but the slot will not be primary
## A subsequent reload will not run the new code

- name: Download cumulus linux to local system
  get_url:
    src: ftp://cumuluslinux.bin
    dest: /root/CumulusLinux-2.0.1.bin

- name: Install image from local filesystem. Get version from the filename.
  cl_img_install:
    src: /root/CumulusLinux-2.0.1.bin

## If the image name has been changed from the original name, use the `version` option
## to inform the module exactly what code version is been installed

- name: Download cumulus linux to local system
  get_url:
    src: ftp://CumulusLinux-2.0.1.bin
    dest: /root/image.bin

- name: install image and switch slots. Only reboot needed
  cl_img_install:
    version: 2.0.1
    src: /root/image.bin
    switch_slot: yes

RETURN VALUES:
changed:
    description: whether the interface was changed
    returned: changed
    type: bool
    sample: True
msg:
    description: human-readable report of success or failure
    returned: always
    type: string
    sample: "interface bond0 config updated"


MAINTAINERS: Cumulus Networks (@CumulusLinux)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> CL_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/cumulus/_cl_interface.py)

  Configures a front panel, sub-interface, SVI, management or loopback port on a Cumulus Linux switch. For bridge ports
  use the cl_bridge module. For bond ports use the cl_bond module. When configuring bridge related features like the
  "vid" option, please follow the guidelines for configuring "vlan aware" bridging. For more details review the Layer2
  Interface Guide at http://docs.cumulusnetworks.com

DEPRECATED: 
Deprecated in 2.3. Use M(nclu) instead.

Options (= is mandatory):

- addr_method
        Address method.
        (Choices: loopback, dhcp)[Default: (null)]
- alias_name
        Description of the port.
        [Default: (null)]
- clagd_enable
        Enables the clagd daemon. This command should only be applied to the clag peerlink interface.
        [Default: (null)]
- clagd_peer_ip
        IP address of the directly connected peer switch interface.
        [Default: (null)]
- clagd_priority
        Integer that changes the role the switch has in the clag domain. The lower priority switch will assume the
        primary role. The number can be between 0 and 65535.
        [Default: (null)]
- clagd_sys_mac
        Clagd system mac address. Recommended to use the range starting with 44:38:39:ff. Needs to be the same between 2
        Clag switches.
        [Default: (null)]
- ipv4
        List of IPv4 addresses to configure on the interface. In the form `X.X.X.X/YY'.
        [Default: (null)]
- ipv6
        List of IPv6 addresses to configure on the interface. In the form `X:X:X::X/YYY'.
        [Default: (null)]
- location
        Interface directory location
        [Default: [u'/etc/network/interfaces.d']]
- mstpctl_bpduguard
        Enables BPDU Guard on a port in vlan-aware mode.
        [Default: (null)]
- mstpctl_portadminedge
        Enables admin edge port.
        [Default: (null)]
- mstpctl_portnetwork
        Enables bridge assurance in vlan-aware mode.
        [Default: (null)]
- mtu
        Set MTU. Configure Jumbo Frame by setting MTU to `9000'.
        [Default: (null)]
= name
        Name of the interface.

- pvid
        In vlan-aware mode, defines vlan that is the untagged vlan.
        [Default: (null)]
- speed
        Set speed of the swp(front panel) or management(eth0) interface. speed is in MB.
        [Default: (null)]
- vids
        In vlan-aware mode, lists VLANs defined under the interface.
        [Default: (null)]
- virtual_ip
        Define IPv4 virtual IP used by the Cumulus Linux VRR feature.
        [Default: (null)]
- virtual_mac
        Define Ethernet mac associated with Cumulus Linux VRR feature.
        [Default: (null)]
Notes:
  * As this module writes the interface directory location, ensure that ``/etc/network/interfaces`` has a 'source
        /etc/network/interfaces.d/\*' or whatever path is mentioned in the ``location`` attribute.
  * For the config to be activated, i.e installed in the kernel, "service networking reload" needs be be executed.
        See EXAMPLES section.
Requirements:  Alternate Debian network interface manager - ifupdown2 @ github.com/CumulusNetworks/ifupdown2

EXAMPLES:
# Options ['virtual_mac', 'virtual_ip'] are required together
- name: Configure a front panel port with an IP
  cl_interface:
    name: swp1
    ipv4: 10.1.1.1/24
  notify: reload networking

- name: Configure front panel to use DHCP
  cl_interface:
    name: swp2
    addr_family: dhcp
  notify: reload networking

- name: Configure a SVI for vlan 100 interface with an IP
  cl_interface:
    name: bridge.100
    ipv4: 10.1.1.1/24
  notify: reload networking

- name: Configure subinterface with an IP
  cl_interface:
    name: bond0.100
    alias_name: my bond
    ipv4: 10.1.1.1/24
  notify: reload networking

# define cl_interfaces once in tasks
# then write interfaces in variables file
# with just the options you want.
- name: Create interfaces
  cl_interface:
      name: '{{ item.key }}'
      ipv4: '{{ item.value.ipv4 | default(omit) }}'
      ipv6: '{{ item.value.ipv6 | default(omit) }}'
      alias_name: '{{ item.value.alias_name | default(omit) }}'
      addr_method: '{{ item.value.addr_method | default(omit) }}'
      speed: '{{ item.value.link_speed | default(omit) }}'
      mtu: '{{ item.value.mtu | default(omit) }}'
      clagd_enable: '{{ item.value.clagd_enable | default(omit) }}'
      clagd_peer_ip: '{{ item.value.clagd_peer_ip | default(omit) }}'
      clagd_sys_mac: '{{ item.value.clagd_sys_mac | default(omit) }}'
      clagd_priority: '{{ item.value.clagd_priority | default(omit) }}'
      vids: '{{ item.value.vids | default(omit) }}'
      virtual_ip: '{{ item.value.virtual_ip | default(omit) }}'
      virtual_mac: '{{ item.value.virtual_mac | default(omit) }}'
      mstpctl_portnetwork: "{{ item.value.mstpctl_portnetwork | default('no') }}"
      mstpctl_portadminedge: "{{ item.value.mstpctl_portadminedge | default('no') }}"
      mstpctl_bpduguard: "{{ item.value.mstpctl_bpduguard | default('no') }}"
  with_dict: '{{ cl_interfaces }}'
  notify: reload networking

# In vars file
# ============
---
cl_interfaces:
  swp1:
    alias_name: uplink to isp
    ipv4: 10.1.1.1/24
  swp2:
    alias_name: l2 trunk connection
    vids:
      - 1
      - 50
  swp3:
    speed: 1000
    alias_name: connects to 1G link
##########
#   br0 interface is configured by cl_bridge
##########
  br0.100:
    alias_name: SVI for vlan 100
    ipv4: 10.2.2.2/24
    ipv6: '10:2:2::2/127'
    virtual_ip: 10.2.2.254
    virtual_mac: 00:00:5E:00:10:10

RETURN VALUES:
changed:
    description: whether the interface was changed
    returned: changed
    type: bool
    sample: True
msg:
    description: human-readable report of success or failure
    returned: always
    type: string
    sample: "interface bond0 config updated"


MAINTAINERS: Cumulus Networks (@CumulusNetworks)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> CL_INTERFACE_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/network/cumulus/_cl_interface_policy.py)

  This module affects the configuration files located in the interfaces folder defined by ifupdown2. Interfaces port and
  port ranges listed in the "allowed" parameter define what interfaces will be available on the switch. If the user runs
  this module and has an interface configured on the switch, but not found in the "allowed" list, this interface will be
  unconfigured. By default this is `/etc/network/interface.d` For more details go the Configuring Interfaces at
  http://docs.cumulusnetworks.com.

DEPRECATED: 
Deprecated in 2.3. Use M(nclu) instead.

Options (= is mandatory):

= allowed
        List of ports to run initial run at 10G.

- location
        Directory to store interface files.
        [Default: /etc/network/interfaces.d/]
Notes:
  * lo must be included in the allowed list.
  * eth0 must be in allowed list if out of band management is done
EXAMPLES:
# Example playbook entries using the cl_interface_policy module.

    - name: shows types of interface ranges supported
      cl_interface_policy:
          allowed: "lo eth0 swp1-9, swp11, swp12-13s0, swp12-30s1, swp12-30s2, bond0-12"


RETURN VALUES:
changed:
    description: whether the interface was changed
    returned: changed
    type: bool
    sample: True
msg:
    description: human-readable report of success or failure
    returned: always
    type: string
    sample: "interface bond0 config updated"


MAINTAINERS: Cumulus Networks (@CumulusNetworks)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> CL_LICENSE    (/usr/lib/python2.7/site-packages/ansible/modules/network/cumulus/_cl_license.py)

  Installs a Cumulus Linux license. The module reports no change of status when a license is installed. For more details
  go the Cumulus Linux License Documentation at http://docs.cumulusnetwork.com and the Licensing KB Site at
  https://support.cumulusnetworks.com/hc/en-us/sections/200507688

DEPRECATED: 
Deprecated in 2.3.

Options (= is mandatory):

- force
        Force installation of a license. Typically not needed. It is recommended to manually run this command via the
        ansible command. A reload of switchd is not required. Running the force option in a playbook will break the
        idempotent state machine of the module and cause the switchd notification to kick in all the time, causing a
        disruption.
        (Choices: True, False)[Default: (null)]
= src
        The full path to the license. Can be local path or HTTP URL.

Notes:
  * To activate a license for the FIRST time, the switchd service must be restarted. This action is disruptive. The
        license renewal process occurs via the Cumulus Networks Customer Portal -
        http://customers.cumulusnetworks.com.
  * A non-EULA license is REQUIRED for automation. Manually install the license on a test switch, using the command
        "cl-license -i <license_file>" to confirm the license is a Non-EULA license. See EXAMPLES, for the proper
        way to issue this notify action.
EXAMPLES:
# Example playbook using the cl_license module to manage licenses on Cumulus Linux

- hosts: all
  tasks:
    - name: install license using http url
      cl_license:
        src: http://10.1.1.1/license.txt
      notify: restart switchd

    - name: Triggers switchd to be restarted right away, before play, or role
            is over. This is desired behaviour
      meta: flush_handlers

    - name: Configure interfaces
      template:
        src: interfaces.j2
        dest: /etc/network/interfaces
      notify: restart networking

  handlers:
   - name: restart switchd
     service:
      name: switchd
      state: restarted
   - name: restart networking
     service:
      name: networking
      state: reloaded

# Force all switches to accept a new license. Typically not needed
# ansible -m cl_license -a "src='http://10.1.1.1/new_lic' force=yes" -u root all

RETURN VALUES:
changed:
    description: whether the interface was changed
    returned: changed
    type: bool
    sample: True
msg:
    description: human-readable report of success or failure
    returned: always
    type: string
    sample: "interface bond0 config updated"


MAINTAINERS: Cumulus Networks (@CumulusNetworks)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> CL_PORTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/cumulus/_cl_ports.py)

  Set the initial port attribute defined in the Cumulus Linux ports.conf, file. This module does not do any error
  checking at the moment. Be careful to not include ports that do not exist on the switch. Carefully read the original
  ports.conf file for any exceptions or limitations. For more details go the Configure Switch Port Attribute
  Documentation at http://docs.cumulusnetworks.com.

DEPRECATED: 
Deprecated in 2.3. Use M(nclu) instead.

Options (= is mandatory):

- speed_10g
        List of ports to run initial run at 10G.
        [Default: (null)]
- speed_40g
        List of ports to run initial run at 40G.
        [Default: (null)]
- speed_40g_div_4
        List of 10G ports that will be ganged to form a 40G port.
        [Default: (null)]
- speed_4_by_10g
        List of 40G ports that will be unganged to run as 4 10G ports.
        [Default: (null)]
EXAMPLES:
# Use cl_ports module to manage the switch attributes defined in the
# ports.conf file on Cumulus Linux

## Unganged port configuration on certain ports
- name: configure ports.conf setup
  cl_ports:
    speed_4_by_10g:
      - swp1
      - swp32
    speed_40g:
      - swp2-31

## Unganged port configuration on certain ports
- name: configure ports.conf setup
  cl_ports:
    speed_4_by_10g:
      - swp1-3
      - swp6
    speed_40g:
      - swp4-5
      - swp7-32

RETURN VALUES:
changed:
    description: whether the interface was changed
    returned: changed
    type: bool
    sample: True
msg:
    description: human-readable report of success or failure
    returned: always
    type: string
    sample: "interface bond0 config updated"


MAINTAINERS: Cumulus Networks (@CumulusNetworks)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> CLC_AA_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_aa_policy.py)

  An Ansible module to Create or Delete Anti Affinity Policies at CenturyLink Cloud.

Options (= is mandatory):

= location
        Datacenter in which the policy lives/should live.

= name
        The name of the Anti Affinity Policy.

- state
        Whether to create or delete the policy.
        (Choices: present, absent)[Default: present]
- wait
        Whether to wait for the tasks to finish before returning.
        (Choices: True, False)[Default: True]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
# Note - You must set the CLC_V2_API_USERNAME And CLC_V2_API_PASSWD Environment variables before running these examples

---
- name: Create AA Policy
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Create an Anti Affinity Policy
      clc_aa_policy:
        name: Hammer Time
        location: UK3
        state: present
      register: policy

    - name: debug
      debug:
        var: policy

---
- name: Delete AA Policy
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Delete an Anti Affinity Policy
      clc_aa_policy:
        name: Hammer Time
        location: UK3
        state: absent
      register: policy

    - name: debug
      debug:
        var: policy

RETURN VALUES:
policy:
    description: The anti affinity policy information
    returned: success
    type: dict
    sample:
        {
           "id":"1a28dd0988984d87b9cd61fa8da15424",
           "name":"test_aa_policy",
           "location":"UC1",
           "links":[
              {
                 "rel":"self",
                 "href":"/v2/antiAffinityPolicies/wfad/1a28dd0988984d87b9cd61fa8da15424",
                 "verbs":[
                    "GET",
                    "DELETE",
                    "PUT"
                 ]
              },
              {
                 "rel":"location",
                 "href":"/v2/datacenters/wfad/UC1",
                 "id":"uc1",
                 "name":"UC1 - US West (Santa Clara)"
              }
           ]
        }


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_ALERT_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_alert_policy.py)

  An Ansible module to Create or Delete Alert Policies at CenturyLink Cloud.

Options (= is mandatory):

- alert_recipients
        A list of recipient email ids to notify the alert. This is required for state 'present'
        [Default: None]
= alias
        The alias of your CLC Account

- duration
        The length of time in minutes that the condition must exceed the threshold. This is required for state 'present'
        [Default: None]
- id
        The alert policy id. This is mutually exclusive with name
        [Default: None]
- metric
        The metric on which to measure the condition that will trigger the alert. This is required for state 'present'
        (Choices: cpu, memory, disk)[Default: None]
- name
        The name of the alert policy. This is mutually exclusive with id
        [Default: None]
- state
        Whether to create or delete the policy.
        (Choices: present, absent)[Default: present]
- threshold
        The threshold that will trigger the alert when the metric equals or exceeds it. This is required for state
        'present' This number represents a percentage and must be a value between 5.0 - 95.0 that is a multiple of 5.0
        [Default: None]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
# Note - You must set the CLC_V2_API_USERNAME And CLC_V2_API_PASSWD Environment variables before running these examples

---
- name: Create Alert Policy Example
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Create an Alert Policy for disk above 80% for 5 minutes
      clc_alert_policy:
        alias: wfad
        name: 'alert for disk > 80%'
        alert_recipients:
            - test1@centurylink.com
            - test2@centurylink.com
        metric: 'disk'
        duration: '00:05:00'
        threshold: 80
        state: present
      register: policy

    - name: debug
      debug: var=policy

---
- name: Delete Alert Policy Example
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Delete an Alert Policy
      clc_alert_policy:
        alias: wfad
        name: 'alert for disk > 80%'
        state: absent
      register: policy

    - name: debug
      debug: var=policy

RETURN VALUES:
policy:
    description: The alert policy information
    returned: success
    type: dict
    sample:
        {
            "actions": [
                {
                "action": "email",
                "settings": {
                    "recipients": [
                        "user1@domain.com",
                        "user1@domain.com"
                    ]
                }
                }
            ],
            "id": "ba54ac54a60d4a4f1ed6d48c1ce240a7",
            "links": [
                {
                "href": "/v2/alertPolicies/alias/ba54ac54a60d4a4fb1d6d48c1ce240a7",
                "rel": "self",
                "verbs": [
                    "GET",
                    "DELETE",
                    "PUT"
                ]
                }
            ],
            "name": "test_alert",
            "triggers": [
                {
                "duration": "00:05:00",
                "metric": "disk",
                "threshold": 80.0
                }
            ]
        }


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_BLUEPRINT_PACKAGE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_blueprint_package.py)

  An Ansible module to deploy blue print package on a set of servers in CenturyLink Cloud.

Options (= is mandatory):

= package_id
        The package id of the blue print.

- package_params
        The dictionary of arguments required to deploy the blue print.
        [Default: {}]
= server_ids
        A list of server Ids to deploy the blue print package.

- state
        Whether to install or un-install the package. Currently it supports only "present" for install action.
        (Choices: present)[Default: present]
- wait
        Whether to wait for the tasks to finish before returning.
        (Choices: True, False)[Default: True]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
# Note - You must set the CLC_V2_API_USERNAME And CLC_V2_API_PASSWD Environment variables before running these examples

- name: Deploy package
  clc_blueprint_package:
        server_ids:
            - UC1TEST-SERVER1
            - UC1TEST-SERVER2
        package_id: 77abb844-579d-478d-3955-c69ab4a7ba1a
        package_params: {}

RETURN VALUES:
server_ids:
    description: The list of server ids that are changed
    returned: success
    type: list
    sample:
        [
            "UC1TEST-SERVER1",
            "UC1TEST-SERVER2"
        ]


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_FIREWALL_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_firewall_policy.py)

  Create or delete or update firewall polices on Centurylink Cloud

Options (= is mandatory):

- destination
        The list of destination addresses for traffic on the terminating firewall. This is required when state is
        'present'
        [Default: None]
- destination_account_alias
        CLC alias for the destination account
        [Default: None]
- enabled
        Whether the firewall policy is enabled or disabled
        (Choices: True, False)[Default: True]
- firewall_policy_id
        Id of the firewall policy. This is required to update or delete an existing firewall policy
        [Default: None]
= location
        Target datacenter for the firewall policy

- ports
        The list of ports associated with the policy. TCP and UDP can take in single ports or port ranges.
        (Choices: any, icmp, TCP/123, UDP/123, TCP/123-456, UDP/123-456)[Default: None]
- source
        The list  of source addresses for traffic on the originating firewall. This is required when state is 'present"
        [Default: None]
= source_account_alias
        CLC alias for the source account

- state
        Whether to create or delete the firewall policy
        (Choices: present, absent)[Default: present]
- wait
        Whether to wait for the provisioning tasks to finish before returning.
        (Choices: True, False)[Default: True]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
---
- name: Create Firewall Policy
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Create / Verify an Firewall Policy at CenturyLink Cloud
      clc_firewall:
        source_account_alias: WFAD
        location: VA1
        state: present
        source: 10.128.216.0/24
        destination: 10.128.216.0/24
        ports: Any
        destination_account_alias: WFAD

---
- name: Delete Firewall Policy
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Delete an Firewall Policy at CenturyLink Cloud
      clc_firewall:
        source_account_alias: WFAD
        location: VA1
        state: absent
        firewall_policy_id: c62105233d7a4231bd2e91b9c791e43e1

RETURN VALUES:
firewall_policy_id:
    description: The fire wall policy id
    returned: success
    type: string
    sample: fc36f1bfd47242e488a9c44346438c05
firewall_policy:
    description: The fire wall policy information
    returned: success
    type: dict
    sample:
        {
           "destination":[
              "10.1.1.0/24",
              "10.2.2.0/24"
           ],
           "destinationAccount":"wfad",
           "enabled":true,
           "id":"fc36f1bfd47242e488a9c44346438c05",
           "links":[
              {
                 "href":"http://api.ctl.io/v2-experimental/firewallPolicies/wfad/uc1/fc36f1bfd47242e488a9c44346438c05",
                 "rel":"self",
                 "verbs":[
                    "GET",
                    "PUT",
                    "DELETE"
                 ]
              }
           ],
           "ports":[
              "any"
           ],
           "source":[
              "10.1.1.0/24",
              "10.2.2.0/24"
           ],
           "status":"active"
        }


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_group.py)

  Create or delete Server Groups at Centurylink Centurylink Cloud

Options (= is mandatory):

- description
        A description of the Server Group
        [Default: (null)]
- location
        Datacenter to create the group in. If location is not provided, the group gets created in the default datacenter
        associated with the account
        [Default: (null)]
= name
        The name of the Server Group

- parent
        The parent group of the server group. If parent is not provided, it creates the group at top level.
        [Default: (null)]
- state
        Whether to create or delete the group
        (Choices: present, absent)[Default: present]
- wait
        Whether to wait for the tasks to finish before returning.
        (Choices: True, False)[Default: True]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:

# Create a Server Group

---
- name: Create Server Group
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Create / Verify a Server Group at CenturyLink Cloud
      clc_group:
        name: My Cool Server Group
        parent: Default Group
        state: present
      register: clc

    - name: debug
      debug:
        var: clc

# Delete a Server Group

---
- name: Delete Server Group
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Delete / Verify Absent a Server Group at CenturyLink Cloud
      clc_group:
        name: My Cool Server Group
        parent: Default Group
        state: absent
      register: clc

    - name: debug
      debug:
        var: clc

RETURN VALUES:
group:
    description: The group information
    returned: success
    type: dict
    sample:
        {
           "changeInfo":{
              "createdBy":"service.wfad",
              "createdDate":"2015-07-29T18:52:47Z",
              "modifiedBy":"service.wfad",
              "modifiedDate":"2015-07-29T18:52:47Z"
           },
           "customFields":[

           ],
           "description":"test group",
           "groups":[

           ],
           "id":"bb5f12a3c6044ae4ad0a03e73ae12cd1",
           "links":[
              {
                 "href":"/v2/groups/wfad",
                 "rel":"createGroup",
                 "verbs":[
                    "POST"
                 ]
              },
              {
                 "href":"/v2/servers/wfad",
                 "rel":"createServer",
                 "verbs":[
                    "POST"
                 ]
              },
              {
                 "href":"/v2/groups/wfad/bb5f12a3c6044ae4ad0a03e73ae12cd1",
                 "rel":"self",
                 "verbs":[
                    "GET",
                    "PATCH",
                    "DELETE"
                 ]
              },
              {
                 "href":"/v2/groups/wfad/086ac1dfe0b6411989e8d1b77c4065f0",
                 "id":"086ac1dfe0b6411989e8d1b77c4065f0",
                 "rel":"parentGroup"
              },
              {
                 "href":"/v2/groups/wfad/bb5f12a3c6044ae4ad0a03e73ae12cd1/defaults",
                 "rel":"defaults",
                 "verbs":[
                    "GET",
                    "POST"
                 ]
              },
              {
                 "href":"/v2/groups/wfad/bb5f12a3c6044ae4ad0a03e73ae12cd1/billing",
                 "rel":"billing"
              },
              {
                 "href":"/v2/groups/wfad/bb5f12a3c6044ae4ad0a03e73ae12cd1/archive",
                 "rel":"archiveGroupAction"
              },
              {
                 "href":"/v2/groups/wfad/bb5f12a3c6044ae4ad0a03e73ae12cd1/statistics",
                 "rel":"statistics"
              },
              {
                 "href":"/v2/groups/wfad/bb5f12a3c6044ae4ad0a03e73ae12cd1/upcomingScheduledActivities",
                 "rel":"upcomingScheduledActivities"
              },
              {
                 "href":"/v2/groups/wfad/bb5f12a3c6044ae4ad0a03e73ae12cd1/horizontalAutoscalePolicy",
                 "rel":"horizontalAutoscalePolicyMapping",
                 "verbs":[
                    "GET",
                    "PUT",
                    "DELETE"
                 ]
              },
              {
                 "href":"/v2/groups/wfad/bb5f12a3c6044ae4ad0a03e73ae12cd1/scheduledActivities",
                 "rel":"scheduledActivities",
                 "verbs":[
                    "GET",
                    "POST"
                 ]
              }
           ],
           "locationId":"UC1",
           "name":"test group",
           "status":"active",
           "type":"default"
        }


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_LOADBALANCER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_loadbalancer.py)

  An Ansible module to Create, Delete shared loadbalancers in CenturyLink Cloud.

Options (= is mandatory):

= alias
        The alias of your CLC Account

- description
        A description for the loadbalancer
        [Default: None]
= location
        The location of the datacenter where the load balancer resides in

- method
        -The balancing method for the load balancer pool
        (Choices: leastConnection, roundRobin)[Default: None]
= name
        The name of the loadbalancer

- nodes
        A list of nodes that needs to be added to the load balancer pool
        [Default: []]
- persistence
        The persistence method for the load balancer
        (Choices: standard, sticky)[Default: None]
- port
        Port to configure on the public-facing side of the load balancer pool
        (Choices: 80, 443)[Default: None]
- state
        Whether to create or delete the load balancer pool
        (Choices: present, absent, port_absent, nodes_present, nodes_absent)[Default: present]
- status
        The status of the loadbalancer
        (Choices: enabled, disabled)[Default: enabled]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
# Note - You must set the CLC_V2_API_USERNAME And CLC_V2_API_PASSWD Environment variables before running these examples
- name: Create Loadbalancer
  hosts: localhost
  connection: local
  tasks:
    - name: Actually Create things
      clc_loadbalancer:
        name: test
        description: test
        alias: TEST
        location: WA1
        port: 443
        nodes:
          - ipAddress: 10.11.22.123
            privatePort: 80
        state: present

- name: Add node to an existing loadbalancer pool
  hosts: localhost
  connection: local
  tasks:
    - name: Actually Create things
      clc_loadbalancer:
        name: test
        description: test
        alias: TEST
        location: WA1
        port: 443
        nodes:
          - ipAddress: 10.11.22.234
            privatePort: 80
        state: nodes_present

- name: Remove node from an existing loadbalancer pool
  hosts: localhost
  connection: local
  tasks:
    - name: Actually Create things
      clc_loadbalancer:
        name: test
        description: test
        alias: TEST
        location: WA1
        port: 443
        nodes:
          - ipAddress: 10.11.22.234
            privatePort: 80
        state: nodes_absent

- name: Delete LoadbalancerPool
  hosts: localhost
  connection: local
  tasks:
    - name: Actually Delete things
      clc_loadbalancer:
        name: test
        description: test
        alias: TEST
        location: WA1
        port: 443
        nodes:
          - ipAddress: 10.11.22.123
            privatePort: 80
        state: port_absent

- name: Delete Loadbalancer
  hosts: localhost
  connection: local
  tasks:
    - name: Actually Delete things
      clc_loadbalancer:
        name: test
        description: test
        alias: TEST
        location: WA1
        port: 443
        nodes:
          - ipAddress: 10.11.22.123
            privatePort: 80
        state: absent

RETURN VALUES:
loadbalancer:
    description: The load balancer result object from CLC
    returned: success
    type: dict
    sample:
        {
           "description":"test-lb",
           "id":"ab5b18cb81e94ab9925b61d1ca043fb5",
           "ipAddress":"66.150.174.197",
           "links":[
              {
                 "href":"/v2/sharedLoadBalancers/wfad/wa1/ab5b18cb81e94ab9925b61d1ca043fb5",
                 "rel":"self",
                 "verbs":[
                    "GET",
                    "PUT",
                    "DELETE"
                 ]
              },
              {
                 "href":"/v2/sharedLoadBalancers/wfad/wa1/ab5b18cb81e94ab9925b61d1ca043fb5/pools",
                 "rel":"pools",
                 "verbs":[
                    "GET",
                    "POST"
                 ]
              }
           ],
           "name":"test-lb",
           "pools":[

           ],
           "status":"enabled"
        }


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_MODIFY_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_modify_server.py)

  An Ansible module to modify servers in CenturyLink Cloud.

Options (= is mandatory):

- alert_policy_id
        The alert policy id to be associated to the server. This is mutually exclusive with 'alert_policy_name'
        [Default: None]
- alert_policy_name
        The alert policy name to be associated to the server. This is mutually exclusive with 'alert_policy_id'
        [Default: None]
- anti_affinity_policy_id
        The anti affinity policy id to be set for a hyper scale server. This is mutually exclusive with
        'anti_affinity_policy_name'
        [Default: None]
- anti_affinity_policy_name
        The anti affinity policy name to be set for a hyper scale server. This is mutually exclusive with
        'anti_affinity_policy_id'
        [Default: None]
- cpu
        How many CPUs to update on the server
        [Default: None]
- memory
        Memory (in GB) to set to the server.
        [Default: None]
= server_ids
        A list of server Ids to modify.

- state
        The state to insure that the provided resources are in.
        (Choices: present, absent)[Default: present]
- wait
        Whether to wait for the provisioning tasks to finish before returning.
        (Choices: True, False)[Default: True]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
# Note - You must set the CLC_V2_API_USERNAME And CLC_V2_API_PASSWD Environment variables before running these examples

- name: set the cpu count to 4 on a server
  clc_modify_server:
    server_ids:
        - UC1TESTSVR01
        - UC1TESTSVR02
    cpu: 4
    state: present

- name: set the memory to 8GB on a server
  clc_modify_server:
    server_ids:
        - UC1TESTSVR01
        - UC1TESTSVR02
    memory: 8
    state: present

- name: set the anti affinity policy on a server
  clc_modify_server:
    server_ids:
        - UC1TESTSVR01
        - UC1TESTSVR02
    anti_affinity_policy_name: 'aa_policy'
    state: present

- name: remove the anti affinity policy on a server
  clc_modify_server:
    server_ids:
        - UC1TESTSVR01
        - UC1TESTSVR02
    anti_affinity_policy_name: 'aa_policy'
    state: absent

- name: add the alert policy on a server
  clc_modify_server:
    server_ids:
        - UC1TESTSVR01
        - UC1TESTSVR02
    alert_policy_name: 'alert_policy'
    state: present

- name: remove the alert policy on a server
  clc_modify_server:
    server_ids:
        - UC1TESTSVR01
        - UC1TESTSVR02
    alert_policy_name: 'alert_policy'
    state: absent

- name: set the memory to 16GB and cpu to 8 core on a lust if servers
  clc_modify_server:
    server_ids:
        - UC1TESTSVR01
        - UC1TESTSVR02
    cpu: 8
    memory: 16
    state: present

RETURN VALUES:
server_ids:
    description: The list of server ids that are changed
    returned: success
    type: list
    sample:
        [
            "UC1TEST-SVR01",
            "UC1TEST-SVR02"
        ]
servers:
    description: The list of server objects that are changed
    returned: success
    type: list
    sample:
        [
           {
              "changeInfo":{
                 "createdBy":"service.wfad",
                 "createdDate":1438196820,
                 "modifiedBy":"service.wfad",
                 "modifiedDate":1438196820
              },
              "description":"test-server",
              "details":{
                 "alertPolicies":[

                 ],
                 "cpu":1,
                 "customFields":[

                 ],
                 "diskCount":3,
                 "disks":[
                    {
                       "id":"0:0",
                       "partitionPaths":[

                       ],
                       "sizeGB":1
                    },
                    {
                       "id":"0:1",
                       "partitionPaths":[

                       ],
                       "sizeGB":2
                    },
                    {
                       "id":"0:2",
                       "partitionPaths":[

                       ],
                       "sizeGB":14
                    }
                 ],
                 "hostName":"",
                 "inMaintenanceMode":false,
                 "ipAddresses":[
                    {
                       "internal":"10.1.1.1"
                    }
                 ],
                 "memoryGB":1,
                 "memoryMB":1024,
                 "partitions":[

                 ],
                 "powerState":"started",
                 "snapshots":[

                 ],
                 "storageGB":17
              },
              "groupId":"086ac1dfe0b6411989e8d1b77c4065f0",
              "id":"test-server",
              "ipaddress":"10.120.45.23",
              "isTemplate":false,
              "links":[
                 {
                    "href":"/v2/servers/wfad/test-server",
                    "id":"test-server",
                    "rel":"self",
                    "verbs":[
                       "GET",
                       "PATCH",
                       "DELETE"
                    ]
                 },
                 {
                    "href":"/v2/groups/wfad/086ac1dfe0b6411989e8d1b77c4065f0",
                    "id":"086ac1dfe0b6411989e8d1b77c4065f0",
                    "rel":"group"
                 },
                 {
                    "href":"/v2/accounts/wfad",
                    "id":"wfad",
                    "rel":"account"
                 },
                 {
                    "href":"/v2/billing/wfad/serverPricing/test-server",
                    "rel":"billing"
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/publicIPAddresses",
                    "rel":"publicIPAddresses",
                    "verbs":[
                       "POST"
                    ]
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/credentials",
                    "rel":"credentials"
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/statistics",
                    "rel":"statistics"
                 },
                 {
                    "href":"/v2/servers/wfad/510ec21ae82d4dc89d28479753bf736a/upcomingScheduledActivities",
                    "rel":"upcomingScheduledActivities"
                 },
                 {
                    "href":"/v2/servers/wfad/510ec21ae82d4dc89d28479753bf736a/scheduledActivities",
                    "rel":"scheduledActivities",
                    "verbs":[
                       "GET",
                       "POST"
                    ]
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/capabilities",
                    "rel":"capabilities"
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/alertPolicies",
                    "rel":"alertPolicyMappings",
                    "verbs":[
                       "POST"
                    ]
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/antiAffinityPolicy",
                    "rel":"antiAffinityPolicyMapping",
                    "verbs":[
                       "PUT",
                       "DELETE"
                    ]
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/cpuAutoscalePolicy",
                    "rel":"cpuAutoscalePolicyMapping",
                    "verbs":[
                       "PUT",
                       "DELETE"
                    ]
                 }
              ],
              "locationId":"UC1",
              "name":"test-server",
              "os":"ubuntu14_64Bit",
              "osType":"Ubuntu 14 64-bit",
              "status":"active",
              "storageType":"standard",
              "type":"standard"
           }
        ]


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_PUBLICIP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_publicip.py)

  An Ansible module to add or delete public ip addresses on an existing server or servers in CenturyLink Cloud.

Options (= is mandatory):

- ports
        A list of ports to expose. This is required when state is 'present'
        [Default: None]
- protocol
        The protocol that the public IP will listen for.
        (Choices: TCP, UDP, ICMP)[Default: TCP]
= server_ids
        A list of servers to create public ips on.

- state
        Determine whether to create or delete public IPs. If present module will not create a second public ip if one
        already exists.
        (Choices: present, absent)[Default: present]
- wait
        Whether to wait for the tasks to finish before returning.
        (Choices: True, False)[Default: True]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
# Note - You must set the CLC_V2_API_USERNAME And CLC_V2_API_PASSWD Environment variables before running these examples

- name: Add Public IP to Server
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Create Public IP For Servers
      clc_publicip:
        protocol: TCP
        ports:
          - 80
        server_ids:
          - UC1TEST-SVR01
          - UC1TEST-SVR02
        state: present
      register: clc

    - name: debug
      debug:
        var: clc

- name: Delete Public IP from Server
  hosts: localhost
  gather_facts: False
  connection: local
  tasks:
    - name: Create Public IP For Servers
      clc_publicip:
        server_ids:
          - UC1TEST-SVR01
          - UC1TEST-SVR02
        state: absent
      register: clc

    - name: debug
      debug:
        var: clc

RETURN VALUES:
server_ids:
    description: The list of server ids that are changed
    returned: success
    type: list
    sample:
        [
            "UC1TEST-SVR01",
            "UC1TEST-SVR02"
        ]


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_server.py)

  An Ansible module to Create, Delete, Start and Stop servers in CenturyLink Cloud.

Options (= is mandatory):

- add_public_ip
        Whether to add a public ip to the server
        (Choices: False, True)[Default: False]
- additional_disks
        The list of additional disks for the server
        [Default: []]
- alert_policy_id
        The alert policy to assign to the server. This is mutually exclusive with 'alert_policy_name'.
        [Default: None]
- alert_policy_name
        The alert policy to assign to the server. This is mutually exclusive with 'alert_policy_id'.
        [Default: None]
- alias
        The account alias to provision the servers under.
        [Default: None]
- anti_affinity_policy_id
        The anti-affinity policy to assign to the server. This is mutually exclusive with 'anti_affinity_policy_name'.
        [Default: None]
- anti_affinity_policy_name
        The anti-affinity policy to assign to the server. This is mutually exclusive with 'anti_affinity_policy_id'.
        [Default: None]
- configuration_id
        Only required for bare metal servers. Specifies the identifier for the specific configuration type of bare metal
        server to deploy.
        [Default: None]
- count
        The number of servers to build (mutually exclusive with exact_count)
        [Default: 1]
- count_group
        Required when exact_count is specified.  The Server Group use to determine how many severs to deploy.
        [Default: None]
- cpu
        How many CPUs to provision on the server
        [Default: 1]
- cpu_autoscale_policy_id
        The autoscale policy to assign to the server.
        [Default: None]
- custom_fields
        The list of custom fields to set on the server.
        [Default: []]
- description
        The description to set for the server.
        [Default: None]
- exact_count
        Run in idempotent mode.  Will insure that this exact number of servers are running in the provided group,
        creating and deleting them to reach that count.  Requires count_group to be set.
        [Default: None]
- group
        The Server Group to create servers under.
        [Default: Default Group]
- ip_address
        The IP Address for the server. One is assigned if not provided.
        [Default: None]
- location
        The Datacenter to create servers in.
        [Default: None]
- managed_os
        Whether to create the server as 'Managed' or not.
        (Choices: True, False)[Default: False]
- memory
        Memory in GB.
        [Default: 1]
- name
        A 1 to 6 character identifier to use for the server. This is required when state is 'present'
        [Default: None]
- network_id
        The network UUID on which to create servers.
        [Default: None]
- os_type
        Only required for bare metal servers. Specifies the OS to provision with the bare metal server.
        (Choices: redHat6_64Bit, centOS6_64Bit, windows2012R2Standard_64Bit, ubuntu14_64Bit)[Default: None]
- packages
        The list of blue print packages to run on the server after its created.
        [Default: []]
- password
        Password for the administrator / root user
        [Default: None]
- primary_dns
        Primary DNS used by the server.
        [Default: None]
- public_ip_ports
        A list of ports to allow on the firewall to the servers public ip, if add_public_ip is set to True.
        [Default: []]
- public_ip_protocol
        The protocol to use for the public ip if add_public_ip is set to True.
        (Choices: TCP, UDP, ICMP)[Default: TCP]
- secondary_dns
        Secondary DNS used by the server.
        [Default: None]
- server_ids
        Required for started, stopped, and absent states. A list of server Ids to insure are started, stopped, or absent.
        [Default: []]
- source_server_password
        The password for the source server if a clone is specified.
        [Default: None]
- state
        The state to insure that the provided resources are in.
        (Choices: present, absent, started, stopped)[Default: present]
- storage_type
        The type of storage to attach to the server.
        (Choices: standard, hyperscale)[Default: standard]
- template
        The template to use for server creation.  Will search for a template if a partial string is provided. This is
        required when state is 'present'
        [Default: None]
- ttl
        The time to live for the server in seconds.  The server will be deleted when this time expires.
        [Default: None]
- type
        The type of server to create.
        (Choices: standard, hyperscale, bareMetal)[Default: standard]
- wait
        Whether to wait for the provisioning tasks to finish before returning.
        (Choices: True, False)[Default: True]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
# Note - You must set the CLC_V2_API_USERNAME And CLC_V2_API_PASSWD Environment variables before running these examples

- name: Provision a single Ubuntu Server
  clc_server:
    name: test
    template: ubuntu-14-64
    count: 1
    group: Default Group
    state: present

- name: Ensure 'Default Group' has exactly 5 servers
  clc_server:
    name: test
    template: ubuntu-14-64
    exact_count: 5
    count_group: Default Group
    group: Default Group

- name: Stop a Server
  clc_server:
    server_ids:
      - UC1ACCT-TEST01
    state: stopped

- name: Start a Server
  clc_server:
    server_ids:
      - UC1ACCT-TEST01
    state: started

- name: Delete a Server
  clc_server:
    server_ids:
      - UC1ACCT-TEST01
    state: absent

RETURN VALUES:
server_ids:
    description: The list of server ids that are created
    returned: success
    type: list
    sample:
        [
            "UC1TEST-SVR01",
            "UC1TEST-SVR02"
        ]
partially_created_server_ids:
    description: The list of server ids that are partially created
    returned: success
    type: list
    sample:
        [
            "UC1TEST-SVR01",
            "UC1TEST-SVR02"
        ]
servers:
    description: The list of server objects returned from CLC
    returned: success
    type: list
    sample:
        [
           {
              "changeInfo":{
                 "createdBy":"service.wfad",
                 "createdDate":1438196820,
                 "modifiedBy":"service.wfad",
                 "modifiedDate":1438196820
              },
              "description":"test-server",
              "details":{
                 "alertPolicies":[

                 ],
                 "cpu":1,
                 "customFields":[

                 ],
                 "diskCount":3,
                 "disks":[
                    {
                       "id":"0:0",
                       "partitionPaths":[

                       ],
                       "sizeGB":1
                    },
                    {
                       "id":"0:1",
                       "partitionPaths":[

                       ],
                       "sizeGB":2
                    },
                    {
                       "id":"0:2",
                       "partitionPaths":[

                       ],
                       "sizeGB":14
                    }
                 ],
                 "hostName":"",
                 "inMaintenanceMode":false,
                 "ipAddresses":[
                    {
                       "internal":"10.1.1.1"
                    }
                 ],
                 "memoryGB":1,
                 "memoryMB":1024,
                 "partitions":[

                 ],
                 "powerState":"started",
                 "snapshots":[

                 ],
                 "storageGB":17
              },
              "groupId":"086ac1dfe0b6411989e8d1b77c4065f0",
              "id":"test-server",
              "ipaddress":"10.120.45.23",
              "isTemplate":false,
              "links":[
                 {
                    "href":"/v2/servers/wfad/test-server",
                    "id":"test-server",
                    "rel":"self",
                    "verbs":[
                       "GET",
                       "PATCH",
                       "DELETE"
                    ]
                 },
                 {
                    "href":"/v2/groups/wfad/086ac1dfe0b6411989e8d1b77c4065f0",
                    "id":"086ac1dfe0b6411989e8d1b77c4065f0",
                    "rel":"group"
                 },
                 {
                    "href":"/v2/accounts/wfad",
                    "id":"wfad",
                    "rel":"account"
                 },
                 {
                    "href":"/v2/billing/wfad/serverPricing/test-server",
                    "rel":"billing"
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/publicIPAddresses",
                    "rel":"publicIPAddresses",
                    "verbs":[
                       "POST"
                    ]
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/credentials",
                    "rel":"credentials"
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/statistics",
                    "rel":"statistics"
                 },
                 {
                    "href":"/v2/servers/wfad/510ec21ae82d4dc89d28479753bf736a/upcomingScheduledActivities",
                    "rel":"upcomingScheduledActivities"
                 },
                 {
                    "href":"/v2/servers/wfad/510ec21ae82d4dc89d28479753bf736a/scheduledActivities",
                    "rel":"scheduledActivities",
                    "verbs":[
                       "GET",
                       "POST"
                    ]
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/capabilities",
                    "rel":"capabilities"
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/alertPolicies",
                    "rel":"alertPolicyMappings",
                    "verbs":[
                       "POST"
                    ]
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/antiAffinityPolicy",
                    "rel":"antiAffinityPolicyMapping",
                    "verbs":[
                       "PUT",
                       "DELETE"
                    ]
                 },
                 {
                    "href":"/v2/servers/wfad/test-server/cpuAutoscalePolicy",
                    "rel":"cpuAutoscalePolicyMapping",
                    "verbs":[
                       "PUT",
                       "DELETE"
                    ]
                 }
              ],
              "locationId":"UC1",
              "name":"test-server",
              "os":"ubuntu14_64Bit",
              "osType":"Ubuntu 14 64-bit",
              "status":"active",
              "storageType":"standard",
              "type":"standard"
           }
        ]


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLC_SERVER_SNAPSHOT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/centurylink/clc_server_snapshot.py)

  An Ansible module to Create, Delete and Restore server snapshots in CenturyLink Cloud.

Options (= is mandatory):

- expiration_days
        The number of days to keep the server snapshot before it expires.
        [Default: 7]
= server_ids
        The list of CLC server Ids.

- state
        The state to insure that the provided resources are in.
        (Choices: present, absent, restore)[Default: present]
- wait
        Whether to wait for the provisioning tasks to finish before returning.
        (Choices: True, False)[Default: True]
Notes:
  * To use this module, it is required to set the below environment variables which enables access to the
        Centurylink Cloud - CLC_V2_API_USERNAME, the account login id for the centurylink cloud -
        CLC_V2_API_PASSWORD, the account password for the centurylink cloud
  * Alternatively, the module accepts the API token and account alias. The API token can be generated using the CLC
        account login and password via the HTTP api call @ https://api.ctl.io/v2/authentication/login -
        CLC_V2_API_TOKEN, the API token generated from https://api.ctl.io/v2/authentication/login - CLC_ACCT_ALIAS,
        the account alias associated with the centurylink cloud
  * Users can set CLC_V2_API_URL to specify an endpoint for pointing to a different CLC environment.
Requirements:  python = 2.7, requests >= 2.5.0, clc-sdk

EXAMPLES:
# Note - You must set the CLC_V2_API_USERNAME And CLC_V2_API_PASSWD Environment variables before running these examples

- name: Create server snapshot
  clc_server_snapshot:
    server_ids:
        - UC1TEST-SVR01
        - UC1TEST-SVR02
    expiration_days: 10
    wait: True
    state: present

- name: Restore server snapshot
  clc_server_snapshot:
    server_ids:
        - UC1TEST-SVR01
        - UC1TEST-SVR02
    wait: True
    state: restore

- name: Delete server snapshot
  clc_server_snapshot:
    server_ids:
        - UC1TEST-SVR01
        - UC1TEST-SVR02
    wait: True
    state: absent

RETURN VALUES:
server_ids:
    description: The list of server ids that are changed
    returned: success
    type: list
    sample:
        [
            "UC1TEST-SVR01",
            "UC1TEST-SVR02"
        ]


MAINTAINERS: CLC Runner (@clc-runner)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLOUDFLARE_DNS    (/usr/lib/python2.7/site-packages/ansible/modules/network/cloudflare_dns.py)

  Manages dns records via the Cloudflare API, see the docs: https://api.cloudflare.com/

Options (= is mandatory):

= account_api_token
        Account API token. You can obtain your API key from the bottom of the Cloudflare 'My Account' page, found here:
        https://www.cloudflare.com/a/account

= account_email
        Account email.

- port
        Service port. Required for `type=SRV'
        [Default: None]
- priority
        Record priority. Required for `type=MX' and `type=SRV'
        [Default: 1]
- proto
        Service protocol. Required for `type=SRV'
        (Choices: tcp, udp)[Default: None]
- proxied
        Proxy through cloudflare network or just use DNS
        [Default: False]
- record
        Record to add. Required if `state=present'. Default is `@' (e.g. the zone name)
        [Default: @]
- service
        Record service. Required for `type=SRV'
        [Default: None]
- solo
        Whether the record should be the only one for that record type and record name. Only use with `state=present'
        This will delete all other records with the same record name and type.
        [Default: None]
- state
        Whether the record(s) should exist or not
        (Choices: present, absent)[Default: present]
- timeout
        Timeout for Cloudflare API calls
        [Default: 30]
- ttl
        The TTL to give the new record. Must be between 120 and 2,147,483,647 seconds, or 1 for automatic.
        [Default: 1 (automatic)]
- type
        The type of DNS record to create. Required if `state=present'
        (Choices: A, AAAA, CNAME, TXT, SRV, MX, NS, SPF)[Default: None]
- value
        The record value. Required for `state=present'
        [Default: None]
- weight
        Service weight. Required for `type=SRV'
        [Default: 1]
= zone
        The name of the Zone to work with (e.g. "example.com"). The Zone must already exist.

Requirements:  python >= 2.6

EXAMPLES:
# create a test.my.com A record to point to 127.0.0.1
- cloudflare_dns:
    zone: my.com
    record: test
    type: A
    value: 127.0.0.1
    account_email: test@example.com
    account_api_token: dummyapitoken
  register: record

# create a my.com CNAME record to example.com
- cloudflare_dns:
    zone: my.com
    type: CNAME
    value: example.com
    state: present
    account_email: test@example.com
    account_api_token: dummyapitoken

# change it's ttl
- cloudflare_dns:
    zone: my.com
    type: CNAME
    value: example.com
    ttl: 600
    state: present
    account_email: test@example.com
    account_api_token: dummyapitoken

# and delete the record
- cloudflare_dns:
    zone: my.com
    type: CNAME
    value: example.com
    state: absent
    account_email: test@example.com
    account_api_token: dummyapitoken

# create a my.com CNAME record to example.com and proxy through cloudflare's network
- cloudflare_dns:
    zone: my.com
    type: CNAME
    value: example.com
    state: present
    proxied: yes
    account_email: test@example.com
    account_api_token: dummyapitoken

# create TXT record "test.my.com" with value "unique value"
# delete all other TXT records named "test.my.com"
- cloudflare_dns:
    domain: my.com
    record: test
    type: TXT
    value: unique value
    state: present
    solo: true
    account_email: test@example.com
    account_api_token: dummyapitoken

# create a SRV record _foo._tcp.my.com
- cloudflare_dns:
    domain: my.com
    service: foo
    proto: tcp
    port: 3500
    priority: 10
    weight: 20
    type: SRV
    value: fooserver.my.com

RETURN VALUES:
record:
    description: dictionary containing the record data
    returned: success, except on record deletion
    type: complex
    contains:
        content:
            description: the record content (details depend on record type)
            returned: success
            type: string
            sample: 192.0.2.91
        created_on:
            description: the record creation date
            returned: success
            type: string
            sample: 2016-03-25T19:09:42.516553Z
        data:
            description: additional record data
            returned: success, if type is SRV
            type: dictionary
            sample: {
                name: "jabber",
                port: 8080,
                priority: 10,
                proto: "_tcp",
                service: "_xmpp",
                target: "jabberhost.sample.com",
                weight: 5,
            }
        id:
            description: the record id
            returned: success
            type: string
            sample: f9efb0549e96abcb750de63b38c9576e
        locked:
            description: No documentation available
            returned: success
            type: boolean
            sample: False
        meta:
            description: No documentation available
            returned: success
            type: dictionary
            sample: { auto_added: false }
        modified_on:
            description: record modification date
            returned: success
            type: string
            sample: 2016-03-25T19:09:42.516553Z
        name:
            description: the record name as FQDN (including _service and _proto for SRV)
            returned: success
            type: string
            sample: www.sample.com
        priority:
            description: priority of the MX record
            returned: success, if type is MX
            type: int
            sample: 10
        proxiable:
            description: whether this record can be proxied through cloudflare
            returned: success
            type: boolean
            sample: False
        proxied:
            description: whether the record is proxied through cloudflare
            returned: success
            type: boolean
            sample: False
        ttl:
            description: the time-to-live for the record
            returned: success
            type: int
            sample: 300
        type:
            description: the record type
            returned: success
            type: string
            sample: A
        zone_id:
            description: the id of the zone containing the record
            returned: success
            type: string
            sample: abcede0bf9f0066f94029d2e6b73856a
        zone_name:
            description: the name of the zone containing the record
            returned: success
            type: string
            sample: sample.com


MAINTAINERS: Michael Gruener (@mgruener)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLOUDFORMATION    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/cloudformation.py)

  Launches or updates an AWS CloudFormation stack and waits for it complete.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- disable_rollback
        If a stacks fails to form, rollback will remove the stack
        (Choices: true, false)[Default: false]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- notification_arns
        The Simple Notification Service (SNS) topic ARNs to publish stack related events.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- role_arn
        The role that AWS CloudFormation assumes to create the stack. See the AWS CloudFormation Service Role docs
        http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-iam-servicerole.html
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= stack_name
        name of the cloudformation stack

- stack_policy
        the path of the cloudformation stack policy. A policy cannot be removed once placed, but it can be modified. (for
        instance, [allow all updates](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-
        resources.html#d0e9051)
        [Default: None]
= state
        If state is "present", stack will be created.  If state is "present" and if stack exists and template has
        changed, it will be updated. If state is "absent", stack will be removed.

- tags
        Dictionary of tags to associate with stack and its resources during stack creation. Can be updated later,
        updating tags removes previous entries.
        [Default: None]
- template
        The local path of the cloudformation template.
        This must be the full path to the file, relative to the working directory. If using roles this may look like
        "roles/cloudformation/files/cloudformation-example.json".
        If 'state' is 'present' and the stack does not exist yet, either 'template' or 'template_url' must be specified
        (but not both). If 'state' is present, the stack does exist, and neither 'template' nor 'template_url' are
        specified, the previous template will be reused.
        [Default: None]
- template_format
        (deprecated) For local templates, allows specification of json or yaml format. Templates are now passed raw to
        CloudFormation regardless of format. This parameter is ignored since Ansible 2.3.
        (Choices: json, yaml)[Default: json]
- template_parameters
        a list of hashes of all the template variables for the stack
        [Default: {}]
- template_url
        Location of file containing the template body. The URL must point to a template (max size 307,200 bytes) located
        in an S3 bucket in the same region as the stack.
        If 'state' is 'present' and the stack does not exist yet, either 'template' or 'template_url' must be specified
        (but not both). If 'state' is present, the stack does exist, and neither 'template' nor 'template_url' are
        specified, the previous template will be reused.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * As of version 2.3, migrated to boto3 to enable new features. To match existing behavior, YAML parsing is done
        in the module, not given to AWS as YAML. This will change (in fact, it may change before 2.3 is out).
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, botocore>=1.4.57, python >= 2.6

EXAMPLES:
# Basic task example
- name: launch ansible cloudformation example
  cloudformation:
    stack_name: "ansible-cloudformation"
    state: "present"
    region: "us-east-1"
    disable_rollback: true
    template: "files/cloudformation-example.json"
    template_parameters:
      KeyName: "jmartin"
      DiskType: "ephemeral"
      InstanceType: "m1.small"
      ClusterSize: 3
    tags:
      Stack: "ansible-cloudformation"

# Basic role example
- name: launch ansible cloudformation example
  cloudformation:
    stack_name: "ansible-cloudformation"
    state: "present"
    region: "us-east-1"
    disable_rollback: true
    template: "roles/cloudformation/files/cloudformation-example.json"
    template_parameters:
      KeyName: "jmartin"
      DiskType: "ephemeral"
      InstanceType: "m1.small"
      ClusterSize: 3
    tags:
      Stack: "ansible-cloudformation"

# Removal example
- name: tear down old deployment
  cloudformation:
    stack_name: "ansible-cloudformation-old"
    state: "absent"

# Use a template from a URL
- name: launch ansible cloudformation example
  cloudformation:
    stack_name: "ansible-cloudformation"
    state: present
    region: us-east-1
    disable_rollback: true
    template_url: https://s3.amazonaws.com/my-bucket/cloudformation.template
  args:
    template_parameters:
      KeyName: jmartin
      DiskType: ephemeral
      InstanceType: m1.small
      ClusterSize: 3
    tags:
      Stack: ansible-cloudformation

# Use a template from a URL, and assume a role to execute
- name: launch ansible cloudformation example with role assumption
  cloudformation:
    stack_name: "ansible-cloudformation"
    state: present
    region: us-east-1
    disable_rollback: true
    template_url: https://s3.amazonaws.com/my-bucket/cloudformation.template
    role_arn: 'arn:aws:iam::123456789012:role/cloudformation-iam-role'
  args:
    template_parameters:
      KeyName: jmartin
      DiskType: ephemeral
      InstanceType: m1.small
      ClusterSize: 3
    tags:
      Stack: ansible-cloudformation

RETURN VALUES:
events:
  type: list
  description: Most recent events in Cloudformation's event log. This may be from a previous run in some cases.
  returned: always
  sample: ["StackEvent AWS::CloudFormation::Stack stackname UPDATE_COMPLETE", "StackEvent AWS::CloudFormation::Stack stackname UPDATE_COMPLETE_CLEANUP_IN_PROGRESS"]
log:
  description: Debugging logs. Useful when modifying or finding an error.
  returned: always
  type: list
  sample: ["updating stack"]
stack_resources:
  description: AWS stack resources and their status. List of dictionaries, one dict per resource.
  type: list
  sample: [
          {
              "last_updated_time": "2016-10-11T19:40:14.979000+00:00",
              "logical_resource_id": "CFTestSg",
              "physical_resource_id": "cloudformation2-CFTestSg-16UQ4CYQ57O9F",
              "resource_type": "AWS::EC2::SecurityGroup",
              "status": "UPDATE_COMPLETE",
              "status_reason": null
          }
      ]
stack_outputs:
  type: dict
  description: A key:value dictionary of all the stack outputs currently defined. If there are no stack outputs, it is an empty dictionary.
  returned: always
  sample: {"MySg": "AnsibleModuleTestYAML-CFTestSg-C8UVS567B6NS"}


MAINTAINERS: James S. Martin (@jsmartin)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> CLOUDFORMATION_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/cloudformation_facts.py)

  Gets information about an AWS CloudFormation stack

Options (= is mandatory):

- all_facts
        Get all stack information for the stack
        [Default: False]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- stack_events
        Get stack events for the stack
        [Default: False]
= stack_name
        The name or id of the CloudFormation stack

- stack_policy
        Get stack policy for the stack
        [Default: False]
- stack_resources
        Get stack resources for the stack
        [Default: False]
- stack_template
        Get stack template body for the stack
        [Default: False]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3 >= 1.0.0, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Get summary information about a stack
- cloudformation_facts:
    stack_name: my-cloudformation-stack

# Facts are published in ansible_facts['cloudformation'][<stack_name>]
- debug:
    msg: "{{ ansible_facts['cloudformation']['my-cloudformation-stack'] }}"

# Get all stack information about a stack
- cloudformation_facts:
    stack_name: my-cloudformation-stack
    all_facts: true

# Get stack resource and stack policy information about a stack
- cloudformation_facts:
    stack_name: my-cloudformation-stack
    stack_resources: true
    stack_policy: true

# Example dictionary outputs for stack_outputs, stack_parameters and stack_resources:
# "stack_outputs": {
#     "ApplicationDatabaseName": "dazvlpr01xj55a.ap-southeast-2.rds.amazonaws.com",
#     ...
# },
# "stack_parameters": {
#     "DatabaseEngine": "mysql",
#     "DatabasePassword": "****",
#     ...
# },
# "stack_resources": {
#     "AutoscalingGroup": "dev-someapp-AutoscalingGroup-1SKEXXBCAN0S7",
#     "AutoscalingSecurityGroup": "sg-abcd1234",
#     "ApplicationDatabase": "dazvlpr01xj55a",
#     "EcsTaskDefinition": "arn:aws:ecs:ap-southeast-2:123456789:task-definition/dev-someapp-EcsTaskDefinition-1F2VM9QB0I7K9:1"
#     ...
# }

RETURN VALUES:
stack_description:
    description: Summary facts about the stack
    returned: always
    type: dict
stack_outputs:
    description: Dictionary of stack outputs keyed by the value of each output 'OutputKey' parameter and corresponding value of each output 'OutputValue' parameter
    returned: always
    type: dict
stack_parameters:
    description: Dictionary of stack parameters keyed by the value of each parameter 'ParameterKey' parameter and corresponding value of each parameter 'ParameterValue' parameter
    returned: always
    type: dict
stack_events:
    description: All stack events for the stack
    returned: only if all_facts or stack_events is true
    type: list of events
stack_policy:
    description: Describes the stack policy for the stack
    returned: only if all_facts or stack_policy is true
    type: dict
stack_template:
    description: Describes the stack template for the stack
    returned: only if all_facts or stack_template is true
    type: dict
stack_resource_list:
    description: Describes stack resources for the stack
    returned: only if all_facts or stack_resourses is true
    type: list of resources
stack_resources:
    description: Dictionary of stack resources keyed by the value of each resource 'LogicalResourceId' parameter and corresponding value of each resource 'PhysicalResourceId' parameter
    returned: only if all_facts or stack_resourses is true
    type: dict


MAINTAINERS: Justin Menga (@jmenga)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLOUDFRONT_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/cloudfront_facts.py)

  Gets information about an AWS CloudFront distribution

Options (= is mandatory):

- all_lists
        Get all cloudfront lists that do not require parameters.
        [Default: False]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- distribution
        Get information about a distribution. Requires `distribution_id' or `domain_name_alias' to be specified.
        [Default: False]
- distribution_config
        Get the configuration information about a distribution. Requires `distribution_id' or `domain_name_alias' to be
        specified.
        [Default: False]
- distribution_id
        The id of the CloudFront distribution. Used with `distribution', `distribution_config', `invalidation',
        `streaming_distribution', `streaming_distribution_config', `list_invalidations'.
        [Default: (null)]
- domain_name_alias
        Can be used instead of `distribution_id' - uses the aliased CNAME for the cloudfront distribution to get the
        distribution id where required.
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- invalidation
        Get information about an invalidation. Requires `invalidation_id' to be specified.
        [Default: False]
- invalidation_id
        The id of the invalidation to get information about. Used with `invalidation'.
        [Default: (null)]
- list_distributions
        Get a list of cloudfront distributions.
        [Default: False]
- list_distributions_by_web_acl_id
        Get a list of distributions using web acl id as a filter. Requires `web_acl_id' to be set.
        [Default: False]
- list_invalidations
        Get a list of invalidations. Requires `distribution_id' or `domain_name_alias' to be specified.
        [Default: False]
- list_origin_access_identities
        Get a list of cloudfront origin access identities. Requires `origin_access_identity_id' to be set.
        [Default: False]
- list_streaming_distributions
        Get a list of streaming distributions.
        [Default: False]
- origin_access_identity
        Get information about an origin access identity. Requires `origin_access_identity_id' to be specified.
        [Default: False]
- origin_access_identity_config
        Get the configuration information about an origin access identity. Requires `origin_access_identity_id' to be
        specified.
        [Default: False]
- origin_access_identity_id
        The id of the cloudfront origin access identity to get information about.
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- streaming_distribution
        Get information about a specified RTMP distribution. Requires `distribution_id' or `domain_name_alias' to be
        specified.
        [Default: False]
- streaming_distribution_configuration
        Get the configuration information about a specified RTMP distribution. Requires `distribution_id' or
        `domain_name_alias' to be specified.
        [Default: False]
- summary
        Returns a summary of all distributions, streaming distributions and origin_access_identities. This is the default
        behaviour if no option is selected.
        [Default: False]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- web_acl_id
        Used with `list_distributions_by_web_acl_id'.
        [Default: (null)]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3 >= 1.0.0, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Get a summary of distributions
- cloudfront_facts:
    summary: true

# Get information about a distribution
- cloudfront_facts:
    distribution: true
    distribution_id: my-cloudfront-distribution-id

# Get information about a distribution using the CNAME of the cloudfront distribution.
- cloudfront_facts:
    distribution: true
    domain_name_alias: www.my-website.com

# Facts are published in ansible_facts['cloudfront'][<distribution_name>]
- debug:
    msg: "{{ ansible_facts['cloudfront']['my-cloudfront-distribution-id'] }}"

- debug:
    msg: "{{ ansible_facts['cloudfront']['www.my-website.com'] }}"

# Get all information about an invalidation for a distribution.
- cloudfront_facts:
    invalidation: true
    distribution_id: my-cloudfront-distribution-id
    invalidation_id: my-cloudfront-invalidation-id

# Get all information about a cloudfront origin access identity.
- cloudfront_facts:
    origin_access_identity: true
    origin_access_identity_id: my-cloudfront-origin-access-identity-id

# Get all information about lists not requiring parameters (ie. list_origin_access_identities, list_distributions, list_streaming_distributions)
- cloudfront_facts:
    origin_access_identity: true
    origin_access_identity_id: my-cloudfront-origin-access-identity-id

# Get all information about lists not requiring parameters (ie. list_origin_access_identities, list_distributions, list_streaming_distributions)
- cloudfront_facts:
    all_lists: true

RETURN VALUES:
origin_access_identity:
    description: Describes the origin access identity information. Requires I(origin_access_identity_id) to be set.
    returned: only if I(origin_access_identity) is true
    type: dict
origin_access_identity_configuration:
    description: Describes the origin access identity information configuration information. Requires I(origin_access_identity_id) to be set.
    returned: only if I(origin_access_identity_configuration) is true
    type: dict
distribution:
    description: >
      Facts about a cloudfront distribution. Requires I(distribution_id) or I(domain_name_alias)
      to be specified. Requires I(origin_access_identity_id) to be set.
    returned: only if distribution is true
    type: dict
distribution_config:
    description: >
      Facts about a cloudfront distribution's config. Requires I(distribution_id) or I(domain_name_alias)
      to be specified.
    returned: only if I(distribution_config) is true
    type: dict
invalidation:
    description: >
      Describes the invalidation information for the distribution. Requires
      I(invalidation_id) to be specified and either I(distribution_id) or I(domain_name_alias.)
    returned: only if invalidation is true
    type: dict
streaming_distribution:
    description: >
      Describes the streaming information for the distribution. Requires
      I(distribution_id) or I(domain_name_alias) to be specified.
    returned: only if I(streaming_distribution) is true
    type: dict
streaming_distribution_configuration:
    description: >
      Describes the streaming configuration information for the distribution.
      Requires I(distribution_id) or I(domain_name_alias) to be specified.
    returned: only if I(streaming_distribution_configuration) is true
    type: dict
summary:
    description: Gives a summary of distributions, streaming distributions and origin access identities.
    returned: as default or if summary is true
    type: dict


MAINTAINERS: Willem van Ketwich (@wilvk)

METADATA:
	Status: ['preview']
	Supported_by: community
> CLOUDSCALE_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudscale/cloudscale_server.py)

  Create, start, stop and delete servers on the cloudscale.ch IaaS service. All operations are performed using the
  cloudscale.ch public API v1. For details consult the full API documentation: https://www.cloudscale.ch/en/api/v1. An
  valid API token is required for all operations. You can create as many tokens as you like using the cloudscale.ch
  control panel at https://control.cloudscale.ch.

Options (= is mandatory):

- anti_affinity_with
        UUID of another server to create an anti-affinity group with
        [Default: (null)]
- api_token
        cloudscale.ch API token.
        This can also be passed in the CLOUDSCALE_API_TOKEN environment variable.
        [Default: (null)]
- bulk_volume_size_gb
        Size of the bulk storage volume in GB
        [Default: null (no bulk storage volume)]
- flavor
        Flavor of the server
        [Default: (null)]
- image
        Image used to create the server
        [Default: (null)]
- name
        Name of the Server
        Either `name' or `uuid' are required. These options are mutually exclusive.
        [Default: (null)]
- ssh_keys
        List of SSH public keys
        Use the full content of your .pub file here.
        [Default: (null)]
- state
        State of the server
        (Choices: running, stopped, absent)[Default: running]
- use_ipv6
        Enable IPv6 on the public network interface
        [Default: True]
- use_private_network
        Attach a private network interface to the server
        [Default: False]
- use_public_network
        Attach a public network interface to the server
        [Default: True]
- user_data
        Cloud-init configuration (cloud-config) data to use for the server.
        [Default: (null)]
- uuid
        UUID of the server
        Either `name' or `uuid' are required. These options are mutually exclusive.
        [Default: (null)]
- volume_size_gb
        Size of the root volume in GB
        [Default: 10]
Notes:
  * Instead of the api_token parameter the CLOUDSCALE_API_TOKEN environment variable can be used.
  * To create a new server at least the `name', `ssh_key', `image' and `flavor' options are required.
  * If more than one server with the name given by the `name' option exists, execution is aborted.
  * Once a server is created all parameters except `state' are read-only. You can't change the name, flavor or any
        other property. This is a limitation of the cloudscale.ch API. The module will silently ignore differences
        between the configured parameters and the running server if a server with the correct name or UUID exists.
        Only state changes will be applied.
EXAMPLES:
# Start a server (if it does not exist) and register the server details
- name: Start cloudscale.ch server
  cloudscale_server:
    name: my-shiny-cloudscale-server
    image: debian-8
    flavor: flex-4
    ssh_keys: ssh-rsa XXXXXXXXXX...XXXX ansible@cloudscale
    use_private_network: True
    bulk_volume_size_gb: 100
    api_token: xxxxxx
  register: server1

# Start another server in anti-affinity to the first one
- name: Start second cloudscale.ch server
  cloudscale_server:
    name: my-other-shiny-server
    image: ubuntu-16.04
    flavor: flex-8
    ssh_keys: ssh-rsa XXXXXXXXXXX ansible@cloudscale
    anti_affinity_with: '{{ server1.uuid }}'
    api_token: xxxxxx

# Stop the first server
- name: Stop my first server
  cloudscale_server:
    uuid: '{{ server1.uuid }}'
    state: stopped
    api_token: xxxxxx

# Delete my second server
- name: Delete my second server
  cloudscale_server:
    name: my-other-shiny-server
    state: absent
    api_token: xxxxxx

# Start a server and wait for the SSH host keys to be generated
- name: Start server and wait for SSH host keys
  cloudscale_server:
    name: my-cloudscale-server-with-ssh-key
    image: debian-8
    flavor: flex-4
    ssh_keys: ssh-rsa XXXXXXXXXXX ansible@cloudscale
    api_token: xxxxxx
  register: server
  until: server.ssh_fingerprints
  retries: 60
  delay: 2

RETURN VALUES:
href:
  description: API URL to get details about this server
  returned: success when not state == absent
  type: string
  sample: https://api.cloudscale.ch/v1/servers/cfde831a-4e87-4a75-960f-89b0148aa2cc
uuid:
  description: The unique identifier for this server
  returned: success
  type: string
  sample: cfde831a-4e87-4a75-960f-89b0148aa2cc
name:
  description: The display name of the server
  returned: success
  type: string
  sample: its-a-me-mario.cloudscale.ch
state:
  description: The current status of the server
  returned: success
  type: string
  sample: running
flavor:
  description: The flavor that has been used for this server
  returned: success when not state == absent
  type: string
  sample: flex-8
image:
  description: The image used for booting this server
  returned: success when not state == absent
  type: string
  sample: debian-8
volumes:
  description: List of volumes attached to the server
  returned: success when not state == absent
  type: list
  sample: [ {"type": "ssd", "device": "/dev/vda", "size_gb": "50"} ]
interfaces:
  description: List of network ports attached to the server
  returned: success when not state == absent
  type: list
  sample: [ { "type": "public", "addresses": [ ... ] } ]
ssh_fingerprints:
  description: A list of SSH host key fingerprints. Will be null until the host keys could be retrieved from the server.
  returned: success when not state == absent
  type: list
  sample: ["ecdsa-sha2-nistp256 SHA256:XXXX", ... ]
ssh_host_keys:
  description: A list of SSH host keys. Will be null until the host keys could be retrieved from the server.
  returned: success when not state == absent
  type: list
  sample: ["ecdsa-sha2-nistp256 XXXXX", ... ]
anti_affinity_with:
  description: List of servers in the same anti-affinity group
  returned: success when not state == absent
  type: string
  sample: []


MAINTAINERS: Gaudenz Steinlin <gaudenz.steinlin@cloudscale.ch>

METADATA:
	Status: ['preview']
	Supported_by: community
> CLOUDTRAIL    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/cloudtrail.py)

  Creates or deletes CloudTrail configuration. Ensures logging is also enabled.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- include_global_events
        record API calls from global services such as IAM and STS?
        (Choices: true, false)[Default: False]
- name
        name for given CloudTrail configuration.
        This is a primary key and is used to identify the configuration.
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the EC2_REGION environment variable, if any, is used.
        [Default: (null)]
- s3_bucket_prefix
        bucket to place CloudTrail in.
        this bucket should exist and have the proper policy. See
        http://docs.aws.amazon.com/awscloudtrail/latest/userguide/aggregating_logs_regions_bucket_policy.html
        required when state=enabled.
        [Default: (null)]
- s3_key_prefix
        prefix to keys in bucket. A trailing slash is not necessary and will be removed.
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        add or remove CloudTrail configuration.
        (Choices: enabled, disabled)
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto >= 2.21, python >= 2.6

EXAMPLES:
  - name: enable cloudtrail
    local_action:
      module: cloudtrail
      state: enabled
      name: main
      s3_bucket_name: ourbucket
      s3_key_prefix: cloudtrail
      region: us-east-1

  - name: enable cloudtrail with different configuration
    local_action:
      module: cloudtrail
      state: enabled
      name: main
      s3_bucket_name: ourbucket2
      s3_key_prefix: ''
      region: us-east-1

  - name: remove cloudtrail
    local_action:
      module: cloudtrail
      state: disabled
      name: main
      region: us-east-1


MAINTAINERS: Ansible Core Team, Ted Timmons

METADATA:
	Status: ['preview']
	Supported_by: community
> CLOUDWATCHEVENT_RULE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/cloudwatchevent_rule.py)

  This module creates and manages CloudWatch event rules and targets.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- description
        A description of the rule
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- event_pattern
        A string pattern (in valid JSON format) that is used to match against incoming events to determine if the rule
        should be triggered
        [Default: (null)]
= name
        The name of the rule you are creating, updating or deleting. No spaces or special characters allowed (i.e. must
        match `[\.\-_A-Za-z0-9]+')

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- role_arn
        The Amazon Resource Name (ARN) of the IAM role associated with the rule
        [Default: (null)]
- schedule_expression
        A cron or rate expression that defines the schedule the rule will trigger on. For example, `cron(0 20 * * ? *'),
        `rate(5 minutes')
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Whether the rule is present (and enabled), disabled, or absent
        (Choices: present, disabled, absent)[Default: present]
- targets
        A dictionary array of targets to add to or update for the rule, in the form `{ id: [string], arn: [string],
        input: [valid JSON string], input_path: [valid JSONPath string] }'. `id' [required] is the unique target
        assignment ID. `arn' (required) is the Amazon Resource Name associated with the target. `input' (optional) is a
        JSON object that will override the event data when passed to the target.  `input_path' (optional) is a JSONPath
        string (e.g. `$.detail') that specifies the part of the event data to be passed to the target. If neither `input'
        nor `input_path' is specified, then the entire event is passed to the target in JSON form.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * A rule must contain at least an `event_pattern' or `schedule_expression'. A rule can have both an
        `event_pattern' and a `schedule_expression', in which case the rule will trigger on matching events as well
        as on a schedule.
  * When specifying targets, `input' and `input_path' are mutually-exclusive and optional parameters.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
- cloudwatchevent_rule:
    name: MyCronTask
    schedule_expression: "cron(0 20 * * ? *)"
    description: Run my scheduled task
    targets:
      - id: MyTargetId
        arn: arn:aws:lambda:us-east-1:123456789012:function:MyFunction

- cloudwatchevent_rule:
    name: MyDisabledCronTask
    schedule_expression: "cron(5 minutes)"
    description: Run my disabled scheduled task
    state: disabled
    targets:
      - id: MyOtherTargetId
        arn: arn:aws:lambda:us-east-1:123456789012:function:MyFunction
        input: '{"foo": "bar"}'

- cloudwatchevent_rule:
    name: MyCronTask
    state: absent

RETURN VALUES:
rule:
    description: CloudWatch Event rule data
    returned: success
    type: dict
    sample: "{ 'arn': 'arn:aws:events:us-east-1:123456789012:rule/MyCronTask', 'description': 'Run my scheduled task', 'name': 'MyCronTask', 'schedule_expression': 'cron(0 20 * * ? *)', 'state': 'ENABLED' }"
targets:
    description: CloudWatch Event target(s) assigned to the rule
    returned: success
    type: list
    sample: "[{ 'arn': 'arn:aws:lambda:us-east-1:123456789012:function:MyFunction', 'id': 'MyTargetId' }]"


MAINTAINERS: Jim Dalton (@jsdalton) <jim.dalton@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_BACKUP    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_backup.py)

  This module allows you to work with switch configurations. It provides a way to back up the running or startup
  configurations of a switch to a remote server. This is achieved by periodically saving a copy of the startup or running
  configuration of the network device to a remote server using FTP, SFTP, TFTP, or SCP. The first step is to create a
  directory from where the remote server can be reached. The next step is to provide the full file path of the location
  where the configuration will be backed up. Authentication details required by the remote server must be provided as
  well. This module uses SSH to manage network device configuration. The results of the operation will be placed in a
  directory named 'results' that must be created by the user in their local directory to where the playbook is run. For
  more information about this module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_backup.html

Options (= is mandatory):

= configType
        This specifies what type of configuration will be backed up. The choices are the running or startup
        configurations. There is no default value, so it will result in an error if the input is incorrect.
        (Choices: running-config, startup-config)[Default: None]
= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= protocol
        This refers to the protocol used by the network device to interact with the remote server to where to upload the
        backup configuration. The choices are FTP, SFTP, TFTP, or SCP. Any other protocols will result in error. If this
        parameter is not specified, there is no default value to be used.
        (Choices: SFTP, SCP, FTP, TFTP)[Default: None]
= rcpath
        This specifies the full file path where the configuration file will be copied on the remote server. In case the
        relative path is used as the variable value, the root folder for the user of the server needs to be specified.
        [Default: None]
= rcserverip
        -This specifies the IP Address of the remote server to where the configuration will be backed up.
        [Default: None]
= serverpassword
        Specify the password for the server relating to the protocol used.
        [Default: None]
= serverusername
        Specify the username for the server relating to the protocol used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_backup. These are written in the main.yml file of the tasks directory.
---
- name: Test Running Config Backup
  cnos_backup:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_backup_{{ inventory_hostname }}_output.txt"
      configType: running-config
      protocol: "sftp"
      serverip: "10.241.106.118"
      rcpath: "/root/cnos/G8272-running-config.txt"
      serverusername: "root"
      serverpassword: "root123"

- name: Test Startup Config Backup
  cnos_backup:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_backup_{{ inventory_hostname }}_output.txt"
      configType: startup-config
      protocol: "sftp"
      serverip: "10.241.106.118"
      rcpath: "/root/cnos/G8272-startup-config.txt"
      serverusername: "root"
      serverpassword: "root123"

- name: Test Running Config Backup -TFTP
  cnos_backup:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_backup_{{ inventory_hostname }}_output.txt"
      configType: running-config
      protocol: "tftp"
      serverip: "10.241.106.118"
      rcpath: "/anil/G8272-running-config.txt"
      serverusername: "root"
      serverpassword: "root123"

- name: Test Startup Config Backup - TFTP
  cnos_backup:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_backup_{{ inventory_hostname }}_output.txt"
      configType: startup-config
      protocol: "tftp"
      serverip: "10.241.106.118"
      rcpath: "/anil/G8272-startup-config.txt"
      serverusername: "root"
      serverpassword: "root123"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Config file tranferred to server"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_BGP    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_bgp.py)

  This module allows you to work with Border Gateway Protocol (BGP) related configurations. The operators used are
  overloaded to ensure control over switch BGP configurations. This module is invoked using method with asNumber as one
  of its arguments. The first level of the BGP configuration allows to set up an AS number, with the following attributes
  going into various configuration operations under the context of BGP. After passing this level, there are eight BGP
  arguments that will perform further configurations. They are bgpArg1, bgpArg2, bgpArg3, bgpArg4, bgpArg5, bgpArg6,
  bgpArg7, and bgpArg8. For more details on how to use these arguments, see [Overloaded Variables]. This module uses SSH
  to manage network device configuration. The results of the operation will be placed in a directory named 'results' that
  must be created by the user in their local directory to where the playbook is run. For more information about this
  module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_bgp.html

Options (= is mandatory):

= asNum
        AS number
        [Default: None]
= bgpArg1
        This is an overloaded bgp first argument. Usage of this argument can be found is the User Guide referenced above.
        (Choices: address-family, bestpath, bgp, cluster-id, confederation, enforce-first-as, fast-external-failover,
        graceful-restart, graceful-restart-helper, log-neighbor-changes, maxas-limit, neighbor, router-id, shutdown,
        synchronization, timers, vrf)[Default: None]
- bgpArg2
        This is an overloaded bgp second argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: ipv4 or ipv6, always-compare-med, compare-confed-aspath, compare-routerid, dont-compare-originator-id,
        tie-break-on-age, as-path, med, identifier, peers)[Default: None]
- bgpArg3
        This is an overloaded bgp third argument. Usage of this argument can be found is the User Guide referenced above.
        (Choices: aggregate-address, client-to-client, dampening, distance, maximum-paths, network, nexthop,
        redistribute, save, synchronization, ignore or multipath-relax, confed or missing-as-worst or non-deterministic
        or remove-recv-med or remove-send-med)[Default: None]
- bgpArg4
        This is an overloaded bgp fourth argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: Aggregate prefix, Reachability Half-life time, route-map, Distance for routes external, ebgp or ibgp,
        IP prefix <network>, IP prefix <network>/<length>, synchronization, Delay value, direct, ospf, static,
        memory)[Default: None]
- bgpArg5
        This is an overloaded bgp fifth argument. Usage of this argument can be found is the User Guide referenced above.
        (Choices: as-set, summary-only, Value to start reusing a route, Distance for routes internal, Supported multipath
        numbers, backdoor, map, route-map)[Default: None]
- bgpArg6
        This is an overloaded bgp sixth argument. Usage of this argument can be found is the User Guide referenced above.
        (Choices: summary-only, as-set, route-map name, Value to start suppressing a route, Distance for local routes,
        Network mask, Pointer to route-map entries)[Default: None]
- bgpArg7
        This is an overloaded bgp seventh argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: Maximum duration to suppress a stable route(minutes), backdoor, route-map, Name of the route
        map)[Default: None]
- bgpArg8
        This is an overloaded bgp eigth argument. Usage of this argument can be found is the User Guide referenced above.
        (Choices: Un-reachability Half-life time for the penalty(minutes), backdoor)[Default: None]
= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks: The following are examples of using the module cnos_bgp. These are written in the main.yml file of the tasks directory.
---
- name: Test BGP  - neighbor
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "neighbor"
      bgpArg2: "10.241.107.40"
      bgpArg3: 13
      bgpArg4: "address-family"
      bgpArg5: "ipv4"
      bgpArg6: "next-hop-self"

- name: Test BGP  - BFD
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "neighbor"
      bgpArg2: "10.241.107.40"
      bgpArg3: 13
      bgpArg4: "bfd"

- name: Test BGP  - address-family - dampening
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "address-family"
      bgpArg2: "ipv4"
      bgpArg3: "dampening"
      bgpArg4: 13
      bgpArg5: 233
      bgpArg6: 333
      bgpArg7: 15
      bgpArg8: 33

- name: Test BGP  - address-family - network
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "address-family"
      bgpArg2: "ipv4"
      bgpArg3: "network"
      bgpArg4: "1.2.3.4/5"
      bgpArg5: "backdoor"

- name: Test BGP - bestpath - always-compare-med
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "bestpath"
      bgpArg2: "always-compare-med"

- name: Test BGP - bestpath-compare-confed-aspat
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "bestpath"
      bgpArg2: "compare-confed-aspath"

- name: Test BGP - bgp
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "bgp"
      bgpArg2: 33

- name: Test BGP  - cluster-id
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "cluster-id"
      bgpArg2: "1.2.3.4"

- name: Test BGP - confederation-identifier
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "confederation"
      bgpArg2: "identifier"
      bgpArg3: 333

- name: Test BGP - enforce-first-as
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "enforce-first-as"

- name: Test BGP - fast-external-failover
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "fast-external-failover"

- name: Test BGP  - graceful-restart
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "graceful-restart"
      bgpArg2: 333

- name: Test BGP - graceful-restart-helper
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "graceful-restart-helper"

- name: Test BGP - maxas-limit
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "maxas-limit"
      bgpArg2: 333

- name: Test BGP  - neighbor
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "neighbor"
      bgpArg2: "10.241.107.40"
      bgpArg3: 13
      bgpArg4: "address-family"
      bgpArg5: "ipv4"
      bgpArg6: "next-hop-self"

- name: Test BGP - router-id
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "router-id"
      bgpArg2: "1.2.3.4"

- name: Test BGP - synchronization
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "synchronization"

- name: Test BGP - timers
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "timers"
      bgpArg2: 333
      bgpArg3: 3333

- name: Test BGP - vrf
  cnos_bgp:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_bgp_{{ inventory_hostname }}_output.txt"
      asNum: 33
      bgpArg1: "vrf"


RETURN VALUES:
msg:
  description: Success or failure message. Upon any failure, the method returns an error display string.
  returned: always
  type: string


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_command.py)

  This module allows you to modify the switch running configuration. It provides a way to execute a single CNOS command
  on a switch by evaluating the current running configuration and executing the command only if the specific setting has
  not been already configured. The CNOS command is passed as an argument of the method. This module uses SSH to manage
  network device configuration. The results of the operation will be placed in a directory named 'results' that must be
  created by the user in their local directory to where the playbook is run. For more information about this module from
  Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_command.html

Options (= is mandatory):

= clicommand
        This specifies the CLI command as an attribute to this method. The command is passed using double quotes. The
        variables can be placed directly on to the CLI commands or can be invoked from the vars directory.
        [Default: None]
= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_command. These are written in the main.yml file of the tasks directory.
---
- name: Test Command
  cnos_command:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      outputfile: "./results/test_command_{{ inventory_hostname }}_output.txt"
      clicommand: "display users"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Command Applied"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_CONDITIONAL_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_conditional_command.py)

  This module allows you to modify the running configuration of a switch. It provides a way to execute a single CNOS
  command on a network device by evaluating the current running configuration and executing the command only if the
  specific settings have not been already configured. The CNOS command is passed as an argument of the method. This
  module functions the same as the cnos_command module. The only exception is that the following inventory variable can
  be specified [“condition = <flag string>”] When this inventory variable is specified as the variable of a task, the
  command is executed for the network element that matches the flag string. Usually, commands are executed across a group
  of network devices. When there is a requirement to skip the execution of the command on one or more devices, it is
  recommended to use this module. This module uses SSH to manage network device configuration. For more information about
  this module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_conditional_command.html

Options (= is mandatory):

= clicommand
        This specifies the CLI command as an attribute to this method. The command is passed using double quotes. The
        variables can be placed directly on to the CLI commands or can be invoked from the vars directory.
        [Default: None]
= condition
        If you specify condition=false in the inventory file against any device, the command execution is skipped for
        that device.
        [Default: None]
= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= flag
        If a task needs to be executed, you have to set the flag the same as it is specified in the inventory for that
        device.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_conditional_command. These are written in the main.yml file of the tasks directory.
---
- name: Applying CLI template on VLAG Tier1 Leaf Switch1
  cnos_conditional_command:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_conditional_command_{{ inventory_hostname }}_output.txt"
      condition: "{{ hostvars[inventory_hostname]['condition']}}"
      flag: leaf_switch2
      command: "spanning-tree mode enable"
      enablePassword: "anil"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Command Applied"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_CONDITIONAL_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_conditional_template.py)

  This module allows you to work with the running configuration of a switch. It provides a way to execute a set of CNOS
  commands on a switch by evaluating the current running configuration and executing the commands only if the specific
  settings have not been already configured. The configuration source can be a set of commands or a template written in
  the Jinja2 templating language. This module functions the same as the cnos_template module. The only exception is that
  the following inventory variable can be specified [“condition = <flag string>”] When this inventory variable is
  specified as the variable of a task, the template is executed for the network element that matches the flag string.
  Usually, templates are used when commands are the same across a group of network devices. When there is a requirement
  to skip the execution of the template on one or more devices, it is recommended to use this module. This module uses
  SSH to manage network device configuration. For more information about this module from Lenovo and customizing it usage
  for your use cases, please visit http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.do
  c%2Fcnos_conditional_template.html

Options (= is mandatory):

= commandfile
        This specifies the path to the CNOS command file which needs to be applied. This usually comes from the commands
        folder. Generally this file is the output of the variables applied on a template file. So this command is
        preceded by a template module. The command file must contain the Ansible keyword {{ inventory_hostname }} and the
        condition flag in its filename to ensure that the command file is unique for each switch and condition. If this
        is omitted, the command file will be overwritten during iteration. For example,
        commandfile=./commands/clos_leaf_bgp_{{ inventory_hostname }}_LP21_commands.txt
        [Default: None]
= condition
        If you specify condition=<flag string> in the inventory file against any device, the template execution is done
        for that device in case it matches the flag setting for that task.
        [Default: None]
= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= flag
        If a task needs to be executed, you have to set the flag the same as it is specified in the inventory for that
        device.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_conditional_template. These are written in the main.yml file of the tasks directory.
---
- name: Applying CLI template on VLAG Tier1 Leaf Switch1
  cnos_conditional_template:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      outputfile: "./results/vlag_1tier_leaf_switch1_{{ inventory_hostname }}_output.txt"
      condition: "{{ hostvars[inventory_hostname]['condition']}}"
      flag: "leaf_switch1"
      commandfile: "./commands/vlag_1tier_leaf_switch1_{{ inventory_hostname }}_commands.txt"
      enablePassword: "anil"
      stp_mode1: "disable"
      port_range1: "17,18,29,30"
      portchannel_interface_number1: 1001
      portchannel_mode1: active
      slot_chassis_number1: 1/48
      switchport_mode1: trunk

RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Template Applied."


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_FACTORY    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_factory.py)

  This module allows you to reset a switch’s startup configuration. The method provides a way to reset the startup
  configuration to its factory settings. This is helpful when you want to move the switch to another topology as a new
  network device. This module uses SSH to manage network device configuration. The results of the operation can be viewed
  in results directory. For more information about this module from Lenovo and customizing it usage for your use cases,
  please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_factory.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_reload. These are written in the main.yml file of the tasks directory.
---
- name: Test Reset to factory
  cnos_factory:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      outputfile: "./results/test_factory_{{ inventory_hostname }}_output.txt"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Switch Startup Config is Reset to factory settings"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_facts.py)

  This module allows you to view the switch information. It executes the show sysinfo CLI command on a switch and returns
  a file containing all the system information of the target network device. This module uses SSH to manage network
  device configuration. The results of the operation can be viewed in results directory. For more information about this
  module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_facts.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_facts. These are written in the main.yml file of the tasks directory.
---
- name: Test Sys Info
  cnos_facts:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/cnos_facts_{{ inventory_hostname }}_output.txt"

RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Device Sys Info is saved to file"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_IMAGE    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_image.py)

  This module allows you to work with switch firmware images. It provides a way to download a firmware image to a network
  device from a remote server using FTP, SFTP, TFTP, or SCP. The first step is to create a directory from where the
  remote server can be reached. The next step is to provide the full file path of the image’s location. Authentication
  details required by the remote server must be provided as well. By default, this method makes the newly downloaded
  firmware image the active image, which will be used by the switch during the next restart. This module uses SSH to
  manage network device configuration. The results of the operation will be placed in a directory named 'results' that
  must be created by the user in their local directory to where the playbook is run. For more information about this
  module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_image.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= imgpath
        This specifies the full file path of the image located on the remote server. In case the relative path is used as
        the variable value, the root folder for the user of the server needs to be specified.
        [Default: None]
= imgtype
        This specifies the firmware image type to be downloaded
        (Choices: all, boot, os, onie)[Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= protocol
        This refers to the protocol used by the network device to interact with the remote server from where to download
        the firmware image. The choices are FTP, SFTP, TFTP, or SCP. Any other protocols will result in error. If this
        parameter is not specified, there is no default value to be used.
        (Choices: SFTP, SCP, FTP, TFTP)[Default: None]
= serverip
        This specifies the IP Address of the remote server from where the software image will be downloaded.
        [Default: None]
- serverpassword
        Specify the password for the server relating to the protocol used.
        [Default: None]
= serverusername
        Specify the username for the server relating to the protocol used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_image. These are written in the main.yml file of the tasks directory.
---
- name: Test Image transfer
  cnos_image:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_image_{{ inventory_hostname }}_output.txt"
      protocol: "sftp"
      serverip: "10.241.106.118"
      imgpath: "/root/cnos_images/G8272-10.1.0.112.img"
      imgtype: "os"
      serverusername: "root"
      serverpassword: "root123"

- name: Test Image tftp
  cnos_image:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_image_{{ inventory_hostname }}_output.txt"
      protocol: "tftp"
      serverip: "10.241.106.118"
      imgpath: "/anil/G8272-10.2.0.34.img"
      imgtype: "os"
      serverusername: "root"
      serverpassword: "root123"

RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Image file tranferred to device"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_interface.py)

  This module allows you to work with interface related configurations. The operators used are overloaded to ensure
  control over switch interface configurations. Apart from the regular device connection related attributes, there are
  seven interface arguments that will perform further configurations. They are interfaceArg1, interfaceArg2,
  interfaceArg3, interfaceArg4, interfaceArg5, interfaceArg6, and interfaceArg7. For more details on how to use these
  arguments, see [Overloaded Variables]. Interface configurations are taken care at six contexts in a regular CLI. They
  are 1. Interface Name - Configurations 2. Ethernet Interface - Configurations 3. Loopback Interface Configurations 4.
  Management Interface Configurations 5. Port Aggregation - Configurations 6. VLAN Configurations This module uses SSH to
  manage network device configuration. The results of the operation will be placed in a directory named 'results' that
  must be created by the user in their local directory to where the playbook is run. For more information about this
  module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_interface.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= interfaceArg1
        This is an overloaded interface first argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: aggregation-group, bfd, bridgeport, description, duplex, flowcontrol, ip, ipv6, lacp, lldp, load-
        interval, mac, mac-address, mac-learn, microburst-detection, mtu, service, service-policy, shutdown, snmp,
        spanning-tree, speed, storm-control, vlan, vrrp, port-aggregation)[Default: None]
- interfaceArg2
        This is an overloaded interface second argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: aggregation-group number, access or mode or trunk, description, auto or full or half, recieve or send,
        port-priority, suspend-individual, timeout, receive or transmit or trap-notification, tlv-select, Load interval
        delay in seconds, counter, Name for the MAC Access List, mac-address in HHHH.HHHH.HHHH format, THRESHOLD  Value
        in unit of buffer cell, <64-9216>  MTU in bytes-<64-9216> for L2 packet, <576-9216> for L3 IPv4 packet,
        <1280-9216> for L3 IPv6 packet, enter the instance id, input or output, copp-system-policy, type, 1000  or  10000
        or   40000 or   auto, broadcast or multicast or unicast, disable or enable or egress-only, Virtual router
        identifier, destination-ip or destination-mac or destination-port or source-dest-ip or source-dest-mac or source-
        dest-port or source-interface or source-ip or source-mac or source-port)[Default: None]
- interfaceArg3
        This is an overloaded interface third argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: active or on or passive, on or off, LACP port priority, long or short, link-aggregation or mac-phy-
        status or management-address or max-frame-size or port-description or port-protocol-vlan or port-vlan or power-
        mdi or protocol-identity or system-capabilities or system-description or system-name or vid-management or vlan-
        name, counter for load interval, policy input name, all or Copp class name to attach, qos, queing, Enter the
        allowed traffic level, ipv6)[Default: None]
- interfaceArg4
        This is an overloaded interface fourth argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: key-chain, key-id, keyed-md5 or keyed-sha1 or meticulous-keyed-md5 or meticulous-keyed-sha1 or simple,
        Interval value in milliseconds, Destination IP (Both IPV4 and IPV6), in or out, MAC address, Time-out value in
        seconds, class-id, request, Specify the IPv4 address, OSPF area ID as a decimal value, OSPF area ID in IP address
        format, anycast or secondary, ethernet, vlan, MAC (hardware) address in HHHH.HHHH.HHHH format, Load interval
        delay in seconds, Specify policy input name, input or output, cost, port-priority, BFD minimum receive interval,
        source-interface)[Default: None]
- interfaceArg5
        This is an overloaded interface fifth argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: name of key-chain, key-Id Value, key-chain, key-id, BFD minimum receive interval, Value of Hello
        Multiplier, admin-down or multihop or non-persistent, Vendor class-identifier name, bootfile-name or host-name or
        log-server or ntp-server or tftp-server-name, Slot/chassis number, Vlan interface, Specify policy input name,
        Port path cost or auto, Port priority increments of 32)[Default: None]
- interfaceArg6
        This is an overloaded interface sixth argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: Authentication key string, name of key-chain, key-Id Value, Value of Hello Multiplier, admin-down or
        non-persistent)[Default: None]
- interfaceArg7
        This is an overloaded interface seventh argument. Usage of this argument can be found is the User Guide
        referenced above.
        (Choices: Authentication key string, admin-down)[Default: None]
= interfaceOption
        This specifies the attribute you specify subsequent to interface command
        (Choices: None, ethernet, loopback, mgmt, port-aggregation, vlan)[Default: None]
= interfaceRange
        This specifies the interface range in which the port aggregation is envisaged
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_interface. These are written in the main.yml file of the tasks directory.
---
- name: Test Interface Ethernet - aggregation-group
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 1
      interfaceArg1: "aggregation-group"
      interfaceArg2: 33
      interfaceArg3: "on"

- name: Test Interface Ethernet - bridge-port
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "bridge-port"
      interfaceArg2: "access"
      interfaceArg3: 33

- name: Test Interface Ethernet - bridgeport mode
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "bridge-port"
      interfaceArg2: "mode"
      interfaceArg3: "access"

- name: Test Interface Ethernet  - Description
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "description"
      interfaceArg2: "Hentammoo "

- name: Test Interface Ethernet - Duplex
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 1
      interfaceArg1: "duplex"
      interfaceArg2: "auto"

- name: Test Interface Ethernet - flowcontrol
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "flowcontrol"
      interfaceArg2: "send"
      interfaceArg3: "off"

- name: Test Interface Ethernet - lacp
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "lacp"
      interfaceArg2: "port-priority"
      interfaceArg3: 33

- name: Test Interface Ethernet  - lldp
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "lldp"
      interfaceArg2: "tlv-select"
      interfaceArg3: "max-frame-size"

- name: Test Interface Ethernet - load-interval
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "load-interval"
      interfaceArg2: "counter"
      interfaceArg3: 2
      interfaceArg4: 33

- name: Test Interface Ethernet - mac
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "mac"
      interfaceArg2: "copp-system-acl-vlag-hc"

- name: Test Interface Ethernet - microburst-detection
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "microburst-detection"
      interfaceArg2: 25

- name: Test Interface Ethernet  - mtu
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "mtu"
      interfaceArg2: 66

- name: Test Interface Ethernet - service-policy
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "service-policy"
      interfaceArg2: "input"
      interfaceArg3: "Anil"

- name: Test Interface Ethernet - speed
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 1
      interfaceArg1: "speed"
      interfaceArg2: "auto"

- name: Test Interface Ethernet - storm
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "storm-control"
      interfaceArg2: "broadcast"
      interfaceArg3: 12.5

- name: Test Interface Ethernet - vlan
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "vlan"
      interfaceArg2: "disable"

- name: Test Interface Ethernet - vrrp
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "vrrp"
      interfaceArg2: 33

- name: Test Interface Ethernet - spanning tree1
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "spanning-tree"
      interfaceArg2: "bpduguard"
      interfaceArg3: "enable"

- name: Test Interface Ethernet - spanning tree 2
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "spanning-tree"
      interfaceArg2: "mst"
      interfaceArg3: "33-35"
      interfaceArg4: "cost"
      interfaceArg5: 33

- name: Test Interface Ethernet - ip1
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "ip"
      interfaceArg2: "access-group"
      interfaceArg3: "anil"
      interfaceArg4: "in"

- name: Test Interface Ethernet - ip2
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "ip"
      interfaceArg2: "port"
      interfaceArg3: "anil"

- name: Test Interface Ethernet - bfd
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "bfd"
      interfaceArg2: "interval"
      interfaceArg3: 55
      interfaceArg4: 55
      interfaceArg5: 33

- name: Test Interface Ethernet - bfd
  cnos_interface:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_interface_{{ inventory_hostname }}_output.txt"
      interfaceOption: 'ethernet'
      interfaceRange: 33
      interfaceArg1: "bfd"
      interfaceArg2: "ipv4"
      interfaceArg3: "authentication"
      interfaceArg4: "meticulous-keyed-md5"
      interfaceArg5: "key-chain"
      interfaceArg6: "mychain"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Interface configurations accomplished."


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_PORTCHANNEL    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_portchannel.py)

  This module allows you to work with port aggregation related configurations. The operators used are overloaded to
  ensure control over switch port aggregation configurations. Apart from the regular device connection related
  attributes, there are five LAG arguments which are overloaded variables that will perform further configurations. They
  are interfaceArg1, interfaceArg2, interfaceArg3, interfaceArg4, and interfaceArg5. For more details on how to use these
  arguments, see [Overloaded Variables]. This module uses SSH to manage network device configuration. The results of the
  operation will be placed in a directory named 'results' that must be created by the user in their local directory to
  where the playbook is run. For more information about this module from Lenovo and customizing it usage for your use
  cases, please
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_portchannel.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= interfaceArg1
        This is an overloaded Port Channel first argument. Usage of this argument can be found is the User Guide
        referenced above.
        (Choices: aggregation-group, bfd, bridgeport, description, duplex, flowcontrol, ip, ipv6, lacp, lldp, load-
        interval, mac, mac-address, mac-learn, microburst-detection, mtu, service, service-policy, shutdown, snmp,
        spanning-tree, speed, storm-control, vlan, vrrp, port-aggregation)[Default: None]
- interfaceArg2
        This is an overloaded Port Channel second argument. Usage of this argument can be found is the User Guide
        referenced above.
        (Choices: aggregation-group number, access or mode or trunk, description, auto or full or half, recieve or send,
        port-priority, suspend-individual, timeout, receive or transmit or trap-notification, tlv-select, Load interval
        delay in seconds, counter, Name for the MAC Access List, mac-address in HHHH.HHHH.HHHH format, THRESHOLD  Value
        in unit of buffer cell, <64-9216>  MTU in bytes-<64-9216> for L2 packet, <576-9216> for L3 IPv4 packet,
        <1280-9216> for L3 IPv6 packet, enter the instance id, input or output, copp-system-policy, type, 1000  or  10000
        or   40000 or   auto, broadcast or multicast or unicast, disable or enable or egress-only, Virtual router
        identifier, destination-ip or destination-mac or destination-port or source-dest-ip or source-dest-mac or source-
        dest-port or source-interface or source-ip or source-mac or source-port)[Default: None]
- interfaceArg3
        This is an overloaded Port Channel third argument. Usage of this argument can be found is the User Guide
        referenced above.
        (Choices: active or on or passive, on or off, LACP port priority, long or short, link-aggregation or mac-phy-
        status or management-address or max-frame-size or port-description or port-protocol-vlan or port-vlan or power-
        mdi or protocol-identity or system-capabilities or system-description or system-name or vid-management or vlan-
        name, counter for load interval, policy input name, all or Copp class name to attach, qos, queing, Enter the
        allowed traffic level, ipv6)[Default: None]
- interfaceArg4
        This is an overloaded Port Channel fourth argument. Usage of this argument can be found is the User Guide
        referenced above.
        (Choices: key-chain, key-id, keyed-md5 or keyed-sha1 or meticulous-keyed-md5 or meticulous-keyed-sha1 or simple,
        Interval value in milliseconds, Destination IP (Both IPV4 and IPV6), in or out, MAC address, Time-out value in
        seconds, class-id, request, Specify the IPv4 address, OSPF area ID as a decimal value, OSPF area ID in IP address
        format, anycast or secondary, ethernet, vlan, MAC (hardware) address in HHHH.HHHH.HHHH format, Load interval
        delay in seconds, Specify policy input name, input or output, cost, port-priority, BFD minimum receive interval,
        source-interface)[Default: None]
- interfaceArg5
        This is an overloaded Port Channel fifth argument. Usage of this argument can be found is the User Guide
        referenced above.
        (Choices: name of key-chain, key-Id Value, key-chain, key-id, BFD minimum receive interval, Value of Hello
        Multiplier, admin-down or multihop or non-persistent, Vendor class-identifier name, bootfile-name or host-name or
        log-server or ntp-server or tftp-server-name, Slot/chassis number, Vlan interface, Specify policy input name,
        Port path cost or auto, Port priority increments of 32)[Default: None]
- interfaceArg6
        This is an overloaded Port Channel sixth argument. Usage of this argument can be found is the User Guide
        referenced above.
        (Choices: Authentication key string, name of key-chain, key-Id Value, Value of Hello Multiplier, admin-down or
        non-persistent)[Default: None]
- interfaceArg7
        This is an overloaded Port Channel seventh argument. Usage of this argument can be found is the User Guide
        referenced above.
        (Choices: Authentication key string, admin-down)[Default: None]
= interfaceRange
        This specifies the interface range in which the port aggregation is envisaged
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_portchannel. These are written in the main.yml file of the tasks directory.
---
- name: Test Port Channel - aggregation-group
  cnos_portchannel:
    host: "{{ inventory_hostname }}"
    username: "{{ hostvars[inventory_hostname]['username'] }}"
    password: "{{ hostvars[inventory_hostname]['password'] }}"
    deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
    outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
    interfaceRange: 33
    interfaceArg1: "aggregation-group"
    interfaceArg2: 33
    interfaceArg3: "on"

- name: Test Port Channel - aggregation-group - Interface Range
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: "1/1-2"
  interfaceArg1: "aggregation-group"
  interfaceArg2: 33
  interfaceArg3: "on"

- name: Test Port Channel - bridge-port
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "bridge-port"
  interfaceArg2: "access"
  interfaceArg3: 33

- name: Test Port Channel - bridgeport mode
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "bridge-port"
  interfaceArg2: "mode"
  interfaceArg3: "access"

- name: Test Port Channel  - Description
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "description"
  interfaceArg2: "Hentammoo "

- name: Test Port Channel - Duplex
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "duplex"
  interfaceArg2: "auto"

- name: Test Port Channel - flowcontrol
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "flowcontrol"
  interfaceArg2: "send"
  interfaceArg3: "off"

- name: Test Port Channel - lacp
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "lacp"
  interfaceArg2: "port-priority"
  interfaceArg3: 33

- name: Test Port Channel  - lldp
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "lldp"
  interfaceArg2: "tlv-select"
  interfaceArg3: "max-frame-size"

- name: Test Port Channel - load-interval
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "load-interval"
  interfaceArg2: "counter"
  interfaceArg3: 2
  interfaceArg4: 33

#- name: Test Port Channel - mac
#  cnos_portchannel:
#  host: "{{ inventory_hostname }}"
#  username: "{{ hostvars[inventory_hostname]['username'] }}"
#  password: "{{ hostvars[inventory_hostname]['password'] }}"
#  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
#  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
#  interfaceRange: 33,
#  interfaceArg1: "mac"
#  interfaceArg2: "copp-system-acl-vlag-hc"

- name: Test Port Channel - microburst-detection
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "microburst-detection"
  interfaceArg2: 25

- name: Test Port Channel  - mtu
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "mtu"
  interfaceArg2: 66

- name: Test Port Channel - service-policy
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "service-policy"
  interfaceArg2: "input"
  interfaceArg3: "Anil"

- name: Test Port Channel - speed
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "speed"
  interfaceArg2: "auto"

- name: Test Port Channel - storm
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "storm-control"
  interfaceArg2: "broadcast"
  interfaceArg3: 12.5

#- name: Test Port Channel - vlan
#  cnos_portchannel:
#  host: "{{ inventory_hostname }}"
#  username: "{{ hostvars[inventory_hostname]['username'] }}"
#  password: "{{ hostvars[inventory_hostname]['password'] }}"
#  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
#  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
#  interfaceRange: 33
#  interfaceArg1: "vlan"
#  interfaceArg2: "disable"

- name: Test Port Channel - vrrp
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "vrrp"
  interfaceArg2: 33

- name: Test Port Channel - spanning tree1
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "spanning-tree"
  interfaceArg2: "bpduguard"
  interfaceArg3: "enable"

- name: Test Port Channel - spanning tree 2
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "spanning-tree"
  interfaceArg2: "mst"
  interfaceArg3: "33-35"
  interfaceArg4: "cost"
  interfaceArg5: 33

- name: Test Port Channel - ip1
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "ip"
  interfaceArg2: "access-group"
  interfaceArg3: "anil"
  interfaceArg4: "in"

- name: Test Port Channel - ip2
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "ip"
  interfaceArg2: "port"
  interfaceArg3: "anil"

- name: Test Port Channel - bfd
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "bfd"
  interfaceArg2: "interval"
  interfaceArg3: 55
  interfaceArg4: 55
  interfaceArg5: 33

- name: Test Port Channel - bfd
  cnos_portchannel:
  host: "{{ inventory_hostname }}"
  username: "{{ hostvars[inventory_hostname]['username'] }}"
  password: "{{ hostvars[inventory_hostname]['password'] }}"
  deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
  outputfile: "./results/test_portchannel_{{ inventory_hostname }}_output.txt"
  interfaceRange: 33
  interfaceArg1: "bfd"
  interfaceArg2: "ipv4"
  interfaceArg3: "authentication"
  interfaceArg4: "meticulous-keyed-md5"
  interfaceArg5: "key-chain"
  interfaceArg6: "mychain"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Port Channel configurations accomplished"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_RELOAD    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_reload.py)

  This module allows you to restart the switch using the current startup configuration. The module is usually invoked
  after the running configuration has been saved over the startup configuration. This module uses SSH to manage network
  device configuration. The results of the operation can be viewed in results directory. For more information about this
  module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_reload.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_reload. These are written in the main.yml file of the tasks directory.
---
- name: Test Reload
  cnos_reload:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_reload_{{ inventory_hostname }}_output.txt"

RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Device is Reloading. Please wait..."


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_ROLLBACK    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_rollback.py)

  This module allows you to work with switch configurations. It provides a way to roll back configurations of a switch
  from a remote server. This is achieved by using startup or running configurations of the target device that were
  previously backed up to a remote server using FTP, SFTP, TFTP, or SCP. The first step is to create a directory from
  where the remote server can be reached. The next step is to provide the full file path of the backup configuration’s
  location. Authentication details required by the remote server must be provided as well. By default, this method
  overwrites the switch’s configuration file with the newly downloaded file. This module uses SSH to manage network
  device configuration. The results of the operation will be placed in a directory named 'results' that must be created
  by the user in their local directory to where the playbook is run. For more information about this module from Lenovo
  and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_rollback.html

Options (= is mandatory):

= configType
        This refers to the type of configuration which will be used for the rolling back process. The choices are the
        running or startup configurations. There is no default value, so it will result in an error if the input is
        incorrect.
        (Choices: running-config, startup-config)[Default: None]
= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= protocol
        This refers to the protocol used by the network device to interact with the remote server from where to download
        the backup configuration. The choices are FTP, SFTP, TFTP, or SCP. Any other protocols will result in error. If
        this parameter is not specified, there is no default value to be used.
        (Choices: SFTP, SCP, FTP, TFTP)[Default: None]
= rcpath
        This specifies the full file path of the configuration file located on the remote server. In case the relative
        path is used as the variable value, the root folder for the user of the server needs to be specified.
        [Default: None]
= rcserverip
        This specifies the IP Address of the remote server from where the backup configuration will be downloaded.
        [Default: None]
= serverpassword
        Specify the password for the server relating to the protocol used.
        [Default: None]
= serverusername
        Specify the username for the server relating to the protocol used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_rollback. These are written in the main.yml file of the tasks directory.
---

- name: Test Rollback of config - Running config
  cnos_rolback:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_rollback_{{ inventory_hostname }}_output.txt"
      configType: running-config
      protocol: "sftp"
      serverip: "10.241.106.118"
      rcpath: "/root/cnos/G8272-running-config.txt"
      serverusername: "root"
      serverpassword: "root123"

- name: Test Rollback of config - Startup config
  cnos_rolback:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_rollback_{{ inventory_hostname }}_output.txt"
      configType: startup-config
      protocol: "sftp"
      serverip: "10.241.106.118"
      rcpath: "/root/cnos/G8272-startup-config.txt"
      serverusername: "root"
      serverpassword: "root123"

- name: Test Rollback of config - Running config - TFTP
  cnos_rolback:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_rollback_{{ inventory_hostname }}_output.txt"
      configType: running-config
      protocol: "tftp"
      serverip: "10.241.106.118"
      rcpath: "/anil/G8272-running-config.txt"
      serverusername: "root"
      serverpassword: "root123"

- name: Test Rollback of config - Startup config - TFTP
  cnos_rolback:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_rollback_{{ inventory_hostname }}_output.txt"
      configType: startup-config
      protocol: "tftp"
      serverip: "10.241.106.118"
      rcpath: "/anil/G8272-startup-config.txt"
      serverusername: "root"
      serverpassword: "root123"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Config file tranferred to Device"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_SAVE    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_save.py)

  This module allows you to copy the running configuration of a switch over its startup configuration. It is recommended
  to use this module shortly after any major configuration changes so they persist after a switch restart. This module
  uses SSH to manage network device configuration. The results of the operation will be placed in a directory named
  'results' that must be created by the user in their local directory to where the playbook is run. For more information
  about this module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_save.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_save. These are written in the main.yml file of the tasks directory.
---
- name: Test Save
  cnos_save:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_save_{{ inventory_hostname }}_output.txt"

RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Switch Running Config is Saved to Startup Config"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_SHOWRUN    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_showrun.py)

  This module allows you to view the switch running configuration. It executes the display running-config CLI command on
  a switch and returns a file containing the current running configuration of the target network device. This module uses
  SSH to manage network device configuration. The results of the operation will be placed in a directory named 'results'
  that must be created by the user in their local directory to where the playbook is run. For more information about this
  module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_showrun.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_showrun. These are written in the main.yml file of the tasks directory.
---
- name: Run show running-config
  cnos_showrun:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_showrun_{{ inventory_hostname }}_output.txt"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Running Configuration saved in file"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_template.py)

  This module allows you to work with the running configuration of a switch. It provides a way to execute a set of CNOS
  commands on a switch by evaluating the current running configuration and executing the commands only if the specific
  settings have not been already configured. The configuration source can be a set of commands or a template written in
  the Jinja2 templating language. This module uses SSH to manage network device configuration. The results of the
  operation will be placed in a directory named 'results' that must be created by the user in their local directory to
  where the playbook is run. For more information about this module from Lenovo and customizing it usage for your use
  cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_template.html

Options (= is mandatory):

= commandfile
        This specifies the path to the CNOS command file which needs to be applied. This usually comes from the commands
        folder. Generally this file is the output of the variables applied on a template file. So this command is
        preceded by a template module. Note The command file must contain the Ansible keyword {{ inventory_hostname }} in
        its filename to ensure that the command file is unique for each switch and condition. If this is omitted, the
        command file will be overwritten during iteration. For example, commandfile=./commands/clos_leaf_bgp_{{
        inventory_hostname }}_commands.txt
        [Default: None]
= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
EXAMPLES:
Tasks : The following are examples of using the module cnos_template. These are written in the main.yml file of the tasks directory.
---
- name: Replace Config CLI command template with values
  template:
      src: demo_template.j2
      dest: "./commands/demo_template_{{ inventory_hostname }}_commands.txt"
      vlanid1: 13
      slot_chassis_number1: "1/2"
      portchannel_interface_number1: 100
      portchannel_mode1: "active"

- name: Applying CLI commands on Switches
  cnos_template:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      commandfile: "./commands/demo_template_{{ inventory_hostname }}_commands.txt"
      outputfile: "./results/demo_template_command_{{ inventory_hostname }}_output.txt"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "Template Applied."


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_VLAG    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_vlag.py)

  This module allows you to work with virtual Link Aggregation Groups (vLAG) related configurations. The operators used
  are overloaded to ensure control over switch vLAG configurations. Apart from the regular device connection related
  attributes, there are four vLAG arguments which are overloaded variables that will perform further configurations. They
  are vlagArg1, vlagArg2, vlagArg3, and vlagArg4. For more details on how to use these arguments, see [Overloaded
  Variables]. This module uses SSH to manage network device configuration. The results of the operation will be placed in
  a directory named 'results' that must be created by the user in their local directory to where the playbook is run. For
  more information about this module from Lenovo and customizing it usage for your use cases, please visit
  http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_vlag.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= vlagArg1
        This is an overloaded vlag first argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: enable, auto-recovery, config-consistency, isl, mac-address-table, peer-gateway, priority, startup-
        delay, tier-id, vrrp, instance, hlthchk)[Default: None]
- vlagArg2
        This is an overloaded vlag second argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: Interval in seconds, disable or strict, Port Aggregation Number, VLAG priority, Delay time in seconds,
        VLAG tier-id value, VLAG instance number, keepalive-attempts, keepalive-interval, retry-interval, peer-
        ip)[Default: None]
- vlagArg3
        This is an overloaded vlag third argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: enable or port-aggregation, Number of keepalive attempts, Interval in seconds, Interval in seconds,
        VLAG health check peer IP4 address)[Default: None]
- vlagArg4
        This is an overloaded vlag fourth argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: Port Aggregation Number, default or management)[Default: None]
EXAMPLES:

Tasks : The following are examples of using the module cnos_vlag. These are written in the main.yml file of the tasks directory.
---
- name: Test Vlag  - enable
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "enable"

- name: Test Vlag - autorecovery
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "auto-recovery"
      vlagArg2: 266

- name: Test Vlag - config-consistency
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "config-consistency"
      vlagArg2: "strict"

- name: Test Vlag - isl
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "isl"
      vlagArg2: 23

- name: Test Vlag  - mac-address-table
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "mac-address-table"

- name: Test Vlag - peer-gateway
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "peer-gateway"

- name: Test Vlag - priority
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "priority"
      vlagArg2: 1313

- name: Test Vlag - startup-delay
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "startup-delay"
      vlagArg2: 323

- name: Test Vlag  - tier-id
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "tier-id"
      vlagArg2: 313

- name: Test Vlag - vrrp
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "vrrp"

- name: Test Vlag - instance
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "instance"
      vlagArg2: 33
      vlagArg3: 333

- name: Test Vlag - instance2
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "instance"
      vlagArg2: "33"

- name: Test Vlag  - keepalive-attempts
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "hlthchk"
      vlagArg2: "keepalive-attempts"
      vlagArg3: 13

- name: Test Vlag - keepalive-interval
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "hlthchk"
      vlagArg2: "keepalive-interval"
      vlagArg3: 131

- name: Test Vlag - retry-interval
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "hlthchk"
      vlagArg2: "retry-interval"
      vlagArg3: 133

- name: Test Vlag - peer ip
  cnos_vlag:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username']}}"
      password: "{{ hostvars[inventory_hostname]['password']}}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType']}}"
      outputfile: "./results/cnos_vlag_{{ inventory_hostname }}_output.txt"
      vlagArg1: "hlthchk"
      vlagArg2: "peer-ip"
      vlagArg3: "1.2.3.4"


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "vLAG configurations accomplished"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> CNOS_VLAN    (/usr/lib/python2.7/site-packages/ansible/modules/network/lenovo/cnos_vlan.py)

  This module allows you to work with VLAN related configurations. The operators used are overloaded to ensure control
  over switch VLAN configurations. The first level of VLAN configuration allows to set up the VLAN range, the VLAN tag
  persistence, a VLAN access map and access map filter. After passing this level, there are five VLAN arguments that will
  perform further configurations. They are vlanArg1, vlanArg2, vlanArg3, vlanArg4, and vlanArg5. The value of vlanArg1
  will determine the way following arguments will be evaluated. For more details on how to use these arguments, see
  [Overloaded Variables]. This module uses SSH to manage network device configuration. The results of the operation will
  be placed in a directory named 'results' that must be created by the user in their local directory to where the
  playbook is run. For more information about this module from Lenovo and customizing it usage for your use cases, please
  visit http://systemx.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.switchmgt.ansible.doc%2Fcnos_vlan.html

Options (= is mandatory):

= deviceType
        This specifies the type of device where the method is executed.
        (Choices: g8272_cnos, g8296_cnos, g8332_cnos)[Default: None]
- enablePassword
        Configures the password used to enter Global Configuration command mode on the switch. If the switch does not
        request this password, the parameter is ignored.While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= host
        This is the variable used to search the hosts file at /etc/ansible/hosts and identify the IP address of the
        device on which the template is going to be applied. Usually the Ansible keyword {{ inventory_hostname }} is
        specified in the playbook as an abstraction of the group of network elements that need to be configured.
        [Default: None]
= outputfile
        This specifies the file path where the output of each command execution is saved. Each command that is specified
        in the merged template file and each response from the device are saved here. Usually the location is the results
        folder, but you can choose another location based on your write permission.
        [Default: None]
= password
        Configures the password used to authenticate the connection to the remote device. The value of the password
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= username
        Configures the username used to authenticate the connection to the remote device. The value of the username
        parameter is used to authenticate the SSH session. While generally the value should come from the inventory file,
        you can also specify it as a variable. This parameter is optional. If it is not specified, no default value will
        be used.
        [Default: None]
= vlanArg1
        This is an overloaded vlan first argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: access-map, dot1q, filter, <1-3999> VLAN ID 1-3999 or range)[Default: None]
- vlanArg2
        This is an overloaded vlan second argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: VLAN Access Map name, egress-only, name, flood, state, ip)[Default: None]
- vlanArg3
        This is an overloaded vlan third argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: action, match, statistics, enter VLAN id or range of vlan, ascii name for the VLAN, ipv4 or ipv6,
        active or suspend, fast-leave, last-member-query-interval, mrouter, querier, querier-timeout, query-interval,
        query-max-response-time, report-suppression, robustness-variable, startup-query-count, startup-query-interval,
        static-group)[Default: None]
- vlanArg4
        This is an overloaded vlan fourth argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: drop or forward or redirect, ip or mac, Interval in seconds, ethernet, port-aggregation, Querier IP
        address, Querier Timeout in seconds, Query Interval in seconds, Query Max Response Time in seconds, Robustness
        Variable value, Number of queries sent at startup, Query Interval at startup)[Default: None]
- vlanArg5
        This is an overloaded vlan fifth argument. Usage of this argument can be found is the User Guide referenced
        above.
        (Choices: access-list name, Slot/chassis number, Port Aggregation Number)[Default: None]
EXAMPLES:

Tasks: The following are examples of using the module cnos_vlan. These are written in the main.yml file of the tasks directory.
---
- name: Test Vlan - Create a vlan, name it
  cnos_vlan:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_vlan_{{ inventory_hostname }}_output.txt"
      vlanArg1: 13
      vlanArg2: "name"
      vlanArg3: "Anil"

- name: Test Vlan - Create a vlan, Flood configuration
  cnos_vlan:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_vlan_{{ inventory_hostname }}_output.txt"
      vlanArg1: 13
      vlanArg2: "flood"
      vlanArg3: "ipv4"

- name: Test Vlan - Create a vlan, State configuration
  cnos_vlan:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_vlan_{{ inventory_hostname }}_output.txt"
      vlanArg1: 13
      vlanArg2: "state"
      vlanArg3: "active"

- name: Test Vlan - VLAN Access map1
  cnos_vlan:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_vlan_{{ inventory_hostname }}_output.txt"
      vlanArg1: "access-map"
      vlanArg2: "Anil"
      vlanArg3: "statistics"

- name: Test Vlan - VLAN Accep Map2
  cnos_vlan:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_vlan_{{ inventory_hostname }}_output.txt"
      vlanArg1: "access-map"
      vlanArg2: "Anil"
      vlanArg3: "action"
      vlanArg4: "forward"

- name: Test Vlan - ip igmp snooping query interval
  cnos_vlan:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_vlan_{{ inventory_hostname }}_output.txt"
      vlanArg1: 13
      vlanArg2: "ip"
      vlanArg3: "query-interval"
      vlanArg4: 1313

- name: Test Vlan - ip igmp snooping mrouter interface port-aggregation 23
  cnos_vlan:
      host: "{{ inventory_hostname }}"
      username: "{{ hostvars[inventory_hostname]['username'] }}"
      password: "{{ hostvars[inventory_hostname]['password'] }}"
      deviceType: "{{ hostvars[inventory_hostname]['deviceType'] }}"
      enablePassword: "{{ hostvars[inventory_hostname]['enablePassword'] }}"
      outputfile: "./results/test_vlan_{{ inventory_hostname }}_output.txt"
      vlanArg1: 13
      vlanArg2: "ip"
      vlanArg3: "mrouter"
      vlanArg4: "port-aggregation"
      vlanArg5: 23


RETURN VALUES:
msg:
  description: Success or failure message
  returned: always
  type: string
  sample: "VLAN configuration is accomplished"


MAINTAINERS: Dave Kasberg (@dkasberg)

METADATA:
	Status: ['preview']
	Supported_by: community
> COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/commands/command.py)

  The `command' module takes the command name followed by a list of space-delimited arguments. The given command will be
  executed on all selected nodes. It will not be processed through the shell, so variables like `$HOME' and operations
  like `"<"', `">"', `"|"', `";"' and `"&"' will not work (use the [shell] module if you need these features).

Options (= is mandatory):

- chdir
        cd into this directory before running the command
        [Default: None]
- creates
        a filename or (since 2.0) glob pattern, when it already exists, this step will *not* be run.
        [Default: None]
- executable
        change the shell used to execute the command. Should be an absolute path to the executable.
        [Default: None]
= free_form
        the command module takes a free form command to run.  There is no parameter actually named 'free form'. See the
        examples!
        [Default: None]
- removes
        a filename or (since 2.0) glob pattern, when it does not exist, this step will *not* be run.
        [Default: None]
- warn
        if command warnings are on in ansible.cfg, do not warn about this particular line if set to no/false.
        [Default: True]
Notes:
  * If you want to run a command through the shell (say you are using `<', `>', `|', etc), you actually want the
        [shell] module instead. The `command' module is much more secure as it's not affected by the user's
        environment.
  *  `creates', `removes', and `chdir' can be specified after the command. For instance, if you only want to run a
        command if a certain file does not exist, use this.
EXAMPLES:
- name: return motd to registered var
  command: cat /etc/motd
  register: mymotd

- name: Run the command if the specified file does not exist.
  command: /usr/bin/make_database.sh arg1 arg2 creates=/path/to/database

# You can also use the 'args' form to provide the options.
- name: This command will change the working directory to somedir/ and will only run when /path/to/database doesn't exist.
  command: /usr/bin/make_database.sh arg1 arg2
  args:
    chdir: somedir/
    creates: /path/to/database

- name: safely use templated variable to run command. Always use the quote filter to avoid injection issues.
  command: cat {{ myfile|quote }}
  register: myoutput


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> COMPOSER    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/composer.py)

  Composer is a tool for dependency management in PHP. It allows you to declare the dependent libraries your project
  needs and it will install them in your project for you.

Options (= is mandatory):

- arguments
        Composer arguments like required package, version and so on.
        [Default: None]
- command
        Composer command like "install", "update" and so on.
        [Default: install]
- ignore_platform_reqs
        Ignore php, hhvm, lib-* and ext-* requirements and force the installation even if the local machine does not
        fulfill these.
        (Choices: True, False)[Default: False]
- no_dev
        Disables installation of require-dev packages (see --no-dev).
        (Choices: True, False)[Default: True]
- no_plugins
        Disables all plugins ( see --no-plugins ).
        (Choices: True, False)[Default: False]
- no_scripts
        Skips the execution of all scripts defined in composer.json (see --no-scripts).
        (Choices: True, False)[Default: False]
- optimize_autoloader
        Optimize autoloader during autoloader dump (see --optimize-autoloader).
        Convert PSR-0/4 autoloading to classmap to get a faster autoloader.
        Recommended especially for production, but can take a bit of time to run so it is currently not done by default.
        (Choices: True, False)[Default: True]
- prefer_dist
        Forces installation from package dist even for dev versions (see --prefer-dist).
        (Choices: True, False)[Default: False]
- prefer_source
        Forces installation from package sources when possible (see --prefer-source).
        (Choices: True, False)[Default: False]
= working_dir
        Directory of your project (see --working-dir).
        [Default: None]
Notes:
  * Default options that are always appended in each execution are --no-ansi, --no-interaction and --no-progress if
        available.
  * We received reports about issues on macOS if composer was installed by Homebrew. Please use the official
        install method to avoid issues.
Requirements:  php, composer installed in bin path (recommended /usr/local/bin)

EXAMPLES:
# Downloads and installs all the libs and dependencies outlined in the /path/to/project/composer.lock
- composer:
    command: install
    working_dir: /path/to/project

- composer:
    command: require
    arguments: my/package
    working_dir: /path/to/project

# Clone project and install with all dependencies
- composer:
    command: create-project
    arguments: package/package /path/to/project ~1.0
    working_dir: /path/to/project
    prefer_dist: yes


MAINTAINERS: Dimitrios Tydeas Mengidis (@dmtrs), René Moser (@resmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> CONSUL    (/usr/lib/python2.7/site-packages/ansible/modules/clustering/consul.py)

  Registers services and checks for an agent with a consul cluster. A service is some process running on the agent node
  that should be advertised by consul's discovery mechanism. It may optionally supply a check definition, a periodic
  service test to notify the consul cluster of service's health. Checks may also be registered per node e.g. disk usage,
  or cpu usage and notify the health of the entire node to the cluster. Service level checks do not require a check name
  or id as these are derived by Consul from the Service name and id respectively by appending 'service:' Node level
  checks require a check_name and optionally a check_id. Currently, there is no complete way to retrieve the script,
  interval or ttl metadata for a registered check. Without this metadata it is  not possible to tell if the data supplied
  with ansible represents a change to a check. As a result this does not attempt to determine changes and will always
  report a changed occurred. An api method is planned to supply this metadata so at that stage change management will be
  added. See http://consul.io for more details.

Options (= is mandatory):

- check_id
        an ID for the service check, defaults to the check name, ignored if part of a service definition.
        [Default: None]
- check_name
        a name for the service check, defaults to the check id. required if standalone, ignored if part of service
        definition.
        [Default: None]
- host
        host of the consul agent defaults to localhost
        [Default: localhost]
- http
        checks can be registered with an http endpoint. This means that consul will check that the http endpoint returns
        a successful http status. Interval must also be provided with this option.
        [Default: None]
- interval
        the interval at which the service check will be run. This is a number with a s or m suffix to signify the units
        of seconds or minutes e.g 15s or 1m. If no suffix is supplied, m will be used by default e.g. 1 will be 1m.
        Required if the script param is specified.
        [Default: None]
- notes
        Notes to attach to check when registering it.
        [Default: None]
- port
        the port on which the consul agent is running
        [Default: 8500]
- scheme
        the protocol scheme on which the consul agent is running
        [Default: http]
- script
        the script/command that will be run periodically to check the health of the service. Scripts require an interval
        and vise versa
        [Default: None]
- service_address
        the address to advertise that the service will be listening on. This value will be passed as the `Address'
        parameter to Consul's /v1/agent/service/register API method, so refer to the Consul API documentation for further
        details.
        [Default: None]
- service_id
        the ID for the service, must be unique per node, defaults to the service name if the service name is supplied
        [Default: service_name if supplied]
- service_name
        Unique name for the service on a node, must be unique per node, required if registering a service. May be omitted
        if registering a node level check
        [Default: (null)]
- service_port
        the port on which the service is listening required for registration of a service, i.e. if service_name or
        service_id is set
        [Default: (null)]
= state
        register or deregister the consul service, defaults to present
        (Choices: present, absent)
- tags
        a list of tags that will be attached to the service registration.
        [Default: None]
- timeout
        A custom HTTP check timeout. The consul default is 10 seconds. Similar to the interval this is a number with a s
        or m suffix to signify the units of seconds or minutes, e.g. 15s or 1m.
        [Default: None]
- token
        the token key indentifying an ACL rule set. May be required to register services.
        [Default: None]
- ttl
        checks can be registered with a ttl instead of a script and interval this means that the service will check in
        with the agent before the ttl expires. If it doesn't the check will be considered failed. Required if registering
        a check and the script an interval are missing Similar to the interval this is a number with a s or m suffix to
        signify the units of seconds or minutes e.g 15s or 1m. If no suffix is supplied, m will be used by default e.g. 1
        will be 1m
        [Default: None]
- validate_certs
        whether to verify the tls certificate of the consul agent
        [Default: True]
Requirements:  python >= 2.6, python-consul, requests

EXAMPLES:
- name: register nginx service with the local consul agent
  consul:
    service_name: nginx
    service_port: 80

- name: register nginx service with curl check
  consul:
    service_name: nginx
    service_port: 80
    script: curl http://localhost
    interval: 60s

- name: register nginx with an http check
  consul:
    service_name: nginx
    service_port: 80
    interval: 60s
    http: http://localhost:80/status

- name: register external service nginx available at 10.1.5.23
  consul:
    service_name: nginx
    service_port: 80
    service_address: 10.1.5.23

- name: register nginx with some service tags
  consul:
    service_name: nginx
    service_port: 80
    tags:
      - prod
      - webservers

- name: remove nginx service
  consul:
    service_name: nginx
    state: absent

- name: create a node level check to test disk usage
  consul:
    check_name: Disk usage
    check_id: disk_usage
    script: /opt/disk_usage.py
    interval: 5m

- name: register an http check against a service that's already registered
  consul:
    check_name: nginx-check2
    check_id: nginx-check2
    service_id: nginx
    interval: 60s
    http: http://localhost:80/morestatus


MAINTAINERS: Steve Gargan (@sgargan)

METADATA:
	Status: ['preview']
	Supported_by: community
> CONSUL_ACL    (/usr/lib/python2.7/site-packages/ansible/modules/clustering/consul_acl.py)

  allows the addition, modification and deletion of ACL keys and associated rules in a consul cluster via the agent. For
  more details on using and configuring ACLs, see https://www.consul.io/docs/internals/acl.html.

Options (= is mandatory):

- host
        host of the consul agent defaults to localhost
        [Default: localhost]
- mgmt_token
        a management token is required to manipulate the acl lists
        [Default: (null)]
- name
        the name that should be associated with the acl key, this is opaque to Consul
        [Default: (null)]
- port
        the port on which the consul agent is running
        [Default: 8500]
- rules
        an list of the rules that should be associated with a given token.
        [Default: (null)]
- scheme
        the protocol scheme on which the consul agent is running
        [Default: http]
- state
        whether the ACL pair should be present or absent
        (Choices: present, absent)[Default: present]
- token
        the token key indentifying an ACL rule set. If generated by consul this will be a UUID.
        [Default: (null)]
- token_type
        the type of token that should be created, either management or client
        (Choices: client, management)[Default: client]
- validate_certs
        whether to verify the tls certificate of the consul agent
        [Default: True]
Requirements:  python >= 2.6, python-consul, pyhcl, requests

EXAMPLES:
    - name: create an acl token with rules
      consul_acl:
        mgmt_token: 'some_management_acl'
        host: 'consul1.mycluster.io'
        name: 'Foo access'
        rules:
          - key: 'foo'
            policy: read
          - key: 'private/foo'
            policy: deny

    - name: create an acl with specific token with both key and service rules
      consul_acl:
        mgmt_token: 'some_management_acl'
        name: 'Foo access'
        token: 'some_client_token'
        rules:
          - key: 'foo'
            policy: read
          - service: ''
            policy: write
          - service: 'secret-'
            policy: deny

    - name: remove a token
      consul_acl:
        mgmt_token: 'some_management_acl'
        host: 'consul1.mycluster.io'
        token: '172bd5c8-9fe9-11e4-b1b0-3c15c2c9fd5e'
        state: absent


MAINTAINERS: Steve Gargan (@sgargan)

METADATA:
	Status: ['preview']
	Supported_by: community
> CONSUL_KV    (/usr/lib/python2.7/site-packages/ansible/modules/clustering/consul_kv.py)

  Allows the addition, modification and deletion of key/value entries in a consul cluster via the agent. The entire
  contents of the record, including the indices, flags and session are returned as 'value'. If the key represents a
  prefix then Note that when a value is removed, the existing value if any is returned as part of the results. See
  http://www.consul.io/docs/agent/http.html#kv for more details.

Options (= is mandatory):

- cas
        used when acquiring a lock with a session. If the cas is 0, then Consul will only put the key if it does not
        already exist. If the cas value is non-zero, then the key is only set if the index matches the ModifyIndex of
        that key.
        [Default: None]
- flags
        opaque integer value that can be passed when setting a value.
        [Default: None]
- host
        host of the consul agent defaults to localhost
        [Default: localhost]
= key
        the key at which the value should be stored.

- port
        the port on which the consul agent is running
        [Default: 8500]
- recurse
        if the key represents a prefix, each entry with the prefix can be retrieved by setting this to true.
        [Default: False]
- scheme
        the protocol scheme on which the consul agent is running
        [Default: http]
- session
        the session that should be used to acquire or release a lock associated with a key/value pair
        [Default: None]
- state
        the action to take with the supplied key and value. If the state is 'present', the key contents will be set to
        the value supplied, 'changed' will be set to true only if the value was different to the current contents. The
        state 'absent' will remove the key/value pair, again 'changed' will be set to true only if the key actually
        existed prior to the removal. An attempt can be made to obtain or free the lock associated with a key/value pair
        with the states 'acquire' or 'release' respectively. a valid session must be supplied to make the attempt changed
        will be true if the attempt is successful, false otherwise.
        (Choices: present, absent, acquire, release)[Default: present]
- token
        the token key indentifying an ACL rule set that controls access to the key value pair
        [Default: None]
- validate_certs
        whether to verify the tls certificate of the consul agent
        [Default: True]
= value
        the value should be associated with the given key, required if state is present

Requirements:  python >= 2.6, python-consul, requests

EXAMPLES:

  - name: add or update the value associated with a key in the key/value store
    consul_kv:
      key: somekey
      value: somevalue

  - name: remove a key from the store
    consul_kv:
      key: somekey
      state: absent

  - name: add a node to an arbitrary group via consul inventory (see consul.ini)
    consul_kv:
      key: ansible/groups/dc1/somenode
      value: 'top_secret'

  - name: Register a key/value pair with an associated session
    consul_kv:
      key: stg/node/server_birthday
      value: 20160509
      session: "{{ sessionid }}"
      state: acquire


MAINTAINERS: Steve Gargan (@sgargan)

METADATA:
	Status: ['preview']
	Supported_by: community
> CONSUL_SESSION    (/usr/lib/python2.7/site-packages/ansible/modules/clustering/consul_session.py)

  allows the addition, modification and deletion of sessions in a consul cluster. These sessions can then be used in
  conjunction with key value pairs to implement distributed locks. In depth documentation for working with sessions can
  be found here http://www.consul.io/docs/internals/sessions.html

Options (= is mandatory):

- behavior
        the optional behavior that can be attached to the session when it is created. This can be set to either ‘release’
        or ‘delete’. This controls the behavior when a session is invalidated.
        [Default: release]
- checks
        a list of checks that will be used to verify the session health. If all the checks fail, the session will be
        invalidated and any locks associated with the session will be release and can be acquired once the associated
        lock delay has expired.
        [Default: None]
- datacenter
        name of the datacenter in which the session exists or should be created.
        [Default: None]
- delay
        the optional lock delay that can be attached to the session when it is created. Locks for invalidated sessions ar
        blocked from being acquired until this delay has expired. Durations are in seconds
        [Default: 15]
- host
        host of the consul agent defaults to localhost
        [Default: localhost]
- name
        the name that should be associated with the session. This is opaque to Consul and not required.
        [Default: None]
- node
        the name of the node that with which the session will be associated. by default this is the name of the agent.
        [Default: None]
- port
        the port on which the consul agent is running
        [Default: 8500]
- scheme
        the protocol scheme on which the consul agent is running
        [Default: http]
- state
        whether the session should be present i.e. created if it doesn't exist, or absent, removed if present. If
        created, the ID for the session is returned in the output. If absent, the name or ID is required to remove the
        session. Info for a single session, all the sessions for a node or all available sessions can be retrieved by
        specifying info, node or list for the state; for node or info, the node name or session id is required as
        parameter.
        (Choices: present, absent, info, node, list)[Default: present]
- validate_certs
        whether to verify the tls certificate of the consul agent
        [Default: True]
Requirements:  python >= 2.6, python-consul, requests

EXAMPLES:
- name: register basic session with consul
  consul_session:
    name: session1

- name: register a session with an existing check
  consul_session:
    name: session_with_check
    checks:
      - existing_check_name

- name: register a session with lock_delay
  consul_session:
    name: session_with_delay
    delay: 20s

- name: retrieve info about session by id
  consul_session: id=session_id state=info

- name: retrieve active sessions
  consul_session: state=list


MAINTAINERS: Steve Gargan @sgargan

METADATA:
	Status: ['preview']
	Supported_by: community
> COPY    (/usr/lib/python2.7/site-packages/ansible/modules/files/copy.py)

  The `copy' module copies a file on the local box to remote locations. Use the [fetch] module to copy files from remote
  locations to the local box. If you need variable interpolation in copied files, use the [template] module.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- content
        When used instead of 'src', sets the contents of a file directly to the specified value. This is for simple
        values, for anything complex or with formatting please switch to the template module.
        [Default: None]
= dest
        Remote absolute path where the file should be copied to. If src is a directory, this must be a directory too.
        [Default: None]
- directory_mode
        When doing a recursive copy set the mode for the directories. If this is not set we will use the system defaults.
        The mode is only set on directories which are newly created, and will not affect those that already existed.
        [Default: (null)]
- follow
        This flag indicates that filesystem links, if they exist, should be followed.
        (Choices: yes, no)[Default: no]
- force
        the default is `yes', which will replace the remote file when contents are different than the source. If `no',
        the file will only be transferred if the destination does not exist.
        (Choices: yes, no)[Default: yes]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- remote_src
        If False, it will search for src at originating/master machine, if True it will go to the remote/target machine
        for the src. Default is False.
        Currently remote_src does not support recursive copying.
        (Choices: True, False)[Default: False]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- src
        Local path to a file to copy to the remote server; can be absolute or relative. If path is a directory, it is
        copied recursively. In this case, if path ends with "/", only inside contents of that directory are copied to
        destination. Otherwise, if it does not end with "/", the directory itself with all contents is copied. This
        behavior is similar to Rsync.
        [Default: None]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- validate
        The validation command to run before copying into place. The path to the file to validate is passed in via '%s'
        which must be present as in the example below. The command is passed securely so shell features like expansion
        and pipes won't work.
        [Default: None]
Notes:
  * The "copy" module recursively copy facility does not scale to lots (>hundreds) of files. For alternative, see
        synchronize module, which is a wrapper around rsync.
EXAMPLES:
# Example from Ansible Playbooks
- copy:
    src: /srv/myfiles/foo.conf
    dest: /etc/foo.conf
    owner: foo
    group: foo
    mode: 0644

# The same example as above, but using a symbolic mode equivalent to 0644
- copy:
    src: /srv/myfiles/foo.conf
    dest: /etc/foo.conf
    owner: foo
    group: foo
    mode: "u=rw,g=r,o=r"

# Another symbolic mode example, adding some permissions and removing others
- copy:
    src: /srv/myfiles/foo.conf
    dest: /etc/foo.conf
    owner: foo
    group: foo
    mode: "u+rw,g-wx,o-rwx"

# Copy a new "ntp.conf file into place, backing up the original if it differs from the copied version
- copy:
    src: /mine/ntp.conf
    dest: /etc/ntp.conf
    owner: root
    group: root
    mode: 0644
    backup: yes

# Copy a new "sudoers" file into place, after passing validation with visudo
- copy:
    src: /mine/sudoers
    dest: /etc/sudoers
    validate: 'visudo -cf %s'

RETURN VALUES:
dest:
    description: destination file/path
    returned: success
    type: string
    sample: "/path/to/file.txt"
src:
    description: source file used for the copy on the target machine
    returned: changed
    type: string
    sample: "/home/httpd/.ansible/tmp/ansible-tmp-1423796390.97-147729857856000/source"
md5sum:
    description: md5 checksum of the file after running copy
    returned: when supported
    type: string
    sample: "2a5aeecc61dc98c4d780b14b330e3282"
checksum:
    description: sha1 checksum of the file after running copy
    returned: success
    type: string
    sample: "6e642bb8dd5c2e027bf21dd923337cbb4214f827"
backup_file:
    description: name of backup file created
    returned: changed and if backup=yes
    type: string
    sample: "/path/to/file.txt.2015-02-12@22:09~"
gid:
    description: group id of the file, after execution
    returned: success
    type: int
    sample: 100
group:
    description: group of the file, after execution
    returned: success
    type: string
    sample: "httpd"
owner:
    description: owner of the file, after execution
    returned: success
    type: string
    sample: "httpd"
uid:
    description: owner id of the file, after execution
    returned: success
    type: int
    sample: 100
mode:
    description: permissions of the target, after execution
    returned: success
    type: string
    sample: "0644"
size:
    description: size of the target, after execution
    returned: success
    type: int
    sample: 1220
state:
    description: state of the target, after execution
    returned: success
    type: string
    sample: "file"


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> CPANM    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/cpanm.py)

  Manage Perl library dependencies.

Options (= is mandatory):

- executable
        Override the path to the cpanm executable
        [Default: None]
- from_path
        The local directory from where to install
        [Default: None]
- installdeps
        Only install dependencies
        [Default: False]
- locallib
        Specify the install base to install modules
        [Default: False]
- mirror
        Specifies the base URL for the CPAN mirror to use
        [Default: False]
- mirror_only
        Use the mirror's index file instead of the CPAN Meta DB
        [Default: False]
- name
        The name of the Perl library to install. You may use the "full distribution path", e.g.
        MIYAGAWA/Plack-0.99_05.tar.gz
        [Default: None]
- notest
        Do not run unit tests
        [Default: False]
- system_lib
        Use this if you want to install modules to the system perl include path. You must be root or have "passwordless"
        sudo for this to work.
        This uses the cpanm commandline option '--sudo', which has nothing to do with ansible privilege escalation.
        [Default: False]
- version
        minimum version of perl module to consider acceptable
        [Default: False]
Notes:
  * Please note that http://search.cpan.org/dist/App-cpanminus/bin/cpanm, cpanm must be installed on the remote
        host.
EXAMPLES:
# install Dancer perl package
- cpanm:
    name: Dancer

# install version 0.99_05 of the Plack perl package
- cpanm:
    name: MIYAGAWA/Plack-0.99_05.tar.gz

# install Dancer into the specified locallib
- cpanm:
    name: Dancer
    locallib: /srv/webapps/my_app/extlib

# install perl dependencies from local directory
- cpanm:
    from_path: /srv/webapps/my_app/src/

# install Dancer perl package without running the unit tests in indicated locallib
- cpanm:
    name: Dancer
    notest: True
    locallib: /srv/webapps/my_app/extlib

# install Dancer perl package from a specific mirror
- cpanm:
    name: Dancer
    mirror: 'http://cpan.cpantesters.org/'

# install Dancer perl package into the system root path
- cpanm:
    name: Dancer
    system_lib: yes

# install Dancer if it's not already installed
# OR the installed version is older than version 1.0
- cpanm:
    name: Dancer
    version: '1.0'


MAINTAINERS: Franck Cuny (@franckcuny)

METADATA:
	Status: ['preview']
	Supported_by: community
> CRON    (/usr/lib/python2.7/site-packages/ansible/modules/system/cron.py)

  Use this module to manage crontab and environment variables entries. This module allows you to create environment
  variables and named crontab entries, update, or delete them. When crontab jobs are managed: the module includes one
  line with the description of the crontab entry `"#Ansible: <name>"' corresponding to the "name" passed to the module,
  which is used by future ansible/module calls to find/check the state. The "name" parameter should be unique, and
  changing the "name" value will result in a new cron task being created (or a different one being removed). When
  environment variables are managed: no comment line is added, but, when the module needs to find/check the state, it
  uses the "name" parameter to find the environment variable definition line. When using symbols such as %, they must be
  properly escaped.

Options (= is mandatory):

- backup
        If set, create a backup of the crontab before it is modified. The location of the backup is returned in the
        `backup_file' variable by this module.
        (Choices: yes, no)[Default: False]
- cron_file
        If specified, uses this file instead of an individual user's crontab. If this is a relative path, it is
        interpreted with respect to /etc/cron.d. (If it is absolute, it will typically be /etc/crontab). To use the
        `cron_file' parameter you must specify the `user' as well.
        [Default: None]
- day
        Day of the month the job should run ( 1-31, *, */2, etc )
        [Default: *]
- disabled
        If the job should be disabled (commented out) in the crontab. Only has effect if state=present
        [Default: False]
- env
        If set, manages a crontab's environment variable. New variables are added on top of crontab. "name" and "value"
        parameters are the name and the value of environment variable.
        (Choices: yes, no)[Default: no]
- hour
        Hour when the job should run ( 0-23, *, */2, etc )
        [Default: *]
- insertafter
        Used with `state=present' and `env'. If specified, the environment variable will be inserted after the
        declaration of specified environment variable.
        [Default: None]
- insertbefore
        Used with `state=present' and `env'. If specified, the environment variable will be inserted before the
        declaration of specified environment variable.
        [Default: None]
- job
        The command to execute or, if env is set, the value of environment variable. Required if state=present.
        [Default: None]
- minute
        Minute when the job should run ( 0-59, *, */2, etc )
        [Default: *]
- month
        Month of the year the job should run ( 1-12, *, */2, etc )
        [Default: *]
- name
        Description of a crontab entry or, if env is set, the name of environment variable. Required if state=absent.
        Note that if name is not set and state=present, then a new crontab entry will always be created, regardless of
        existing ones.
        [Default: None]
- reboot
        If the job should be run at reboot. This option is deprecated. Users should use special_time.
        (Choices: yes, no)[Default: no]
- special_time
        Special time specification nickname.
        (Choices: reboot, yearly, annually, monthly, weekly, daily, hourly)[Default: None]
- state
        Whether to ensure the job or environment variable is present or absent.
        (Choices: present, absent)[Default: present]
- user
        The specific user whose crontab should be modified.
        [Default: root]
- weekday
        Day of the week that the job should run ( 0-6 for Sunday-Saturday, *, etc )
        [Default: *]
Requirements:  cron

EXAMPLES:
# Ensure a job that runs at 2 and 5 exists.
# Creates an entry like "0 5,2 * * ls -alh > /dev/null"
- cron:
    name: "check dirs"
    minute: "0"
    hour: "5,2"
    job: "ls -alh > /dev/null"

# Ensure an old job is no longer present. Removes any job that is prefixed
# by "#Ansible: an old job" from the crontab
- cron:
    name: "an old job"
    state: absent

# Creates an entry like "@reboot /some/job.sh"
- cron:
    name: "a job for reboot"
    special_time: reboot
    job: "/some/job.sh"

# Creates an entry like "PATH=/opt/bin" on top of crontab
- cron:
    name: PATH
    env: yes
    value: /opt/bin

# Creates an entry like "APP_HOME=/srv/app" and insert it after PATH
# declaration
- cron:
    name: APP_HOME
    env: yes
    value: /srv/app
    insertafter: PATH

# Creates a cron file under /etc/cron.d
- cron:
    name: yum autoupdate
    weekday: 2
    minute: 0
    hour: 12
    user: root
    job: "YUMINTERACTIVE: 0 /usr/sbin/yum-autoupdate"
    cron_file: ansible_yum-autoupdate

# Removes a cron file from under /etc/cron.d
- cron:
    name: "yum autoupdate"
    cron_file: ansible_yum-autoupdate
    state: absent

# Removes "APP_HOME" environment variable from crontab
- cron:
    name: APP_HOME
    env: yes
    state: absent


MAINTAINERS: Patrick Callahan, Mike Grozak, Evan Kaufman (@EvanK), Luca Berruti (@lberruti), Dane Summers (@dsummersl)

METADATA:
	Status: ['preview']
	Supported_by: community
> CRONVAR    (/usr/lib/python2.7/site-packages/ansible/modules/system/cronvar.py)

  Use this module to manage crontab variables. This module allows you to create, update, or delete cron variable
  definitions.

Options (= is mandatory):

- backup
        If set, create a backup of the crontab before it is modified. The location of the backup is returned in the
        `backup' variable by this module.
        [Default: False]
- cron_file
        If specified, uses this file instead of an individual user's crontab. Without a leading /, this is assumed to be
        in /etc/cron.d.  With a leading /, this is taken as absolute.
        [Default: None]
- insertafter
        Used with `state=present'. If specified, the variable will be inserted after the variable specified.
        [Default: None]
- insertbefore
        Used with `state=present'. If specified, the variable will be inserted just before the variable specified.
        [Default: None]
= name
        Name of the crontab variable.
        [Default: None]
- state
        Whether to ensure that the variable is present or absent.
        (Choices: present, absent)[Default: present]
- user
        The specific user whose crontab should be modified.
        [Default: root]
- value
        The value to set this variable to.  Required if state=present.
        [Default: None]
Requirements:  cron

EXAMPLES:
# Ensure a variable exists.
# Creates an entry like "EMAIL=doug@ansibmod.con.com"
- cronvar:
    name: EMAIL
    value: doug@ansibmod.con.com

# Make sure a variable is gone.  This will remove any variable named
# "LEGACY"
- cronvar:
    name: LEGACY
    state: absent

# Adds a variable to a file under /etc/cron.d
- cronvar:
    name: LOGFILE
    value: /var/log/yum-autoupdate.log
    user: root
    cron_file: ansible_yum-autoupdate


MAINTAINERS: Doug Luce (@dougluce)

METADATA:
	Status: ['preview']
	Supported_by: community
> CRYPTTAB    (/usr/lib/python2.7/site-packages/ansible/modules/system/crypttab.py)

  Control Linux encrypted block devices that are set up during system boot in `/etc/crypttab'.

Options (= is mandatory):

- backing_device
        Path to the underlying block device or file, or the UUID of a block-device prefixed with `UUID='
        [Default: None]
= name
        Name of the encrypted block device as it appears in the `/etc/crypttab' file, or optionaly prefixed with
        `/dev/mapper/', as it appears in the filesystem. `/dev/mapper/' will be stripped from `name'.
        [Default: None]
- opts
        A comma-delimited list of options. See `crypttab(5' ) for details.
        [Default: (null)]
- password
        Encryption password, the path to a file containing the password, or 'none' or '-' if the password should be
        entered at boot.
        [Default: none]
- path
        Path to file to use instead of `/etc/crypttab'. This might be useful in a chroot environment.
        [Default: /etc/crypttab]
= state
        Use `present' to add a line to `/etc/crypttab' or update it's definition if already present. Use `absent' to
        remove a line with matching `name'. Use `opts_present' to add options to those already present; options with
        different values will be updated. Use `opts_absent' to remove options from the existing set.
        (Choices: present, absent, opts_present, opts_absent)[Default: None]
EXAMPLES:

# Since column is a special character in YAML, if your string contains a column, it's better to use quotes around the string
- name: Set the options explicitly a device which must already exist
  crypttab:
    name: luks-home
    state: present
    opts: 'discard,cipher=aes-cbc-essiv:sha256'

- name: Add the 'discard' option to any existing options for all devices
  crypttab:
    name: '{{ item.device }}'
    state: opts_present
    opts: discard
  with_items: '{{ ansible_mounts }}'
  when: "'/dev/mapper/luks-' in {{ item.device }}"


MAINTAINERS: Steve (@groks)

METADATA:
	Status: ['preview']
	Supported_by: community
> CS_ACCOUNT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_account.py)

  Create, disable, lock, enable and remove accounts.

Options (= is mandatory):

- account_type
        Type of the account.
        (Choices: user, root_admin, domain_admin)[Default: user]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the account is related to.
        [Default: ROOT]
- email
        Email of the user to be created if account did not exist.
        Required on `state=present'.
        [Default: None]
- first_name
        First name of the user to be created if account did not exist.
        Required on `state=present'.
        [Default: None]
- last_name
        Last name of the user to be created if account did not exist.
        Required on `state=present'.
        [Default: None]
= name
        Name of account.

- network_domain
        Network domain of the account.
        [Default: None]
- password
        Password of the user to be created if account did not exist.
        Required on `state=present'.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- state
        State of the account.
        `unlocked' is an alias for `enabled'.
        (Choices: present, absent, enabled, disabled, locked, unlocked)[Default: present]
- timezone
        Timezone of the user to be created if account did not exist.
        [Default: None]
- username
        Username of the user to be created if account did not exist.
        Required on `state=present'.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# create an account in domain 'CUSTOMERS'
local_action:
  module: cs_account
  name: customer_xy
  username: customer_xy
  password: S3Cur3
  last_name: Doe
  first_name: John
  email: john.doe@example.com
  domain: CUSTOMERS

# Lock an existing account in domain 'CUSTOMERS'
local_action:
  module: cs_account
  name: customer_xy
  domain: CUSTOMERS
  state: locked

# Disable an existing account in domain 'CUSTOMERS'
local_action:
  module: cs_account
  name: customer_xy
  domain: CUSTOMERS
  state: disabled

# Enable an existing account in domain 'CUSTOMERS'
local_action:
  module: cs_account
  name: customer_xy
  domain: CUSTOMERS
  state: enabled

# Remove an account in domain 'CUSTOMERS'
local_action:
  module: cs_account
  name: customer_xy
  domain: CUSTOMERS
  state: absent

RETURN VALUES:
---
id:
  description: UUID of the account.
  returned: success
  type: string
  sample: 87b1e0ce-4e01-11e4-bb66-0050569e64b8
name:
  description: Name of the account.
  returned: success
  type: string
  sample: linus@example.com
account_type:
  description: Type of the account.
  returned: success
  type: string
  sample: user
state:
  description: State of the account.
  returned: success
  type: string
  sample: enabled
network_domain:
  description: Network domain of the account.
  returned: success
  type: string
  sample: example.local
domain:
  description: Domain the account is related.
  returned: success
  type: string
  sample: ROOT


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_AFFINITYGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_affinitygroup.py)

  Create and remove affinity groups.

Options (= is mandatory):

- account
        Account the affinity group is related to.
        [Default: None]
- affinty_type
        Type of the affinity group. If not specified, first found affinity type is used.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- description
        Description of the affinity group.
        [Default: None]
- domain
        Domain the affinity group is related to.
        [Default: None]
= name
        Name of the affinity group.

- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the affinity group is related to.
        [Default: None]
- state
        State of the affinity group.
        (Choices: present, absent)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create a affinity group
- local_action:
    module: cs_affinitygroup
    name: haproxy
    affinty_type: host anti-affinity

# Remove a affinity group
- local_action:
    module: cs_affinitygroup
    name: haproxy
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the affinity group.
  returned: success
  type: string
  sample: 87b1e0ce-4e01-11e4-bb66-0050569e64b8
name:
  description: Name of affinity group.
  returned: success
  type: string
  sample: app
description:
  description: Description of affinity group.
  returned: success
  type: string
  sample: application affinity group
affinity_type:
  description: Type of affinity group.
  returned: success
  type: string
  sample: host anti-affinity
project:
  description: Name of project the affinity group is related to.
  returned: success
  type: string
  sample: Production
domain:
  description: Domain the affinity group is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the affinity group is related to.
  returned: success
  type: string
  sample: example account


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_CLUSTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_cluster.py)

  Create, update and remove clusters.

Options (= is mandatory):

- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cluster_type
        Type of the cluster.
        Required if `state=present'
        (Choices: CloudManaged, ExternalManaged)[Default: None]
- guest_vswitch_name
        Name of virtual switch used for guest traffic in the cluster.
        This would override zone wide traffic label setting.
        [Default: None]
- guest_vswitch_type
        Type of virtual switch used for guest traffic in the cluster.
        Allowed values are, vmwaresvs (for VMware standard vSwitch) and vmwaredvs (for VMware distributed vSwitch)
        (Choices: vmwaresvs, vmwaredvs)[Default: None]
- hypervisor
        Name the hypervisor to be used.
        Required if `state=present'.
        (Choices: KVM, VMware, BareMetal, XenServer, LXC, HyperV, UCS, OVM)[Default: none]
= name
        name of the cluster.

- ovm3_cluster
        Ovm3 native OCFS2 clustering enabled for cluster.
        [Default: None]
- ovm3_pool
        Ovm3 native pooling enabled for cluster.
        [Default: None]
- ovm3_vip
        Ovm3 vip to use for pool (and cluster).
        [Default: None]
- password
        Password for the cluster.
        [Default: None]
- pod
        Name of the pod in which the cluster belongs to.
        [Default: None]
- public_vswitch_name
        Name of virtual switch used for public traffic in the cluster.
        This would override zone wide traffic label setting.
        [Default: None]
- public_vswitch_type
        Type of virtual switch used for public traffic in the cluster.
        Allowed values are, vmwaresvs (for VMware standard vSwitch) and vmwaredvs (for VMware distributed vSwitch)
        (Choices: vmwaresvs, vmwaredvs)[Default: None]
- state
        State of the cluster.
        (Choices: present, absent, disabled, enabled)[Default: present]
- url
        URL for the cluster
        [Default: None]
- username
        Username for the cluster.
        [Default: None]
- vms_ip_address
        IP address of the VSM associated with this cluster.
        [Default: None]
- vms_password
        Password for the VSM associated with this cluster.
        [Default: None]
- vms_username
        Username for the VSM associated with this cluster.
        [Default: None]
- zone
        Name of the zone in which the cluster belongs to.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure a cluster is present
- local_action:
    module: cs_cluster
    name: kvm-cluster-01
    zone: ch-zrh-ix-01
    hypervisor: KVM
    cluster_type: CloudManaged

# Ensure a cluster is disabled
- local_action:
    module: cs_cluster
    name: kvm-cluster-01
    zone: ch-zrh-ix-01
    state: disabled

# Ensure a cluster is enabled
- local_action:
    module: cs_cluster
    name: kvm-cluster-01
    zone: ch-zrh-ix-01
    state: enabled

# Ensure a cluster is absent
- local_action:
    module: cs_cluster
    name: kvm-cluster-01
    zone: ch-zrh-ix-01
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the cluster.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the cluster.
  returned: success
  type: string
  sample: cluster01
allocation_state:
  description: State of the cluster.
  returned: success
  type: string
  sample: Enabled
cluster_type:
  description: Type of the cluster.
  returned: success
  type: string
  sample: ExternalManaged
cpu_overcommit_ratio:
  description: The CPU overcommit ratio of the cluster.
  returned: success
  type: string
  sample: 1.0
memory_overcommit_ratio:
  description: The memory overcommit ratio of the cluster.
  returned: success
  type: string
  sample: 1.0
managed_state:
  description: Whether this cluster is managed by CloudStack.
  returned: success
  type: string
  sample: Managed
ovm3_vip:
  description: Ovm3 VIP to use for pooling and/or clustering
  returned: success
  type: string
  sample: 10.10.10.101
hypervisor:
  description: Hypervisor of the cluster
  returned: success
  type: string
  sample: VMware
zone:
  description: Name of zone the cluster is in.
  returned: success
  type: string
  sample: ch-gva-2
pod:
  description: Name of pod the cluster is in.
  returned: success
  type: string
  sample: pod01


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_CONFIGURATION    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_configuration.py)

  Manages global, zone, account, storage and cluster configurations.

Options (= is mandatory):

- account
        Ensure the value for corresponding account.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cluster
        Ensure the value for corresponding cluster.
        [Default: None]
- domain
        Domain the account is related to.
        Only considered if `account' is used.
        [Default: ROOT]
= name
        Name of the configuration.

- storage
        Ensure the value for corresponding storage pool.
        [Default: None]
= value
        Value of the configuration.

- zone
        Ensure the value for corresponding zone.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure global configuration
- local_action:
    module: cs_configuration
    name: router.reboot.when.outofband.migrated
    value: false

# Ensure zone configuration
- local_action:
    module: cs_configuration
    name: router.reboot.when.outofband.migrated
    zone: ch-gva-01
    value: true

# Ensure storage configuration
- local_action:
    module: cs_configuration
    name: storage.overprovisioning.factor
    storage: storage01
    value: 2.0

# Ensure account configuration
- local_action:
    module: cs_configuration
    name: allow.public.user.templates
    value: false
    account: acme inc
    domain: customers

RETURN VALUES:
---
category:
  description: Category of the configuration.
  returned: success
  type: string
  sample: Advanced
scope:
  description: Scope (zone/cluster/storagepool/account) of the parameter that needs to be updated.
  returned: success
  type: string
  sample: storagepool
description:
  description: Description of the configuration.
  returned: success
  type: string
  sample: Setup the host to do multipath
name:
  description: Name of the configuration.
  returned: success
  type: string
  sample: zone.vlan.capacity.notificationthreshold
value:
  description: Value of the configuration.
  returned: success
  type: string
  sample: "0.75"
account:
  description: Account of the configuration.
  returned: success
  type: string
  sample: admin
Domain:
  description: Domain of account of the configuration.
  returned: success
  type: string
  sample: ROOT
zone:
  description: Zone of the configuration.
  returned: success
  type: string
  sample: ch-gva-01
cluster:
  description: Cluster of the configuration.
  returned: success
  type: string
  sample: cluster01
storage:
  description: Storage of the configuration.
  returned: success
  type: string
  sample: storage01


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_DOMAIN    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_domain.py)

  Create, update and remove domains.

Options (= is mandatory):

- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- clean_up
        Clean up all domain resources like child domains and accounts.
        Considered on `state=absent'.
        [Default: False]
- network_domain
        Network domain for networks in the domain.
        [Default: None]
= path
        Path of the domain.
        Prefix `ROOT/' or `/ROOT/' in path is optional.

- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- state
        State of the domain.
        (Choices: present, absent)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create a domain
local_action:
  module: cs_domain
  path: ROOT/customers
  network_domain: customers.example.com

# Create another subdomain
local_action:
  module: cs_domain
  path: ROOT/customers/xy
  network_domain: xy.customers.example.com

# Remove a domain
local_action:
  module: cs_domain
  path: ROOT/customers/xy
  state: absent

RETURN VALUES:
---
id:
  description: UUID of the domain.
  returned: success
  type: string
  sample: 87b1e0ce-4e01-11e4-bb66-0050569e64b8
name:
  description: Name of the domain.
  returned: success
  type: string
  sample: customers
path:
  description: Domain path.
  returned: success
  type: string
  sample: /ROOT/customers
parent_domain:
  description: Parent domain of the domain.
  returned: success
  type: string
  sample: ROOT
network_domain:
  description: Network domain of the domain.
  returned: success
  type: string
  sample: example.local


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_facts.py)

  This module fetches data from the metadata API in CloudStack. The module must be called from within the instance
  itself.

Options (= is mandatory):

- filter
        Filter for a specific fact.
        (Choices: cloudstack_service_offering, cloudstack_availability_zone, cloudstack_public_hostname,
        cloudstack_public_ipv4, cloudstack_local_hostname, cloudstack_local_ipv4, cloudstack_instance_id,
        cloudstack_user_data)[Default: None]
Requirements:  yaml

EXAMPLES:
# Gather all facts on instances
- name: Gather cloudstack facts
  cs_facts:

# Gather specific fact on instances
- name: Gather cloudstack facts
  cs_facts: filter=cloudstack_instance_id

RETURN VALUES:
---
cloudstack_availability_zone:
  description: zone the instance is deployed in.
  returned: success
  type: string
  sample: ch-gva-2
cloudstack_instance_id:
  description: UUID of the instance.
  returned: success
  type: string
  sample: ab4e80b0-3e7e-4936-bdc5-e334ba5b0139
cloudstack_local_hostname:
  description: local hostname of the instance.
  returned: success
  type: string
  sample: VM-ab4e80b0-3e7e-4936-bdc5-e334ba5b0139
cloudstack_local_ipv4:
  description: local IPv4 of the instance.
  returned: success
  type: string
  sample: 185.19.28.35
cloudstack_public_hostname:
  description: public IPv4 of the router. Same as C(cloudstack_public_ipv4).
  returned: success
  type: string
  sample: VM-ab4e80b0-3e7e-4936-bdc5-e334ba5b0139
cloudstack_public_ipv4:
  description: public IPv4 of the router.
  returned: success
  type: string
  sample: 185.19.28.35
cloudstack_service_offering:
  description: service offering of the instance.
  returned: success
  type: string
  sample: Micro 512mb 1cpu
cloudstack_user_data:
  description: data of the instance provided by users.
  returned: success
  type: dict
  sample: { "bla": "foo" }


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_FIREWALL    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_firewall.py)

  Creates and removes firewall rules.

Options (= is mandatory):

- account
        Account the firewall rule is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cidr
        CIDR (full notation) to be used for firewall rule.
        [Default: 0.0.0.0/0]
- domain
        Domain the firewall rule is related to.
        [Default: None]
- end_port
        End port for this rule. Considered if `protocol=tcp' or `protocol=udp'. If not specified, equal `start_port'.
        [Default: None]
- icmp_code
        Error code for this icmp message. Considered if `protocol=icmp'.
        [Default: None]
- icmp_type
        Type of the icmp message being sent. Considered if `protocol=icmp'.
        [Default: None]
- ip_address
        Public IP address the ingress rule is assigned to.
        Required if `type=ingress'.
        [Default: None]
- network
        Network the egress rule is related to.
        Required if `type=egress'.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the firewall rule is related to.
        [Default: None]
- protocol
        Protocol of the firewall rule.
        `all' is only available if `type=egress'
        (Choices: tcp, udp, icmp, all)[Default: tcp]
- start_port
        Start port for this rule. Considered if `protocol=tcp' or `protocol=udp'.
        [Default: None]
- state
        State of the firewall rule.
        (Choices: present, absent)[Default: present]
- type
        Type of the firewall rule.
        (Choices: ingress, egress)[Default: ingress]
- zone
        Name of the zone in which the virtual machine is in.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Allow inbound port 80/tcp from 1.2.3.4 to 4.3.2.1
- local_action:
    module: cs_firewall
    ip_address: 4.3.2.1
    port: 80
    cidr: 1.2.3.4/32

# Allow inbound tcp/udp port 53 to 4.3.2.1
- local_action:
    module: cs_firewall
    ip_address: 4.3.2.1
    port: 53
    protocol: '{{ item }}'
  with_items:
  - tcp
  - udp

# Ensure firewall rule is removed
- local_action:
    module: cs_firewall
    ip_address: 4.3.2.1
    start_port: 8000
    end_port: 8888
    cidr: 17.0.0.0/8
    state: absent

# Allow all outbound traffic
- local_action:
    module: cs_firewall
    network: my_network
    type: egress
    protocol: all

# Allow only HTTP outbound traffic for an IP
- local_action:
    module: cs_firewall
    network: my_network
    type: egress
    port: 80
    cidr: 10.101.1.20

RETURN VALUES:
---
id:
  description: UUID of the rule.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
ip_address:
  description: IP address of the rule if C(type=ingress)
  returned: success
  type: string
  sample: 10.100.212.10
type:
  description: Type of the rule.
  returned: success
  type: string
  sample: ingress
cidr:
  description: CIDR of the rule.
  returned: success
  type: string
  sample: 0.0.0.0/0
protocol:
  description: Protocol of the rule.
  returned: success
  type: string
  sample: tcp
start_port:
  description: Start port of the rule.
  returned: success
  type: int
  sample: 80
end_port:
  description: End port of the rule.
  returned: success
  type: int
  sample: 80
icmp_code:
  description: ICMP code of the rule.
  returned: success
  type: int
  sample: 1
icmp_type:
  description: ICMP type of the rule.
  returned: success
  type: int
  sample: 1
network:
  description: Name of the network if C(type=egress)
  returned: success
  type: string
  sample: my_network


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_host.py)

  Create, update and remove hosts.

Options (= is mandatory):

- allocation_state
        Allocation state of the host.
        (Choices: enabled, disabled)[Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cluster
        Name of the cluster.
        [Default: None]
- host_tags
        Tags of the host.
        [Default: None]
- hypervisor
        Name of the cluster.
        Required if `state=present' and host does not yet exist.
        (Choices: KVM, VMware, BareMetal, XenServer, LXC, HyperV, UCS, OVM, Simulator)[Default: None]
= name
        Name of the host.

- password
        Password for the host.
        Required if `state=present' and host does not yet exist.
        [Default: None]
- pod
        Name of the pod.
        Required if `state=present' and host does not yet exist.
        [Default: None]
- state
        State of the host.
        (Choices: present, absent)[Default: present]
- username
        Username for the host.
        Required if `state=present' and host does not yet exist.
        [Default: None]
- zone
        Name of the zone in which the host should be deployed.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure a host is present but disabled
- local_action:
    module: cs_host
    name: ix-pod01-esx01.example.com
    cluster: vcenter.example.com/ch-zrh-ix/pod01-cluster01
    pod: pod01
    zone: ch-zrh-ix-01
    hypervisor: VMware
    allocation_state: disabled
    host_tags:
    - perf
    - gpu

# Ensure an existing host is disabled
- local_action:
    module: cs_host
    name: ix-pod01-esx01.example.com
    zone: ch-zrh-ix-01
    allocation_state: disabled

# Ensure an existing host is disabled
- local_action:
    module: cs_host
    name: ix-pod01-esx01.example.com
    zone: ch-zrh-ix-01
    allocation_state: enabled

# Ensure a host is absent
- local_action:
    module: cs_host
    name: ix-pod01-esx01.example.com
    zone: ch-zrh-ix-01
    state: absent

RETURN VALUES:
---
capabilities:
  description: Capabilities of the host.
  returned: success
  type: string
  sample: hvm
cluster:
  description: Cluster of the host.
  returned: success
  type: string
  sample: vcenter.example.com/zone/cluster01
cluster_type:
  description: Type of the cluster of the host.
  returned: success
  type: string
  sample: ExternalManaged
cpu_allocated:
  description: Amount in percent of the host's CPU currently allocated.
  returned: success
  type: string
  sample: 166.25%
cpu_number:
  description: Number of CPUs of the host.
  returned: success
  type: string
  sample: 24
cpu_sockets:
  description: Number of CPU sockets of the host.
  returned: success
  type: int
  sample: 2
cpu_speed:
  description: CPU speed in Mhz
  returned: success
  type: int
  sample: 1999
cpu_used:
  description: Amount of the host's CPU currently used.
  returned: success
  type: string
  sample: 33.6%
cpu_with_overprovisioning:
  description: Amount of the host's CPU after applying the cpu.overprovisioning.factor.
  returned: success
  type: string
  sample: 959520.0
created:
  description: Date when the host was created.
  returned: success
  type: string
  sample: 2015-05-03T15:05:51+0200
disconnected:
  description: Date when the host was disconnected.
  returned: success
  type: string
  sample: 2015-05-03T15:05:51+0200
disk_size_allocated:
  description: Host's currently allocated disk size.
  returned: success
  type: int
  sample: 2593
disk_size_total:
  description: Total disk size of the host
  returned: success
  type: int
  sample: 259300
events:
  description: Events available for the host
  returned: success
  type: string
  sample: "Ping; HostDown; AgentConnected; AgentDisconnected; PingTimeout; ShutdownRequested; Remove; StartAgentRebalance; ManagementServerDown"
ha_host:
  description: Whether the host is a HA host.
  returned: success
  type: bool
  sample: false
has_enough_capacity:
  description: Whether the host has enough CPU and RAM capacity to migrate a VM to it.
  returned: success
  type: bool
  sample: true
host_tags:
  description: Comma-separated list of tags for the host.
  returned: success
  type: string
  sample: "perf"
hypervisor:
  description: Host's hypervisor.
  returned: success
  type: string
  sample: VMware
hypervisor_version:
  description: Hypervisor version.
  returned: success
  type: string
  sample: 5.1
ip_address:
  description: IP address of the host
  returned: success
  type: string
  sample: 10.10.10.1
is_local_storage_active:
  description: Whether the local storage is available or not.
  returned: success
  type: bool
  sample: false
last_pinged:
  description: Date and time the host was last pinged.
  returned: success
  type: string
  sample: "1970-01-17T17:27:32+0100"
management_server_id:
  description: Management server ID of the host.
  returned: success
  type: int
  sample: 345050593418
memory_allocated:
  description: Amount of the host's memory currently allocated.
  returned: success
  type: int
  sample: 69793218560
memory_total:
  description: Total of memory of the host.
  returned: success
  type: int
  sample: 206085263360
memory_used:
  description: Amount of the host's memory currently used.
  returned: success
  type: int
  sample: 65504776192
name:
  description: Name of the host.
  returned: success
  type: string
  sample: esx32.example.com
network_kbs_read:
  description: Incoming network traffic on the host.
  returned: success
  type: int
  sample: 0
network_kbs_write:
  description: Outgoing network traffic on the host.
  returned: success
  type: int
  sample: 0
os_category:
  description: OS category name of the host.
  returned: success
  type: string
  sample: ...
out_of_band_management:
  description: Host out-of-band management information.
  returned: success
  type: string
  sample: ...
pod:
  description: Pod name of the host.
  returned: success
  type: string
  sample: Pod01
removed:
  description: Date and time the host was removed.
  returned: success
  type: string
  sample: "1970-01-17T17:27:32+0100"
resource_state:
  description: Resource state of the host.
  returned: success
  type: string
  sample: Enabled
state:
  description: State of the host.
  returned: success
  type: string
  sample: Up
suitable_for_migration:
  description: Whether this host is suitable (has enough capacity and satisfies all conditions like hosttags, max guests VM limit, etc) to migrate a VM to it or not.
  returned: success
  type: string
  sample: true
host_type:
  description: Type of the host.
  returned: success
  type: string
  sample: Routing
host_version:
  description: Version of the host.
  returned: success
  type: string
  sample: 4.5.2
gpu_group:
  description: GPU cards present in the host.
  returned: success
  type: list
  sample: []
zone:
  description: Zone of the host.
  returned: success
  type: string
  sample: zone01


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> CS_INSTANCE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_instance.py)

  Deploy, start, update, scale, restart, restore, stop and destroy instances.

Options (= is mandatory):

- account
        Account the instance is related to.
        [Default: None]
- affinity_groups
        Affinity groups names to be applied to the new instance.
        [Default: []]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cpu
        The number of CPUs to allocate to the instance, used with custom service offerings
        [Default: None]
- cpu_speed
        The clock speed/shares allocated to the instance, used with custom service offerings
        [Default: None]
- disk_offering
        Name of the disk offering to be used.
        [Default: None]
- disk_size
        Disk size in GByte required if deploying instance from ISO.
        [Default: None]
- display_name
        Custom display name of the instances.
        Display name will be set to `name' if not specified.
        Either `name' or `display_name' is required.
        [Default: None]
- domain
        Domain the instance is related to.
        [Default: None]
- force
        Force stop/start the instance if required to apply changes, otherwise a running instance will not be changed.
        [Default: False]
- group
        Group in where the new instance should be in.
        [Default: None]
- hypervisor
        Name the hypervisor to be used for creating the new instance.
        Relevant when using `state=present', but only considered if not set on ISO/template.
        If not set or found on ISO/template, first found hypervisor will be used.
        (Choices: KVM, VMware, BareMetal, XenServer, LXC, HyperV, UCS, OVM)[Default: None]
- ip6_address
        IPv6 address for default instance's network.
        [Default: None]
- ip_address
        IPv4 address for default instance's network during creation.
        [Default: None]
- ip_to_networks
        List of mappings in the form {'network': NetworkName, 'ip': 1.2.3.4}
        Mutually exclusive with `networks' option.
        [Default: None]
- iso
        Name or id of the ISO to be used for creating the new instance.
        Required when using `state=present'.
        Mutually exclusive with `template' option.
        [Default: None]
- keyboard
        Keyboard device type for the instance.
        (Choices: de, de-ch, es, fi, fr, fr-be, fr-ch, is, it, jp, nl-be, no, pt, uk, us)[Default: None]
- memory
        The memory allocated to the instance, used with custom service offerings
        [Default: None]
- name
        Host name of the instance. `name' can only contain ASCII letters.
        Name will be generated (UUID) by CloudStack if not specified and can not be changed afterwards.
        Either `name' or `display_name' is required.
        [Default: None]
- networks
        List of networks to use for the new instance.
        [Default: []]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the instance to be deployed in.
        [Default: None]
- root_disk_size
        Root disk size in GByte required if deploying instance with KVM hypervisor and want resize the root disk size at
        startup (need CloudStack >= 4.4, cloud-initramfs-growroot installed and enabled in the template)
        [Default: None]
- security_groups
        List of security groups the instance to be applied to.
        [Default: None]
- service_offering
        Name or id of the service offering of the new instance.
        If not set, first found service offering is used.
        [Default: None]
- ssh_key
        Name of the SSH key to be deployed on the new instance.
        [Default: None]
- state
        State of the instance.
        (Choices: deployed, started, stopped, restarted, restored, destroyed, expunged, present, absent)[Default:
        present]
- tags
        List of tags. Tags are a list of dictionaries having keys `key' and `value'.
        If you want to delete all tags, set a empty list e.g. `tags: []'.
        [Default: None]
- template
        Name or id of the template to be used for creating the new instance.
        Required when using `state=present'.
        Mutually exclusive with `ISO' option.
        [Default: None]
- template_filter
        Name of the filter used to search for the template or iso.
        Used for params `iso' or `template' on `state=present'.
        (Choices: featured, self, selfexecutable, sharedexecutable, executable, community)[Default: executable]
- user_data
        Optional data (ASCII) that can be sent to the instance upon a successful deployment.
        The data will be automatically base64 encoded.
        Consider switching to HTTP_POST by using `CLOUDSTACK_METHOD=post' to increase the HTTP_GET size limit of 2KB to
        32 KB.
        [Default: None]
- zone
        Name of the zone in which the instance should be deployed.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create a instance from an ISO
# NOTE: Names of offerings and ISOs depending on the CloudStack configuration.
- cs_instance:
    name: web-vm-1
    iso: Linux Debian 7 64-bit
    hypervisor: VMware
    project: Integration
    zone: ch-zrh-ix-01
    service_offering: 1cpu_1gb
    disk_offering: PerfPlus Storage
    disk_size: 20
    networks:
      - Server Integration
      - Sync Integration
      - Storage Integration
  delegate_to: localhost

# For changing a running instance, use the 'force' parameter
- cs_instance:
    name: web-vm-1
    display_name: web-vm-01.example.com
    iso: Linux Debian 7 64-bit
    service_offering: 2cpu_2gb
    force: yes
  delegate_to: localhost

# Create or update a instance on Exoscale's public cloud using display_name.
# Note: user_data can be used to kickstart the instance using cloud-init yaml config.
- cs_instance:
    display_name: web-vm-1
    template: Linux Debian 7 64-bit
    service_offering: Tiny
    ssh_key: john@example.com
    tags:
      - key: admin
        value: john
      - key: foo
        value: bar
    user_data: |
        #cloud-config
        packages:
          - nginx
  delegate_to: localhost

# Create an instance with multiple interfaces specifying the IP addresses
- cs_instance:
    name: web-vm-1
    template: Linux Debian 7 64-bit
    service_offering: Tiny
    ip_to_networks:
      - network: NetworkA
        ip: 10.1.1.1
      - network: NetworkB
        ip: 192.0.2.1
  delegate_to: localhost

# Ensure an instance is stopped
- cs_instance:
    name: web-vm-1
    state: stopped
  delegate_to: localhost

# Ensure an instance is running
- cs_instance:
    name: web-vm-1
    state: started
  delegate_to: localhost

# Remove an instance
- cs_instance:
    name: web-vm-1
    state: absent
  delegate_to: localhost

RETURN VALUES:
---
id:
  description: UUID of the instance.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the instance.
  returned: success
  type: string
  sample: web-01
display_name:
  description: Display name of the instance.
  returned: success
  type: string
  sample: web-01
group:
  description: Group name of the instance is related.
  returned: success
  type: string
  sample: web
created:
  description: Date of the instance was created.
  returned: success
  type: string
  sample: 2014-12-01T14:57:57+0100
password_enabled:
  description: True if password setting is enabled.
  returned: success
  type: boolean
  sample: true
password:
  description: The password of the instance if exists.
  returned: success
  type: string
  sample: Ge2oe7Do
ssh_key:
  description: Name of SSH key deployed to instance.
  returned: success
  type: string
  sample: key@work
domain:
  description: Domain the instance is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the instance is related to.
  returned: success
  type: string
  sample: example account
project:
  description: Name of project the instance is related to.
  returned: success
  type: string
  sample: Production
default_ip:
  description: Default IP address of the instance.
  returned: success
  type: string
  sample: 10.23.37.42
public_ip:
  description: Public IP address with instance via static NAT rule.
  returned: success
  type: string
  sample: 1.2.3.4
iso:
  description: Name of ISO the instance was deployed with.
  returned: success
  type: string
  sample: Debian-8-64bit
template:
  description: Name of template the instance was deployed with.
  returned: success
  type: string
  sample: Debian-8-64bit
service_offering:
  description: Name of the service offering the instance has.
  returned: success
  type: string
  sample: 2cpu_2gb
zone:
  description: Name of zone the instance is in.
  returned: success
  type: string
  sample: ch-gva-2
state:
  description: State of the instance.
  returned: success
  type: string
  sample: Running
security_groups:
  description: Security groups the instance is in.
  returned: success
  type: list
  sample: '[ "default" ]'
affinity_groups:
  description: Affinity groups the instance is in.
  returned: success
  type: list
  sample: '[ "webservers" ]'
tags:
  description: List of resource tags associated with the instance.
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'
hypervisor:
  description: Hypervisor related to this instance.
  returned: success
  type: string
  sample: KVM
instance_name:
  description: Internal name of the instance (ROOT admin only).
  returned: success
  type: string
  sample: i-44-3992-VM


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_INSTANCE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_instance_facts.py)

  Gathering facts from the API of an instance.

Options (= is mandatory):

- account
        Account the instance is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the instance is related to.
        [Default: None]
= name
        Name or display name of the instance.

- project
        Project the instance is related to.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
- cs_instance_facts:
    name: web-vm-1
  delegate_to: localhost

- debug:
    var: cloudstack_instance

RETURN VALUES:
---
cloudstack_instance.id:
  description: UUID of the instance.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
cloudstack_instance.name:
  description: Name of the instance.
  returned: success
  type: string
  sample: web-01
cloudstack_instance.display_name:
  description: Display name of the instance.
  returned: success
  type: string
  sample: web-01
cloudstack_instance.group:
  description: Group name of the instance is related.
  returned: success
  type: string
  sample: web
created:
  description: Date of the instance was created.
  returned: success
  type: string
  sample: 2014-12-01T14:57:57+0100
cloudstack_instance.password_enabled:
  description: True if password setting is enabled.
  returned: success
  type: boolean
  sample: true
cloudstack_instance.password:
  description: The password of the instance if exists.
  returned: success
  type: string
  sample: Ge2oe7Do
cloudstack_instance.ssh_key:
  description: Name of SSH key deployed to instance.
  returned: success
  type: string
  sample: key@work
cloudstack_instance.domain:
  description: Domain the instance is related to.
  returned: success
  type: string
  sample: example domain
cloudstack_instance.account:
  description: Account the instance is related to.
  returned: success
  type: string
  sample: example account
cloudstack_instance.project:
  description: Name of project the instance is related to.
  returned: success
  type: string
  sample: Production
cloudstack_instance.default_ip:
  description: Default IP address of the instance.
  returned: success
  type: string
  sample: 10.23.37.42
cloudstack_instance.public_ip:
  description: Public IP address with instance via static NAT rule.
  returned: success
  type: string
  sample: 1.2.3.4
cloudstack_instance.iso:
  description: Name of ISO the instance was deployed with.
  returned: success
  type: string
  sample: Debian-8-64bit
cloudstack_instance.template:
  description: Name of template the instance was deployed with.
  returned: success
  type: string
  sample: Debian-8-64bit
cloudstack_instance.service_offering:
  description: Name of the service offering the instance has.
  returned: success
  type: string
  sample: 2cpu_2gb
cloudstack_instance.zone:
  description: Name of zone the instance is in.
  returned: success
  type: string
  sample: ch-gva-2
cloudstack_instance.state:
  description: State of the instance.
  returned: success
  type: string
  sample: Running
cloudstack_instance.security_groups:
  description: Security groups the instance is in.
  returned: success
  type: list
  sample: '[ "default" ]'
cloudstack_instance.affinity_groups:
  description: Affinity groups the instance is in.
  returned: success
  type: list
  sample: '[ "webservers" ]'
cloudstack_instance.tags:
  description: List of resource tags associated with the instance.
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'
cloudstack_instance.hypervisor:
  description: Hypervisor related to this instance.
  returned: success
  type: string
  sample: KVM
cloudstack_instance.instance_name:
  description: Internal name of the instance (ROOT admin only).
  returned: success
  type: string
  sample: i-44-3992-VM


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_INSTANCEGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_instancegroup.py)

  Create and remove instance groups.

Options (= is mandatory):

- account
        Account the instance group is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the instance group is related to.
        [Default: None]
= name
        Name of the instance group.

- project
        Project the instance group is related to.
        [Default: None]
- state
        State of the instance group.
        (Choices: present, absent)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create an instance group
- local_action:
    module: cs_instancegroup
    name: loadbalancers

# Remove an instance group
- local_action:
    module: cs_instancegroup
    name: loadbalancers
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the instance group.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the instance group.
  returned: success
  type: string
  sample: webservers
created:
  description: Date when the instance group was created.
  returned: success
  type: string
  sample: 2015-05-03T15:05:51+0200
domain:
  description: Domain the instance group is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the instance group is related to.
  returned: success
  type: string
  sample: example account
project:
  description: Project the instance group is related to.
  returned: success
  type: string
  sample: example project


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_IP_ADDRESS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_ip_address.py)

  Acquires and associates a public IP to an account or project. Due to API limitations this is not an idempotent call, so
  be sure to only conditionally call this when `state=present'

Options (= is mandatory):

- account
        Account the IP address is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the IP address is related to.
        [Default: None]
- ip_address
        Public IP address.
        Required if `state=absent'
        [Default: None]
- network
        Network the IP address is related to.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the IP address is related to.
        [Default: None]
- vpc
        VPC the IP address is related to.
        [Default: None]
- zone
        Name of the zone in which the IP address is in.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Associate an IP address conditonally
- local_action:
    module: cs_ip_address
    network: My Network
  register: ip_address
  when: instance.public_ip is undefined

# Disassociate an IP address
- local_action:
    module: cs_ip_address
    ip_address: 1.2.3.4
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the Public IP address.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
ip_address:
  description: Public IP address.
  returned: success
  type: string
  sample: 1.2.3.4
zone:
  description: Name of zone the IP address is related to.
  returned: success
  type: string
  sample: ch-gva-2
project:
  description: Name of project the IP address is related to.
  returned: success
  type: string
  sample: Production
account:
  description: Account the IP address is related to.
  returned: success
  type: string
  sample: example account
domain:
  description: Domain the IP address is related to.
  returned: success
  type: string
  sample: example domain


MAINTAINERS: Darren Worrall (@dazworrall), René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_ISO    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_iso.py)

  Register and remove ISO images.

Options (= is mandatory):

- account
        Account the ISO is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- bootable
        Register the ISO to be bootable. Only used if `state' is present.
        [Default: True]
- checksum
        The MD5 checksum value of this ISO. If set, we search by checksum instead of name.
        [Default: False]
- domain
        Domain the ISO is related to.
        [Default: None]
- is_dynamically_scalable
        Register the ISO having XS/VMWare tools installed inorder to support dynamic scaling of VM cpu/memory. Only used
        if `state' is present.
        [Default: False]
- is_featured
        Register the ISO to be featured. Only used if `state' is present.
        [Default: False]
- is_public
        Register the ISO to be publicly available to all users. Only used if `state' is present.
        [Default: False]
- is_ready
        This flag is used for searching existing ISOs. If set to `true', it will only list ISO ready for deployment e.g.
        successfully downloaded and installed. Recommended to set it to `false'.
        [Default: False]
- iso_filter
        Name of the filter used to search for the ISO.
        (Choices: featured, self, selfexecutable, sharedexecutable, executable, community)[Default: self]
= name
        Name of the ISO.

- os_type
        Name of the OS that best represents the OS of this ISO. If the iso is bootable this parameter needs to be passed.
        Required if `state' is present.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the ISO to be registered in.
        [Default: None]
- state
        State of the ISO.
        (Choices: present, absent)[Default: present]
- url
        URL where the ISO can be downloaded from. Required if `state' is present.
        [Default: None]
- zone
        Name of the zone you wish the ISO to be registered or deleted from. If not specified, first zone found will be
        used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Register an ISO if ISO name does not already exist.
- local_action:
    module: cs_iso
    name: Debian 7 64-bit
    url: http://mirror.switch.ch/ftp/mirror/debian-cd/current/amd64/iso-cd/debian-7.7.0-amd64-netinst.iso
    os_type: Debian GNU/Linux 7(64-bit)

# Register an ISO with given name if ISO md5 checksum does not already exist.
- local_action:
    module: cs_iso
    name: Debian 7 64-bit
    url: http://mirror.switch.ch/ftp/mirror/debian-cd/current/amd64/iso-cd/debian-7.7.0-amd64-netinst.iso
    os_type: Debian GNU/Linux 7(64-bit)
    checksum: 0b31bccccb048d20b551f70830bb7ad0

# Remove an ISO by name
- local_action:
    module: cs_iso
    name: Debian 7 64-bit
    state: absent

# Remove an ISO by checksum
- local_action:
    module: cs_iso
    name: Debian 7 64-bit
    checksum: 0b31bccccb048d20b551f70830bb7ad0
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the ISO.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
name:
  description: Name of the ISO.
  returned: success
  type: string
  sample: Debian 7 64-bit
display_text:
  description: Text to be displayed of the ISO.
  returned: success
  type: string
  sample: Debian 7.7 64-bit minimal 2015-03-19
zone:
  description: Name of zone the ISO is registered in.
  returned: success
  type: string
  sample: zuerich
status:
  description: Status of the ISO.
  returned: success
  type: string
  sample: Successfully Installed
is_ready:
  description: True if the ISO is ready to be deployed from.
  returned: success
  type: boolean
  sample: true
checksum:
  description: MD5 checksum of the ISO.
  returned: success
  type: string
  sample: 0b31bccccb048d20b551f70830bb7ad0
created:
  description: Date of registering.
  returned: success
  type: string
  sample: 2015-03-29T14:57:06+0200
domain:
  description: Domain the ISO is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the ISO is related to.
  returned: success
  type: string
  sample: example account
project:
  description: Project the ISO is related to.
  returned: success
  type: string
  sample: example project


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_LOADBALANCER_RULE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_loadbalancer_rule.py)

  Add, update and remove load balancer rules.

Options (= is mandatory):

- account
        Account the rule is related to.
        [Default: None]
- algorithm
        Load balancer algorithm
        Required when using `state=present'.
        (Choices: source, roundrobin, leastconn)[Default: source]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cidr
        CIDR (full notation) to be used for firewall rule if required.
        [Default: None]
- description
        The description of the load balancer rule.
        [Default: None]
- domain
        Domain the rule is related to.
        [Default: None]
= ip_address
        Public IP address from where the network traffic will be load balanced from.

= name
        The name of the load balancer rule.

- open_firewall
        Whether the firewall rule for public port should be created, while creating the new rule.
        Use [cs_firewall] for managing firewall rules.
        [Default: False]
- private_port
        The private port of the private ip address/virtual machine where the network traffic will be load balanced to.
        Required when using `state=present'.
        Can not be changed once the rule exists due API limitation.
        [Default: None]
- project
        Name of the project the load balancer IP address is related to.
        [Default: None]
- protocol
        The protocol to be used on the load balancer
        [Default: None]
= public_port
        The public port from where the network traffic will be load balanced from.
        Required when using `state=present'.
        Can not be changed once the rule exists due API limitation.
        [Default: None]
= state
        State of the rule.
        (Choices: present, absent)[Default: present]
- zone
        Name of the zone in which the rule should be created.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create a load balancer rule
- local_action:
    module: cs_loadbalancer_rule
    name: balance_http
    public_ip: 1.2.3.4
    algorithm: leastconn
    public_port: 80
    private_port: 8080

# update algorithm of an existing load balancer rule
- local_action:
    module: cs_loadbalancer_rule
    name: balance_http
    public_ip: 1.2.3.4
    algorithm: roundrobin
    public_port: 80
    private_port: 8080

# Delete a load balancer rule
- local_action:
    module: cs_loadbalancer_rule
    name: balance_http
    public_ip: 1.2.3.4
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the rule.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
zone:
  description: Name of zone the rule is related to.
  returned: success
  type: string
  sample: ch-gva-2
project:
  description: Name of project the rule is related to.
  returned: success
  type: string
  sample: Production
account:
  description: Account the rule is related to.
  returned: success
  type: string
  sample: example account
domain:
  description: Domain the rule is related to.
  returned: success
  type: string
  sample: example domain
algorithm:
  description: Load balancer algorithm used.
  returned: success
  type: string
  sample: "source"
cidr:
  description: CIDR to forward traffic from.
  returned: success
  type: string
  sample: ""
name:
  description: Name of the rule.
  returned: success
  type: string
  sample: "http-lb"
description:
  description: Description of the rule.
  returned: success
  type: string
  sample: "http load balancer rule"
protocol:
  description: Protocol of the rule.
  returned: success
  type: string
  sample: "tcp"
public_port:
  description: Public port.
  returned: success
  type: string
  sample: 80
private_port:
  description: Private IP address.
  returned: success
  type: string
  sample: 80
public_ip:
  description: Public IP address.
  returned: success
  type: string
  sample: "1.2.3.4"
tags:
  description: List of resource tags associated with the rule.
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'
state:
  description: State of the rule.
  returned: success
  type: string
  sample: "Add"


MAINTAINERS: Darren Worrall (@dazworrall), René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_LOADBALANCER_RULE_MEMBER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_loadbalancer_rule_member.py)

  Add and remove load balancer rule members.

Options (= is mandatory):

- account
        Account the rule is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the rule is related to.
        [Default: None]
- ip_address
        Public IP address from where the network traffic will be load balanced from.
        Only needed to find the rule if `name' is not unique.
        [Default: None]
= name
        The name of the load balancer rule.

- project
        Name of the project the firewall rule is related to.
        [Default: None]
- state
        Should the VMs be present or absent from the rule.
        (Choices: present, absent)[Default: present]
= vms
        List of VMs to assign to or remove from the rule.

- zone
        Name of the zone in which the rule should be located.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Add VMs to an exising load balancer
- local_action:
    module: cs_loadbalancer_rule_member
    name: balance_http
    vms:
      - web01
      - web02

# Remove a VM from an existing load balancer
- local_action:
    module: cs_loadbalancer_rule_member
    name: balance_http
    vms:
      - web01
      - web02
    state: absent

# Rolling upgrade of hosts
- hosts: webservers
  serial: 1
  pre_tasks:
    - name: Remove from load balancer
      local_action:
        module: cs_loadbalancer_rule_member
        name: balance_http
        vm: "{{ ansible_hostname }}"
        state: absent
  tasks:
    # Perform update
  post_tasks:
    - name: Add to load balancer
      local_action:
        module: cs_loadbalancer_rule_member
        name: balance_http
        vm: "{{ ansible_hostname }}"
        state: present

RETURN VALUES:
---
id:
  description: UUID of the rule.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
zone:
  description: Name of zone the rule is related to.
  returned: success
  type: string
  sample: ch-gva-2
project:
  description: Name of project the rule is related to.
  returned: success
  type: string
  sample: Production
account:
  description: Account the rule is related to.
  returned: success
  type: string
  sample: example account
domain:
  description: Domain the rule is related to.
  returned: success
  type: string
  sample: example domain
algorithm:
  description: Load balancer algorithm used.
  returned: success
  type: string
  sample: "source"
cidr:
  description: CIDR to forward traffic from.
  returned: success
  type: string
  sample: ""
name:
  description: Name of the rule.
  returned: success
  type: string
  sample: "http-lb"
description:
  description: Description of the rule.
  returned: success
  type: string
  sample: "http load balancer rule"
protocol:
  description: Protocol of the rule.
  returned: success
  type: string
  sample: "tcp"
public_port:
  description: Public port.
  returned: success
  type: string
  sample: 80
private_port:
  description: Private IP address.
  returned: success
  type: string
  sample: 80
public_ip:
  description: Public IP address.
  returned: success
  type: string
  sample: "1.2.3.4"
vms:
  description: Rule members.
  returned: success
  type: list
  sample: '[ "web01", "web02" ]'
tags:
  description: List of resource tags associated with the rule.
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'
state:
  description: State of the rule.
  returned: success
  type: string
  sample: "Add"


MAINTAINERS: Darren Worrall (@dazworrall), René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_NETWORK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_network.py)

  Create, update, restart and delete networks.

Options (= is mandatory):

- account
        Account the network is related to.
        [Default: None]
- acl_type
        Access control type.
        Only considered on create.
        (Choices: account, domain)[Default: account]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cidr_ipv6
        CIDR of IPv6 network, must be at least /64.
        Only considered on create.
        [Default: None]
- clean_up
        Cleanup old network elements.
        Only considered on `state=restarted'.
        [Default: False]
- display_text
        Display text of the network.
        If not specified, `name' will be used as `display_text'.
        [Default: None]
- domain
        Domain the network is related to.
        [Default: None]
- end_ip
        The ending IPv4 address of the network belongs to.
        If not specified, value of `start_ip' is used.
        Only considered on create.
        [Default: None]
- end_ipv6
        The ending IPv6 address of the network belongs to.
        If not specified, value of `start_ipv6' is used.
        Only considered on create.
        [Default: None]
- gateway
        The gateway of the network.
        Required for shared networks and isolated networks when it belongs to a VPC.
        Only considered on create.
        [Default: None]
- gateway_ipv6
        The gateway of the IPv6 network.
        Required for shared networks.
        Only considered on create.
        [Default: None]
- isolated_pvlan
        The isolated private VLAN for this network.
        [Default: None]
= name
        Name (case sensitive) of the network.

- netmask
        The netmask of the network.
        Required for shared networks and isolated networks when it belongs to a VPC.
        Only considered on create.
        [Default: None]
- network_domain
        The network domain.
        [Default: None]
- network_offering
        Name of the offering for the network.
        Required if `state=present'.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the network to be deployed in.
        [Default: None]
- start_ip
        The beginning IPv4 address of the network belongs to.
        Only considered on create.
        [Default: None]
- start_ipv6
        The beginning IPv6 address of the network belongs to.
        Only considered on create.
        [Default: None]
- state
        State of the network.
        (Choices: present, absent, restarted)[Default: present]
- vlan
        The ID or VID of the network.
        [Default: None]
- vpc
        Name of the VPC of the network.
        [Default: None]
- zone
        Name of the zone in which the network should be deployed.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# create a network
- local_action:
    module: cs_network
    name: my network
    zone: gva-01
    network_offering: DefaultIsolatedNetworkOfferingWithSourceNatService
    network_domain: example.com

# update a network
- local_action:
    module: cs_network
    name: my network
    display_text: network of domain example.local
    network_domain: example.local

# restart a network with clean up
- local_action:
    module: cs_network
    name: my network
    clean_up: yes
    state: restared

# remove a network
- local_action:
    module: cs_network
    name: my network
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the network.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the network.
  returned: success
  type: string
  sample: web project
display_text:
  description: Display text of the network.
  returned: success
  type: string
  sample: web project
dns1:
  description: IP address of the 1st nameserver.
  returned: success
  type: string
  sample: 1.2.3.4
dns2:
  description: IP address of the 2nd nameserver.
  returned: success
  type: string
  sample: 1.2.3.4
cidr:
  description: IPv4 network CIDR.
  returned: success
  type: string
  sample: 10.101.64.0/24
gateway:
  description: IPv4 gateway.
  returned: success
  type: string
  sample: 10.101.64.1
netmask:
  description: IPv4 netmask.
  returned: success
  type: string
  sample: 255.255.255.0
cidr_ipv6:
  description: IPv6 network CIDR.
  returned: success
  type: string
  sample: 2001:db8::/64
gateway_ipv6:
  description: IPv6 gateway.
  returned: success
  type: string
  sample: 2001:db8::1
state:
  description: State of the network.
  returned: success
  type: string
  sample: Implemented
zone:
  description: Name of zone.
  returned: success
  type: string
  sample: ch-gva-2
domain:
  description: Domain the network is related to.
  returned: success
  type: string
  sample: ROOT
account:
  description: Account the network is related to.
  returned: success
  type: string
  sample: example account
project:
  description: Name of project.
  returned: success
  type: string
  sample: Production
tags:
  description: List of resource tags associated with the network.
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'
acl_type:
  description: Access type of the network (Domain, Account).
  returned: success
  type: string
  sample: Account
broadcast_domain_type:
  description: Broadcast domain type of the network.
  returned: success
  type: string
  sample: Vlan
type:
  description: Type of the network.
  returned: success
  type: string
  sample: Isolated
traffic_type:
  description: Traffic type of the network.
  returned: success
  type: string
  sample: Guest
state:
  description: State of the network (Allocated, Implemented, Setup).
  returned: success
  type: string
  sample: Allocated
is_persistent:
  description: Whether the network is persistent or not.
  returned: success
  type: boolean
  sample: false
network_domain:
  description: The network domain
  returned: success
  type: string
  sample: example.local
network_offering:
  description: The network offering name.
  returned: success
  type: string
  sample: DefaultIsolatedNetworkOfferingWithSourceNatService


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_NIC    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_nic.py)

  Add and remove secondary IPs to and from a NIC.

Options (= is mandatory):

- account
        Account the instance is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the instance is related to.
        [Default: None]
- network
        Name of the network.
        Required to find the NIC if instance has multiple networks assigned.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the instance is deployed in.
        [Default: None]
- state
        State of the ipaddress.
        (Choices: present, absent)[Default: present]
= vm
        Name of instance.

- vm_guest_ip
        Secondary IP address to be added to the instance nic.
        If not set, the API always returns a new IP address and idempotency is not given.
        [Default: None]
- vpc
        Name of the VPC the `vm' is related to.
        [Default: None]
- zone
        Name of the zone in which the instance is deployed in.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Assign a specific IP to the default NIC of the VM
- local_action:
    module: cs_nic
    vm: customer_xy
    vm_guest_ip: 10.10.10.10

# Assign an IP to the default NIC of the VM
# Note: If vm_guest_ip is not set, you will get a new IP address on every run.
- local_action:
    module: cs_nic
    vm: customer_xy

# Remove a specific IP from the default NIC
- local_action:
    module: cs_nic
    vm: customer_xy
    vm_guest_ip: 10.10.10.10
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the nic.
  returned: success
  type: string
  sample: 87b1e0ce-4e01-11e4-bb66-0050569e64b8
vm:
  description: Name of the VM.
  returned: success
  type: string
  sample: web-01
ip_address:
  description: Primary IP of the NIC.
  returned: success
  type: string
  sample: 10.10.10.10
netmask:
  description: Netmask of the NIC.
  returned: success
  type: string
  sample: 255.255.255.0
mac_address:
  description: MAC address of the NIC.
  returned: success
  type: string
  sample: 02:00:33:31:00:e4
vm_guest_ip:
  description: Secondary IP of the NIC.
  returned: success
  type: string
  sample: 10.10.10.10
network:
  description: Name of the network if not default.
  returned: success
  type: string
  sample: sync network
domain:
  description: Domain the VM is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the VM is related to.
  returned: success
  type: string
  sample: example account
project:
  description: Name of project the VM is related to.
  returned: success
  type: string
  sample: Production


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_POD    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_pod.py)

  Create, update, delete pods.

Options (= is mandatory):

- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- end_ip
        Ending IP address for the Pod.
        [Default: None]
- gateway
        Gateway for the Pod.
        Required on `state=present'
        [Default: None]
- id
        uuid of the exising pod.
        [Default: None]
= name
        Name of the pod.

- netmask
        Netmask for the Pod.
        Required on `state=present'
        [Default: None]
- start_ip
        Starting IP address for the Pod.
        Required on `state=present'
        [Default: None]
- state
        State of the pod.
        (Choices: present, enabled, disabled, absent)[Default: present]
- zone
        Name of the zone in which the pod belongs to.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure a pod is present
- local_action:
    module: cs_pod
    name: pod1
    zone: ch-zrh-ix-01
    start_ip: 10.100.10.101
    gateway: 10.100.10.1
    netmask: 255.255.255.0

# Ensure a pod is disabled
- local_action:
    module: cs_pod
    name: pod1
    zone: ch-zrh-ix-01
    state: disabled

# Ensure a pod is enabled
- local_action:
    module: cs_pod
    name: pod1
    zone: ch-zrh-ix-01
    state: enabled

# Ensure a pod is absent
- local_action:
    module: cs_pod
    name: pod1
    zone: ch-zrh-ix-01
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the pod.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the pod.
  returned: success
  type: string
  sample: pod01
start_ip:
  description: Starting IP of the pod.
  returned: success
  type: string
  sample: 10.100.1.101
end_ip:
  description: Ending IP of the pod.
  returned: success
  type: string
  sample: 10.100.1.254
netmask:
  description: Netmask of the pod.
  returned: success
  type: string
  sample: 255.255.255.0
gateway:
  description: Gateway of the pod.
  returned: success
  type: string
  sample: 10.100.1.1
allocation_state:
  description: State of the pod.
  returned: success
  type: string
  sample: Enabled
zone:
  description: Name of zone the pod is in.
  returned: success
  type: string
  sample: ch-gva-2


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_PORTFORWARD    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_portforward.py)

  Create, update and remove port forwarding rules.

Options (= is mandatory):

- account
        Account the `vm' is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the `vm' is related to.
        [Default: None]
= ip_address
        Public IP address the rule is assigned to.

- network
        Name of the network.
        [Default: None]
- open_firewall
        Whether the firewall rule for public port should be created, while creating the new rule.
        Use [cs_firewall] for managing firewall rules.
        [Default: False]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- private_end_port
        End private port for this rule.
        If not specified equal `private_port'.
        [Default: None]
= private_port
        Start private port for this rule.

- project
        Name of the project the `vm' is located in.
        [Default: None]
- protocol
        Protocol of the port forwarding rule.
        (Choices: tcp, udp)[Default: tcp]
- public_end_port
        End public port for this rule.
        If not specified equal `public_port'.
        [Default: None]
= public_port
        Start public port for this rule.

- state
        State of the port forwarding rule.
        (Choices: present, absent)[Default: present]
- vm
        Name of virtual machine which we make the port forwarding rule for.
        Required if `state=present'.
        [Default: None]
- vm_guest_ip
        VM guest NIC secondary IP address for the port forwarding rule.
        [Default: False]
- vpc
        Name of the VPC.
        [Default: None]
- zone
        Name of the zone in which the virtual machine is in.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# 1.2.3.4:80 -> web01:8080
- local_action:
    module: cs_portforward
    ip_address: 1.2.3.4
    vm: web01
    public_port: 80
    private_port: 8080

# forward SSH and open firewall
- local_action:
    module: cs_portforward
    ip_address: '{{ public_ip }}'
    vm: '{{ inventory_hostname }}'
    public_port: '{{ ansible_ssh_port }}'
    private_port: 22
    open_firewall: true

# forward DNS traffic, but do not open firewall
- local_action:
    module: cs_portforward
    ip_address: 1.2.3.4
    vm: '{{ inventory_hostname }}'
    public_port: 53
    private_port: 53
    protocol: udp

# remove ssh port forwarding
- local_action:
    module: cs_portforward
    ip_address: 1.2.3.4
    public_port: 22
    private_port: 22
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the public IP address.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
ip_address:
  description: Public IP address.
  returned: success
  type: string
  sample: 1.2.3.4
protocol:
  description: Protocol.
  returned: success
  type: string
  sample: tcp
private_port:
  description: Start port on the virtual machine's IP address.
  returned: success
  type: int
  sample: 80
private_end_port:
  description: End port on the virtual machine's IP address.
  returned: success
  type: int
public_port:
  description: Start port on the public IP address.
  returned: success
  type: int
  sample: 80
public_end_port:
  description: End port on the public IP address.
  returned: success
  type: int
  sample: 80
tags:
  description: Tags related to the port forwarding.
  returned: success
  type: list
  sample: []
vm_name:
  description: Name of the virtual machine.
  returned: success
  type: string
  sample: web-01
vm_display_name:
  description: Display name of the virtual machine.
  returned: success
  type: string
  sample: web-01
vm_guest_ip:
  description: IP of the virtual machine.
  returned: success
  type: string
  sample: 10.101.65.152
vpc:
  description: Name of the VPC.
  version_added: "2.3"
  returned: success
  type: string
  sample: my_vpc
network:
  description: Name of the network.
  version_added: "2.3"
  returned: success
  type: string
  sample: dmz


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_PROJECT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_project.py)

  Create, update, suspend, activate and remove projects.

Options (= is mandatory):

- account
        Account the project is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- display_text
        Display text of the project.
        If not specified, `name' will be used as `display_text'.
        [Default: None]
- domain
        Domain the project is related to.
        [Default: None]
= name
        Name of the project.

- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- state
        State of the project.
        (Choices: present, absent, active, suspended)[Default: present]
- tags
        List of tags. Tags are a list of dictionaries having keys `key' and `value'.
        If you want to delete all tags, set a empty list e.g. `tags: []'.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create a project
- local_action:
    module: cs_project
    name: web
    tags:
      - { key: admin, value: john }
      - { key: foo,   value: bar }

# Rename a project
- local_action:
    module: cs_project
    name: web
    display_text: my web project

# Suspend an existing project
- local_action:
    module: cs_project
    name: web
    state: suspended

# Activate an existing project
- local_action:
    module: cs_project
    name: web
    state: active

# Remove a project
- local_action:
    module: cs_project
    name: web
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the project.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the project.
  returned: success
  type: string
  sample: web project
display_text:
  description: Display text of the project.
  returned: success
  type: string
  sample: web project
state:
  description: State of the project.
  returned: success
  type: string
  sample: Active
domain:
  description: Domain the project is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the project is related to.
  returned: success
  type: string
  sample: example account
tags:
  description: List of resource tags associated with the project.
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_REGION    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_region.py)

  Add, update and remove regions.

Options (= is mandatory):

- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- endpoint
        Endpoint URL of the region.
        Required if `state=present'
        [Default: None]
= id
        ID of the region.
        Must be an number (int).

- name
        Name of the region.
        Required if `state=present'
        [Default: None]
- state
        State of the region.
        (Choices: present, absent)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# create a region
local_action:
  module: cs_region
  id: 2
  name: geneva
  endpoint: https://cloud.gva.example.com

# remove a region with ID 2
local_action:
  module: cs_region
  id: 2
  state: absent

RETURN VALUES:
---
id:
  description: ID of the region.
  returned: success
  type: int
  sample: 1
name:
  description: Name of the region.
  returned: success
  type: string
  sample: local
endpoint:
  description: Endpoint of the region.
  returned: success
  type: string
  sample: http://cloud.example.com
gslb_service_enabled:
  description: Whether the GSLB service is enabled or not
  returned: success
  type: bool
  sample: true
portable_ip_service_enabled:
  description: Whether the portable IP service is enabled or not
  returned: success
  type: bool
  sample: true


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> CS_RESOURCELIMIT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_resourcelimit.py)

  Manage limits of resources for domains, accounts and projects.

Options (= is mandatory):

- account
        Account the resource is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the resource is related to.
        [Default: None]
- limit
        Maximum number of the resource.
        Default is unlimited `-1'.
        [Default: -1]
- project
        Name of the project the resource is related to.
        [Default: None]
= resource_type
        Type of the resource.
        (Choices: instance, ip_address, volume, snapshot, template, network, vpc, cpu, memory, primary_storage,
        secondary_storage)
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Update a resource limit for instances of a domain
local_action:
  module: cs_resourcelimit
  type: instance
  limit: 10
  domain: customers

# Update a resource limit for instances of an account
local_action:
  module: cs_resourcelimit
  type: instance
  limit: 12
  account: moserre
  domain: customers

RETURN VALUES:
---
recource_type:
  description: Type of the resource
  returned: success
  type: string
  sample: instance
limit:
  description: Maximum number of the resource.
  returned: success
  type: int
  sample: -1
domain:
  description: Domain the resource is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the resource is related to.
  returned: success
  type: string
  sample: example account
project:
  description: Project the resource is related to.
  returned: success
  type: string
  sample: example project


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_role.py)

  Create, update, delete user roles.

Options (= is mandatory):

- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- description
        Description of the role.
        [Default: None]
- id
        ID of the role.
        If provided, `id' is used as key.
        [Default: None]
= name
        Name of the role.

- role_type
        Type of the role.
        Only considered for creation.
        (Choices: User, DomainAdmin, ResourceAdmin, Admin)[Default: User]
- state
        State of the role.
        (Choices: present, absent)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure an user role is present
- local_action:
    module: cs_role
    name: myrole_user

# Ensure a role having particular ID is named as myrole_user
- local_action:
    module: cs_role
    name: myrole_user
    id: 04589590-ac63-4ffc-93f5-b698b8ac38b6

# Ensure a role is absent
- local_action:
    module: cs_role
    name: myrole_user
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the role.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the role.
  returned: success
  type: string
  sample: myrole
description:
  description: Description of the role.
  returned: success
  type: string
  sample: "This is my role description"
role_type:
  description: Type of the role.
  returned: success
  type: string
  sample: User


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> CS_ROUTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_router.py)

  Start, restart, stop and destroy routers. `state=present' is not able to create routers, use [cs_network] instead.

Options (= is mandatory):

- account
        Account the router is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the router is related to.
        [Default: None]
= name
        Name of the router.

- project
        Name of the project the router is related to.
        [Default: None]
- service_offering
        Name or id of the service offering of the router.
        [Default: None]
- state
        State of the router.
        (Choices: present, absent, started, stopped, restarted)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure the router has the desired service offering, no matter if
# the router is running or not.
- local_action:
    module: cs_router
    name: r-40-VM
    service_offering: System Offering for Software Router

# Ensure started
- local_action:
    module: cs_router
    name: r-40-VM
    state: started

# Ensure started with desired service offering.
# If the service offerings changes, router will be rebooted.
- local_action:
    module: cs_router
    name: r-40-VM
    service_offering: System Offering for Software Router
    state: started

# Ensure stopped
- local_action:
    module: cs_router
    name: r-40-VM
    state: stopped

# Remove a router
- local_action:
    module: cs_router
    name: r-40-VM
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the router.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the router.
  returned: success
  type: string
  sample: r-40-VM
created:
  description: Date of the router was created.
  returned: success
  type: string
  sample: 2014-12-01T14:57:57+0100
template_version:
  description: Version of the system VM template.
  returned: success
  type: string
  sample: 4.5.1
requires_upgrade:
  description: Whether the router needs to be upgraded to the new template.
  returned: success
  type: bool
  sample: false
redundant_state:
  description: Redundant state of the router.
  returned: success
  type: string
  sample: UNKNOWN
role:
  description: Role of the router.
  returned: success
  type: string
  sample: VIRTUAL_ROUTER
zone:
  description: Name of zone the router is in.
  returned: success
  type: string
  sample: ch-gva-2
service_offering:
  description: Name of the service offering the router has.
  returned: success
  type: string
  sample: System Offering For Software Router
state:
  description: State of the router.
  returned: success
  type: string
  sample: Active
domain:
  description: Domain the router is related to.
  returned: success
  type: string
  sample: ROOT
account:
  description: Account the router is related to.
  returned: success
  type: string
  sample: admin


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_SECURITYGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_securitygroup.py)

  Create and remove security groups.

Options (= is mandatory):

- account
        Account the security group is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- description
        Description of the security group.
        [Default: None]
- domain
        Domain the security group is related to.
        [Default: None]
= name
        Name of the security group.

- project
        Name of the project the security group to be created in.
        [Default: None]
- state
        State of the security group.
        (Choices: present, absent)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create a security group
- local_action:
    module: cs_securitygroup
    name: default
    description: default security group

# Remove a security group
- local_action:
    module: cs_securitygroup
    name: default
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the security group.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
name:
  description: Name of security group.
  returned: success
  type: string
  sample: app
description:
  description: Description of security group.
  returned: success
  type: string
  sample: application security group
tags:
  description: List of resource tags associated with the security group.
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'
project:
  description: Name of project the security group is related to.
  returned: success
  type: string
  sample: Production
domain:
  description: Domain the security group is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the security group is related to.
  returned: success
  type: string
  sample: example account


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_SECURITYGROUP_RULE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_securitygroup_rule.py)

  Add and remove security group rules.

Options (= is mandatory):

- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cidr
        CIDR (full notation) to be used for security group rule.
        [Default: 0.0.0.0/0]
- end_port
        End port for this rule. Required if `protocol=tcp' or `protocol=udp', but `start_port' will be used if not set.
        [Default: None]
- icmp_code
        Error code for this icmp message. Required if `protocol=icmp'.
        [Default: None]
- icmp_type
        Type of the icmp message being sent. Required if `protocol=icmp'.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the security group to be created in.
        [Default: None]
- protocol
        Protocol of the security group rule.
        (Choices: tcp, udp, icmp, ah, esp, gre)[Default: tcp]
= security_group
        Name of the security group the rule is related to. The security group must be existing.

- start_port
        Start port for this rule. Required if `protocol=tcp' or `protocol=udp'.
        [Default: None]
- state
        State of the security group rule.
        (Choices: present, absent)[Default: present]
- type
        Ingress or egress security group rule.
        (Choices: ingress, egress)[Default: ingress]
- user_security_group
        Security group this rule is based of.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
---
# Allow inbound port 80/tcp from 1.2.3.4 added to security group 'default'
- local_action:
    module: cs_securitygroup_rule
    security_group: default
    port: 80
    cidr: 1.2.3.4/32

# Allow tcp/udp outbound added to security group 'default'
- local_action:
    module: cs_securitygroup_rule
    security_group: default
    type: egress
    start_port: 1
    end_port: 65535
    protocol: '{{ item }}'
  with_items:
  - tcp
  - udp

# Allow inbound icmp from 0.0.0.0/0 added to security group 'default'
- local_action:
    module: cs_securitygroup_rule
    security_group: default
    protocol: icmp
    icmp_code: -1
    icmp_type: -1

# Remove rule inbound port 80/tcp from 0.0.0.0/0 from security group 'default'
- local_action:
    module: cs_securitygroup_rule
    security_group: default
    port: 80
    state: absent

# Allow inbound port 80/tcp from security group web added to security group 'default'
- local_action:
    module: cs_securitygroup_rule
    security_group: default
    port: 80
    user_security_group: web

RETURN VALUES:
---
id:
  description: UUID of the of the rule.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
security_group:
  description: security group of the rule.
  returned: success
  type: string
  sample: default
type:
  description: type of the rule.
  returned: success
  type: string
  sample: ingress
cidr:
  description: CIDR of the rule.
  returned: success and cidr is defined
  type: string
  sample: 0.0.0.0/0
user_security_group:
  description: user security group of the rule.
  returned: success and user_security_group is defined
  type: string
  sample: default
protocol:
  description: protocol of the rule.
  returned: success
  type: string
  sample: tcp
start_port:
  description: start port of the rule.
  returned: success
  type: int
  sample: 80
end_port:
  description: end port of the rule.
  returned: success
  type: int
  sample: 80


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_SNAPSHOT_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_snapshot_policy.py)

  Create, update and delete volume snapshot policies.

Options (= is mandatory):

- account
        Account the volume is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- device_id
        ID of the device on a VM the volume is attached to.
        This will only be considered if VM has multiple DATADISK volumes.
        [Default: None]
- domain
        Domain the volume is related to.
        [Default: None]
- interval_type
        Interval of the snapshot.
        (Choices: hourly, daily, weekly, monthly)[Default: daily]
- max_snaps
        Max number of snapshots.
        [Default: 8]
- project
        Name of the project the volume is related to.
        [Default: None]
- schedule
        Time the snapshot is scheduled. Required if `state=present'.
        Format for `interval_type=HOURLY': `MM'
        Format for `interval_type=DAILY': `MM:HH'
        Format for `interval_type=WEEKLY': `MM:HH:DD (1-7')
        Format for `interval_type=MONTHLY': `MM:HH:DD (1-28')
        [Default: None]
- state
        State of the snapshot policy.
        (Choices: present, absent)[Default: present]
- time_zone
        Specifies a timezone for this command.
        [Default: UTC]
- vm
        Name of the instance to select the volume from.
        Use `volume_type' if VM has a DATADISK and ROOT volume.
        In case of `volume_type=DATADISK', additionally use `device_id' if VM has more than one DATADISK volume.
        Either `volume' or `vm' is required.
        [Default: None]
- volume
        Name of the volume.
        Either `volume' or `vm' is required.
        [Default: None]
- volume_type
        Type of the volume.
        (Choices: DATADISK, ROOT)[Default: None]
- vpc
        Name of the vpc the instance is deployed in.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure a snapshot policy daily at 1h00 UTC
- local_action:
    module: cs_snapshot_policy
    volume: ROOT-478
    schedule: '00:1'
    max_snaps: 3

# Ensure a snapshot policy daily at 1h00 UTC on the second DATADISK of VM web-01
- local_action:
    module: cs_snapshot_policy
    vm: web-01
    volume_type: DATADISK
    device_id: 2
    schedule: '00:1'
    max_snaps: 3

# Ensure a snapshot policy hourly at minute 5 UTC
- local_action:
    module: cs_snapshot_policy
    volume: ROOT-478
    schedule: '5'
    interval_type: hourly
    max_snaps: 1

# Ensure a snapshot policy weekly on Sunday at 05h00, TZ Europe/Zurich
- local_action:
    module: cs_snapshot_policy
    volume: ROOT-478
    schedule: '00:5:1'
    interval_type: weekly
    max_snaps: 1
    time_zone: 'Europe/Zurich'

# Ensure a snapshot policy is absent
- local_action:
    module: cs_snapshot_policy
    volume: ROOT-478
    interval_type: hourly
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the snapshot policy.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
interval_type:
  description: interval type of the snapshot policy.
  returned: success
  type: string
  sample: daily
schedule:
  description: schedule of the snapshot policy.
  returned: success
  type: string
  sample:
max_snaps:
  description: maximum number of snapshots retained.
  returned: success
  type: int
  sample: 10
time_zone:
  description: the time zone of the snapshot policy.
  returned: success
  type: string
  sample: Etc/UTC
volume:
  description: the volume of the snapshot policy.
  returned: success
  type: string
  sample: Etc/UTC
zone:
  description: Name of zone the volume is related to.
  returned: success
  type: string
  sample: ch-gva-2
project:
  description: Name of project the volume is related to.
  returned: success
  type: string
  sample: Production
account:
  description: Account the volume is related to.
  returned: success
  type: string
  sample: example account
domain:
  description: Domain the volume is related to.
  returned: success
  type: string
  sample: example domain


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_SSHKEYPAIR    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_sshkeypair.py)

  Create, register and remove SSH keys. If no key was found and no public key was provided and a new SSH private/public
  key pair will be created and the private key will be returned.

Options (= is mandatory):

- account
        Account the public key is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the public key is related to.
        [Default: None]
= name
        Name of public key.

- project
        Name of the project the public key to be registered in.
        [Default: None]
- public_key
        String of the public key.
        [Default: None]
- state
        State of the public key.
        (Choices: present, absent)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# create a new private / public key pair:
- cs_sshkeypair:
    name: linus@example.com
  delegate_to: localhost
  register: key
- debug:
    msg: 'Private key is {{ key.private_key }}'

# remove a public key by its name:
- cs_sshkeypair:
    name: linus@example.com
    state: absent
  delegate_to: localhost

# register your existing local public key:
- cs_sshkeypair:
    name: linus@example.com
    public_key: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
  delegate_to: localhost

RETURN VALUES:
---
id:
  description: UUID of the SSH public key.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
name:
  description: Name of the SSH public key.
  returned: success
  type: string
  sample: linus@example.com
fingerprint:
  description: Fingerprint of the SSH public key.
  returned: success
  type: string
  sample: "86:5e:a3:e8:bd:95:7b:07:7c:c2:5c:f7:ad:8b:09:28"
private_key:
  description: Private key of generated SSH keypair.
  returned: changed
  type: string
  sample: "-----BEGIN RSA PRIVATE KEY-----
MII...8tO
-----END RSA PRIVATE KEY-----
"


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_STATICNAT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_staticnat.py)

  Create, update and remove static NATs.

Options (= is mandatory):

- account
        Account the static NAT is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the static NAT is related to.
        [Default: None]
= ip_address
        Public IP address the static NAT is assigned to.

- network
        Network the IP address is related to.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the static NAT is related to.
        [Default: None]
- state
        State of the static NAT.
        (Choices: present, absent)[Default: present]
- vm
        Name of virtual machine which we make the static NAT for.
        Required if `state=present'.
        [Default: None]
- vm_guest_ip
        VM guest NIC secondary IP address for the static NAT.
        [Default: False]
- vpc
        VPC the network related to.
        [Default: None]
- zone
        Name of the zone in which the virtual machine is in.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# create a static NAT: 1.2.3.4 -> web01
- local_action:
    module: cs_staticnat
    ip_address: 1.2.3.4
    vm: web01

# remove a static NAT
- local_action:
    module: cs_staticnat
    ip_address: 1.2.3.4
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the ip_address.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
ip_address:
  description: Public IP address.
  returned: success
  type: string
  sample: 1.2.3.4
vm_name:
  description: Name of the virtual machine.
  returned: success
  type: string
  sample: web-01
vm_display_name:
  description: Display name of the virtual machine.
  returned: success
  type: string
  sample: web-01
vm_guest_ip:
  description: IP of the virtual machine.
  returned: success
  type: string
  sample: 10.101.65.152
zone:
  description: Name of zone the static NAT is related to.
  returned: success
  type: string
  sample: ch-gva-2
project:
  description: Name of project the static NAT is related to.
  returned: success
  type: string
  sample: Production
account:
  description: Account the static NAT is related to.
  returned: success
  type: string
  sample: example account
domain:
  description: Domain the static NAT is related to.
  returned: success
  type: string
  sample: example domain


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_template.py)

  Register a template from URL, create a template from a ROOT volume of a stopped VM or its snapshot, extract and delete
  templates.

Options (= is mandatory):

- account
        Account the template, snapshot or VM is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- bits
        32 or 64 bits support.
        [Default: 64]
- checksum
        The MD5 checksum value of this template.
        If set, we search by checksum instead of name.
        [Default: False]
- cross_zones
        Whether the template should be synced or removed across zones.
        Only used if `state' is present or absent.
        [Default: False]
- details
        Template details in key/value pairs.
        [Default: None]
- display_text
        Display text of the template.
        [Default: None]
- domain
        Domain the template, snapshot or VM is related to.
        [Default: None]
- format
        The format for the template.
        Relevant when using `state=present'.
        (Choices: QCOW2, RAW, VHD, OVA)[Default: None]
- hypervisor
        Name the hypervisor to be used for creating the new template.
        Relevant when using `state=present'.
        (Choices: KVM, VMware, BareMetal, XenServer, LXC, HyperV, UCS, OVM)[Default: None]
- is_dynamically_scalable
        Register the template having XS/VMWare tools installed in order to support dynamic scaling of VM CPU/memory.
        Only used if `state' is present.
        [Default: False]
- is_extractable
        True if the template or its derivatives are extractable.
        [Default: False]
- is_featured
        Register the template to be featured.
        Only used if `state' is present.
        [Default: False]
- is_public
        Register the template to be publicly available to all users.
        Only used if `state' is present.
        [Default: False]
- is_ready
        This flag is used for searching existing templates.
        If set to `true', it will only list template ready for deployment e.g. successfully downloaded and installed.
        Recommended to set it to `false'.
        [Default: False]
- is_routing
        True if the template type is routing i.e., if template is used to deploy router.
        Only considered if `url' is used.
        [Default: False]
- mode
        Mode for the template extraction.
        Only used if `state=extracted'.
        (Choices: http_download, ftp_upload)[Default: http_download]
= name
        Name of the template.

- os_type
        OS type that best represents the OS of this template.
        [Default: None]
- password_enabled
        True if the template supports the password reset feature.
        [Default: False]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the template to be registered in.
        [Default: None]
- requires_hvm
        true if this template requires HVM.
        [Default: False]
- snapshot
        Name of the snapshot, created from the VM ROOT volume, the template will be created from.
        `vm' is required together with this argument.
        [Default: None]
- sshkey_enabled
        True if the template supports the sshkey upload feature.
        [Default: False]
- state
        State of the template.
        (Choices: present, absent, extacted)[Default: present]
- template_filter
        Name of the filter used to search for the template.
        (Choices: featured, self, selfexecutable, sharedexecutable, executable, community)[Default: self]
- template_tag
        the tag for this template.
        [Default: None]
- url
        URL of where the template is hosted on `state=present'.
        URL to which the template would be extracted on `state=extracted'.
        Mutually exclusive with `vm'.
        [Default: None]
- vm
        VM name the template will be created from its volume or alternatively from a snapshot.
        VM must be in stopped state if created from its volume.
        Mutually exclusive with `url'.
        [Default: None]
- zone
        Name of the zone you wish the template to be registered or deleted from.
        If not specified, first found zone will be used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Register a systemvm template
- local_action:
    module: cs_template
    name: systemvm-vmware-4.5
    url: "http://packages.shapeblue.com/systemvmtemplate/4.5/systemvm64template-4.5-vmware.ova"
    hypervisor: VMware
    format: OVA
    cross_zones: yes
    os_type: Debian GNU/Linux 7(64-bit)

# Create a template from a stopped virtual machine's volume
- local_action:
    module: cs_template
    name: debian-base-template
    vm: debian-base-vm
    os_type: Debian GNU/Linux 7(64-bit)
    zone: tokio-ix
    password_enabled: yes
    is_public: yes

# Create a template from a virtual machine's root volume snapshot
- local_action:
    module: cs_template
    name: debian-base-template
    vm: debian-base-vm
    snapshot: ROOT-233_2015061509114
    os_type: Debian GNU/Linux 7(64-bit)
    zone: tokio-ix
    password_enabled: yes
    is_public: yes

# Remove a template
- local_action:
    module: cs_template
    name: systemvm-4.2
    cross_zones: yes
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the template.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
name:
  description: Name of the template.
  returned: success
  type: string
  sample: Debian 7 64-bit
display_text:
  description: Display text of the template.
  returned: success
  type: string
  sample: Debian 7.7 64-bit minimal 2015-03-19
checksum:
  description: MD5 checksum of the template.
  returned: success
  type: string
  sample: 0b31bccccb048d20b551f70830bb7ad0
status:
  description: Status of the template.
  returned: success
  type: string
  sample: Download Complete
is_ready:
  description: True if the template is ready to be deployed from.
  returned: success
  type: boolean
  sample: true
is_public:
  description: True if the template is public.
  returned: success
  type: boolean
  sample: true
is_featured:
  description: True if the template is featured.
  returned: success
  type: boolean
  sample: true
is_extractable:
  description: True if the template is extractable.
  returned: success
  type: boolean
  sample: true
format:
  description: Format of the template.
  returned: success
  type: string
  sample: OVA
os_type:
  description: Typo of the OS.
  returned: success
  type: string
  sample: CentOS 6.5 (64-bit)
password_enabled:
  description: True if the reset password feature is enabled, false otherwise.
  returned: success
  type: boolean
  sample: false
sshkey_enabled:
  description: true if template is sshkey enabled, false otherwise.
  returned: success
  type: boolean
  sample: false
cross_zones:
  description: true if the template is managed across all zones, false otherwise.
  returned: success
  type: boolean
  sample: false
template_type:
  description: Type of the template.
  returned: success
  type: string
  sample: USER
created:
  description: Date of registering.
  returned: success
  type: string
  sample: 2015-03-29T14:57:06+0200
template_tag:
  description: Template tag related to this template.
  returned: success
  type: string
  sample: special
hypervisor:
  description: Hypervisor related to this template.
  returned: success
  type: string
  sample: VMware
mode:
  description: Mode of extraction
  returned: success
  type: string
  sample: http_download
state:
  description: State of the extracted template
  returned: success
  type: string
  sample: DOWNLOAD_URL_CREATED
url:
  description: Url to which the template is extracted to
  returned: success
  type: string
  sample: "http://1.2.3.4/userdata/eb307f13-4aca-45e8-b157-a414a14e6b04.ova"
tags:
  description: List of resource tags associated with the template.
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'
zone:
  description: Name of zone the template is registered in.
  returned: success
  type: string
  sample: zuerich
domain:
  description: Domain the template is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the template is related to.
  returned: success
  type: string
  sample: example account
project:
  description: Name of project the template is related to.
  returned: success
  type: string
  sample: Production


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_USER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_user.py)

  Create, update, disable, lock, enable and remove users.

Options (= is mandatory):

- account
        Account the user will be created under.
        Required on `state=present'.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- domain
        Domain the user is related to.
        [Default: ROOT]
- email
        Email of the user.
        Required on `state=present'.
        [Default: None]
- first_name
        First name of the user.
        Required on `state=present'.
        [Default: None]
- last_name
        Last name of the user.
        Required on `state=present'.
        [Default: None]
- password
        Password of the user to be created.
        Required on `state=present'.
        Only considered on creation and will not be updated if user exists.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- state
        State of the user.
        `unlocked' is an alias for `enabled'.
        (Choices: present, absent, enabled, disabled, locked, unlocked)[Default: present]
- timezone
        Timezone of the user.
        [Default: None]
= username
        Username of the user.

Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# create an user in domain 'CUSTOMERS'
local_action:
  module: cs_user
  account: developers
  username: johndoe
  password: S3Cur3
  last_name: Doe
  first_name: John
  email: john.doe@example.com
  domain: CUSTOMERS

# Lock an existing user in domain 'CUSTOMERS'
local_action:
  module: cs_user
  username: johndoe
  domain: CUSTOMERS
  state: locked

# Disable an existing user in domain 'CUSTOMERS'
local_action:
  module: cs_user
  username: johndoe
  domain: CUSTOMERS
  state: disabled

# Enable/unlock an existing user in domain 'CUSTOMERS'
local_action:
  module: cs_user
  username: johndoe
  domain: CUSTOMERS
  state: enabled

# Remove an user in domain 'CUSTOMERS'
local_action:
  module: cs_user
  name: customer_xy
  domain: CUSTOMERS
  state: absent

RETURN VALUES:
---
id:
  description: UUID of the user.
  returned: success
  type: string
  sample: 87b1e0ce-4e01-11e4-bb66-0050569e64b8
username:
  description: Username of the user.
  returned: success
  type: string
  sample: johndoe
fist_name:
  description: First name of the user.
  returned: success
  type: string
  sample: John
last_name:
  description: Last name of the user.
  returned: success
  type: string
  sample: Doe
email:
  description: Emailof the user.
  returned: success
  type: string
  sample: john.doe@example.com
api_key:
  description: API key of the user.
  returned: success
  type: string
  sample: JLhcg8VWi8DoFqL2sSLZMXmGojcLnFrOBTipvBHJjySODcV4mCOo29W2duzPv5cALaZnXj5QxDx3xQfaQt3DKg
api_secret:
  description: API secret of the user.
  returned: success
  type: string
  sample: FUELo3LB9fa1UopjTLPdqLv_6OXQMJZv9g9N4B_Ao3HFz8d6IGFCV9MbPFNM8mwz00wbMevja1DoUNDvI8C9-g
account:
  description: Account name of the user.
  returned: success
  type: string
  sample: developers
account_type:
  description: Type of the account.
  returned: success
  type: string
  sample: user
timezone:
  description: Timezone of the user.
  returned: success
  type: string
  sample: enabled
created:
  description: Date the user was created.
  returned: success
  type: string
  sample: Doe
state:
  description: State of the user.
  returned: success
  type: string
  sample: enabled
domain:
  description: Domain the user is related.
  returned: success
  type: string
  sample: ROOT


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_VMSNAPSHOT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_vmsnapshot.py)

  Create, remove and revert VM from snapshots.

Options (= is mandatory):

- account
        Account the VM snapshot is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- description
        Description of the snapshot.
        [Default: None]
- domain
        Domain the VM snapshot is related to.
        [Default: None]
= name
        Unique Name of the snapshot. In CloudStack terms display name.

- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the VM is assigned to.
        [Default: None]
- snapshot_memory
        Snapshot memory if set to true.
        [Default: False]
- state
        State of the snapshot.
        (Choices: present, absent, revert)[Default: present]
= vm
        Name of the virtual machine.

- zone
        Name of the zone in which the VM is in. If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create a VM snapshot of disk and memory before an upgrade
- local_action:
    module: cs_vmsnapshot
    name: Snapshot before upgrade
    vm: web-01
    snapshot_memory: yes

# Revert a VM to a snapshot after a failed upgrade
- local_action:
    module: cs_vmsnapshot
    name: Snapshot before upgrade
    vm: web-01
    state: revert

# Remove a VM snapshot after successful upgrade
- local_action:
    module: cs_vmsnapshot
    name: Snapshot before upgrade
    vm: web-01
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the snapshot.
  returned: success
  type: string
  sample: a6f7a5fc-43f8-11e5-a151-feff819cdc9f
name:
  description: Name of the snapshot.
  returned: success
  type: string
  sample: snapshot before update
display_name:
  description: Display name of the snapshot.
  returned: success
  type: string
  sample: snapshot before update
created:
  description: date of the snapshot.
  returned: success
  type: string
  sample: 2015-03-29T14:57:06+0200
current:
  description: true if snapshot is current
  returned: success
  type: boolean
  sample: True
state:
  description: state of the vm snapshot
  returned: success
  type: string
  sample: Allocated
type:
  description: type of vm snapshot
  returned: success
  type: string
  sample: DiskAndMemory
description:
  description: description of vm snapshot
  returned: success
  type: string
  sample: snapshot brought to you by Ansible
domain:
  description: Domain the the vm snapshot is related to.
  returned: success
  type: string
  sample: example domain
account:
  description: Account the vm snapshot is related to.
  returned: success
  type: string
  sample: example account
project:
  description: Name of project the vm snapshot is related to.
  returned: success
  type: string
  sample: Production


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_VOLUME    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_volume.py)

  Create, destroy, attach, detach volumes.

Options (= is mandatory):

- account
        Account the volume is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- custom_id
        Custom id to the resource.
        Allowed to Root Admins only.
        [Default: None]
- disk_offering
        Name of the disk offering to be used.
        Required one of `disk_offering', `snapshot' if volume is not already `state=present'.
        [Default: None]
- display_volume
        Whether to display the volume to the end user or not.
        Allowed to Root Admins only.
        [Default: True]
- domain
        Name of the domain the volume to be deployed in.
        [Default: None]
- force
        Force removal of volume even it is attached to a VM.
        Considered on `state=absnet' only.
        [Default: False]
- max_iops
        Max iops
        [Default: None]
- min_iops
        Min iops
        [Default: None]
= name
        Name of the volume.
        `name' can only contain ASCII letters.

- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the volume to be deployed in.
        [Default: None]
- shrink_ok
        Whether to allow to shrink the volume.
        [Default: False]
- size
        Size of disk in GB
        [Default: None]
- snapshot
        The snapshot name for the disk volume.
        Required one of `disk_offering', `snapshot' if volume is not already `state=present'.
        [Default: None]
- state
        State of the volume.
        (Choices: present, absent, attached, detached)[Default: present]
- vm
        Name of the virtual machine to attach the volume to.
        [Default: None]
- zone
        Name of the zone in which the volume should be deployed.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Create volume within project, zone with specified storage options
- local_action:
    module: cs_volume
    name: web-vm-1-volume
    project: Integration
    zone: ch-zrh-ix-01
    disk_offering: PerfPlus Storage
    size: 20

# Create/attach volume to instance
- local_action:
    module: cs_volume
    name: web-vm-1-volume
    disk_offering: PerfPlus Storage
    size: 20
    vm: web-vm-1
    state: attached

# Detach volume
- local_action:
    module: cs_volume
    name: web-vm-1-volume
    state: detached

# Remove volume
- local_action:
    module: cs_volume
    name: web-vm-1-volume
    state: absent

RETURN VALUES:
id:
  description: ID of the volume.
  returned: success
  type: string
  sample:
name:
  description: Name of the volume.
  returned: success
  type: string
  sample: web-volume-01
display_name:
  description: Display name of the volume.
  returned: success
  type: string
  sample: web-volume-01
group:
  description: Group the volume belongs to
  returned: success
  type: string
  sample: web
domain:
  description: Domain the volume belongs to
  returned: success
  type: string
  sample: example domain
project:
  description: Project the volume belongs to
  returned: success
  type: string
  sample: Production
zone:
  description: Name of zone the volume is in.
  returned: success
  type: string
  sample: ch-gva-2
created:
  description: Date of the volume was created.
  returned: success
  type: string
  sample: 2014-12-01T14:57:57+0100
attached:
  description: Date of the volume was attached.
  returned: success
  type: string
  sample: 2014-12-01T14:57:57+0100
type:
  description: Disk volume type.
  returned: success
  type: string
  sample: DATADISK
size:
  description: Size of disk volume.
  returned: success
  type: string
  sample: 20
vm:
  description: Name of the vm the volume is attached to (not returned when detached)
  returned: success
  type: string
  sample: web-01
state:
  description: State of the volume
  returned: success
  type: string
  sample: Attached
device_id:
  description: Id of the device on user vm the volume is attached to (not returned when detached)
  returned: success
  type: string
  sample: 1


MAINTAINERS: René Moser (@resmo), Jefferson Girão (@jeffersongirao)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_VPC    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_vpc.py)

  Create, update and delete VPCs.

Options (= is mandatory):

- account
        Account the VPC is related to.
        [Default: None]
- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- cidr
        CIDR of the VPC, e.g. 10.1.0.0/16
        All VPC guest networks' CIDRs must be within this CIDR.
        Required on `state=present'.
        [Default: None]
- display_text
        Display text of the VPC.
        If not set, `name' will be used for creating.
        [Default: None]
- domain
        Domain the VPC is related to.
        [Default: None]
= name
        Name of the VPC.

- network_domain
        Network domain for the VPC.
        All networks inside the VPC will belong to this domain.
        [Default: None]
- poll_async
        Poll async jobs until job has finished.
        [Default: True]
- project
        Name of the project the VPC is related to.
        [Default: None]
- state
        State of the VPC.
        (Choices: present, absent, restarted)[Default: present]
- tags
        List of tags. Tags are a list of dictionaries having keys `key' and `value'.
        For deleting all tags, set an empty list e.g. `tags: []'.
        [Default: None]
- vpc_offering
        Name of the VPC offering.
        If not set, default VPC offering is used.
        [Default: None]
- zone
        Name of the zone.
        If not set, default zone is used.
        [Default: None]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure a VPC is present
- local_action:
    module: cs_vpc
    name: my_vpc
    display_text: My example VPC
    cidr: 10.10.0.0/16

# Ensure a VPC is absent
- local_action:
    module: cs_vpc
    name: my_vpc
    state: absent

# Ensure a VPC is restarted
- local_action:
    module: cs_vpc
    name: my_vpc
    state: restarted

RETURN VALUES:
---
id:
  description: "UUID of the VPC."
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: "Name of the VPC."
  returned: success
  type: string
  sample: my_vpc
display_text:
  description: "Display text of the VPC."
  returned: success
  type: string
  sample: My example VPC
cidr:
  description: "CIDR of the VPC."
  returned: success
  type: string
  sample: 10.10.0.0/16
network_domain:
  description: "Network domain of the VPC."
  returned: success
  type: string
  sample: example.com
region_level_vpc:
  description: "Whether the VPC is region level or not."
  returned: success
  type: boolean
  sample: true
restart_required:
  description: "Wheter the VPC router needs a restart or not."
  returned: success
  type: boolean
  sample: true
distributed_vpc_router:
  description: "Whether the VPC uses distributed router or not."
  returned: success
  type: boolean
  sample: true
redundant_vpc_router:
  description: "Whether the VPC has redundant routers or not."
  returned: success
  type: boolean
  sample: true
domain:
  description: "Domain the VPC is related to."
  returned: success
  type: string
  sample: example domain
account:
  description: "Account the VPC is related to."
  returned: success
  type: string
  sample: example account
project:
  description: "Name of project the VPC is related to."
  returned: success
  type: string
  sample: Production
zone:
  description: "Name of zone the VPC is in."
  returned: success
  type: string
  sample: ch-gva-2
state:
  description: "State of the VPC."
  returned: success
  type: string
  sample: Enabled
tags:
  description: "List of resource tags associated with the VPC."
  returned: success
  type: dict
  sample: '[ { "key": "foo", "value": "bar" } ]'


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_ZONE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_zone.py)

  Create, update and remove zones.

Options (= is mandatory):

- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
- dhcp_provider
        DHCP provider for the Zone.
        [Default: None]
- dns1
        First DNS for the zone.
        Required if `state=present'
        [Default: None]
- dns1_ipv6
        First DNS for IPv6 for the zone.
        [Default: None]
- dns2
        Second DNS for the zone.
        [Default: None]
- dns2_ipv6
        Second DNS for IPv6 for the zone.
        [Default: None]
- domain
        Domain the zone is related to.
        Zone is a public zone if not set.
        [Default: None]
- guest_cidr_address
        Guest CIDR address for the zone.
        [Default: None]
- id
        uuid of the exising zone.
        [Default: None]
- internal_dns1
        First internal DNS for the zone.
        If not set `dns1' will be used on `state=present'.
        [Default: None]
- internal_dns2
        Second internal DNS for the zone.
        [Default: None]
= name
        Name of the zone.

- network_domain
        Network domain for the zone.
        [Default: None]
- network_type
        Network type of the zone.
        (Choices: basic, advanced)[Default: basic]
- state
        State of the zone.
        (Choices: present, enabled, disabled, absent)[Default: present]
Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
# Ensure a zone is present
- local_action:
    module: cs_zone
    name: ch-zrh-ix-01
    dns1: 8.8.8.8
    dns2: 8.8.4.4
    network_type: basic

# Ensure a zone is disabled
- local_action:
    module: cs_zone
    name: ch-zrh-ix-01
    state: disabled

# Ensure a zone is enabled
- local_action:
    module: cs_zone
    name: ch-zrh-ix-01
    state: enabled

# Ensure a zone is absent
- local_action:
    module: cs_zone
    name: ch-zrh-ix-01
    state: absent

RETURN VALUES:
---
id:
  description: UUID of the zone.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
name:
  description: Name of the zone.
  returned: success
  type: string
  sample: zone01
dns1:
  description: First DNS for the zone.
  returned: success
  type: string
  sample: 8.8.8.8
dns2:
  description: Second DNS for the zone.
  returned: success
  type: string
  sample: 8.8.4.4
internal_dns1:
  description: First internal DNS for the zone.
  returned: success
  type: string
  sample: 8.8.8.8
internal_dns2:
  description: Second internal DNS for the zone.
  returned: success
  type: string
  sample: 8.8.4.4
dns1_ipv6:
  description: First IPv6 DNS for the zone.
  returned: success
  type: string
  sample: "2001:4860:4860::8888"
dns2_ipv6:
  description: Second IPv6 DNS for the zone.
  returned: success
  type: string
  sample: "2001:4860:4860::8844"
allocation_state:
  description: State of the zone.
  returned: success
  type: string
  sample: Enabled
domain:
  description: Domain the zone is related to.
  returned: success
  type: string
  sample: ROOT
network_domain:
  description: Network domain for the zone.
  returned: success
  type: string
  sample: example.com
network_type:
  description: Network type for the zone.
  returned: success
  type: string
  sample: basic
local_storage_enabled:
  description: Local storage offering enabled.
  returned: success
  type: bool
  sample: false
securitygroups_enabled:
  description: Security groups support is enabled.
  returned: success
  type: bool
  sample: false
guest_cidr_address:
  description: Guest CIDR address for the zone
  returned: success
  type: string
  sample: 10.1.1.0/24
dhcp_provider:
  description: DHCP provider for the zone
  returned: success
  type: string
  sample: VirtualRouter
zone_token:
  description: Zone token
  returned: success
  type: string
  sample: ccb0a60c-79c8-3230-ab8b-8bdbe8c45bb7
tags:
  description: List of resource tags associated with the zone.
  returned: success
  type: dict
  sample: [ { "key": "foo", "value": "bar" } ]


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> CS_ZONE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/cloudstack/cs_zone_facts.py)

  Gathering facts from the API of a zone.

Options (= is mandatory):

- api_http_method
        HTTP method used.
        (Choices: get, post)[Default: get]
- api_key
        API key of the CloudStack API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the CloudStack API.
        [Default: None]
- api_timeout
        HTTP timeout.
        [Default: 10]
- api_url
        URL of the CloudStack API e.g. https://cloud.example.com/client/api.
        [Default: None]
= name
        Name of the zone.

Notes:
  * Ansible uses the `cs' library's configuration method if credentials are not provided by the arguments
        `api_url', `api_key', `api_secret'. Configuration is read from several locations, in the following order. -
        The `CLOUDSTACK_ENDPOINT', `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' and `CLOUDSTACK_METHOD'.
        `CLOUDSTACK_TIMEOUT' environment variables. - A `CLOUDSTACK_CONFIG' environment variable pointing to an
        `.ini' file, - A `cloudstack.ini' file in the current working directory. - A `.cloudstack.ini' file in the
        users home directory. Optionally multiple credentials and endpoints can be specified using ini sections in
        `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'. See https://github.com/exoscale/cs for more information.
  * A detailed guide about cloudstack modules can be found on http://docs.ansible.com/ansible/guide_cloudstack.html
  * This module supports check mode.
Requirements:  python >= 2.6, cs >= 0.6.10

EXAMPLES:
- cs_zone_facts:
    name: ch-gva-1
  delegate_to: localhost

- debug:
    var: cloudstack_zone

RETURN VALUES:
---
cloudstack_zone.id:
  description: UUID of the zone.
  returned: success
  type: string
  sample: 04589590-ac63-4ffc-93f5-b698b8ac38b6
cloudstack_zone.name:
  description: Name of the zone.
  returned: success
  type: string
  sample: zone01
cloudstack_zone.dns1:
  description: First DNS for the zone.
  returned: success
  type: string
  sample: 8.8.8.8
cloudstack_zone.dns2:
  description: Second DNS for the zone.
  returned: success
  type: string
  sample: 8.8.4.4
cloudstack_zone.internal_dns1:
  description: First internal DNS for the zone.
  returned: success
  type: string
  sample: 8.8.8.8
cloudstack_zone.internal_dns2:
  description: Second internal DNS for the zone.
  returned: success
  type: string
  sample: 8.8.4.4
cloudstack_zone.dns1_ipv6:
  description: First IPv6 DNS for the zone.
  returned: success
  type: string
  sample: "2001:4860:4860::8888"
cloudstack_zone.dns2_ipv6:
  description: Second IPv6 DNS for the zone.
  returned: success
  type: string
  sample: "2001:4860:4860::8844"
cloudstack_zone.allocation_state:
  description: State of the zone.
  returned: success
  type: string
  sample: Enabled
cloudstack_zone.domain:
  description: Domain the zone is related to.
  returned: success
  type: string
  sample: ROOT
cloudstack_zone.network_domain:
  description: Network domain for the zone.
  returned: success
  type: string
  sample: example.com
cloudstack_zone.network_type:
  description: Network type for the zone.
  returned: success
  type: string
  sample: basic
cloudstack_zone.local_storage_enabled:
  description: Local storage offering enabled.
  returned: success
  type: bool
  sample: false
cloudstack_zone.securitygroups_enabled:
  description: Security groups support is enabled.
  returned: success
  type: bool
  sample: false
cloudstack_zone.guest_cidr_address:
  description: Guest CIDR address for the zone
  returned: success
  type: string
  sample: 10.1.1.0/24
cloudstack_zone.dhcp_provider:
  description: DHCP provider for the zone
  returned: success
  type: string
  sample: VirtualRouter
cloudstack_zone.zone_token:
  description: Zone token
  returned: success
  type: string
  sample: ccb0a60c-79c8-3230-ab8b-8bdbe8c45bb7
cloudstack_zone.tags:
  description: List of resource tags associated with the zone.
  returned: success
  type: dict
  sample: [ { "key": "foo", "value": "bar" } ]


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> DATADOG_EVENT    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/datadog_event.py)

  Allows to post events to DataDog (www.datadoghq.com) service. Uses http://docs.datadoghq.com/api/#events API.

Options (= is mandatory):

- aggregation_key
        An arbitrary string to use for aggregation.
        [Default: None]
- alert_type
        Type of alert.
        (Choices: error, warning, info, success)[Default: info]
= api_key
        Your DataDog API key.
        [Default: None]
= app_key
        Your DataDog app key.

- date_happened
        POSIX timestamp of the event.
        Default value is now.
        [Default: now]
- priority
        The priority of the event.
        (Choices: normal, low)[Default: normal]
- tags
        Comma separated list of tags to apply to the event.
        [Default: None]
= text
        The body of the event.
        [Default: None]
= title
        The event title.
        [Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
# Post an event with low priority
- datadog_event:
    title: Testing from ansible
    text: Test
    priority: low
    api_key: 9775a026f1ca7d1c6c5af9d94d9595a4
    app_key: j4JyCYfefWHhgFgiZUqRm63AXHNZQyPGBfJtAzmN
# Post an event with several tags
- datadog_event:
    title: Testing from ansible
    text: Test
    api_key: 9775a026f1ca7d1c6c5af9d94d9595a4
    app_key: j4JyCYfefWHhgFgiZUqRm63AXHNZQyPGBfJtAzmN
    tags: 'aa,bb,#host:{{ inventory_hostname }}'


MAINTAINERS: Naoya Nakazawa (@n0ts), Artūras `arturaz` Šlajus (@arturaz)

METADATA:
	Status: ['preview']
	Supported_by: community
> DATADOG_MONITOR    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/datadog_monitor.py)

  Manages monitors within Datadog Options like described on http://docs.datadoghq.com/api/

Options (= is mandatory):

= api_key
        Your DataDog API key.

= app_key
        Your DataDog app key.

- escalation_message
        A message to include with a re-notification. Supports the '@username' notification we allow elsewhere. Not
        applicable if renotify_interval is None
        [Default: None]
- id
        The id of the alert. If set, will be used instead of the name to locate the alert.
        [Default: None]
- locked
        A boolean indicating whether changes to this monitor should be restricted to the creator or admins.
        [Default: False]
- message
        A message to include with notifications for this monitor. Email notifications can be sent to specific users by
        using the same '@username' notation as events. Monitor message template variables can be accessed by using double
        square brackets, i.e '[[' and ']]'.
        [Default: None]
= name
        The name of the alert.

- no_data_timeframe
        The number of minutes before a monitor will notify when data stops reporting. Must be at least 2x the monitor
        timeframe for metric alerts or 2 minutes for service checks.
        [Default: 2x timeframe for metric, 2 minutes for service]
- notify_audit
        A boolean indicating whether tagged users will be notified on changes to this monitor.
        [Default: False]
- notify_no_data
        A boolean indicating whether this monitor will notify when data stops reporting..
        [Default: False]
- query
        The monitor query to notify on with syntax varying depending on what type of monitor you are creating.
        [Default: None]
- renotify_interval
        The number of minutes after the last notification before a monitor will re-notify on the current status. It will
        only re-notify if it's not resolved.
        [Default: None]
- require_full_window
        A boolean indicating whether this monitor needs a full window of data before it's evaluated. We highly recommend
        you set this to False for sparse metrics, otherwise some evaluations will be skipped.
        [Default: None]
- silenced
        Dictionary of scopes to timestamps or None. Each scope will be muted until the given POSIX timestamp or forever
        if the value is None.
        [Default: ]
= state
        The designated state of the monitor.
        (Choices: present, absent, muted, unmuted)
- tags
        A list of tags to associate with your monitor when creating or updating. This can help you categorize and filter
        monitors.
        [Default: None]
- thresholds
        A dictionary of thresholds by status. This option is only available for service checks and metric alerts. Because
        each of them can have multiple thresholds, we don't define them directly in the query.
        [Default: {u'warning': 1, u'ok': 1, u'critical': 1}]
- timeout_h
        The number of hours of the monitor not reporting data before it will automatically resolve from a triggered
        state.
        [Default: None]
- type
        The type of the monitor.
        The 'event alert'is available starting at Ansible 2.1
        (Choices: metric alert, service check, event alert)[Default: None]
Requirements:  datadog

EXAMPLES:
# Create a metric monitor
datadog_monitor:
  type: "metric alert"
  name: "Test monitor"
  state: "present"
  query: "datadog.agent.up.over('host:host1').last(2).count_by_status()"
  message: "Host [[host.name]] with IP [[host.ip]] is failing to report to datadog."
  api_key: "9775a026f1ca7d1c6c5af9d94d9595a4"
  app_key: "87ce4a24b5553d2e482ea8a8500e71b8ad4554ff"

# Deletes a monitor
datadog_monitor:
  name: "Test monitor"
  state: "absent"
  api_key: "9775a026f1ca7d1c6c5af9d94d9595a4"
  app_key: "87ce4a24b5553d2e482ea8a8500e71b8ad4554ff"

# Mutes a monitor
datadog_monitor:
  name: "Test monitor"
  state: "mute"
  silenced: '{"*":None}'
  api_key: "9775a026f1ca7d1c6c5af9d94d9595a4"
  app_key: "87ce4a24b5553d2e482ea8a8500e71b8ad4554ff"

# Unmutes a monitor
datadog_monitor:
  name: "Test monitor"
  state: "unmute"
  api_key: "9775a026f1ca7d1c6c5af9d94d9595a4"
  app_key: "87ce4a24b5553d2e482ea8a8500e71b8ad4554ff"


MAINTAINERS: Sebastian Kornehl (@skornehl)

METADATA:
	Status: ['preview']
	Supported_by: community
> DEBCONF    (/usr/lib/python2.7/site-packages/ansible/modules/system/debconf.py)

  Configure a .deb package using debconf-set-selections. Or just query existing selections.

Options (= is mandatory):

= name
        Name of package to configure.
        [Default: None]
- question
        A debconf configuration setting
        [Default: None]
- unseen
        Do not set 'seen' flag when pre-seeding
        [Default: False]
- value
        Value to set the configuration to
        [Default: None]
- vtype
        The type of the value supplied.
        `seen' was added in 2.2.
        (Choices: string, password, boolean, select, multiselect, note, error, title, text, seen)[Default: None]
Notes:
  * This module requires the command line debconf tools.
  * A number of questions have to be answered (depending on the package). Use 'debconf-show <package>' on any
        Debian or derivative with the package installed to see questions/settings available.
  * Some distros will always record tasks involving the setting of passwords as changed. This is due to debconf-
        get-selections masking passwords.
Requirements:  debconf, debconf-utils

EXAMPLES:
# Set default locale to fr_FR.UTF-8
- debconf:
    name: locales
    question: locales/default_environment_locale
    value: fr_FR.UTF-8
    vtype: select

# set to generate locales:
- debconf:
    name: locales
    question: locales/locales_to_be_generated
    value: en_US.UTF-8 UTF-8, fr_FR.UTF-8 UTF-8
    vtype: multiselect

# Accept oracle license
- debconf:
    name: oracle-java7-installer
    question: shared/accepted-oracle-license-v1-1
    value: true
    vtype: select

# Specifying package you can register/return the list of questions and current values
- debconf:
    name: tzdata


MAINTAINERS: Brian Coca (@bcoca)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> DEBUG    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/debug.py)

  This module prints statements during execution and can be useful for debugging variables or expressions without
  necessarily halting the playbook. Useful for debugging together with the 'when:' directive.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- msg
        The customized message that is printed. If omitted, prints a generic message.
        [Default: Hello world!]
- var
        A variable name to debug.  Mutually exclusive with the 'msg' option.
        [Default: (null)]
- verbosity
        A number that controls when the debug is run, if you set to 3 it will only run debug when -vvv or above
        [Default: 0]
EXAMPLES:
# Example that prints the loopback address and gateway for each host
- debug:
    msg: "System {{ inventory_hostname }} has uuid {{ ansible_product_uuid }}"

- debug:
    msg: "System {{ inventory_hostname }} has gateway {{ ansible_default_ipv4.gateway }}"
  when: ansible_default_ipv4.gateway is defined

- shell: /usr/bin/uptime
  register: result

- debug:
    var: result
    verbosity: 2

- name: Display all variables/facts known for a host
  debug:
    var: hostvars[inventory_hostname]
    verbosity: 4


MAINTAINERS: Michael DeHaan, Dag Wieers (@dagwieers)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> DELLOS10_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos10/dellos10_command.py)

  Sends arbitrary commands to a Dell OS10 node and returns the results read from the device. This module includes an
  argument that will cause the module to wait for a specific condition before returning or timing out if the condition is
  not met. This module does not support running commands in configuration mode. Please use [dellos10_config] to configure
  Dell OS10 devices.

Options (= is mandatory):

= commands
        List of commands to send to the remote dellos10 device over the configured provider. The resulting output from
        the command is returned. If the `wait_for' argument is provided, the module is not returned until the condition
        is satisfied or the number of retries has expired.

- interval
        Configures the interval in seconds to wait between retries of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should by tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditions.
        [Default: 10]
- wait_for
        List of conditions to evaluate against the output of the command. The task will wait for each condition to be
        true before moving forward. If the conditional is not true within the configured number of `retries', the task
        fails. See examples.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

tasks:
  - name: run show version on remote devices
    dellos10_command:
      commands: show version
      provider: "{{ cli }}"

  - name: run show version and check to see if output contains OS10
    dellos10_command:
      commands: show version
      wait_for: result[0] contains OS10
      provider: "{{ cli }}"

  - name: run multiple commands on remote nodes
    dellos10_command:
      commands:
        - show version
        - show interface
      provider: "{{ cli }}"

  - name: run multiple commands and evaluate the output
    dellos10_command:
      commands:
        - show version
        - show interface
      wait_for:
        - result[0] contains OS10
        - result[1] contains Ethernet
      provider: "{{ cli }}"

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']

stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]

failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']

warnings:
  description: The list of warnings (if any) generated by module based on arguments
  returned: always
  type: list
  sample: ['...', '...']


MAINTAINERS: Senthil Kumar Ganesan (@skg-net)

METADATA:
	Status: ['preview']
	Supported_by: community
> DELLOS10_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos10/dellos10_config.py)

  OS10 configurations use a simple block indent file syntax for segmenting configuration into sections.  This module
  provides an implementation for working with OS10 configuration sections in a deterministic way.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  As with
        `before', the playbook designer can use this argument  to append a set of commands to be executed after the
        command set.
        [Default: None]
- backup
        This argument causes the module to create a full backup of the current `running-config' from the remote device
        before any changes are made.  The backup file is written to the `backup' folder in the playbook root directory.
        If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  The playbook designer
        can  use this argument to perform configuration commands prior to pushing any changes without affecting how the
        set of commands are matched against the system.
        [Default: None]
- config
        The playbook designer can use the `config' argument to supply the base configuration to be used to validate
        necessary configuration changes.  If you specify this argument, the module does not download the running-config
        from the remote node.
        [Default: None]
- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config. Note the configuration command syntax as the device config parser
        automatically modifies some commands. This argument is mutually exclusive with `src'.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If you set match to `line', commands match line by line.  If you set match to `strict', command lines match by
        position.  If you set match to `exact', command lines must be an equal match.  Finally, if you set match to
        `none', the module does not attempt to compare the source configuration with the running configuration on the
        remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If you
        omit the parents argument, the commands are checked against the set of top level or global commands.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device. If you set the replace argument to
        `line', then the modified lines push to the device in configuration mode.  If you set the replace argument to
        `block', then the entire command block pushes to the device in configuration mode if any line is not correct.
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running- config to the startup-config at the conclusion of
        the module running.  If you specify check mode, this argument is ignored.
        (Choices: yes, no)[Default: False]
- src
        Specifies the source path to the file that contains the configuration or configuration template to load.  The
        path to the source file can either be the full path on the Ansible control host or a relative path from the
        playbook or role root dir.  This argument is mutually exclusive with `lines'.
        [Default: None]
- update
        The `update' argument controls how the configuration statements are processed on the remote device.  Valid
        choices for the `update' argument are `merge' and `check'.  When you set the argument to `merge', the
        configuration changes merge with the current device running configuration.  When you set the argument to `check',
        the configuration updates are determined but not actually configured on the remote device.
        (Choices: merge, check)[Default: merge]
EXAMPLES:
- dellos10_config:
    lines: ['hostname {{ inventory_hostname }}']
    provider: "{{ cli }}"

- dellos10_config:
    lines:
      - 10 permit ip host 1.1.1.1 any log
      - 20 permit ip host 2.2.2.2 any log
      - 30 permit ip host 3.3.3.3 any log
      - 40 permit ip host 4.4.4.4 any log
      - 50 permit ip host 5.5.5.5 any log
    parents: ['ip access-list test']
    before: ['no ip access-list test']
    match: exact
    provider: "{{ cli }}"

- dellos10_config:
    lines:
      - 10 permit ip host 1.1.1.1 any log
      - 20 permit ip host 2.2.2.2 any log
      - 30 permit ip host 3.3.3.3 any log
      - 40 permit ip host 4.4.4.4 any log
    parents: ['ip access-list test']
    before: ['no ip access-list test']
    replace: block
    provider: "{{ cli }}"


RETURN VALUES:
updates:
  description: The set of commands pushed to the remote device.
  returned: Always.
  type: list
  sample: ['...', '...']

responses:
  description: The set of responses from issuing the commands on the device.
  returned: When not check_mode.
  type: list
  sample: ['...', '...']

saved:
  description: Returns whether the configuration is saved to the startup
               configuration or not.
  returned: When not check_mode.
  type: bool
  sample: True



MAINTAINERS: Senthil Kumar Ganesan (@skg-net)

METADATA:
	Status: ['preview']
	Supported_by: community
> DELLOS10_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos10/dellos10_facts.py)

  Collects a base set of device facts from a remote device that is running OS10.  This module prepends all of the base
  network fact keys with `ansible_net_<fact>'.  The facts module always collects a base set of facts from the device and
  can enable or disable collection of additional facts.

Options (= is mandatory):

- gather_subset
        When supplied, this argument restricts the facts collected to a given subset.  Possible values for this argument
        include all, hardware, config, and interfaces.  You can specify a list of values to include a larger subset.  You
        can also use values with an initial [!] to specify that a specific subset should not be collected.
        [Default: !config]
- provider
        A dict object containing connection details.
        [Default: None]
EXAMPLES:
# Collect all facts from the device
- dellos10_facts:
    gather_subset: all

# Collect only the config and default facts
- dellos10_facts:
    gather_subset:
      - config

# Do not collect hardware facts
- dellos10_facts:
    gather_subset:
      - "!hardware"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the device.
  returned: Always.
  type: list

# default
ansible_net_name:
  description: The name of the OS that is running.
  returned: Always.
  type: str
ansible_net_version:
  description: The operating system version running on the remote device.
  returned: Always.
  type: str
ansible_net_servicetag:
  description: The service tag number of the remote device.
  returned: Always.
  type: str
ansible_net_model:
  description: The model name returned from the device.
  returned: Always.
  type: str
ansible_net_hostname:
  description: The configured hostname of the device.
  returned: Always.
  type: str

# hardware
ansible_net_cpu_arch:
  description: CPU Architecture of the remote device.
  returned: When hardware is configured.
  type: str
ansible_net_memfree_mb:
  description: The available free memory on the remote device in MB.
  returned: When hardware is configured.
  type: int
ansible_net_memtotal_mb:
  description: The total memory on the remote device in MB.
  returned: When hardware is configured.
  type: int

# config
ansible_net_config:
  description: The current active config from the device.
  returned: When config is configured.
  type: str

# interfaces
ansible_net_all_ipv4_addresses:
  description: All IPv4 addresses configured on the device.
  returned: When interfaces is configured
  type: list
ansible_net_all_ipv6_addresses:
  description: All IPv6 addresses configured on the device.
  returned: When interfaces is configured.
  type: list
ansible_net_interfaces:
  description: A hash of all interfaces running on the system.
  returned: When interfaces is configured.
  type: dict
ansible_net_neighbors:
  description: The list of LLDP neighbors from the remote device.
  returned: When interfaces is configured.
  type: dict


MAINTAINERS: Senthil Kumar Ganesan (@skg-net)

METADATA:
	Status: ['preview']
	Supported_by: community
> DELLOS6_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos6/dellos6_command.py)

  Sends arbitrary commands to a Dell OS6 node and returns the results read from the device. This module includes an
  argument that will cause the module to wait for a specific condition before returning or timing out if the condition is
  not met. This module does not support running commands in configuration mode. Please use [dellos6_config] to configure
  Dell OS6 devices.

Options (= is mandatory):

= commands
        List of commands to send to the remote dellos6 device over the configured provider. The resulting output from the
        command is returned. If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of `retries' as expired.

- interval
        Configures the interval in seconds to wait between retries of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should be tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditions.
        [Default: 10]
- wait_for
        List of conditions to evaluate against the output of the command. The task will wait for each condition to be
        true before moving forward. If the conditional is not true within the configured number of `retries', the task
        fails. See examples.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

tasks:
 - name: run show version on remote devices
   dellos6_command:
     commands: show version
     provider: "{{ cli }}"

 - name: run show version and check to see if output contains Dell
   dellos6_command:
     commands: show version
     wait_for: result[0] contains Dell
     provider: "{{ cli }}"

 - name: run multiple commands on remote nodes
   dellos6_command:
     commands:
      - show version
      - show interfaces
     provider: "{{ cli }}"

 - name: run multiple commands and evaluate the output
   dellos6_command:
     commands:
      - show version
      - show interfaces
     wait_for:
      - result[0] contains Dell
      - result[1] contains Access
     provider: "{{ cli }}"

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']

stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]

failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']

warnings:
  description: The list of warnings (if any) generated by module based on arguments
  returned: always
  type: list
  sample: ['...', '...']


MAINTAINERS: Abirami N (@abirami-n)

METADATA:
	Status: ['preview']
	Supported_by: community
> DELLOS6_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos6/dellos6_config.py)

  OS6 configurations use a simple block indent file syntax for segmenting configuration into sections.  This module
  provides an implementation for working with OS6 configuration sections in a deterministic way.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  As with
        `before', the playbook desinger can use this to append a set of commands to be executed after the command set.
        [Default: None]
- backup
        This argument causes the module to create a full backup of the current `running-config' from the remote device
        before any changes are made.  The backup file is written to the `backup' folder in the playbook root directory.
        If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- config
        The playbook designer can use the `config' argument to supply the base configuration to be used to validate
        necessary configuration changes.  If you specify this argument, the module does not download the running-config
        from the remote node.
        [Default: None]
- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config. Note the configuration command syntax as the device config parser
        automatically modifies some commands. This argument is mutually exclusive with `src'.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If you set match to `line', commands match line by line.  If you set match to `strict', command lines matched by
        respect to position.  If you set match to `exact', command lines must be an equal match.  Finally, if you set
        match to `none', the module does  not attempt to compare the source configuration with the running configuration
        on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If you do
        not specify the parents argument, the commands are checked against the set of top level or global commands.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If you set the replace argument to
        `line', then the modified lines are pushed to the device in configuration mode.  If you set the replace argument
        to `block' then the entire command block is pushed to the device in configuration mode if any line is not
        correct.
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running- config to the startup-config at the conclusion of
        the module running.  If you specify check mode, this argument is ignored.
        (Choices: yes, no)[Default: False]
- src
        Specifies the source path to the file that contains the configuration or configuration template to load.  The
        path to the source file can either be the full path on the Ansible control host or a relative path from the
        playbook or role root dir.  This argument is mutually exclusive with `lines'.
        [Default: None]
- update
        The `update' argument controls how the configuration statements are processed on the remote device.  Valid
        choices for the `update' argument are `merge' and `check'.  When you set this argument to `merge', the
        configuration changes merge with the current device running configuration.  When you set this argument to `check'
        the configuration updates are determined but not actually configured on the remote device.
        (Choices: merge, check)[Default: merge]
EXAMPLES:
- dellos6_config:
    lines: ['hostname {{ inventory_hostname }}']
    provider: "{{ cli }}"

- dellos6_config:
    lines:
      - 10 permit ip 1.1.1.1 any log
      - 20 permit ip 2.2.2.2 any log
      - 30 permit ip 3.3.3.3 any log
      - 40 permit ip 4.4.4.4 any log
      - 50 permit ip  5.5.5.5 any log
    parents: ['ip access-list test']
    before: ['no ip access-list test']
    match: exact
    provider: "{{ cli }}"

- dellos6_config:
    lines:
      - 10 permit ip 1.1.1.1 any log
      - 20 permit ip 2.2.2.2 any log
      - 30 permit ip 3.3.3.3 any log
      - 40 permit ip 4.4.4.4 any log
    parents: ['ip access-list test']
    before: ['no ip access-list test']
    replace: block
    provider: "{{ cli }}"


RETURN VALUES:
updates:
  description: The set of commands pushed to the remote device.
  returned: Always.
  type: list
  sample: ['...', '...']

responses:
  description: The set of responses from issuing the commands on the device.
  returned: When not check_mode.
  type: list
  sample: ['...', '...']

saved:
  description: Returns whether the configuration is saved to the startup
               configuration or not.
  returned: When not check_mode.
  type: bool
  sample: True



MAINTAINERS: Abirami N(@abirami-n)

METADATA:
	Status: ['preview']
	Supported_by: community
> DELLOS6_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos6/dellos6_facts.py)

  Collects a base set of device facts from a remote device that is running OS6.  This module prepends all of the base
  network fact keys with `ansible_net_<fact>'.  The facts module always collects a base set of facts from the device and
  can enable or disable collection of additional facts.

Options (= is mandatory):

- gather_subset
        When specified, this argument restricts the facts collected to a given subset.  Possible values for this argument
        include all, hardware, config, and interfaces.  You can specify a list of values to include a larger subset.  You
        can also use values with an initial [!] to specify that a specific subset should not be collected.
        [Default: !config]
- provider
        A dict object containing connection details.
        [Default: None]
EXAMPLES:
# Collect all facts from the device
- dellos6_facts:
    gather_subset: all

# Collect only the config and default facts
- dellos6_facts:
    gather_subset:
      - config

# Do not collect hardware facts
- dellos6_facts:
    gather_subset:
      - "!interfaces"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the device.
  returned: Always.
  type: list

# default
ansible_net_model:
  description: The model name returned from the device.
  returned: Always.
  type: str
ansible_net_serialnum:
  description: The serial number of the remote device.
  returned: Always.
  type: str
ansible_net_version:
  description: The operating system version running on the remote device.
  returned: Always.
  type: str
ansible_net_hostname:
  description: The configured hostname of the device.
  returned: Always.
  type: string
ansible_net_image:
  description: The image file that the device is running.
  returned: Always
  type: string

# hardware
ansible_net_memfree_mb:
  description: The available free memory on the remote device in MB.
  returned: When hardware is configured.
  type: int
ansible_net_memtotal_mb:
  description: The total memory on the remote device in MB.
  returned: When hardware is configured.
  type: int

# config
ansible_net_config:
  description: The current active config from the device.
  returned: When config is configured.
  type: str

# interfaces
ansible_net_interfaces:
  description: A hash of all interfaces running on the system.
  returned: When interfaces is configured.
  type: dict
ansible_net_neighbors:
  description: The list of LLDP neighbors from the remote device.
  returned: When interfaces is configured.
  type: dict



MAINTAINERS: Abirami N(@abirami-n)

METADATA:
	Status: ['preview']
	Supported_by: community
> DELLOS9_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos9/dellos9_command.py)

  Sends arbitrary commands to a Dell OS9 node and returns the results read from the device. This  module includes an
  argument that will cause the module to wait for a specific condition before returning or timing out if the condition is
  not met. This module does not support running commands in configuration mode. Please use [dellos9_config] to configure
  Dell OS9 devices.

Options (= is mandatory):

= commands
        List of commands to send to the remote dellos9 device over the configured provider. The resulting output from the
        command is returned. If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of retries has expired.

- interval
        Configures the interval in seconds to wait between retries of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should be tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditions.
        [Default: 10]
- wait_for
        List of conditions to evaluate against the output of the command. The task will wait for each condition to be
        true before moving forward. If the conditional is not true within the configured number of `retries', the task
        fails. See examples.
        [Default: None]
Notes:
  * This module requires Dell OS9 version 9.10.0.1P13 or above.
  * This module requires to increase the ssh connection rate limit. Use the following command `ip ssh connection-
        rate-limit 60' to configure the same. This can be done via [dellos9_config] module as well.
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

tasks:
  - name: run show version on remote devices
    dellos9_command:
      commands: show version
      provider: "{{ cli }}"

  - name: run show version and check to see if output contains OS9
    dellos9_command:
      commands: show version
      wait_for: result[0] contains OS9
      provider: "{{ cli }}"

  - name: run multiple commands on remote nodes
    dellos9_command:
      commands:
        - show version
        - show interfaces
      provider: "{{ cli }}"

  - name: run multiple commands and evaluate the output
    dellos9_command:
      commands:
        - show version
        - show interfaces
      wait_for:
        - result[0] contains OS9
        - result[1] contains Loopback
      provider: "{{ cli }}"

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']
stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]
failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']
warnings:
  description: The list of warnings (if any) generated by module based on arguments
  returned: always
  type: list
  sample: ['...', '...']


MAINTAINERS: Dhivya P (@dhivyap)

METADATA:
	Status: ['preview']
	Supported_by: community
> DELLOS9_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos9/dellos9_config.py)

  OS9 configurations use a simple block indent file syntax for segmenting configuration into sections.  This module
  provides an implementation for working with OS9 configuration sections in a deterministic way.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made. As with
        `before', this the playbook designer can append a set of commands to be executed after the command set.
        [Default: None]
- backup
        This argument causes the module to create a full backup of the current `running-config' from the remote device
        before any changes are made.  The backup file is written to the `backup' folder in the playbook root directory.
        If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  The playbook designer
        can use this opportunity to perform configuration commands prior to pushing any changes without affecting how the
        set of commands are matched against the system.
        [Default: None]
- config
        The playbook designer can use the  `config' argument to supply the base configuration to be used to validate
        necessary configuration changes.  If you provide this argument, the module does not download the running-config
        from the remote node.
        [Default: None]
- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config. Note the configuration command syntax as the device config parser
        automatically modifies some commands. This argument is mutually exclusive with `src'.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If you set match to `line', commands match line by line.  If you set match to `strict', command lines match by
        position.  If you set match to `exact', command lines must be an equal match.  Finally, if you set match to
        `none', the module does  not attempt to compare the source configuration with the running configuration on the
        remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If you
        omit the parents argument, the commands are checked against the set of top level or global commands.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If you set the replace argument to
        `line', then the modified lines push to the device in configuration mode.  If you set the replace argument to
        `block', then the entire command block pushes to the device in configuration mode if any line is not correct.
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running- config to the startup-config at the conclusion of
        the module running.  If check mode is specified, this argument is ignored.
        (Choices: yes, no)[Default: False]
- src
        Specifies the source path to the file that contains the configuration or configuration template to load.  The
        path to the source file can either be the full path on the Ansible control host or a relative path from the
        playbook or role root dir.  This argument is mutually exclusive with `lines'.
        [Default: None]
- update
        The `update' argument controls how the configuration statements are processed on the remote device.  Valid
        choices for the `update' argument are `merge' and `check'.  When you set this argument to `merge', the
        configuration changes merge with the current device running configuration.  When you set this argument to `check'
        the configuration updates are determined but not actually configured on the remote device.
        (Choices: merge, check)[Default: merge]
Notes:
  * This module requires Dell OS9 version 9.10.0.1P13 or above.
  * This module requires to increase the ssh connection rate limit. Use the following command `ip ssh connection-
        rate-limit 60' to configure the same. This can also be done with the [dellos9_config] module.
EXAMPLES:
- dellos9_config:
    lines: ['hostname {{ inventory_hostname }}']
    provider: "{{ cli }}"

- dellos9_config:
    lines:
      - 10 permit ip host 1.1.1.1 any log
      - 20 permit ip host 2.2.2.2 any log
      - 30 permit ip host 3.3.3.3 any log
      - 40 permit ip host 4.4.4.4 any log
      - 50 permit ip host 5.5.5.5 any log
    parents: ['ip access-list extended test']
    before: ['no ip access-list extended test']
    match: exact
    provider: "{{ cli }}"

- dellos9_config:
    lines:
      - 10 permit ip host 1.1.1.1 any log
      - 20 permit ip host 2.2.2.2 any log
      - 30 permit ip host 3.3.3.3 any log
      - 40 permit ip host 4.4.4.4 any log
    parents: ['ip access-list extended test']
    before: ['no ip access-list extended test']
    replace: block
    provider: "{{ cli }}"


RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device.
  returned: Always.
  type: list
  sample: ['...', '...']

responses:
  description: The set of responses from issuing the commands on the device.
  returned: When not check_mode.
  type: list
  sample: ['...', '...']

saved:
  description: Returns whether the configuration is saved to the startup
               configuration or not.
  returned: When not check_mode.

  type: bool
  sample: True



MAINTAINERS: Dhivya P (@dhivyap)

METADATA:
	Status: ['preview']
	Supported_by: community
> DELLOS9_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/dellos9/dellos9_facts.py)

  Collects a base set of device facts from a remote device that is running OS9.  This module prepends all of the base
  network fact keys with `ansible_net_<fact>'.  The facts module always collects  a base set of facts from the device and
  can enable or disable collection of additional facts.

Options (= is mandatory):

- gather_subset
        When supplied, this argument restricts the facts collected to a given subset.  Possible values for this argument
        include all, hardware, config, and interfaces.  You can specify a list of values to include a larger subset.  You
        can also use values with an initial [!] to specify that a specific subset should not be collected.
        [Default: !config]
- provider
        A dict object containing connection details.
        [Default: None]
Notes:
  * This module requires OS9 version 9.10.0.1P13 or above.
  * This module requires an increase of the SSH connection rate limit. Use the following command `ip ssh
        connection-rate-limit 60' to configure the same. This can be also be done with the [dellos9_config] module.
EXAMPLES:
# Collect all facts from the device
- dellos9_facts:
    gather_subset: all

# Collect only the config and default facts
- dellos9_facts:
    gather_subset:
      - config

# Do not collect hardware facts
- dellos9_facts:
    gather_subset:
      - "!hardware"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the device.
  returned: Always.
  type: list

# default
ansible_net_model:
  description: The model name returned from the device.
  returned: Always.
  type: str
ansible_net_serialnum:
  description: The serial number of the remote device.
  returned: Always.
  type: str
ansible_net_version:
  description: The operating system version running on the remote device.
  returned: Always.
  type: str
ansible_net_hostname:
  description: The configured hostname of the device.
  returned: Always.
  type: string
ansible_net_image:
  description: The image file the device is running.
  returned: Always.
  type: string

# hardware
ansible_net_filesystems:
  description: All file system names available on the device.
  returned: When hardware is configured.
  type: list
ansible_net_memfree_mb:
  description: The available free memory on the remote device in MB.
  returned: When hardware is configured.
  type: int
ansible_net_memtotal_mb:
  description: The total memory on the remote device in MB.
  returned: When hardware is configured.
  type: int

# config
ansible_net_config:
  description: The current active config from the device.
  returned: When config is configured.
  type: str

# interfaces
ansible_net_all_ipv4_addresses:
  description: All IPv4 addresses configured on the device.
  returned: When interfaces is configured.
  type: list
ansible_net_all_ipv6_addresses:
  description: All IPv6 addresses configured on the device.
  returned: When interfaces is configured.
  type: list
ansible_net_interfaces:
  description: A hash of all interfaces running on the system.
  returned: When interfaces is configured.
  type: dict
ansible_net_neighbors:
  description: The list of LLDP neighbors from the remote device
  returned: When interfaces is configured.
  type: dict


MAINTAINERS: Dhivya P (@dhivyap)

METADATA:
	Status: ['preview']
	Supported_by: community
> DEPLOY_HELPER    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/deploy_helper.py)

  The Deploy Helper manages some of the steps common in deploying software. It creates a folder structure, manages a
  symlink for the current release and cleans up old releases. Running it with the `state=query' or `state=present' will
  return the `deploy_helper' fact. `project_path', whatever you set in the path parameter, `current_path', the path to
  the symlink that points to the active release, `releases_path', the path to the folder to keep releases in,
  `shared_path', the path to the folder to keep shared resources in, `unfinished_filename', the file to check for to
  recognize unfinished builds, `previous_release', the release the 'current' symlink is pointing to,
  `previous_release_path', the full path to the 'current' symlink target, `new_release', either the 'release' parameter
  or a generated timestamp, `new_release_path', the path to the new release folder (not created by the module).

Options (= is mandatory):

- clean
        Whether to run the clean procedure in case of `state=finalize'.
        [Default: True]
- current_path
        the name of the symlink that is created when the deploy is finalized. Used in `finalize' and `clean'. Returned in
        the `deploy_helper.current_path' fact.
        [Default: current]
- keep_releases
        the number of old releases to keep when cleaning. Used in `finalize' and `clean'. Any unfinished builds will be
        deleted first, so only correct releases will count. The current version will not count.
        [Default: 5]
= path
        the root path of the project. Alias `dest'. Returned in the `deploy_helper.project_path' fact.

- release
        the release version that is being deployed. Defaults to a timestamp format %Y%m%d%H%M%S (i.e. '20141119223359').
        This parameter is optional during `state=present', but needs to be set explicitly for `state=finalize'. You can
        use the generated fact `release={{ deploy_helper.new_release }}'.
        [Default: None]
- releases_path
        the name of the folder that will hold the releases. This can be relative to `path' or absolute. Returned in the
        `deploy_helper.releases_path' fact.
        [Default: releases]
- shared_path
        the name of the folder that will hold the shared resources. This can be relative to `path' or absolute. If this
        is set to an empty string, no shared folder will be created. Returned in the `deploy_helper.shared_path' fact.
        [Default: shared]
- state
        the state of the project. `query' will only gather facts, `present' will create the project `root' folder, and in
        it the `releases' and `shared' folders, `finalize' will remove the unfinished_filename file, create a symlink to
        the newly deployed release and optionally clean old releases, `clean' will remove failed & old releases, `absent'
        will remove the project folder (synonymous to the [file] module with `state=absent')
        (Choices: present, finalize, absent, clean, query)[Default: present]
- unfinished_filename
        the name of the file that indicates a deploy has not finished. All folders in the releases_path that contain this
        file will be deleted on `state=finalize' with clean=True, or `state=clean'. This file is automatically deleted
        from the `new_release_path' during `state=finalize'.
        [Default: DEPLOY_UNFINISHED]
Notes:
  * Facts are only returned for `state=query' and `state=present'. If you use both, you should pass any overridden
        parameters to both calls, otherwise the second call will overwrite the facts of the first one.
  * When using `state=clean', the releases are ordered by `creation date'. You should be able to switch to a new
        naming strategy without problems.
  * Because of the default behaviour of generating the `new_release' fact, this module will not be idempotent
        unless you pass your own release name with `release'. Due to the nature of deploying software, this should
        not be much of a problem.
EXAMPLES:

# General explanation, starting with an example folder structure for a project:

# root:
#     releases:
#         - 20140415234508
#         - 20140415235146
#         - 20140416082818
#
#     shared:
#         - sessions
#         - uploads
#
#     current: releases/20140416082818


# The 'releases' folder holds all the available releases. A release is a complete build of the application being
# deployed. This can be a clone of a repository for example, or a sync of a local folder on your filesystem.
# Having timestamped folders is one way of having distinct releases, but you could choose your own strategy like
# git tags or commit hashes.
#
# During a deploy, a new folder should be created in the releases folder and any build steps required should be
# performed. Once the new build is ready, the deploy procedure is 'finalized' by replacing the 'current' symlink
# with a link to this build.
#
# The 'shared' folder holds any resource that is shared between releases. Examples of this are web-server
# session files, or files uploaded by users of your application. It's quite common to have symlinks from a release
# folder pointing to a shared/subfolder, and creating these links would be automated as part of the build steps.
#
# The 'current' symlink points to one of the releases. Probably the latest one, unless a deploy is in progress.
# The web-server's root for the project will go through this symlink, so the 'downtime' when switching to a new
# release is reduced to the time it takes to switch the link.
#
# To distinguish between successful builds and unfinished ones, a file can be placed in the folder of the release
# that is currently in progress. The existence of this file will mark it as unfinished, and allow an automated
# procedure to remove it during cleanup.


# Typical usage
- name: Initialize the deploy root and gather facts
  deploy_helper:
    path: /path/to/root
- name: Clone the project to the new release folder
  git:
    repo: git://foosball.example.org/path/to/repo.git
    dest: '{{ deploy_helper.new_release_path }}'
    version: v1.1.1
- name: Add an unfinished file, to allow cleanup on successful finalize
  file:
    path: '{{ deploy_helper.new_release_path }}/{{ deploy_helper.unfinished_filename }}'
    state: touch
- name: Perform some build steps, like running your dependency manager for example
  composer:
    command: install
    working_dir: '{{ deploy_helper.new_release_path }}'
- name: Create some folders in the shared folder
  file:
    path: '{{ deploy_helper.shared_path }}/{{ item }}'
    state: directory
  with_items:
    - sessions
    - uploads
- name: Add symlinks from the new release to the shared folder
  file:
    path: '{{ deploy_helper.new_release_path }}/{{ item.path }}'
    src: '{{ deploy_helper.shared_path }}/{{ item.src }}'
    state: link
  with_items:
      - path: app/sessions
        src: sessions
      - path: web/uploads
        src: uploads
- name: Finalize the deploy, removing the unfinished file and switching the symlink
  deploy_helper:
    path: /path/to/root
    release: '{{ deploy_helper.new_release }}'
    state: finalize

# Retrieving facts before running a deploy
- name: Run 'state=query' to gather facts without changing anything
  deploy_helper:
    path: /path/to/root
    state: query
# Remember to set the 'release' parameter when you actually call 'state=present' later
- name: Initialize the deploy root
  deploy_helper:
    path: /path/to/root
    release: '{{ deploy_helper.new_release }}'
    state: present

# all paths can be absolute or relative (to the 'path' parameter)
- deploy_helper:
    path: /path/to/root
    releases_path: /var/www/project/releases
    shared_path: /var/www/shared
    current_path: /var/www/active

# Using your own naming strategy for releases (a version tag in this case):
- deploy_helper:
    path: /path/to/root
    release: v1.1.1
    state: present
- deploy_helper:
    path: /path/to/root
    release: '{{ deploy_helper.new_release }}'
    state: finalize

# Using a different unfinished_filename:
- deploy_helper:
    path: /path/to/root
    unfinished_filename: README.md
    release: '{{ deploy_helper.new_release }}'
    state: finalize

# Postponing the cleanup of older builds:
- deploy_helper:
    path: /path/to/root
    release: '{{ deploy_helper.new_release }}'
    state: finalize
    clean: False
- deploy_helper:
    path: /path/to/root
    state: clean
# Or running the cleanup ahead of the new deploy
- deploy_helper:
    path: /path/to/root
    state: clean
- deploy_helper:
    path: /path/to/root
    state: present

# Keeping more old releases:
- deploy_helper:
    path: /path/to/root
    release: '{{ deploy_helper.new_release }}'
    state: finalize
    keep_releases: 10
# Or, if you use 'clean=false' on finalize:
- deploy_helper:
    path: /path/to/root
    state: clean
    keep_releases: 10

# Removing the entire project root folder
- deploy_helper:
    path: /path/to/root
    state: absent

# Debugging the facts returned by the module
- deploy_helper:
    path: /path/to/root
- debug:
    var: deploy_helper


MAINTAINERS: Ramon de la Fuente (@ramondelafuente)

METADATA:
	Status: ['preview']
	Supported_by: community
> DIGITAL_OCEAN    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/digital_ocean/digital_ocean.py)

  Create/delete a droplet in DigitalOcean and optionally wait for it to be 'running', or deploy an SSH key.

Options (= is mandatory):

- api_token
        DigitalOcean api token.
        [Default: (null)]
- backups_enabled
        Optional, Boolean, enables backups for your droplet.
        (Choices: yes, no)[Default: no]
- command
        Which target you want to operate on.
        (Choices: droplet, ssh)[Default: droplet]
- id
        Numeric, the droplet id you want to operate on.
        [Default: (null)]
- image_id
        This is the slug of the image you would like the droplet created with.
        [Default: (null)]
- ipv6
        Optional, Boolean, enable IPv6 for your droplet.
        (Choices: yes, no)[Default: no]
- name
        String, this is the name of the droplet - must be formatted by hostname rules, or the name of a SSH key.
        [Default: (null)]
- private_networking
        Bool, add an additional, private network interface to droplet for inter-droplet communication.
        (Choices: yes, no)[Default: no]
- region_id
        This is the slug of the region you would like your server to be created in.
        [Default: (null)]
- size_id
        This is the slug of the size you would like the droplet created with.
        [Default: (null)]
- ssh_key_ids
        Optional, array of SSH key (numeric) ID that you would like to be added to the server.
        [Default: (null)]
- ssh_pub_key
        The public SSH key you want to add to your account.
        [Default: (null)]
- state
        Indicate desired state of the target.
        (Choices: present, active, absent, deleted)[Default: present]
- unique_name
        Bool, require unique hostnames.  By default, DigitalOcean allows multiple hosts with the same name.  Setting this
        to "yes" allows only one host per name.  Useful for idempotence.
        (Choices: yes, no)[Default: no]
- user_data
        opaque blob of data which is made available to the droplet
        [Default: None]
- virtio
        Bool, turn on virtio driver in droplet for improved network and storage I/O.
        (Choices: yes, no)[Default: yes]
- wait
        Wait for the droplet to be in state 'running' before returning.  If wait is "no" an ip_address may not be
        returned.
        (Choices: yes, no)[Default: yes]
- wait_timeout
        How long before wait gives up, in seconds.
        [Default: 300]
Notes:
  * Two environment variables can be used, DO_API_KEY and DO_API_TOKEN. They both refer to the v2 token.
  * As of Ansible 1.9.5 and 2.0, Version 2 of the DigitalOcean API is used, this removes `client_id' and `api_key'
        options in favor of `api_token'.
  * If you are running Ansible 1.9.4 or earlier you might not be able to use the included version of this module as
        the API version used has been retired. Upgrade Ansible or, if unable to, try downloading the latest version
        of this module from github and putting it into a 'library' directory.
Requirements:  python >= 2.6, dopy

EXAMPLES:
# Ensure a SSH key is present
# If a key matches this name, will return the ssh key id and changed = False
# If no existing key matches this name, a new key is created, the ssh key id is returned and changed = False

- digital_ocean:
    state: present
    command: ssh
    name: my_ssh_key
    ssh_pub_key: 'ssh-rsa AAAA...'
    api_token: XXX

# Create a new Droplet
# Will return the droplet details including the droplet id (used for idempotence)

- digital_ocean:
    state: present
    command: droplet
    name: mydroplet
    api_token: XXX
    size_id: 2gb
    region_id: ams2
    image_id: fedora-19-x64
    wait_timeout: 500
  register: my_droplet

- debug:
    msg: "ID is {{ my_droplet.droplet.id }}"

- debug:
    msg: "IP is {{ my_droplet.droplet.ip_address }}"

# Ensure a droplet is present
# If droplet id already exist, will return the droplet details and changed = False
# If no droplet matches the id, a new droplet will be created and the droplet details (including the new id) are returned, changed = True.

- digital_ocean:
    state: present
    command: droplet
    id: 123
    name: mydroplet
    api_token: XXX
    size_id: 2gb
    region_id: ams2
    image_id: fedora-19-x64
    wait_timeout: 500

# Create a droplet with ssh key
# The ssh key id can be passed as argument at the creation of a droplet (see ssh_key_ids).
# Several keys can be added to ssh_key_ids as id1,id2,id3
# The keys are used to connect as root to the droplet.

- digital_ocean:
    state: present
    ssh_key_ids: 123,456
    name: mydroplet
    api_token: XXX
    size_id: 2gb
    region_id: ams2
    image_id: fedora-19-x64



MAINTAINERS: Vincent Viallet (@zbal)

METADATA:
	Status: ['preview']
	Supported_by: community
> DIGITAL_OCEAN_BLOCK_STORAGE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/digital_ocean/digital_ocean_block_storage.py)

  Create/destroy Block Storage volume in DigitalOcean, or attach/detach Block Storage volume to a droplet.

Options (= is mandatory):

= api_token
        DigitalOcean api token.

- block_size
        The size of the Block Storage volume in gigabytes. Required when command=create and state=present.
        [Default: (null)]
= command
        Which operation do you want to perform.
        (Choices: create, attach)
- description
        Description of the Block Storage volume.
        [Default: (null)]
- droplet_id
        The droplet id you want to operate on. Required when command=attach.
        [Default: (null)]
= region
        The slug of the region where your Block Storage volume should be located in.

= state
        Indicate desired state of the target.
        (Choices: present, absent)
- timeout
        The timeout in seconds used for polling DigitalOcean's API.
        [Default: 10]
= volume_name
        The name of the Block Storage volume.

Notes:
  * Two environment variables can be used, DO_API_KEY and DO_API_TOKEN. They both refer to the v2 token.
EXAMPLES:
# Create new Block Storage
- digital_ocean_block_storage:
    state: present
    command: create
    api_token: <TOKEN>
    region: nyc1
    block_size: 10
    volume_name: nyc1-block-storage
# Delete Block Storage
- digital_ocean_block_storage:
    state: absent
    command: create
    api_token: <TOKEN>
    region: nyc1
    volume_name: nyc1-block-storage
# Attach Block Storage to a Droplet
- digital_ocean_block_storage:
    state: present
    command: attach
    api_token: <TOKEN>
    volume_name: nyc1-block-storage
    region: nyc1
    droplet_id: <ID>
# Detach Block Storage from a Droplet
- digital_ocean_block_storage:
    state: absent
    command: attach
    api_token: <TOKEN>
    volume_name: nyc1-block-storage
    region: nyc1
    droplet_id: <ID>

RETURN VALUES:
id:
    description: Unique identifier of a Block Storage volume returned during creation.
    returned: changed
    type: string
    sample: "69b25d9a-494c-12e6-a5af-001f53126b44"


MAINTAINERS: Harnek Sidhu (github: @harneksidhu)

METADATA:
	Status: ['preview']
	Supported_by: community
> DIGITAL_OCEAN_DOMAIN    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/digital_ocean/digital_ocean_domain.py)

  Create/delete a DNS record in DigitalOcean.

Options (= is mandatory):

- api_token
        DigitalOcean api token.
        [Default: (null)]
- id
        Numeric, the droplet id you want to operate on.
        [Default: (null)]
- ip
        The IP address to point a domain at.
        [Default: (null)]
- name
        String, this is the name of the droplet - must be formatted by hostname rules, or the name of a SSH key, or the
        name of a domain.
        [Default: (null)]
- state
        Indicate desired state of the target.
        (Choices: present, absent)[Default: present]
Notes:
  * Two environment variables can be used, DO_API_KEY and DO_API_TOKEN. They both refer to the v2 token.
  * As of Ansible 1.9.5 and 2.0, Version 2 of the DigitalOcean API is used, this removes `client_id' and `api_key'
        options in favor of `api_token'.
  * If you are running Ansible 1.9.4 or earlier you might not be able to use the included version of this module as
        the API version used has been retired.
Requirements:  python >= 2.6, dopy

EXAMPLES:
# Create a domain record

- digital_ocean_domain:
    state: present
    name: my.digitalocean.domain
    ip: 127.0.0.1

# Create a droplet and a corresponding domain record

- digital_ocean:
    state: present
    name: test_droplet
    size_id: 1gb
    region_id: sgp1
    image_id: ubuntu-14-04-x64


  register: test_droplet

- digital_ocean_domain:
    state: present
    name: "{{ test_droplet.droplet.name }}.my.domain"
    ip: "{{ test_droplet.droplet.ip_address }}"



MAINTAINERS: Michael Gregson (@mgregson)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> DIGITAL_OCEAN_SSHKEY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/digital_ocean/digital_ocean_sshkey.py)

  Create/delete an SSH key.

Options (= is mandatory):

- api_key
        DigitalOcean api key.
        [Default: (null)]
- client_id
        DigitalOcean manager id.
        [Default: (null)]
- id
        Numeric, the SSH key id you want to operate on.
        [Default: (null)]
- name
        String, this is the name of an SSH key to create or destroy.
        [Default: (null)]
- ssh_pub_key
        The public SSH key you want to add to your account.
        [Default: (null)]
- state
        Indicate desired state of the target.
        (Choices: present, absent)[Default: present]
Notes:
  * Two environment variables can be used, DO_CLIENT_ID and DO_API_KEY.
  * Version 1 of DigitalOcean API is used.
Requirements:  python >= 2.6, dopy

EXAMPLES:
# Ensure a SSH key is present
# If a key matches this name, will return the ssh key id and changed = False
# If no existing key matches this name, a new key is created, the ssh key id is returned and changed = False

- digital_ocean_sshkey:
    state: present
    name: my_ssh_key
    ssh_pub_key: 'ssh-rsa AAAA...'
    client_id: XXX
    api_key: XXX



MAINTAINERS: Michael Gregson (@mgregson)

METADATA:
	Status: ['preview']
	Supported_by: community
> DIGITAL_OCEAN_TAG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/digital_ocean/digital_ocean_tag.py)

  Create and remove tag(s) to DigitalOcean resource.

Options (= is mandatory):

- api_token
        DigitalOcean api token.
        [Default: (null)]
= name
        The name of the tag. The supported characters for names include alphanumeric characters, dashes, and underscores.

- resource_id
        The ID of the resource to operate on.
        [Default: (null)]
- resource_type
        The type of resource to operate on. Currently only tagging of droplets is supported.
        (Choices: droplet)[Default: droplet]
- state
        Whether the tag should be present or absent on the resource.
        (Choices: present, absent)[Default: present]
Notes:
  * Two environment variables can be used, DO_API_KEY and DO_API_TOKEN. They both refer to the v2 token.
  * As of Ansible 2.0, Version 2 of the DigitalOcean API is used.
Requirements:  python >= 2.6

EXAMPLES:
- name: create a tag
  digital_ocean_tag:
    name: production
    state: present

- name: tag a resource; creating the tag if it does not exists
  digital_ocean_tag:
    name: "{{ item }}"
    resource_id: YYY
    state: present
  with_items:
    - staging
    - dbserver

- name: untag a resource
  digital_ocean_tag:
    name: staging
    resource_id: YYY
    state: absent

# Deleting a tag also untags all the resources that have previously been
# tagged with it
- name: remove a tag
  digital_ocean_tag:
    name: dbserver
    state: absent

RETURN VALUES:
data:
    description: a DigitalOcean Tag resource
    returned: success and no resource constraint
    type: dict
    sample: {
        "tag": {
        "name": "awesome",
        "resources": {
          "droplets": {
            "count": 0,
            "last_tagged": null
          }
        }
      }
    }


MAINTAINERS: Victor Volle (@kontrafiktion)

METADATA:
	Status: ['preview']
	Supported_by: community
> DIMENSIONDATA_NETWORK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/dimensiondata/dimensiondata_network.py)

  Create, update, and delete MCP 1.0 & 2.0 networks

Options (= is mandatory):

- description
        Additional description of the network domain.
        [Default: (null)]
= location
        The target datacenter.

- mcp_password
        The password used to authenticate to the CloudControl API.
        If not specified, will fall back to `MCP_PASSWORD' from environment variable or `~/.dimensiondata'.
        Required if `mcp_user' is specified.
        [Default: (null)]
- mcp_user
        The username used to authenticate to the CloudControl API.
        If not specified, will fall back to `MCP_USER' from environment variable or `~/.dimensiondata'.
        [Default: (null)]
= name
        The name of the network domain to create.

- region
        The target region.
        (Choices: Regions are defined in Apache libcloud project [libcloud/common/dimensiondata.py], They are also listed
        in https://libcloud.readthedocs.io/en/latest/compute/drivers/dimensiondata.html, Note that the default value "na"
        stands for "North America"., The module prepends 'dd-' to the region choice.)[Default: na]
- service_plan
        The service plan, either “ESSENTIALS” or “ADVANCED”.
        MCP 2.0 Only.
        (Choices: ESSENTIALS, ADVANCED)[Default: ESSENTIALS]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- validate_certs
        If `false', SSL certificates will not be validated.
        This should only be used on private instances of the CloudControl API that use self-signed certificates.
        [Default: True]
- wait
        Should we wait for the task to complete before moving onto the next.
        [Default: False]
- wait_poll_interval
        The amount of time (in seconds) to wait between checks for task completion.
        Only applicable if `wait=true'.
        [Default: 2]
- wait_time
        The maximum amount of time (in seconds) to wait for the task to complete.
        Only applicable if `wait=true'.
        [Default: 600]
EXAMPLES:
# Create an MCP 1.0 network
- dimensiondata_network:
    region: na
    location: NA5
    name: mynet
# Create an MCP 2.0 network
- dimensiondata_network:
    region: na
    mcp_user: my_user
    mcp_password: my_password
    location: NA9
    name: mynet
    service_plan: ADVANCED
# Delete a network
- dimensiondata_network:
    region: na
    location: NA1
    name: mynet
    state: absent

RETURN VALUES:
network:
    description: Dictionary describing the network.
    returned: On success when I(state=present).
    type: dictionary
    contains:
        id:
            description: Network ID.
            type: string
            sample: "8c787000-a000-4050-a215-280893411a7d"
        name:
            description: Network name.
            type: string
            sample: "My network"
        description:
            description: Network description.
            type: string
            sample: "My network description"
        location:
            description: Datacenter location.
            type: string
            sample: NA3
        status:
            description: Network status. (MCP 2.0 only)
            type: string
            sample: NORMAL
        private_net:
            description: Private network subnet. (MCP 1.0 only)
            type: string
            sample: "10.2.3.0"
        multicast:
            description: Multicast enabled? (MCP 1.0 only)
            type: boolean
            sample: false


MAINTAINERS: Aimon Bustardo (@aimonb)

METADATA:
	Status: ['preview']
	Supported_by: community
> DJANGO_MANAGE    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/django_manage.py)

  Manages a Django application using the `manage.py' application frontend to `django-admin'. With the `virtualenv'
  parameter, all management commands will be executed by the given `virtualenv' installation.

Options (= is mandatory):

= app_path
        The path to the root of the Django application where *manage.py* lives.

- apps
        A list of space-delimited apps to target. Used by the 'test' command.
        [Default: (null)]
- cache_table
        The name of the table used for database-backed caching. Used by the 'createcachetable' command.
        [Default: (null)]
= command
        The name of the Django management command to run. Built in commands are cleanup, collectstatic, flush, loaddata,
        migrate, runfcgi, syncdb, test, and validate.
        Other commands can be entered, but will fail if they're unknown to Django.  Other commands that may prompt for
        user input should be run with the `--noinput' flag.
        (Choices: cleanup, collectstatic, flush, loaddata, migrate, runfcgi, syncdb, test, validate)
- database
        The database to target. Used by the 'createcachetable', 'flush', 'loaddata', and 'syncdb' commands.
        [Default: (null)]
- failfast
        Fail the command immediately if a test fails. Used by the 'test' command.
        (Choices: yes, no)[Default: no]
- fixtures
        A space-delimited list of fixture file names to load in the database. *Required* by the 'loaddata' command.
        [Default: (null)]
- link
        Will create links to the files instead of copying them, you can only use this parameter with 'collectstatic'
        command
        [Default: (null)]
- merge
        Will run out-of-order or missing migrations as they are not rollback migrations, you can only use this parameter
        with 'migrate' command
        [Default: (null)]
- pythonpath
        A directory to add to the Python path. Typically used to include the settings module if it is located external to
        the application directory.
        [Default: (null)]
- settings
        The Python path to the application's settings module, such as 'myapp.settings'.
        [Default: (null)]
- skip
        Will skip over out-of-order missing migrations, you can only use this parameter with `migrate'
        [Default: (null)]
- virtualenv
        An optional path to a `virtualenv' installation to use while running the manage application.
        [Default: (null)]
Notes:
  * `virtualenv' (http://www.virtualenv.org) must be installed on the remote host if the virtualenv parameter is
        specified.
  * This module will create a virtualenv if the virtualenv parameter is specified and a virtualenv does not already
        exist at the given location.
  * This module assumes English error messages for the 'createcachetable' command to detect table existence,
        unfortunately.
  * To be able to use the migrate command with django versions < 1.7, you must have south installed and added as an
        app in your settings.
  * To be able to use the collectstatic command, you must have enabled staticfiles in your settings.
  * As of ansible 2.x, your `manage.py' application must be executable (rwxr-xr-x), and must have a valid
        `shebang', i.e. "#!/usr/bin/env python", for invoking the appropriate Python interpreter.
Requirements:  virtualenv, django

EXAMPLES:
# Run cleanup on the application installed in 'django_dir'.
- django_manage:
    command: cleanup
    app_path: "{{ django_dir }}"

# Load the initial_data fixture into the application
- django_manage:
    command: loaddata
    app_path: "{{ django_dir }}"
    fixtures: "{{ initial_data }}"

# Run syncdb on the application
- django_manage:
    command: syncdb
    app_path: "{{ django_dir }}"
    settings: "{{ settings_app_name }}"
    pythonpath: "{{ settings_dir }}"
    virtualenv: "{{ virtualenv_dir }}"

# Run the SmokeTest test case from the main app. Useful for testing deploys.
- django_manage:
    command: test
    app_path: "{{ django_dir }}"
    apps: main.SmokeTest

# Create an initial superuser.
- django_manage:
    command: "createsuperuser --noinput --username=admin --email=admin@example.com"
    app_path: "{{ django_dir }}"


MAINTAINERS: Scott Anderson (@tastychutney)

METADATA:
	Status: ['preview']
	Supported_by: community
> DLADM_ETHERSTUB    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/dladm_etherstub.py)

  Create or delete etherstubs on Solaris/illumos systems.

Options (= is mandatory):

= name
        Etherstub name.

- state
        Create or delete Solaris/illumos etherstub.
        (Choices: present, absent)[Default: present]
- temporary
        Specifies that the etherstub is temporary. Temporary etherstubs do not persist across reboots.
        (Choices: true, false)[Default: False]
EXAMPLES:
# Create 'stub0' etherstub
- dladm_etherstub:
    name: stub0
    state: present

# Remove 'stub0 etherstub
- dladm_etherstub:
    name: stub0
    state: absent

RETURN VALUES:
name:
    description: etherstub name
    returned: always
    type: string
    sample: "switch0"
state:
    description: state of the target
    returned: always
    type: string
    sample: "present"
temporary:
    description: etherstub's persistence
    returned: always
    type: boolean
    sample: "True"


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> DLADM_IPTUN    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/dladm_iptun.py)

  Manage IP tunnel interfaces on Solaris/illumos systems.

Options (= is mandatory):

- local_address
        Literat IP address or hostname corresponding to the tunnel source.
        [Default: (null)]
= name
        IP tunnel interface name.

- remote_address
        Literal IP address or hostname corresponding to the tunnel destination.
        [Default: (null)]
- state
        Create or delete Solaris/illumos VNIC.
        (Choices: present, absent)[Default: present]
- temporary
        Specifies that the IP tunnel interface is temporary. Temporary IP tunnel interfaces do not persist across
        reboots.
        [Default: False]
- type
        Specifies the type of tunnel to be created.
        (Choices: ipv4, ipv6, 6to4)[Default: ipv4]
EXAMPLES:
name: Create IPv4 tunnel interface 'iptun0'
dladm_iptun: name=iptun0 local_address=192.0.2.23 remote_address=203.0.113.10 state=present

name: Change IPv4 tunnel remote address
dladm_iptun: name=iptun0 type=ipv4 local_address=192.0.2.23 remote_address=203.0.113.11

name: Create IPv6 tunnel interface 'tun0'
dladm_iptun: name=tun0 type=ipv6 local_address=192.0.2.23 remote_address=203.0.113.42

name: Remove 'iptun0' tunnel interface
dladm_iptun: name=iptun0 state=absent

RETURN VALUES:
name:
    description: tunnel interface name
    returned: always
    type: string
    sample: iptun0
state:
    description: state of the target
    returned: always
    type: string
    sample: present
temporary:
    description: specifies if operation will persist across reboots
    returned: always
    type: boolean
    sample: True
local_address:
    description: local IP address
    returned: always
    type: string
    sample: 1.1.1.1/32
remote_address:
    description: remote IP address
    returned: always
    type: string
    sample: 2.2.2.2/32
type:
    description: tunnel type
    returned: always
    type: string
    sample: ipv4


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> DLADM_LINKPROP    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/dladm_linkprop.py)

  Set / reset link properties on Solaris/illumos systems.

Options (= is mandatory):

= link
        Link interface name.

= property
        Specifies the name of the property we want to manage.

- state
        Set or reset the property value.
        (Choices: present, absent, reset)[Default: present]
- temporary
        Specifies that lin property configuration is temporary. Temporary link property configuration does not persist
        across reboots.
        [Default: False]
- value
        Specifies the value we want to set for the link property.
        [Default: (null)]
EXAMPLES:
name: Set 'maxbw' to 100M on e1000g1
dladm_linkprop: name=e1000g1 property=maxbw value=100M state=present

name: Set 'mtu' to 9000 on e1000g1
dladm_linkprop: name=e1000g1 property=mtu value=9000

name: Reset 'mtu' property on e1000g1
dladm_linkprop: name=e1000g1 property=mtu state=reset

RETURN VALUES:
property:
    description: property name
    returned: always
    type: string
    sample: mtu
state:
    description: state of the target
    returned: always
    type: string
    sample: present
temporary:
    description: specifies if operation will persist across reboots
    returned: always
    type: boolean
    sample: True
link:
    description: link name
    returned: always
    type: string
    sample: e100g0
value:
    description: property value
    returned: always
    type: string
    sample: 9000


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> DLADM_VLAN    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/dladm_vlan.py)

  Create or delete VLAN interfaces on Solaris/illumos systems.

Options (= is mandatory):

= link
        VLAN underlying link name.

= name
        VLAN interface name.

- state
        Create or delete Solaris/illumos VNIC.
        (Choices: present, absent)[Default: present]
- temporary
        Specifies that the VLAN interface is temporary. Temporary VLANs do not persist across reboots.
        [Default: False]
- vlan_id
        VLAN ID value for VLAN interface.
        [Default: False]
EXAMPLES:
name: Create 'vlan42' VLAN over 'bnx0' link
dladm_vlan: name=vlan42 link=bnx0 vlan_id=42 state=present

name: Remove 'vlan1337' VLAN interface
dladm_vlan: name=vlan1337 state=absent

RETURN VALUES:
name:
    description: VLAN name
    returned: always
    type: string
    sample: vlan42
state:
    description: state of the target
    returned: always
    type: string
    sample: present
temporary:
    description: specifies if operation will persist across reboots
    returned: always
    type: boolean
    sample: True
link:
    description: VLAN's underlying link name
    returned: always
    type: string
    sample: e100g0
vlan_id:
    description: VLAN ID
    returned: always
    type: string
    sample: 42


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> DLADM_VNIC    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/dladm_vnic.py)

  Create or delete VNICs on Solaris/illumos systems.

Options (= is mandatory):

= link
        VNIC underlying link name.

- mac
        Sets the VNIC's MAC address. Must be valid unicast MAC address.
        [Default: False]
= name
        VNIC name.

- state
        Create or delete Solaris/illumos VNIC.
        (Choices: present, absent)[Default: present]
- temporary
        Specifies that the VNIC is temporary. Temporary VNICs do not persist across reboots.
        (Choices: true, false)[Default: False]
- vlan
        Enable VLAN tagging for this VNIC. The VLAN tag will have id `vlan'.
        [Default: False]
EXAMPLES:
# Create 'vnic0' VNIC over 'bnx0' link
- dladm_vnic:
    name: vnic0
    link: bnx0
    state: present

# Create VNIC with specified MAC and VLAN tag over 'aggr0'
- dladm_vnic:
    name: vnic1
    link: aggr0
    mac: '00:00:5E:00:53:23'
    vlan: 4

# Remove 'vnic0' VNIC
- dladm_vnic:
    name: vnic0
    link: bnx0
    state: absent

RETURN VALUES:
name:
    description: VNIC name
    returned: always
    type: string
    sample: "vnic0"
link:
    description: VNIC underlying link name
    returned: always
    type: string
    sample: "igb0"
state:
    description: state of the target
    returned: always
    type: string
    sample: "present"
temporary:
    description: VNIC's persistence
    returned: always
    type: boolean
    sample: "True"
mac:
    description: MAC address to use for VNIC
    returned: if mac is specified
    type: string
    sample: "00:00:5E:00:53:42"
vlan:
    description: VLAN to use for VNIC
    returned: success
    type: int
    sample: 42


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> DNF    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/dnf.py)

  Installs, upgrade, removes, and lists packages and groups with the `dnf' package manager.

Options (= is mandatory):

- conf_file
        The remote dnf configuration file to use for the transaction.
        [Default: None]
- disable_gpg_check
        Whether to disable the GPG checking of signatures of packages being installed. Has an effect only if state is
        `present' or `latest'.
        (Choices: yes, no)[Default: no]
- disablerepo
        `Repoid' of repositories to disable for the install/update operation. These repos will not persist beyond the
        transaction. When specifying multiple repos, separate them with a ",".
        [Default: None]
- enablerepo
        `Repoid' of repositories to enable for the install/update operation. These repos will not persist beyond the
        transaction. When specifying multiple repos, separate them with a ",".
        [Default: None]
- installroot
        Specifies an alternative installroot, relative to which all packages will be installed.
        [Default: /]
- list
        Various (non-idempotent) commands for usage with `/usr/bin/ansible' and `not' playbooks. See examples.
        [Default: None]
= name
        Package name, or package specifier with version, like `name-1.0'. When using state=latest, this can be '*' which
        means run: dnf -y update. You can also pass a url or a local path to a rpm file.
        [Default: None]
- state
        Whether to install (`present', `latest'), or remove (`absent') a package.
        (Choices: present, latest, absent)[Default: present]
Requirements:  python >= 2.6, python-dnf

EXAMPLES:
- name: install the latest version of Apache
  dnf:
    name: httpd
    state: latest

- name: remove the Apache package
  dnf:
    name: httpd
    state: absent

- name: install the latest version of Apache from the testing repo
  dnf:
    name: httpd
    enablerepo: testing
    state: present

- name: upgrade all packages
  dnf:
    name: "*"
    state: latest

- name: install the nginx rpm from a remote repo
  dnf:
    name: 'http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm'
    state: present

- name: install nginx rpm from a local file
  dnf:
    name: /usr/local/src/nginx-release-centos-6-0.el6.ngx.noarch.rpm
    state: present

- name: install the 'Development tools' package group
  dnf:
    name: '@Development tools'
    state: present


MAINTAINERS: "Igor Gnatenko (@ignatenkobrain)" <i.gnatenko.brain@gmail.com>, Berend De Schouwer (github.com/berenddeschouwer), "Cristian van Ee (@DJMuggs)" <cristian at cvee.org>

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> DNSIMPLE    (/usr/lib/python2.7/site-packages/ansible/modules/network/dnsimple.py)

  Manages domains and records via the DNSimple API, see the docs: http://developer.dnsimple.com/

Options (= is mandatory):

- account_api_token
        Account API token. See `account_email' for info.
        [Default: None]
- account_email
        Account email. If omitted, the env variables DNSIMPLE_EMAIL and DNSIMPLE_API_TOKEN will be looked for. If those
        aren't found, a `.dnsimple' file will be looked for, see: https://github.com/mikemaccana/dnsimple-python#getting-
        started
        [Default: None]
- domain
        Domain to work with. Can be the domain name (e.g. "mydomain.com") or the numeric ID of the domain in DNSimple. If
        omitted, a list of domains will be returned.
        If domain is present but the domain doesn't exist, it will be created.
        [Default: None]
- priority
        Record priority
        [Default: None]
- record
        Record to add, if blank a record for the domain will be created, supports the wildcard (*)
        [Default: None]
- record_ids
        List of records to ensure they either exist or don't exist
        [Default: None]
- solo
        Whether the record should be the only one for that record type and record name. Only use with state=present on a
        record
        [Default: None]
- state
        whether the record should exist or not
        (Choices: present, absent)[Default: None]
- ttl
        The TTL to give the new record
        [Default: 3600 (one hour)]
- type
        The type of DNS record to create
        (Choices: A, ALIAS, CNAME, MX, SPF, URL, TXT, NS, SRV, NAPTR, PTR, AAAA, SSHFP, HINFO, POOL)[Default: None]
- value
        Record value
        Must be specified when trying to ensure a record exists
        [Default: None]
Requirements:  dnsimple

EXAMPLES:
# authenticate using email and API token and fetch all domains
- dnsimple:
    account_email: test@example.com
    account_api_token: dummyapitoken
  delegate_to: localhost

# fetch my.com domain records
- dnsimple:
    domain: my.com
    state: present
  delegate_to: localhost
  register: records

# delete a domain
- dnsimple:
    domain: my.com
    state: absent
  delegate_to: localhost

# create a test.my.com A record to point to 127.0.0.01
- dnsimple:
    domain: my.com
    record: test
    type: A
    value: 127.0.0.1
  delegate_to: localhost
  register: record

# and then delete it
- dnsimple:
    domain: my.com
    record_ids: '{{ record["id"] }}'
  delegate_to: localhost

# create a my.com CNAME record to example.com
- dnsimple:
    domain: my.com
    record: ''
    type: CNAME
    value: example.com
    state: present
  delegate_to: localhost

# change it's ttl
- dnsimple:
    domain: my.com
    record: ''
    type: CNAME
    value: example.com
    ttl: 600
    state: present
  delegate_to: localhost

# and delete the record
- dnsimple:
    domain: my.com
    record: ''
    type: CNAME
    value: example.com
    state: absent
  delegate_to: localhost


MAINTAINERS: Alex Coomans (@drcapulet)

METADATA:
	Status: ['preview']
	Supported_by: community
> DNSMADEEASY    (/usr/lib/python2.7/site-packages/ansible/modules/network/dnsmadeeasy.py)

  Manages DNS records via the v2 REST API of the DNS Made Easy service.  It handles records only; there is no
  manipulation of domains or monitor/account support yet. See: https://www.dnsmadeeasy.com/integration/restapi/

Options (= is mandatory):

= account_key
        Account API Key.
        [Default: None]
= account_secret
        Account Secret Key.
        [Default: None]
= domain
        Domain to work with. Can be the domain name (e.g. "mydomain.com") or the numeric ID of the domain in DNS Made
        Easy (e.g. "839989") for faster resolution.
        [Default: None]
- record_name
        Record name to get/create/delete/update. If record_name is not specified; all records for the domain will be
        returned in "result" regardless of the state argument.
        [Default: None]
- record_ttl
        record's "Time to live".  Number of seconds the record remains cached in DNS servers.
        [Default: 1800]
- record_type
        Record type.
        (Choices: A, AAAA, CNAME, HTTPRED, MX, NS, PTR, SRV, TXT)[Default: None]
- record_value
        Record value. HTTPRED: <redirection URL>, MX: <priority> <target name>, NS: <name server>, PTR: <target name>,
        SRV: <priority> <weight> <port> <target name>, TXT: <text value>
        If record_value is not specified; no changes will be made and the record will be returned in 'result' (in other
        words, this module can be used to fetch a record's current id, type, and ttl)
        [Default: None]
= state
        whether the record should exist or not
        (Choices: present, absent)[Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
Notes:
  * The DNS Made Easy service requires that machines interacting with the API have the proper time and timezone
        set. Be sure you are within a few seconds of actual time by using NTP.
  * This module returns record(s) in the "result" element when 'state' is set to 'present'. This value can be be
        registered and used in your playbooks.
Requirements:  hashlib, hmac

EXAMPLES:
# fetch my.com domain records
- dnsmadeeasy:
    account_key: key
    account_secret: secret
    domain: my.com
    state: present
  register: response

# create / ensure the presence of a record
- dnsmadeeasy:
    account_key: key
    account_secret: secret
    domain: my.com
    state: present
    record_name: test
    record_type: A
    record_value: 127.0.0.1

# update the previously created record
- dnsmadeeasy:
    account_key: key
    account_secret: secret
    domain: my.com
    state: present
    record_name: test
    record_value: 192.0.2.23

# fetch a specific record
- dnsmadeeasy:
    account_key: key
    account_secret: secret
    domain: my.com
    state: present
    record_name: test
  register: response

# delete a record / ensure it is absent
- dnsmadeeasy:
    account_key: key
    account_secret: secret
    domain: my.com
    state: absent
    record_name: test


MAINTAINERS: Brice Burgess (@briceburg)

METADATA:
	Status: ['preview']
	Supported_by: community
> DOCKER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/docker/_docker.py)

  This is the original Ansible module for managing the Docker container life cycle. NOTE: Additional and newer modules
  are available. For the latest on orchestrating containers with Ansible visit our Getting Started with Docker Guide at
  https://github.com/ansible/ansible/blob/devel/docsite/rst/guide_docker.rst.

DEPRECATED: 
In 2.2 use M(docker_container) and M(docker_image) instead.

Options (= is mandatory):

- cap_add
        Add capabilities for the container. Requires docker-py >= 0.5.0.
        [Default: False]
- cap_drop
        Drop capabilities for the container. Requires docker-py >= 0.5.0.
        [Default: False]
- command
        Command used to match and launch containers.
        [Default: None]
- count
        Number of matching containers that should be in the desired state.
        [Default: 1]
- cpu_set
        CPUs in which to allow execution. Requires docker-py >= 0.6.0.
        [Default: None]
- cpu_shares
        CPU shares (relative weight). Requires docker-py >= 0.6.0.
        [Default: 0]
- detach
        Enable detached mode to leave the container running in background. If disabled, fail unless the process exits
        cleanly.
        [Default: True]
- devices
        List of host devices to expose to container
        [Default: None]
- dns
        List of custom DNS servers for the container.
        [Default: None]
- docker_api_version
        Remote API version to use. This defaults to the current default as specified by docker-py.
        [Default: docker-py default remote API version]
- docker_url
        URL of the host running the docker daemon. This will default to the env var DOCKER_HOST if unspecified.
        [Default: ${DOCKER_HOST} or unix://var/run/docker.sock]
- docker_user
        Username or UID to use within the container
        [Default: None]
- domainname
        Container domain name.
        [Default: None]
- email
        Remote API email.
        [Default: None]
- entrypoint
        Corresponds to ``--entrypoint`` option of ``docker run`` command and ``ENTRYPOINT`` directive of Dockerfile. Used
        to match and launch containers.
        [Default: None]
- env
        Pass a dict of environment variables to the container.
        [Default: None]
- env_file
        Pass in a path to a file with environment variable (FOO=BAR). If a key value is present in both explicitly
        presented (i.e. as 'env') and in the environment file, the explicit value will override. Requires docker-py >=
        1.4.0.
        [Default: None]
- expose
        List of additional container ports to expose for port mappings or links. If the port is already exposed using
        EXPOSE in a Dockerfile, you don't need to expose it again.
        [Default: None]
- extra_hosts
        Dict of custom host-to-IP mappings to be defined in the container
        [Default: (null)]
- hostname
        Container hostname.
        [Default: None]
= image
        Container image used to match and launch containers.

- insecure_registry
        Use insecure private registry by HTTP instead of HTTPS. Needed for docker-py >= 0.5.0.
        [Default: False]
- labels
        Set container labels. Requires docker >= 1.6 and docker-py >= 1.2.0.
        [Default: None]
- links
        List of other containers to link within this container with an optional
        alias. Use docker CLI-style syntax: `redis:myredis'.
        [Default: None]
- log_driver
        You can specify a different logging driver for the container than for the daemon. "json-file" Default logging
        driver for Docker. Writes JSON messages to file. docker logs command is available only for this logging driver.
        "none" disables any logging for the container. "syslog" Syslog logging driver for Docker. Writes log messages to
        syslog. docker logs command is not available for this logging driver. "journald" Journald logging driver for
        Docker. Writes log messages to "journald". "gelf" Graylog Extended Log Format (GELF) logging driver for Docker.
        Writes log messages to a GELF endpoint likeGraylog or Logstash. "fluentd" Fluentd logging driver for Docker.
        Writes log messages to "fluentd" (forward input). "awslogs" (added in 2.1) Awslogs logging driver for Docker.
        Writes log messages to AWS Cloudwatch Logs. If not defined explicitly, the Docker daemon's default ("json-file")
        will apply. Requires docker >= 1.6.0.
        (Choices: json-file, none, syslog, journald, gelf, fluentd, awslogs)[Default: json-file]
- log_opt
        Additional options to pass to the logging driver selected above. See Docker `log-driver
        <https://docs.docker.com/reference/logging/overview/>` documentation for more information. Requires docker
        >=1.7.0.
        [Default: None]
- lxc_conf
        LXC configuration parameters, such as `lxc.aa_profile:unconfined'.
        [Default: None]
- memory_limit
        RAM allocated to the container as a number of bytes or as a human-readable string like "512MB". Leave as "0" to
        specify no limit.
        [Default: 0]
- name
        Name used to match and uniquely name launched containers. Explicit names are used to uniquely identify a single
        container or to link among containers. Mutually exclusive with a "count" other than "1".
        [Default: None]
- net
        Network mode for the launched container: bridge, none, container:<name|id>
        or host. Requires docker >= 0.11.
        [Default: False]
- password
        Remote API password.
        [Default: None]
- pid
        Set the PID namespace mode for the container (currently only supports 'host'). Requires docker-py >= 1.0.0 and
        docker >= 1.5.0
        [Default: None]
- ports
        List containing private to public port mapping specification. Use docker 'CLI-style syntax: `8000', `9000:8000',
        or `0.0.0.0:9000:8000'' where 8000 is a container port, 9000 is a host port, and 0.0.0.0 is - a host interface.
        The container ports need to be exposed either in the Dockerfile or via the `expose' option.
        [Default: None]
- privileged
        Whether the container should run in privileged mode or not.
        [Default: False]
- publish_all_ports
        Publish all exposed ports to the host interfaces.
        [Default: False]
- pull
        Control when container images are updated from the `docker_url' registry. If "missing," images will be pulled
        only when missing from the host; if '"always," the registry will be checked for a newer version of the image'
        each time the task executes.
        (Choices: missing, always)[Default: missing]
- read_only
        Mount the container's root filesystem as read only
        [Default: None]
- registry
        Remote registry URL to pull images from.
        [Default: DockerHub]
- restart_policy
        Container restart policy.
        The 'unless-stopped' choice is only available starting in Ansible 2.1 and for Docker 1.9 and above.
        (Choices: no, on-failure, always, unless-stopped)[Default: None]
- restart_policy_retry
        Maximum number of times to restart a container. Leave as "0" for unlimited retries.
        [Default: 0]
- signal
        With the state "killed", you can alter the signal sent to the container.
        [Default: KILL]
- state
        Assert the container's desired state. "present" only asserts that the matching containers exist. "started"
        asserts that the matching containers both exist and are running, but takes no action if any configuration has
        changed. "reloaded" (added in Ansible 1.9) asserts that all matching containers are running and restarts any that
        have any images or configuration out of date. "restarted" unconditionally restarts (or starts) the matching
        containers. "stopped" and '"killed" stop and kill all matching containers. "absent" stops and then' removes any
        matching containers.
        (Choices: present, started, reloaded, restarted, stopped, killed, absent)[Default: started]
- stdin_open
        Keep stdin open after a container is launched.
        [Default: False]
- stop_timeout
        How many seconds to wait for the container to stop before killing it.
        [Default: 10]
- timeout
        Docker daemon response timeout in seconds.
        [Default: 60]
- tls_ca_cert
        Path to a PEM-encoded certificate authority to secure the Docker connection. This has no effect if use_tls is
        encrypt.
        [Default: ${DOCKER_CERT_PATH}/ca.pem]
- tls_client_cert
        Path to the PEM-encoded certificate used to authenticate docker client. If specified tls_client_key must be valid
        [Default: ${DOCKER_CERT_PATH}/cert.pem]
- tls_client_key
        Path to the PEM-encoded key used to authenticate docker client. If specified tls_client_cert must be valid
        [Default: ${DOCKER_CERT_PATH}/key.pem]
- tls_hostname
        A hostname to check matches what's supplied in the docker server's certificate.  If unspecified, the hostname is
        taken from the docker_url.
        [Default: Taken from docker_url]
- tty
        Allocate a pseudo-tty within the container.
        [Default: False]
- ulimits
        ulimits, list ulimits with name, soft and optionally hard limit separated by colons. e.g. nofile:1024:2048
        Requires docker-py >= 1.2.0 and docker >= 1.6.0
        [Default: None]
- use_tls
        Whether to use tls to connect to the docker server.  "no" means not to use tls (and ignore any other tls related
        parameters). "encrypt" means to use tls to encrypt the connection to the server.  "verify" means to also verify
        that the server's certificate is valid for the server (this both verifies the certificate against the CA and that
        the certificate was issued for that host. If this is unspecified, tls will only be used if one of the other tls
        options require it.
        (Choices: no, encrypt, verify)[Default: (null)]
- username
        Remote API username.
        [Default: None]
- volumes
        List of volumes to mount within the container
        Use docker CLI-style syntax: `/host:/container[:mode]'
        You can specify a read mode for the mount with either `ro' or `rw'. Starting at version 2.1, SELinux hosts can
        additionally use `z' or `Z' mount options to use a shared or private label for the volume.
        [Default: None]
- volumes_from
        List of names of containers to mount volumes from.
        [Default: None]
Requirements:  python >= 2.6, docker-py >= 0.3.0, The docker server >= 0.10.0

EXAMPLES:
# Containers are matched either by name (if provided) or by an exact match of
# the image they were launched with and the command they're running. The module
# can accept either a name to target a container uniquely, or a count to operate
# on multiple containers at once when it makes sense to do so.

# Ensure that a data container with the name "mydata" exists. If no container
# by this name exists, it will be created, but not started.

- name: data container
  docker:
    name: mydata
    image: busybox
    state: present
    volumes:
    - /data

# Ensure that a Redis server is running, using the volume from the data
# container. Expose the default Redis port.

- name: redis container
  docker:
    name: myredis
    image: redis
    command: redis-server --appendonly yes
    state: started
    expose:
    - 6379
    volumes_from:
    - mydata

# Ensure that a container of your application server is running. This will:
# - pull the latest version of your application image from DockerHub.
# - ensure that a container is running with the specified name and exact image.
#   If any configuration options have changed, the existing container will be
#   stopped and removed, and a new one will be launched in its place.
# - link this container to the existing redis container launched above with
#   an alias.
# - grant the container read write permissions for the host's /dev/sda device
#   through a node named /dev/xvda
# - bind TCP port 9000 within the container to port 8080 on all interfaces
#   on the host.
# - bind UDP port 9001 within the container to port 8081 on the host, only
#   listening on localhost.
# - specify 2 ip resolutions.
# - set the environment variable SECRET_KEY to "ssssh".

- name: application container
  docker:
    name: myapplication
    image: someuser/appimage
    state: reloaded
    pull: always
    links:
    - "myredis:aliasedredis"
    devices:
    - "/dev/sda:/dev/xvda:rwm"
    ports:
    - "8080:9000"
    - "127.0.0.1:8081:9001/udp"
    extra_hosts:
      host1: "192.168.0.1"
      host2: "192.168.0.2"
    env:
        SECRET_KEY: ssssh

# Ensure that exactly five containers of another server are running with this
# exact image and command. If fewer than five are running, more will be launched;
# if more are running, the excess will be stopped.

- name: load-balanced containers
  docker:
    state: reloaded
    count: 5
    image: someuser/anotherappimage
    command: sleep 1d

# Unconditionally restart a service container. This may be useful within a
# handler, for example.

- name: application service
  docker:
    name: myservice
    image: someuser/serviceimage
    state: restarted

# Stop all containers running the specified image.

- name: obsolete container
  docker:
    image: someuser/oldandbusted
    state: stopped

# Stop and remove a container with the specified name.

- name: obsolete container
  docker:
    name: ohno
    image: someuser/oldandbusted
    state: absent

# Example Syslogging Output

- name: myservice container
  docker:
    name: myservice
    image: someservice/someimage
    state: reloaded
    log_driver: syslog
    log_opt:
      syslog-address: tcp://my-syslog-server:514
      syslog-facility: daemon
      syslog-tag: myservice


MAINTAINERS: Thomas Steinbach (@ThomasSteinbach), Cove Schneider (@cove), Philippe Jandot (@zfil), Pavel Antonov (@softzilla), Joshua Conner (@joshuaconner), Daan Oosterveld (@dusdanig)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> DOCKER_CONTAINER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/docker/docker_container.py)

  Manage the life cycle of docker containers. Supports check mode. Run with --check and --diff to view config difference
  and list of actions to be taken.

Options (= is mandatory):

- api_version
        The version of the Docker API running on the Docker Host. Defaults to the latest version of the API supported by
        docker-py.
        [Default: default provided by docker-py]
- blkio_weight
        Block IO (relative weight), between 10 and 1000.
        [Default: None]
- cacert_path
        Use a CA certificate when performing server verification by providing the path to a CA certificate file.
        [Default: None]
- capabilities
        List of capabilities to add to the container.
        [Default: None]
- cert_path
        Path to the client's TLS certificate file.
        [Default: None]
- cleanup
        Use with `detach' to remove the container after successful execution.
        [Default: False]
- command
        Command to execute when the container starts.
        [Default: None]
- cpu_period
        Limit CPU CFS (Completely Fair Scheduler) period
        [Default: 0]
- cpu_quota
        Limit CPU CFS (Completely Fair Scheduler) quota
        [Default: 0]
- cpu_shares
        CPU shares (relative weight).
        [Default: None]
- cpuset_cpus
        CPUs in which to allow execution `1,3' or `1-3'.
        [Default: None]
- cpuset_mems
        Memory nodes (MEMs) in which to allow execution `0-3' or `0,1'
        [Default: None]
- detach
        Enable detached mode to leave the container running in background. If disabled, the task will reflect the status
        of the container run (failed if the command failed).
        [Default: True]
- devices
        List of host device bindings to add to the container. Each binding is a mapping expressed in the format:
        <path_on_host>:<path_in_container>:<cgroup_permissions>
        [Default: None]
- dns_search_domains
        List of custom DNS search domains.
        [Default: None]
- dns_servers
        List of custom DNS servers.
        [Default: None]
- docker_host
        The URL or Unix socket path used to connect to the Docker API. To connect to a remote host, provide the TCP
        connection string. For example, 'tcp://192.0.2.23:2376'. If TLS is used to encrypt the connection, the module
        will automatically replace 'tcp' in the connection URL with 'https'.
        [Default: unix://var/run/docker.sock]
- entrypoint
        Command that overwrites the default ENTRYPOINT of the image.
        [Default: None]
- env
        Dictionary of key,value pairs.
        [Default: None]
- env_file
        Path to a file containing environment variables `FOO=BAR'.
        If variable also present in `env', then `env' value will override.
        Requires docker-py >= 1.4.0.
        [Default: None]
- etc_hosts
        Dict of host-to-IP mappings, where each host name is a key in the dictionary. Each host name will be added to the
        container's /etc/hosts file.
        [Default: None]
- exposed_ports
        List of additional container ports which informs Docker that the container listens on the specified network ports
        at runtime. If the port is already exposed using EXPOSE in a Dockerfile, it does not need to be exposed again.
        [Default: None]
- force_kill
        Use the kill command when stopping a running container.
        [Default: False]
- groups
        List of additional group names and/or IDs that the container process will run as.
        [Default: None]
- hostname
        Container hostname.
        [Default: None]
- ignore_image
        When `state' is `present' or `started' the module compares the configuration of an existing container to
        requested configuration. The evaluation includes the image version. If the image version in the registry does not
        match the container, the container will be recreated. Stop this behavior by setting `ignore_image' to `True'.
        [Default: False]
- image
        Repository path and tag used to create the container. If an image is not found or pull is true, the image will be
        pulled from the registry. If no tag is included, 'latest' will be used.
        [Default: None]
- interactive
        Keep stdin open after a container is launched, even if not attached.
        [Default: False]
- ipc_mode
        Set the IPC mode for the container. Can be one of 'container:<name|id>' to reuse another container's IPC
        namespace or 'host' to use the host's IPC namespace within the container.
        [Default: None]
- keep_volumes
        Retain volumes associated with a removed container.
        [Default: True]
- kernel_memory
        Kernel memory limit (format: <number>[<unit>]). Number is a positive integer. Unit can be one of b, k, m, or g.
        Minimum is 4M.
        [Default: 0]
- key_path
        Path to the client's TLS key file.
        [Default: None]
- kill_signal
        Override default signal used to kill a running container.
        [Default: None]
- labels
        Dictionary of key value pairs.
        [Default: None]
- links
        List of name aliases for linked containers in the format `container_name:alias'
        [Default: None]
- log_driver
        Specify the logging driver. Docker uses json-file by default.
        (Choices: none, json-file, syslog, journald, gelf, fluentd, awslogs, splunk)[Default: None]
- log_options
        Dictionary of options specific to the chosen log_driver. See
        https://docs.docker.com/engine/admin/logging/overview/ for details.
        [Default: None]
- mac_address
        Container MAC address (e.g. 92:d0:c6:0a:29:33)
        [Default: None]
- memory
        Memory limit (format: <number>[<unit>]). Number is a positive integer. Unit can be one of b, k, m, or g
        [Default: 0]
- memory_reservation
        Memory soft limit (format: <number>[<unit>]). Number is a positive integer. Unit can be one of b, k, m, or g
        [Default: 0]
- memory_swap
        Total memory limit (memory + swap, format:<number>[<unit>]). Number is a positive integer. Unit can be one of b,
        k, m, or g.
        [Default: 0]
- memory_swappiness
        Tune a container's memory swappiness behavior. Accepts an integer between 0 and 100.
        [Default: 0]
= name
        Assign a name to a new container or match an existing container.
        When identifying an existing container name may be a name or a long or short container ID.

- network_mode
        Connect the container to a network.
        (Choices: bridge, container:<name|id>, host, none)[Default: None]
- networks
        List of networks the container belongs to.
        Each network is a dict with keys `name', `ipv4_address', `ipv6_address', `links', `aliases'.
        For each network `name' is required, all other keys are optional.
        If included, `links' or `aliases' are lists.
        For examples of the data structure and usage see EXAMPLES below.
        To remove a container from one or more networks, use the `purge_networks' option.
        [Default: None]
- oom_killer
        Whether or not to disable OOM Killer for the container.
        [Default: False]
- oom_score_adj
        An integer value containing the score given to the container in order to tune OOM killer preferences.
        [Default: 0]
- paused
        Use with the started state to pause running processes inside the container.
        [Default: False]
- pid_mode
        Set the PID namespace mode for the container. Currently only supports 'host'.
        [Default: None]
- privileged
        Give extended privileges to the container.
        [Default: False]
- published_ports
        List of ports to publish from the container to the host.
        Use docker CLI syntax: `8000', `9000:8000', or `0.0.0.0:9000:8000', where 8000 is a container port, 9000 is a
        host port, and 0.0.0.0 is a host interface.
        Container ports must be exposed either in the Dockerfile or via the `expose' option.
        A value of all will publish all exposed container ports to random host ports, ignoring any other mappings.
        If `networks' parameter is provided, will inspect each network to see if there exists a bridge network with
        optional parameter com.docker.network.bridge.host_binding_ipv4. If such a network is found, then published ports
        where no host IP address is specified will be bound to the host IP pointed to by
        com.docker.network.bridge.host_binding_ipv4. Note that the first bridge network with a
        com.docker.network.bridge.host_binding_ipv4 value encountered in the list of `networks' is the one that will be
        used.
        [Default: None]
- pull
        If true, always pull the latest version of an image. Otherwise, will only pull an image when missing.
        [Default: False]
- purge_networks
        Remove the container from ALL networks not included in `networks' parameter.
        Any default networks such as `bridge', if not found in `networks', will be removed as well.
        [Default: False]
- read_only
        Mount the container's root file system as read-only.
        [Default: False]
- recreate
        Use with present and started states to force the re-creation of an existing container.
        [Default: False]
- restart
        Use with started state to force a matching container to be stopped and restarted.
        [Default: False]
- restart_policy
        Container restart policy. Place quotes around `no' option.
        (Choices: always, False, on-failure, unless-stopped)[Default: on-failure]
- restart_retries
        Use with restart policy to control maximum number of restart attempts.
        [Default: 0]
- security_opts
        List of security options in the form of `"label:user:User"'
        [Default: None]
- shm_size
        Size of `/dev/shm`. The format is `<number><unit>`. `number` must be greater than `0`. Unit is optional and can
        be `b` (bytes), `k` (kilobytes), `m` (megabytes), or `g` (gigabytes).
        Omitting the unit defaults to bytes. If you omit the size entirely, the system uses `64m`.
        [Default: None]
- ssl_version
        Provide a valid SSL version number. Default value determined by docker-py, currently 1.0.
        [Default: 1.0]
- state
        `absent' - A container matching the specified name will be stopped and removed. Use force_kill to kill the
        container rather than stopping it. Use keep_volumes to retain volumes associated with the removed container.
        `present' - Asserts the existence of a container matching the name and any provided configuration parameters. If
        no container matches the name, a container will be created. If a container matches the name but the provided
        configuration does not match, the container will be updated, if it can be. If it cannot be updated, it will be
        removed and re-created with the requested config. Image version will be taken into account when comparing
        configuration. To ignore image version use the ignore_image option. Use the recreate option to force the re-
        creation of the matching container. Use force_kill to kill the container rather than stopping it. Use
        keep_volumes to retain volumes associated with a removed container.
        `started' - Asserts there is a running container matching the name and any provided configuration. If no
        container matches the name, a container will be created and started. If a container matching the name is found
        but the configuration does not match, the container will be updated, if it can be. If it cannot be updated, it
        will be removed and a new container will be created with the requested configuration and started. Image version
        will be taken into account when comparing configuration. To ignore image version use the ignore_image option. Use
        recreate to always re-create a matching container, even if it is running. Use restart to force a matching
        container to be stopped and restarted. Use force_kill to kill a container rather than stopping it. Use
        keep_volumes to retain volumes associated with a removed container.
        `stopped' - Asserts that the container is first `present', and then if the container is running moves it to a
        stopped state. Use force_kill to kill a container rather than stopping it.
        (Choices: absent, present, stopped, started)[Default: started]
- stop_signal
        Override default signal used to stop the container.
        [Default: None]
- stop_timeout
        Number of seconds to wait for the container to stop before sending SIGKILL.
        [Default: None]
- timeout
        The maximum amount of time in seconds to wait on a response from the API.
        [Default: 60]
- tls
        Secure the connection to the API by using TLS without verifying the authenticity of the Docker host server.
        [Default: False]
- tls_hostname
        When verifying the authenticity of the Docker Host server, provide the expected name of the server.
        [Default: localhost]
- tls_verify
        Secure the connection to the API by using TLS and verifying the authenticity of the Docker host server.
        [Default: False]
- trust_image_content
        If true, skip image verification.
        [Default: False]
- tty
        Allocate a psuedo-TTY.
        [Default: False]
- ulimits
        List of ulimit options. A ulimit is specified as `nofile:262144:262144'
        [Default: None]
- user
        Sets the username or UID used and optionally the groupname or GID for the specified command.
        Can be [ user | user:group | uid | uid:gid | user:gid | uid:group ]
        [Default: None]
- uts
        Set the UTS namespace mode for the container.
        [Default: None]
- volume_driver
        The container volume driver.
        [Default: none]
- volumes
        List of volumes to mount within the container.
        Use docker CLI-style syntax: `/host:/container[:mode]'
        You can specify a read mode for the mount with either `ro' or `rw'.
        SELinux hosts can additionally use `z' or `Z' to use a shared or private label for the volume.
        [Default: None]
- volumes_from
        List of container names or Ids to get volumes from.
        [Default: None]
Notes:
  * Connect to the Docker daemon by providing parameters with each task or by defining environment variables. You
        can define DOCKER_HOST, DOCKER_TLS_HOSTNAME, DOCKER_API_VERSION, DOCKER_CERT_PATH, DOCKER_SSL_VERSION,
        DOCKER_TLS, DOCKER_TLS_VERIFY and DOCKER_TIMEOUT. If you are using docker machine, run the script shipped
        with the product that sets up the environment. It will set these variables for you. See https://docker-
        py.readthedocs.org/en/stable/machine/ for more details.
Requirements:  python >= 2.6, docker-py >= 1.7.0, Docker API >= 1.20

EXAMPLES:
- name: Create a data container
  docker_container:
    name: mydata
    image: busybox
    volumes:
      - /data

- name: Re-create a redis container
  docker_container:
    name: myredis
    image: redis
    command: redis-server --appendonly yes
    state: present
    recreate: yes
    exposed_ports:
      - 6379
    volumes_from:
      - mydata

- name: Restart a container
  docker_container:
    name: myapplication
    image: someuser/appimage
    state: started
    restart: yes
    links:
     - "myredis:aliasedredis"
    devices:
     - "/dev/sda:/dev/xvda:rwm"
    ports:
     - "8080:9000"
     - "127.0.0.1:8081:9001/udp"
    env:
        SECRET_KEY: ssssh

- name: Container present
  docker_container:
    name: mycontainer
    state: present
    image: ubuntu:14.04
    command: sleep infinity

- name: Stop a container
  docker_container:
    name: mycontainer
    state: stopped

- name: Start 4 load-balanced containers
  docker_container:
    name: "container{{ item }}"
    recreate: yes
    image: someuser/anotherappimage
    command: sleep 1d
  with_sequence: count=4

- name: remove container
  docker_container:
    name: ohno
    state: absent

- name: Syslogging output
  docker_container:
    name: myservice
    image: busybox
    log_driver: syslog
    log_options:
      syslog-address: tcp://my-syslog-server:514
      syslog-facility: daemon
      # NOTE: in Docker 1.13+ the "syslog-tag" option was renamed to "tag" for
      # older docker installs, use "syslog-tag" instead
      tag: myservice

- name: Create db container and connect to network
  docker_container:
    name: db_test
    image: "postgres:latest"
    networks:
      - name: "{{ docker_network_name }}"

- name: Start container, connect to network and link
  docker_container:
    name: sleeper
    image: ubuntu:14.04
    networks:
      - name: TestingNet
        ipv4_address: "172.1.1.100"
        aliases:
          - sleepyzz
        links:
          - db_test:db
      - name: TestingNet2

- name: Start a container with a command
  docker_container:
    name: sleepy
    image: ubuntu:14.04
    command: ["sleep", "infinity"]

- name: Add container to networks
  docker_container:
    name: sleepy
    networks:
      - name: TestingNet
        ipv4_address: 172.1.1.18
        links:
          - sleeper
      - name: TestingNet2
        ipv4_address: 172.1.10.20

- name: Update network with aliases
  docker_container:
    name: sleepy
    networks:
      - name: TestingNet
        aliases:
          - sleepyz
          - zzzz

- name: Remove container from one network
  docker_container:
    name: sleepy
    networks:
      - name: TestingNet2
    purge_networks: yes

- name: Remove container from all networks
  docker_container:
    name: sleepy
    purge_networks: yes


RETURN VALUES:
docker_container:
    description:
      - Before 2.3 this was 'ansible_docker_container' but was renamed due to conflicts with the connection plugin.
      - Facts representing the current state of the container. Matches the docker inspection output.
      - Note that facts are not part of registered vars but accessible directly.
      - Empty if C(state) is I(absent)
      - If detached is I(False), will include Output attribute containing any output from container run.
    returned: always
    type: dict
    sample: '{
        "AppArmorProfile": "",
        "Args": [],
        "Config": {
            "AttachStderr": false,
            "AttachStdin": false,
            "AttachStdout": false,
            "Cmd": [
                "/usr/bin/supervisord"
            ],
            "Domainname": "",
            "Entrypoint": null,
            "Env": [
                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
            ],
            "ExposedPorts": {
                "443/tcp": {},
                "80/tcp": {}
            },
            "Hostname": "8e47bf643eb9",
            "Image": "lnmp_nginx:v1",
            "Labels": {},
            "OnBuild": null,
            "OpenStdin": false,
            "StdinOnce": false,
            "Tty": false,
            "User": "",
            "Volumes": {
                "/tmp/lnmp/nginx-sites/logs/": {}
            },
            ...
    }'


MAINTAINERS: Thomas Steinbach (@ThomasSteinbach), Cove Schneider (@cove), Philippe Jandot (@zfil), Pavel Antonov (@softzilla), Joshua Conner (@joshuaconner), Chris Houseknecht (@chouseknecht), Daan Oosterveld (@dusdanig), James Tanner (@jctanner)

METADATA:
	Status: ['preview']
	Supported_by: community
> DOCKER_IMAGE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/docker/docker_image.py)

  Build, load or pull an image, making the image available for creating containers. Also supports tagging an image into a
  repository and archiving an image to a .tar file.

Options (= is mandatory):

- api_version
        The version of the Docker API running on the Docker Host. Defaults to the latest version of the API supported by
        docker-py.
        [Default: default provided by docker-py]
- archive_path
        Use with state `present' to archive an image to a .tar file.
        [Default: (null)]
- buildargs
        Provide a dictionary of `key:value' build arguments that map to Dockerfile ARG directive.
        Docker expects the value to be a string. For convenience any non-string values will be converted to strings.
        Requires Docker API >= 1.21 and docker-py >= 1.7.0.
        [Default: (null)]
- cacert_path
        Use a CA certificate when performing server verification by providing the path to a CA certificate file.
        [Default: None]
- cert_path
        Path to the client's TLS certificate file.
        [Default: None]
- container_limits
        A dictionary of limits applied to each container created by the build process.
        [Default: (null)]
- docker_host
        The URL or Unix socket path used to connect to the Docker API. To connect to a remote host, provide the TCP
        connection string. For example, 'tcp://192.0.2.23:2376'. If TLS is used to encrypt the connection, the module
        will automatically replace 'tcp' in the connection URL with 'https'.
        [Default: unix://var/run/docker.sock]
- dockerfile
        Use with state `present' to provide an alternate name for the Dockerfile to use when building an image.
        [Default: Dockerfile]
- force
        Use with state `absent' to un-tag and remove all images matching the specified name. Use with state `present' to
        build, load or pull an image when the image already exists.
        [Default: False]
- http_timeout
        Timeout for HTTP requests during the image build operation. Provide a positive integer value for the number of
        seconds.
        [Default: (null)]
- key_path
        Path to the client's TLS key file.
        [Default: None]
- load_path
        Use with state `present' to load an image from a .tar file.
        [Default: (null)]
= name
        Image name. Name format will be one of: name, repository/name, registry_server:port/name. When pushing or pulling
        an image the name can optionally include the tag by appending ':tag_name'.

- nocache
        Do not use cache when building an image.
        [Default: False]
- path
        Use with state 'present' to build an image. Will be the path to a directory containing the context and Dockerfile
        for building an image.
        [Default: (null)]
- pull
        When building an image downloads any updates to the FROM image in Dockerfile.
        [Default: True]
- push
        Push the image to the registry. Specify the registry as part of the `name' or `repository' parameter.
        [Default: False]
- repository
        Full path to a repository. Use with state `present' to tag the image into the repository. Expects format
        `repository:tag'. If no tag is provided, will use the value of the `tag' parameter or `latest'.
        [Default: (null)]
- rm
        Remove intermediate containers after build.
        [Default: True]
- ssl_version
        Provide a valid SSL version number. Default value determined by docker-py, currently 1.0.
        [Default: 1.0]
- state
        Make assertions about the state of an image.
        When `absent' an image will be removed. Use the force option to un-tag and remove all images matching the
        provided name.
        When `present' check if an image exists using the provided name and tag. If the image is not found or the force
        option is used, the image will either be pulled, built or loaded. By default the image will be pulled from Docker
        Hub. To build the image, provide a path value set to a directory containing a context and Dockerfile. To load an
        image, specify load_path to provide a path to an archive file. To tag an image to a repository, provide a
        repository path. If the name contains a repository path, it will be pushed.
        NOTE: `build' is DEPRECATED and will be removed in release 2.3. Specifying `build' will behave the same as
        `present'.
        (Choices: absent, present, build)[Default: present]
- tag
        Used to select an image when pulling. Will be added to the image when pushing, tagging or building. Defaults to
        `latest'.
        If `name' parameter format is `name:tag', then tag value from `name' will take precedence.
        [Default: latest]
- timeout
        The maximum amount of time in seconds to wait on a response from the API.
        [Default: 60]
- tls
        Secure the connection to the API by using TLS without verifying the authenticity of the Docker host server.
        [Default: False]
- tls_hostname
        When verifying the authenticity of the Docker Host server, provide the expected name of the server.
        [Default: localhost]
- tls_verify
        Secure the connection to the API by using TLS and verifying the authenticity of the Docker host server.
        [Default: False]
- use_tls
        DEPRECATED. Whether to use tls to connect to the docker server. Set to `no' when TLS will not be used. Set to
        `encrypt' to use TLS. And set to `verify' to use TLS and verify that the server's certificate is valid for the
        server. NOTE: If you specify this option, it will set the value of the tls or tls_verify parameters.
        (Choices: False, encrypt, verify)[Default: False]
Notes:
  * Connect to the Docker daemon by providing parameters with each task or by defining environment variables. You
        can define DOCKER_HOST, DOCKER_TLS_HOSTNAME, DOCKER_API_VERSION, DOCKER_CERT_PATH, DOCKER_SSL_VERSION,
        DOCKER_TLS, DOCKER_TLS_VERIFY and DOCKER_TIMEOUT. If you are using docker machine, run the script shipped
        with the product that sets up the environment. It will set these variables for you. See https://docker-
        py.readthedocs.org/en/stable/machine/ for more details.
Requirements:  python >= 2.6, docker-py >= 1.7.0, Docker API >= 1.20

EXAMPLES:

- name: pull an image
  docker_image:
    name: pacur/centos-7

- name: Tag and push to docker hub
  docker_image:
    name: pacur/centos-7
    repository: dcoppenhagan/myimage
    tag: 7.0
    push: yes

- name: Tag and push to local registry
  docker_image:
     name: centos
     repository: localhost:5000/centos
     tag: 7
     push: yes

- name: Remove image
  docker_image:
    state: absent
    name: registry.ansible.com/chouseknecht/sinatra
    tag: v1

- name: Build an image and push it to a private repo
  docker_image:
    path: ./sinatra
    name: registry.ansible.com/chouseknecht/sinatra
    tag: v1
    push: yes

- name: Archive image
  docker_image:
    name: registry.ansible.com/chouseknecht/sinatra
    tag: v1
    archive_path: my_sinatra.tar

- name: Load image from archive and push to a private registry
  docker_image:
    name: localhost:5000/myimages/sinatra
    tag: v1
    push: yes
    load_path: my_sinatra.tar

- name: Build image and with buildargs
  docker_image:
     path: /path/to/build/dir
     name: myimage
     buildargs:
       log_volume: /var/log/myapp
       listen_port: 8080

RETURN VALUES:
image:
    description: Image inspection results for the affected image.
    returned: success
    type: complex
    sample: {}


MAINTAINERS: Chris Houseknecht (@chouseknecht), James Tanner (@jctanner), Pavel Antonov (@softzilla)

METADATA:
	Status: ['preview']
	Supported_by: community
> DOCKER_IMAGE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/docker/docker_image_facts.py)

  Provide one or more image names, and the module will inspect each, returning an array of inspection results.

Options (= is mandatory):

- api_version
        The version of the Docker API running on the Docker Host. Defaults to the latest version of the API supported by
        docker-py.
        [Default: default provided by docker-py]
- cacert_path
        Use a CA certificate when performing server verification by providing the path to a CA certificate file.
        [Default: None]
- cert_path
        Path to the client's TLS certificate file.
        [Default: None]
- docker_host
        The URL or Unix socket path used to connect to the Docker API. To connect to a remote host, provide the TCP
        connection string. For example, 'tcp://192.0.2.23:2376'. If TLS is used to encrypt the connection, the module
        will automatically replace 'tcp' in the connection URL with 'https'.
        [Default: unix://var/run/docker.sock]
- key_path
        Path to the client's TLS key file.
        [Default: None]
= name
        An image name or a list of image names. Name format will be name[:tag] or repository/name[:tag], where tag is
        optional. If a tag is not provided, 'latest' will be used.
        [Default: None]
- ssl_version
        Provide a valid SSL version number. Default value determined by docker-py, currently 1.0.
        [Default: 1.0]
- timeout
        The maximum amount of time in seconds to wait on a response from the API.
        [Default: 60]
- tls
        Secure the connection to the API by using TLS without verifying the authenticity of the Docker host server.
        [Default: False]
- tls_hostname
        When verifying the authenticity of the Docker Host server, provide the expected name of the server.
        [Default: localhost]
- tls_verify
        Secure the connection to the API by using TLS and verifying the authenticity of the Docker host server.
        [Default: False]
Notes:
  * Connect to the Docker daemon by providing parameters with each task or by defining environment variables. You
        can define DOCKER_HOST, DOCKER_TLS_HOSTNAME, DOCKER_API_VERSION, DOCKER_CERT_PATH, DOCKER_SSL_VERSION,
        DOCKER_TLS, DOCKER_TLS_VERIFY and DOCKER_TIMEOUT. If you are using docker machine, run the script shipped
        with the product that sets up the environment. It will set these variables for you. See https://docker-
        py.readthedocs.org/en/stable/machine/ for more details.
Requirements:  python >= 2.6, docker-py >= 1.7.0, Docker API >= 1.20

EXAMPLES:

- name: Inspect a single image
  docker_image_facts:
    name: pacur/centos-7

- name: Inspect multiple images
  docker_image_facts:
    name:
      - pacur/centos-7
      - sinatra

RETURN VALUES:
images:
    description: Facts for the selected images.
    returned: always
    type: dict
    sample: [
        {
            "Architecture": "amd64",
            "Author": "",
            "Comment": "",
            "Config": {
                "AttachStderr": false,
                "AttachStdin": false,
                "AttachStdout": false,
                "Cmd": [
                    "/etc/docker/registry/config.yml"
                ],
                "Domainname": "",
                "Entrypoint": [
                    "/bin/registry"
                ],
                "Env": [
                    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
                ],
                "ExposedPorts": {
                    "5000/tcp": {}
                },
                "Hostname": "e5c68db50333",
                "Image": "c72dce2618dc8f7b794d2b2c2b1e64e0205ead5befc294f8111da23bd6a2c799",
                "Labels": {},
                "OnBuild": [],
                "OpenStdin": false,
                "StdinOnce": false,
                "Tty": false,
                "User": "",
                "Volumes": {
                    "/var/lib/registry": {}
                },
                "WorkingDir": ""
            },
            "Container": "e83a452b8fb89d78a25a6739457050131ca5c863629a47639530d9ad2008d610",
            "ContainerConfig": {
                "AttachStderr": false,
                "AttachStdin": false,
                "AttachStdout": false,
                "Cmd": [
                    "/bin/sh",
                    "-c",
                    '#(nop) CMD ["/etc/docker/registry/config.yml"]'
                ],
                "Domainname": "",
                "Entrypoint": [
                    "/bin/registry"
                ],
                "Env": [
                    "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
                ],
                "ExposedPorts": {
                    "5000/tcp": {}
                },
                "Hostname": "e5c68db50333",
                "Image": "c72dce2618dc8f7b794d2b2c2b1e64e0205ead5befc294f8111da23bd6a2c799",
                "Labels": {},
                "OnBuild": [],
                "OpenStdin": false,
                "StdinOnce": false,
                "Tty": false,
                "User": "",
                "Volumes": {
                    "/var/lib/registry": {}
                },
                "WorkingDir": ""
            },
            "Created": "2016-03-08T21:08:15.399680378Z",
            "DockerVersion": "1.9.1",
            "GraphDriver": {
                "Data": null,
                "Name": "aufs"
            },
            "Id": "53773d8552f07b730f3e19979e32499519807d67b344141d965463a950a66e08",
            "Name": "registry:2",
            "Os": "linux",
            "Parent": "f0b1f729f784b755e7bf9c8c2e65d8a0a35a533769c2588f02895f6781ac0805",
            "RepoDigests": [],
            "RepoTags": [
                "registry:2"
            ],
            "Size": 0,
            "VirtualSize": 165808884
        }
    ]


MAINTAINERS: James Tanner (@jctanner), Chris Houseknecht (@chouseknecht)

METADATA:
	Status: ['preview']
	Supported_by: community
> DOCKER_LOGIN    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/docker/docker_login.py)

  Provides functionality similar to the "docker login" command. Authenticate with a docker registry and add the
  credentials to your local Docker config file. Adding the credentials to the config files allows future connections to
  the registry using tools such as Ansible's Docker modules, the Docker CLI and docker-py without needing to provide
  credentials. Running in check mode will perform the authentication without updating the config file.

Options (= is mandatory):

- api_version
        The version of the Docker API running on the Docker Host. Defaults to the latest version of the API supported by
        docker-py.
        [Default: default provided by docker-py]
- cacert_path
        Use a CA certificate when performing server verification by providing the path to a CA certificate file.
        [Default: None]
- cert_path
        Path to the client's TLS certificate file.
        [Default: None]
- config_path
        Custom path to the Docker CLI configuration file.
        [Default: ~/.docker/config.json]
- docker_host
        The URL or Unix socket path used to connect to the Docker API. To connect to a remote host, provide the TCP
        connection string. For example, 'tcp://192.0.2.23:2376'. If TLS is used to encrypt the connection, the module
        will automatically replace 'tcp' in the connection URL with 'https'.
        [Default: unix://var/run/docker.sock]
- email
        The email address for the registry account. NOTE: private registries may not require this, but Docker Hub
        requires it.
        [Default: None]
- key_path
        Path to the client's TLS key file.
        [Default: None]
= password
        The plaintext password for the registry account

- reauthorize
        Refresh exiting authentication found in the configuration file.
        (Choices: yes, no)[Default: False]
- registry_url
        The registry URL.
        [Default: https://index.docker.io/v1/]
- ssl_version
        Provide a valid SSL version number. Default value determined by docker-py, currently 1.0.
        [Default: 1.0]
- state
        This controls the current state of the user. `present' will login in a user, `absent' will log him out.
        To logout you only need the registry server, which defaults to DockerHub.
        Before 2.1 you could ONLY log in.
        docker does not support 'logout' with a custom config file.
        (Choices: present, absent)[Default: present]
- timeout
        The maximum amount of time in seconds to wait on a response from the API.
        [Default: 60]
- tls
        Secure the connection to the API by using TLS without verifying the authenticity of the Docker host server.
        [Default: False]
- tls_hostname
        When verifying the authenticity of the Docker Host server, provide the expected name of the server.
        [Default: localhost]
- tls_verify
        Secure the connection to the API by using TLS and verifying the authenticity of the Docker host server.
        [Default: False]
= username
        The username for the registry account

Notes:
  * Connect to the Docker daemon by providing parameters with each task or by defining environment variables. You
        can define DOCKER_HOST, DOCKER_TLS_HOSTNAME, DOCKER_API_VERSION, DOCKER_CERT_PATH, DOCKER_SSL_VERSION,
        DOCKER_TLS, DOCKER_TLS_VERIFY and DOCKER_TIMEOUT. If you are using docker machine, run the script shipped
        with the product that sets up the environment. It will set these variables for you. See https://docker-
        py.readthedocs.org/en/stable/machine/ for more details.
Requirements:  python >= 2.6, docker-py >= 1.7.0, Docker API >= 1.20, Only to be able to logout (state=absent): the
        docker command line utility

EXAMPLES:

- name: Log into DockerHub
  docker_login:
    username: docker
    password: rekcod
    email: docker@docker.io

- name: Log into private registry and force re-authorization
  docker_login:
    registry: your.private.registry.io
    username: yourself
    password: secrets3
    reauthorize: yes

- name: Log into DockerHub using a custom config file
  docker_login:
    username: docker
    password: rekcod
    email: docker@docker.io
    config_path: /tmp/.mydockercfg

- name: Log out of DockerHub
  docker_login:
    state: absent
    email: docker@docker.com

RETURN VALUES:
login_results:
    description: Results from the login.
    returned: when state='present'
    type: dict
    sample: {
        "email": "testuer@yahoo.com",
        "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
        "serveraddress": "localhost:5000",
        "username": "testuser"
    }


MAINTAINERS: James Tanner (@jctanner), Olaf Kilian <olaf.kilian@symanex.com>, Chris Houseknecht (@chouseknecht)

METADATA:
	Status: ['preview']
	Supported_by: community
> DOCKER_NETWORK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/docker/docker_network.py)

  Create/remove Docker networks and connect containers to them. Performs largely the same function as the "docker
  network" CLI subcommand.

Options (= is mandatory):

- api_version
        The version of the Docker API running on the Docker Host. Defaults to the latest version of the API supported by
        docker-py.
        [Default: default provided by docker-py]
- appends
        By default the connected list is canonical, meaning containers not on the list are removed from the network. Use
        `appends' to leave existing containers connected.
        [Default: False]
- cacert_path
        Use a CA certificate when performing server verification by providing the path to a CA certificate file.
        [Default: None]
- cert_path
        Path to the client's TLS certificate file.
        [Default: None]
- connected
        List of container names or container IDs to connect to a network.
        [Default: None]
- docker_host
        The URL or Unix socket path used to connect to the Docker API. To connect to a remote host, provide the TCP
        connection string. For example, 'tcp://192.0.2.23:2376'. If TLS is used to encrypt the connection, the module
        will automatically replace 'tcp' in the connection URL with 'https'.
        [Default: unix://var/run/docker.sock]
- driver
        Specify the type of network. Docker provides bridge and overlay drivers, but 3rd party drivers can also be used.
        [Default: bridge]
- driver_options
        Dictionary of network settings. Consult docker docs for valid options and values.
        [Default: None]
- force
        With state `absent' forces disconnecting all containers from the network prior to deleting the network. With
        state `present' will disconnect all containers, delete the network and re-create the network.  This option is
        required if you have changed the IPAM or driver options and want an existing network to be updated to use the new
        options.
        [Default: False]
- ipam_driver
        Specify an IPAM driver.
        [Default: None]
- ipam_options
        Dictionary of IPAM options.
        [Default: None]
- key_path
        Path to the client's TLS key file.
        [Default: None]
= name
        Name of the network to operate on.

- ssl_version
        Provide a valid SSL version number. Default value determined by docker-py, currently 1.0.
        [Default: 1.0]
- state
        `absent' deletes the network. If a network has connected containers, it cannot be deleted. Use the `force' option
        to disconnect all containers and delete the network.
        `present' creates the network, if it does not already exist with the specified parameters, and connects the list
        of containers provided via the connected parameter. Containers not on the list will be disconnected. An empty
        list will leave no containers connected to the network. Use the `appends' option to leave existing containers
        connected. Use the `force' options to force re-creation of the network.
        (Choices: absent, present)[Default: present]
- timeout
        The maximum amount of time in seconds to wait on a response from the API.
        [Default: 60]
- tls
        Secure the connection to the API by using TLS without verifying the authenticity of the Docker host server.
        [Default: False]
- tls_hostname
        When verifying the authenticity of the Docker Host server, provide the expected name of the server.
        [Default: localhost]
- tls_verify
        Secure the connection to the API by using TLS and verifying the authenticity of the Docker host server.
        [Default: False]
Notes:
  * Connect to the Docker daemon by providing parameters with each task or by defining environment variables. You
        can define DOCKER_HOST, DOCKER_TLS_HOSTNAME, DOCKER_API_VERSION, DOCKER_CERT_PATH, DOCKER_SSL_VERSION,
        DOCKER_TLS, DOCKER_TLS_VERIFY and DOCKER_TIMEOUT. If you are using docker machine, run the script shipped
        with the product that sets up the environment. It will set these variables for you. See https://docker-
        py.readthedocs.org/en/stable/machine/ for more details.
Requirements:  python >= 2.6, docker-py >= 1.7.0, The docker server >= 1.9.0

EXAMPLES:
- name: Create a network
  docker_network:
    name: network_one

- name: Remove all but selected list of containers
  docker_network:
    name: network_one
    connected:
      - container_a
      - container_b
      - container_c

- name: Remove a single container
  docker_network:
    name: network_one
    connected: "{{ fulllist|difference(['container_a']) }}"

- name: Add a container to a network, leaving existing containers connected
  docker_network:
    name: network_one
    connected:
      - container_a
    appends: yes

- name: Create a network with options
  docker_network:
    name: network_two
    driver_options:
      com.docker.network.bridge.name: net2
    ipam_options:
      subnet: '172.3.26.0/16'
      gateway: 172.3.26.1
      iprange: '192.168.1.0/24'

- name: Delete a network, disconnecting all containers
  docker_network:
    name: network_one
    state: absent
    force: yes

RETURN VALUES:
facts:
    description: Network inspection results for the affected network.
    returned: success
    type: complex
    sample: {}


MAINTAINERS: Ben Keith (@keitwb), Chris Houseknecht (@chouseknecht)

METADATA:
	Status: ['preview']
	Supported_by: community
> DOCKER_SERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/docker/docker_service.py)

  Consumes docker compose to start, shutdown and scale services. Works with compose versions 1 and 2. Compose can be read
  from a docker-compose.yml (or .yaml) file or inline using the `definition' option. See the examples for more details.
  Supports check mode.

Options (= is mandatory):

- api_version
        The version of the Docker API running on the Docker Host. Defaults to the latest version of the API supported by
        docker-py.
        [Default: default provided by docker-py]
- build
        Use with state `present' to always build images prior to starting the application.
        Same as running docker-compose build with the pull option.
        Images will only be rebuilt if Docker detects a change in the Dockerfile or build directory contents.
        Use the `nocache' option to ignore the image cache when performing the build.
        If an existing image is replaced, services using the image will be recreated unless `recreate' is `never'.
        [Default: False]
- cacert_path
        Use a CA certificate when performing server verification by providing the path to a CA certificate file.
        [Default: None]
- cert_path
        Path to the client's TLS certificate file.
        [Default: None]
- debug
        Include `actions' in the return values.
        [Default: False]
- definition
        Provide docker-compose yaml describing one or more services, networks and volumes.
        Mutually exclusive with `project_src' and `files'.
        [Default: (null)]
- dependencies
        When `state' is `present' specify whether or not to include linked services.
        [Default: True]
- docker_host
        The URL or Unix socket path used to connect to the Docker API. To connect to a remote host, provide the TCP
        connection string. For example, 'tcp://192.0.2.23:2376'. If TLS is used to encrypt the connection, the module
        will automatically replace 'tcp' in the connection URL with 'https'.
        [Default: unix://var/run/docker.sock]
- files
        List of file names relative to `project_src'. Overrides docker-compose.yml or docker-compose.yaml.
        Files are loaded and merged in the order given.
        [Default: (null)]
- hostname_check
        Whether or not to check the Docker daemon's hostname against the name provided in the client certificate.
        [Default: False]
- key_path
        Path to the client's TLS key file.
        [Default: None]
- nocache
        Use with the build option to ignore the cache during the image build process.
        [Default: False]
- project_name
        Provide a project name. If not provided, the project name is taken from the basename of `project_src'.
        Required when no `definition' is provided.
        [Default: (null)]
- project_src
        Path to a directory containing a docker-compose.yml or docker-compose.yaml file.
        Mutually exclusive with `definition'.
        Required when no `definition' is provided.
        [Default: (null)]
- pull
        Use with state `present' to always pull images prior to starting the application.
        Same as running docker-compose pull.
        When a new image is pulled, services using the image will be recreated unless `recreate' is `never'.
        [Default: False]
- recreate
        By default containers will be recreated when their configuration differs from the service definition.
        Setting to `never' ignores configuration differences and leaves existing containers unchanged.
        Setting to `always' forces recreation of all existing containers.
        (Choices: always, never, smart)[Default: smart]
- remove_images
        Use with state `absent' to remove the all images or only local images.
        [Default: None]
- remove_volumes
        Use with state `absent' to remove data volumes.
        [Default: False]
- restarted
        Use with state `present' to restart all containers.
        [Default: False]
- scale
        When `state' is `present' scale services. Provide a dictionary of key/value pairs where the key is the name of
        the service and the value is an integer count for the number of containers.
        [Default: (null)]
- services
        When `state' is `present' run `docker-compose up' on a subset of services.
        [Default: (null)]
- ssl_version
        Provide a valid SSL version number. Default value determined by docker-py, currently 1.0.
        [Default: 1.0]
- state
        Desired state of the project.
        Specifying `present' is the same as running `docker-compose up'.
        Specifying `absent' is the same as running `docker-compose down'.
        (Choices: absent, present)[Default: present]
- stopped
        Use with state `present' to leave the containers in an exited or non-running state.
        [Default: False]
- timeout
        The maximum amount of time in seconds to wait on a response from the API.
        [Default: 60]
- tls
        Secure the connection to the API by using TLS without verifying the authenticity of the Docker host server.
        [Default: False]
- tls_hostname
        When verifying the authenticity of the Docker Host server, provide the expected name of the server.
        [Default: localhost]
- tls_verify
        Secure the connection to the API by using TLS and verifying the authenticity of the Docker host server.
        [Default: False]
Notes:
  * Connect to the Docker daemon by providing parameters with each task or by defining environment variables. You
        can define DOCKER_HOST, DOCKER_TLS_HOSTNAME, DOCKER_API_VERSION, DOCKER_CERT_PATH, DOCKER_SSL_VERSION,
        DOCKER_TLS, DOCKER_TLS_VERIFY and DOCKER_TIMEOUT. If you are using docker machine, run the script shipped
        with the product that sets up the environment. It will set these variables for you. See https://docker-
        py.readthedocs.org/en/stable/machine/ for more details.
Requirements:  python >= 2.6, docker-compose >= 1.7.0, Docker API >= 1.20, PyYAML >= 3.11

EXAMPLES:
# Examples use the django example at U(https://docs.docker.com/compose/django/). Follow it to create the flask
# directory

- name: Run using a project directory
  hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - docker_service:
        project_src: flask
        state: absent

    - docker_service:
        project_src: flask
      register: output

    - debug:
        var: output

    - docker_service:
        project_src: flask
        build: no
      register: output

    - debug:
        var: output

    - assert:
        that: "not output.changed "

    - docker_service:
        project_src: flask
        build: no
        stopped: true
      register: output

    - debug:
        var: output

    - assert:
        that:
          - "not web.flask_web_1.state.running"
          - "not db.flask_db_1.state.running"

    - docker_service:
        project_src: flask
        build: no
        restarted: true
      register: output

    - debug:
        var: output

    - assert:
        that:
          - "web.flask_web_1.state.running"
          - "db.flask_db_1.state.running"

- name: Scale the web service to 2
  hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - docker_service:
        project_src: flask
        scale:
          web: 2
      register: output

    - debug:
        var: output

- name: Run with inline v2 compose
  hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - docker_service:
        project_src: flask
        state: absent

    - docker_service:
        project_name: flask
        definition:
          version: '2'
          services:
            db:
              image: postgres
            web:
              build: "{{ playbook_dir }}/flask"
              command: "python manage.py runserver 0.0.0.0:8000"
              volumes:
                - "{{ playbook_dir }}/flask:/code"
              ports:
                - "8000:8000"
              depends_on:
                - db
      register: output

    - debug:
        var: output

    - assert:
        that:
          - "web.flask_web_1.state.running"
          - "db.flask_db_1.state.running"

- name: Run with inline v1 compose
  hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - docker_service:
        project_src: flask
        state: absent

    - docker_service:
        project_name: flask
        definition:
            db:
              image: postgres
            web:
              build: "{{ playbook_dir }}/flask"
              command: "python manage.py runserver 0.0.0.0:8000"
              volumes:
                - "{{ playbook_dir }}/flask:/code"
              ports:
                - "8000:8000"
              links:
                - db
      register: output

    - debug:
        var: output

    - assert:
        that:
          - "web.flask_web_1.state.running"
          - "db.flask_db_1.state.running"

RETURN VALUES:
service:
  description: Name of the service.
  returned: success
  type: complex
  contains:
      container_name:
          description: Name of the container. Format is I(project_service_#).
          returned: success
          type: complex
          contains:
              cmd:
                  description: One or more commands to be executed in the container.
                  returned: success
                  type: list
                  example: ["postgres"]
              image:
                  description: Name of the image from which the container was built.
                  returned: success
                  type: str
                  example: postgres
              labels:
                  description: Meta data assigned to the container.
                  returned: success
                  type: complex
                  example: {...}
              networks:
                  description: Contains a dictionary for each network to which the container is a member.
                  returned: success
                  type: complex
                  contains:
                      IPAddress:
                          description: The IP address assigned to the container.
                          returned: success
                          type: string
                          example: 172.17.0.2
                      IPPrefixLen:
                          description: Number of bits used by the subnet.
                          returned: success
                          type: int
                          example: 16
                      aliases:
                          description: Aliases assigned to the container by the network.
                          returned: success
                          type: list
                          example: ['db']
                      globalIPv6:
                          description: IPv6 address assigned to the container.
                          returned: success
                          type: str
                          example: ''
                      globalIPv6PrefixLen:
                          description: IPv6 subnet length.
                          returned: success
                          type: int
                          example: 0
                      links:
                          description: List of container names to which this container is linked.
                          returned: success
                          type: list
                          example: null
                      macAddress:
                          description: Mac Address assigned to the virtual NIC.
                          returned: success
                          type: str
                          example: "02:42:ac:11:00:02"
              state:
                  description: Information regarding the current disposition of the container.
                  returned: success
                  type: complex
                  contains:
                      running:
                          description: Whether or not the container is up with a running process.
                          returned: success
                          type: bool
                          example: true
                      status:
                          description: Description of the running state.
                          returned: success
                          type: str
                          example: running

actions:
  description: Provides the actions to be taken on each service as determined by compose.
  returned: when in check mode or I(debug) true
  type: complex
  contains:
      service_name:
          description: Name of the service.
          returned: always
          type: complex
          contains:
              pulled_image:
                  description: Provides image details when a new image is pulled for the service.
                  returned: on image pull
                  type: complex
                  contains:
                      name:
                          description: name of the image
                          returned: always
                          type: string
                      id:
                          description: image hash
                          returned: always
                          type: string
              built_image:
                  description: Provides image details when a new image is built for the service.
                  returned: on image build
                  type: complex
                  contains:
                      name:
                          description: name of the image
                          returned: always
                          type: string
                      id:
                          description: image hash
                          returned: always
                          type: string

              action:
                  description: A descriptive name of the action to be performed on the service's containers.
                  returned: always
                  type: list
                  contains:
                      id:
                          description: the container's long ID
                          returned: always
                          type: string
                      name:
                          description: the container's name
                          returned: always
                          type: string
                      short_id:
                          description: the container's short ID
                          returned: always
                          type: string


MAINTAINERS: Chris Houseknecht (@chouseknecht)

METADATA:
	Status: ['preview']
	Supported_by: community
> DPKG_SELECTIONS    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/dpkg_selections.py)

  Change dpkg package selection state via --get-selections and --set-selections.

Options (= is mandatory):

= name
        Name of the package

= selection
        The selection state to set the package to.
        (Choices: install, hold, deinstall, purge)
Notes:
  * This module won't cause any packages to be installed/removed/purged, use the `apt' module for that.
EXAMPLES:
# Prevent python from being upgraded.
- dpkg_selections:
    name: python
    selection: hold


MAINTAINERS: Brian Brazil <brian.brazil@boxever.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> DYNAMODB_TABLE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/dynamodb_table.py)

  Create or delete AWS Dynamo DB tables. Can update the provisioned throughput on existing tables. Returns the status of
  the specified table.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- hash_key_name
        Name of the hash key.
        Required when `state=present'.
        [Default: None]
- hash_key_type
        Type of the hash key.
        (Choices: STRING, NUMBER, BINARY)[Default: STRING]
- indexes
        list of dictionaries describing indexes to add to the table. global indexes can be updated. local indexes don't
        support updates or have throughput.
        required options: ['name', 'type', 'hash_key_name']
        valid types: ['all', 'global_all', 'global_include', 'global_keys_only', 'include', 'keys_only']
        other options: ['hash_key_type', 'range_key_name', 'range_key_type', 'includes', 'read_capacity',
        'write_capacity']
        [Default: []]
= name
        Name of the table.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- range_key_name
        Name of the range key.
        [Default: None]
- range_key_type
        Type of the range key.
        (Choices: STRING, NUMBER, BINARY)[Default: STRING]
- read_capacity
        Read throughput capacity (units) to provision.
        [Default: 1]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or delete the table
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- write_capacity
        Write throughput capacity (units) to provision.
        [Default: 1]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto >= 2.37.0, python >= 2.6

EXAMPLES:
# Create dynamo table with hash and range primary key
- dynamodb_table:
    name: my-table
    region: us-east-1
    hash_key_name: id
    hash_key_type: STRING
    range_key_name: create_time
    range_key_type: NUMBER
    read_capacity: 2
    write_capacity: 2

# Update capacity on existing dynamo table
- dynamodb_table:
    name: my-table
    region: us-east-1
    read_capacity: 10
    write_capacity: 10

# set index on existing dynamo table
- dynamodb_table:
    name: my-table
    region: us-east-1
    indexes:
      - name: NamedIndex
        type: global_include
        hash_key_name: id
        range_key_name: create_time
        includes:
          - other_field
          - other_field2
        read_capacity: 10
        write_capacity: 10

# Delete dynamo table
- dynamodb_table:
    name: my-table
    region: us-east-1
    state: absent

RETURN VALUES:
table_status:
    description: The current status of the table.
    returned: success
    type: string
    sample: ACTIVE


MAINTAINERS: Alan Loi (@loia)

METADATA:
	Status: ['preview']
	Supported_by: community
> EASY_INSTALL    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/easy_install.py)

  Installs Python libraries, optionally in a `virtualenv'

Options (= is mandatory):

- executable
        The explicit executable or a pathname to the executable to be used to run easy_install for a specific version of
        Python installed in the system. For example `easy_install-3.3', if there are both Python 2.7 and 3.3
        installations in the system and you want to run easy_install for the Python 3.3 installation.
        [Default: None]
= name
        A Python library name
        [Default: None]
- state
        The desired state of the library. `latest' ensures that the latest version is installed.
        (Choices: present, latest)[Default: present]
- virtualenv
        an optional `virtualenv' directory path to install into. If the `virtualenv' does not exist, it is created
        automatically
        [Default: None]
- virtualenv_command
        The command to create the virtual environment with. For example `pyvenv', `virtualenv', `virtualenv2'.
        [Default: virtualenv]
- virtualenv_site_packages
        Whether the virtual environment will inherit packages from the global site-packages directory.  Note that if this
        setting is changed on an already existing virtual environment it will not have any effect, the environment must
        be deleted and newly created.
        (Choices: yes, no)[Default: no]
Notes:
  * Please note that the `easy_install' module can only install Python libraries. Thus this module is not able to
        remove libraries. It is generally recommended to use the [pip] module which you can first install using
        [easy_install].
  * Also note that `virtualenv' must be installed on the remote host if the `virtualenv' parameter is specified.
Requirements:  virtualenv

EXAMPLES:
# Examples from Ansible Playbooks
- easy_install:
    name: pip
    state: latest

# Install Bottle into the specified virtualenv.
- easy_install:
    name: bottle
    virtualenv: /webapps/myapp/venv


MAINTAINERS: Matt Wright (@mattupstate)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2.py)

  Creates or terminates ec2 instances. `state=restarted' was added in 2.2

Options (= is mandatory):

- assign_public_ip
        when provisioning within vpc, assign a public IP address. Boto library must be 2.13.0+
        (Choices: yes, no)[Default: None]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- count
        number of instances to launch
        [Default: 1]
- count_tag
        Used with 'exact_count' to determine how many nodes based on a specific tag criteria should be running.  This can
        be expressed in multiple ways and is shown in the EXAMPLES section.  For instance, one can request 25 servers
        that are tagged with "class=webserver". The specified tag must already exist or be passed in as the
        'instance_tags' option.
        [Default: None]
- ebs_optimized
        whether instance is using optimized EBS volumes, see
        http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html
        [Default: false]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- exact_count
        An integer value which indicates how many instances that match the 'count_tag' parameter should be running.
        Instances are either created or terminated based on this value.
        [Default: None]
- group
        security group (or list of groups) to use with the instance
        [Default: None]
- group_id
        security group id (or list of ids) to use with the instance
        [Default: None]
- id
        identifier for this instance or set of instances, so that the module will be idempotent with respect to EC2
        instances. This identifier is valid for at least 24 hours after the termination of the instance, and should not
        be reused for another call later on. For details, see the description of client token at
        http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Run_Instance_Idempotency.html.
        [Default: None]
= image
        `ami' ID to use for the instance
        [Default: None]
- instance_ids
        list of instance ids, currently used for states: absent, running, stopped
        [Default: None]
- instance_initiated_shutdown_behavior
        Set whether AWS will Stop or Terminate an instance on shutdown
        (Choices: stop, terminate)[Default: stop]
- instance_profile_name
        Name of the IAM instance profile to use. Boto library must be 2.5.0+
        [Default: None]
- instance_tags
        a hash/dictionary of tags to add to the new instance or for starting/stopping instance by tag; '{"key":"value"}'
        and '{"key":"value","key":"value"}'
        [Default: None]
= instance_type
        instance type to use for the instance, see http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html
        [Default: None]
- kernel
        kernel `eki' to use for the instance
        [Default: None]
- key_name
        key pair to use on the instance
        [Default: None]
- monitoring
        enable detailed monitoring (CloudWatch) for instance
        (Choices: yes, no)[Default: None]
- network_interfaces
        A list of existing network interfaces to attach to the instance at launch. When specifying existing network
        interfaces, none of the assign_public_ip, private_ip, vpc_subnet_id, group, or group_id parameters may be used.
        (Those parameters are for creating a new network interface at launch.)
        [Default: None]
- placement_group
        placement group for the instance when using EC2 Clustered Compute
        [Default: None]
- private_ip
        the private ip address to assign the instance (from the vpc subnet)
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- ramdisk
        ramdisk `eri' to use for the instance
        [Default: None]
- region
        The AWS region to use.  Must be specified if ec2_url is not used. If not specified then the value of the
        EC2_REGION environment variable, if any, is used. See
        http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- source_dest_check
        Enable or Disable the Source/Destination checks (for NAT instances and Virtual Routers)
        (Choices: yes, no)[Default: True]
- spot_launch_group
        Launch group for spot request, see http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-
        work.html#spot-launch-group
        [Default: None]
- spot_price
        Maximum spot price to bid, If not set a regular on-demand instance is requested. A spot request is made with this
        maximum bid. When it is filled, the instance is started.
        [Default: None]
- spot_type
        Type of spot request; one of "one-time" or "persistent". Defaults to "one-time" if not supplied.
        (Choices: one-time, persistent)[Default: one-time]
- spot_wait_timeout
        how long to wait for the spot instance request to be fulfilled
        [Default: 600]
- state
        create or terminate instances
        (Choices: present, absent, running, restarted, stopped)[Default: present]
- tenancy
        An instance with a tenancy of "dedicated" runs on single-tenant hardware and can only be launched into a VPC.
        Note that to use dedicated tenancy you MUST specify a vpc_subnet_id as well. Dedicated tenancy is not available
        for EC2 "micro" instances.
        (Choices: default, dedicated)[Default: default]
- termination_protection
        Enable or Disable the Termination Protection
        (Choices: yes, no)[Default: False]
- user_data
        opaque blob of data which is made available to the ec2 instance
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- volumes
        a list of hash/dictionaries of volumes to add to the new instance; '[{"key":"value", "key":"value"}]'; keys
        allowed are - device_name (str; required), delete_on_termination (bool; False), device_type (deprecated),
        ephemeral (str), encrypted (bool; False), snapshot (str), volume_type (str), iops (int) - device_type is
        deprecated use volume_type, iops must be set when volume_type='io1', ephemeral and snapshot are mutually
        exclusive.
        [Default: None]
- vpc_subnet_id
        the subnet ID in which to launch the instance (VPC)
        [Default: None]
- wait
        wait for the instance to reach its desired state before returning.  Does not wait for SSH, see 'wait_for' example
        for details.
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
- zone
        AWS availability zone in which to launch the instance
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Basic provisioning example
- ec2:
    key_name: mykey
    instance_type: t2.micro
    image: ami-123456
    wait: yes
    group: webserver
    count: 3
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes

# Advanced example with tagging and CloudWatch
- ec2:
    key_name: mykey
    group: databases
    instance_type: t2.micro
    image: ami-123456
    wait: yes
    wait_timeout: 500
    count: 5
    instance_tags:
       db: postgres
    monitoring: yes
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes

# Single instance with additional IOPS volume from snapshot and volume delete on termination
- ec2:
    key_name: mykey
    group: webserver
    instance_type: c3.medium
    image: ami-123456
    wait: yes
    wait_timeout: 500
    volumes:
      - device_name: /dev/sdb
        snapshot: snap-abcdef12
        volume_type: io1
        iops: 1000
        volume_size: 100
        delete_on_termination: true
    monitoring: yes
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes

# Single instance with ssd gp2 root volume
- ec2:
    key_name: mykey
    group: webserver
    instance_type: c3.medium
    image: ami-123456
    wait: yes
    wait_timeout: 500
    volumes:
      - device_name: /dev/xvda
        volume_type: gp2
        volume_size: 8
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes
    exact_count: 1

# Multiple groups example
- ec2:
    key_name: mykey
    group: ['databases', 'internal-services', 'sshable', 'and-so-forth']
    instance_type: m1.large
    image: ami-6e649707
    wait: yes
    wait_timeout: 500
    count: 5
    instance_tags:
        db: postgres
    monitoring: yes
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes

# Multiple instances with additional volume from snapshot
- ec2:
    key_name: mykey
    group: webserver
    instance_type: m1.large
    image: ami-6e649707
    wait: yes
    wait_timeout: 500
    count: 5
    volumes:
    - device_name: /dev/sdb
      snapshot: snap-abcdef12
      volume_size: 10
    monitoring: yes
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes

# Dedicated tenancy example
- local_action:
    module: ec2
    assign_public_ip: yes
    group_id: sg-1dc53f72
    key_name: mykey
    image: ami-6e649707
    instance_type: m1.small
    tenancy: dedicated
    vpc_subnet_id: subnet-29e63245
    wait: yes

# Spot instance example
- ec2:
    spot_price: 0.24
    spot_wait_timeout: 600
    keypair: mykey
    group_id: sg-1dc53f72
    instance_type: m1.small
    image: ami-6e649707
    wait: yes
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes
    spot_launch_group: report_generators

# Examples using pre-existing network interfaces
- ec2:
    key_name: mykey
    instance_type: t2.small
    image: ami-f005ba11
    network_interface: eni-deadbeef

- ec2:
    key_name: mykey
    instance_type: t2.small
    image: ami-f005ba11
    network_interfaces: ['eni-deadbeef', 'eni-5ca1ab1e']

# Launch instances, runs some tasks
# and then terminate them

- name: Create a sandbox instance
  hosts: localhost
  gather_facts: False
  vars:
    key_name: my_keypair
    instance_type: m1.small
    security_group: my_securitygroup
    image: my_ami_id
    region: us-east-1
  tasks:
    - name: Launch instance
      ec2:
         key_name: "{{ keypair }}"
         group: "{{ security_group }}"
         instance_type: "{{ instance_type }}"
         image: "{{ image }}"
         wait: true
         region: "{{ region }}"
         vpc_subnet_id: subnet-29e63245
         assign_public_ip: yes
      register: ec2

    - name: Add new instance to host group
      add_host:
        hostname: "{{ item.public_ip }}"
        groupname: launched
      with_items: "{{ ec2.instances }}"

    - name: Wait for SSH to come up
      wait_for:
        host: "{{ item.public_dns_name }}"
        port: 22
        delay: 60
        timeout: 320
        state: started
      with_items: "{{ ec2.instances }}"

- name: Configure instance(s)
  hosts: launched
  become: True
  gather_facts: True
  roles:
    - my_awesome_role
    - my_awesome_test

- name: Terminate instances
  hosts: localhost
  connection: local
  tasks:
    - name: Terminate instances that were previously launched
      ec2:
        state: 'absent'
        instance_ids: '{{ ec2.instance_ids }}'

# Start a few existing instances, run some tasks
# and stop the instances

- name: Start sandbox instances
  hosts: localhost
  gather_facts: false
  connection: local
  vars:
    instance_ids:
      - 'i-xxxxxx'
      - 'i-xxxxxx'
      - 'i-xxxxxx'
    region: us-east-1
  tasks:
    - name: Start the sandbox instances
      ec2:
        instance_ids: '{{ instance_ids }}'
        region: '{{ region }}'
        state: running
        wait: True
        vpc_subnet_id: subnet-29e63245
        assign_public_ip: yes
  roles:
    - do_neat_stuff
    - do_more_neat_stuff

- name: Stop sandbox instances
  hosts: localhost
  gather_facts: false
  connection: local
  vars:
    instance_ids:
      - 'i-xxxxxx'
      - 'i-xxxxxx'
      - 'i-xxxxxx'
    region: us-east-1
  tasks:
    - name: Stop the sandbox instances
      ec2:
        instance_ids: '{{ instance_ids }}'
        region: '{{ region }}'
        state: stopped
        wait: True
        vpc_subnet_id: subnet-29e63245
        assign_public_ip: yes

#
# Start stopped instances specified by tag
#
- local_action:
    module: ec2
    instance_tags:
        Name: ExtraPower
    state: running

#
# Restart instances specified by tag
#
- local_action:
    module: ec2
    instance_tags:
        Name: ExtraPower
    state: restarted

#
# Enforce that 5 instances with a tag "foo" are running
# (Highly recommended!)
#

- ec2:
    key_name: mykey
    instance_type: c1.medium
    image: ami-40603AD1
    wait: yes
    group: webserver
    instance_tags:
        foo: bar
    exact_count: 5
    count_tag: foo
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes

#
# Enforce that 5 running instances named "database" with a "dbtype" of "postgres"
#

- ec2:
    key_name: mykey
    instance_type: c1.medium
    image: ami-40603AD1
    wait: yes
    group: webserver
    instance_tags:
        Name: database
        dbtype: postgres
    exact_count: 5
    count_tag:
        Name: database
        dbtype: postgres
    vpc_subnet_id: subnet-29e63245
    assign_public_ip: yes

#
# count_tag complex argument examples
#

    # instances with tag foo
    count_tag:
        foo:

    # instances with tag foo=bar
    count_tag:
        foo: bar

    # instances with tags foo=bar & baz
    count_tag:
        foo: bar
        baz:

    # instances with tags foo & bar & baz=bang
    count_tag:
        - foo
        - bar
        - baz: bang



MAINTAINERS: Lester Wade (@lwade), Tim Gerla (@tgerla), Seth Vidal

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_AMI    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_ami.py)

  Creates or deletes ec2 images.

Options (= is mandatory):

- architecture
        The target architecture of the image to register
        [Default: None]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- delete_snapshot
        Delete snapshots when deregistering the AMI.
        (Choices: yes, no)[Default: no]
- description
        Human-readable string describing the contents and purpose of the AMI.
        [Default: None]
- device_mapping
        List of device hashes/dictionaries with custom configurations (same block-device-mapping parameters)
        Valid properties include: device_name, volume_type, size (in GB), delete_on_termination (boolean), no_device
        (boolean), snapshot_id, iops (for io1 volume_type)
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- image_id
        Image ID to be deregistered.
        [Default: None]
- instance_id
        Instance ID to create the AMI from.
        [Default: None]
- kernel_id
        The target kernel id of the image to register
        [Default: None]
- launch_permissions
        Users and groups that should be able to launch the AMI. Expects dictionary with a key of user_ids and/or
        group_names. user_ids should be a list of account ids. group_name should be a list of groups, "all" is the only
        acceptable value currently.
        [Default: None]
- name
        The name of the new AMI.
        [Default: None]
- no_reboot
        Flag indicating that the bundling process should not attempt to shutdown the instance before bundling. If this
        flag is True, the responsibility of maintaining file system integrity is left to the owner of the instance.
        (Choices: yes, no)[Default: False]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- root_device_name
        The root device name of the image to register
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or deregister/delete AMI.
        (Choices: absent, present)[Default: present]
- tags
        A dictionary of tags to add to the new image; '{"key":"value"}' and '{"key":"value","key":"value"}'
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- virtualization_type
        The virtualization type of the image to register
        [Default: None]
- wait
        Wait for the AMI to be in state 'available' before returning.
        (Choices: yes, no)[Default: no]
- wait_timeout
        How long before wait gives up, in seconds.
        [Default: 300]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Basic AMI Creation
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    instance_id: i-xxxxxx
    wait: yes
    name: newtest
    tags:
      Name: newtest
      Service: TestService
  register: image

# Basic AMI Creation, without waiting
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    region: xxxxxx
    instance_id: i-xxxxxx
    wait: no
    name: newtest
  register: image

# AMI Registration from EBS Snapshot
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    region: xxxxxx
    name: newtest
    state: present
    architecture: x86_64
    virtualization_type: hvm
    root_device_name: /dev/xvda
    device_mapping:
      - device_name: /dev/xvda
        size: 8
        snapshot_id: snap-xxxxxxxx
        delete_on_termination: true
        volume_type: gp2
  register: image

# AMI Creation, with a custom root-device size and another EBS attached
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    instance_id: i-xxxxxx
    name: newtest
    device_mapping:
        - device_name: /dev/sda1
          size: XXX
          delete_on_termination: true
          volume_type: gp2
        - device_name: /dev/sdb
          size: YYY
          delete_on_termination: false
          volume_type: gp2
  register: image

# AMI Creation, excluding a volume attached at /dev/sdb
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    instance_id: i-xxxxxx
    name: newtest
    device_mapping:
        - device_name: /dev/sda1
          size: XXX
          delete_on_termination: true
          volume_type: gp2
        - device_name: /dev/sdb
          no_device: yes
  register: image

# Deregister/Delete AMI (keep associated snapshots)
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    region: xxxxxx
    image_id: "{{ instance.image_id }}"
    delete_snapshot: False
    state: absent

# Deregister AMI (delete associated snapshots too)
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    region: xxxxxx
    image_id: "{{ instance.image_id }}"
    delete_snapshot: True
    state: absent

# Update AMI Launch Permissions, making it public
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    region: xxxxxx
    image_id: "{{ instance.image_id }}"
    state: present
    launch_permissions:
      group_names: ['all']

# Allow AMI to be launched by another account
- ec2_ami:
    aws_access_key: xxxxxxxxxxxxxxxxxxxxxxx
    aws_secret_key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    region: xxxxxx
    image_id: "{{ instance.image_id }}"
    state: present
    launch_permissions:
      user_ids: ['123456789012']

RETURN VALUES:
architecture:
    description: architecture of image
    returned: when AMI is created or already exists
    type: string
    sample: "x86_64"
block_device_mapping:
    description: block device mapping associated with image
    returned: when AMI is created or already exists
    type: a dictionary of block devices
    sample: {
        "/dev/sda1": {
            "delete_on_termination": true,
            "encrypted": false,
            "size": 10,
            "snapshot_id": "snap-1a03b80e7",
            "volume_type": "standard"
        }
    }
creationDate:
    description: creation date of image
    returned: when AMI is created or already exists
    type: string
    sample: "2015-10-15T22:43:44.000Z"
description:
    description: description of image
    returned: when AMI is created or already exists
    type: string
    sample: "nat-server"
hypervisor:
    description: type of hypervisor
    returned: when AMI is created or already exists
    type: string
    sample: "xen"
image_id:
    description: id of the image
    returned: when AMI is created or already exists
    type: string
    sample: "ami-1234abcd"
is_public:
    description: whether image is public
    returned: when AMI is created or already exists
    type: bool
    sample: false
location:
    description: location of image
    returned: when AMI is created or already exists
    type: string
    sample: "315210894379/nat-server"
name:
    description: ami name of image
    returned: when AMI is created or already exists
    type: string
    sample: "nat-server"
ownerId:
    description: owner of image
    returned: when AMI is created or already exists
    type: string
    sample: "435210894375"
platform:
    description: platform of image
    returned: when AMI is created or already exists
    type: string
    sample: null
root_device_name:
    description: root device name of image
    returned: when AMI is created or already exists
    type: string
    sample: "/dev/sda1"
root_device_type:
    description: root device type of image
    returned: when AMI is created or already exists
    type: string
    sample: "ebs"
state:
    description: state of image
    returned: when AMI is created or already exists
    type: string
    sample: "available"
tags:
    description: a dictionary of tags assigned to image
    returned: when AMI is created or already exists
    type: dictionary of tags
    sample: {
        "Env": "devel",
        "Name": "nat-server"
    }
virtualization_type:
    description: image virtualization type
    returned: when AMI is created or already exists
    type: string
    sample: "hvm"
snapshots_deleted:
    description: a list of snapshot ids deleted after deregistering image
    returned: after AMI is deregistered, if 'delete_snapshot' is set to 'yes'
    type: list
    sample: [
        "snap-fbcccb8f",
        "snap-cfe7cdb4"
    ]


MAINTAINERS: Ross Williams (@gunzy83) <gunzy83au@gmail.com>, Constantin Bugneac (@Constantin07) <constantin.bugneac@endava.com>, Evan Duffield (@scicoin-project) <eduffield@iacquire.com>

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_AMI_COPY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_ami_copy.py)

  Copies AMI from a source region to a destination region. *Since version 2.3 this module depends on boto3.*

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- description
        An optional human-readable string describing the contents and purpose of the new AMI.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- encrypted
        Whether or not the destination snapshots of the copied AMI should be encrypted.
        [Default: None]
- kms_key_id
        KMS key id used to encrypt image. If not specified, uses default EBS Customer Master Key (CMK) for your account.
        [Default: None]
- name
        The name of the new AMI to copy. (As of 2.3 the default is 'default', in prior versions it was 'null'.)
        [Default: default]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= source_image_id
        The ID of the AMI in source region that should be copied.

= source_region
        The source region the AMI should be copied from.

- tags
        A hash/dictionary of tags to add to the new copied AMI; '{"key":"value"}' and '{"key":"value","key":"value"}'
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        Wait for the copied AMI to be in state 'available' before returning.
        (Choices: yes, no)[Default: no]
- wait_timeout
        How long before wait gives up, in seconds. (As of 2.3 this option is deprecated. See boto3 Waiters)
        [Default: 1200]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# Basic AMI Copy
- ec2_ami_copy:
    source_region: us-east-1
    region: eu-west-1
    source_image_id: ami-xxxxxxx

# AMI copy wait until available
- ec2_ami_copy:
    source_region: us-east-1
    region: eu-west-1
    source_image_id: ami-xxxxxxx
    wait: yes
  register: image_id

# Named AMI copy
- ec2_ami_copy:
    source_region: us-east-1
    region: eu-west-1
    source_image_id: ami-xxxxxxx
    name: My-Awesome-AMI
    description: latest patch

# Tagged AMI copy
- ec2_ami_copy:
    source_region: us-east-1
    region: eu-west-1
    source_image_id: ami-xxxxxxx
    tags:
        Name: My-Super-AMI
        Patch: 1.2.3

# Encrypted AMI copy
- ec2_ami_copy:
    source_region: us-east-1
    region: eu-west-1
    source_image_id: ami-xxxxxxx
    encrypted: yes

# Encrypted AMI copy with specified key
- ec2_ami_copy:
    source_region: us-east-1
    region: eu-west-1
    source_image_id: ami-xxxxxxx
    encrypted: yes
    kms_key_id: arn:aws:kms:us-east-1:XXXXXXXXXXXX:key/746de6ea-50a4-4bcb-8fbc-e3b29f2d367b


MAINTAINERS: Amir Moulavi <amir.moulavi@gmail.com>, Tim C <defunct@defunct.io>

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_AMI_FIND    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_ami_find.py)

  Returns list of matching AMIs with AMI ID, along with other useful information Can search AMIs with different owners
  Can search by matching tag(s), by AMI name and/or other criteria Results can be sorted and sliced

Options (= is mandatory):

- ami_id
        An AMI ID to match.
        [Default: None]
- ami_tags
        A hash/dictionary of tags to match for the AMI.
        [Default: None]
- architecture
        An architecture type to match (e.g. x86_64).
        [Default: None]
- hypervisor
        A hypervisor type type to match (e.g. xen).
        [Default: None]
- is_public
        Whether or not the image(s) are public.
        (Choices: yes, no)[Default: None]
- name
        An AMI name to match.
        [Default: None]
- no_result_action
        What to do when no results are found.
        'success' reports success and returns an empty array
        'fail' causes the module to report failure
        (Choices: success, fail)[Default: success]
- owner
        Search AMIs owned by the specified owner
        Can specify an AWS account ID, or one of the special IDs 'self', 'amazon' or 'aws-marketplace'
        If not specified, all EC2 AMIs in the specified region will be searched.
        You can include wildcards in many of the search options. An asterisk (*) matches zero or more characters, and a
        question mark (?) matches exactly one character. You can escape special characters using a backslash (\) before
        the character. For example, a value of \*amazon\?\ searches for the literal string *amazon?\.
        [Default: None]
- platform
        Platform type to match.
        [Default: None]
- product_code
        Marketplace product code to match.
        [Default: None]
= region
        The AWS region to use.

- sort
        Optional attribute which with to sort the results.
        If specifying 'tag', the 'tag_name' parameter is required.
        Starting at version 2.1, additional sort choices of architecture, block_device_mapping, creationDate, hypervisor,
        is_public, location, owner_id, platform, root_device_name, root_device_type, state, and virtualization_type are
        supported.
        (Choices: name, description, tag, architecture, block_device_mapping, creationDate, hypervisor, is_public,
        location, owner_id, platform, root_device_name, root_device_type, state, virtualization_type)[Default: None]
- sort_end
        Which result to end with (when sorting).
        Corresponds to Python slice notation.
        [Default: None]
- sort_order
        Order in which to sort results.
        Only used when the 'sort' parameter is specified.
        (Choices: ascending, descending)[Default: ascending]
- sort_start
        Which result to start with (when sorting).
        Corresponds to Python slice notation.
        [Default: None]
- sort_tag
        Tag name with which to sort results.
        Required when specifying 'sort=tag'.
        [Default: None]
- state
        AMI state to match.
        [Default: available]
- virtualization_type
        Virtualization type to match (e.g. hvm).
        [Default: None]
Notes:
  * This module is not backwards compatible with the previous version of the ec2_search_ami module which worked
        only for Ubuntu AMIs listed on cloud-images.ubuntu.com.
  * See the example below for a suggestion of how to search by distro/release.
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Search for the AMI tagged "project:website"
- ec2_ami_find:
    owner: self
    ami_tags:
      project: website
    no_result_action: fail
  register: ami_find

# Search for the latest Ubuntu 14.04 AMI
- ec2_ami_find:
    name: "ubuntu/images/ebs/ubuntu-trusty-14.04-amd64-server-*"
    owner: 099720109477
    sort: name
    sort_order: descending
    sort_end: 1
  register: ami_find

# Launch an EC2 instance
- ec2:
    image: "{{ ami_find.results[0].ami_id }}"
    instance_type: m3.medium
    key_name: mykey
    wait: yes

RETURN VALUES:
ami_id:
    description: id of found amazon image
    returned: when AMI found
    type: string
    sample: "ami-e9095e8c"
architecture:
    description: architecture of image
    returned: when AMI found
    type: string
    sample: "x86_64"
architecture:
    description: architecture of image
    returned: when AMI found
    type: string
    sample: "x86_64"
block_device_mapping:
    description: block device mapping associated with image
    returned: when AMI found
    type: dictionary of block devices
    sample: "{
        '/dev/xvda': {
            'delete_on_termination': true,
            'encrypted': false,
            'size': 8,
            'snapshot_id': 'snap-ca0330b8',
            'volume_type': 'gp2'
    }"
creationDate:
    description: creation date of image
    returned: when AMI found
    type: string
    sample: "2015-10-15T22:43:44.000Z"
description:
    description: description of image
    returned: when AMI found
    type: string
    sample: "test-server01"
hypervisor:
    description: type of hypervisor
    returned: when AMI found
    type: string
    sample: "xen"
is_public:
    description: whether image is public
    returned: when AMI found
    type: bool
    sample: false
location:
    description: location of image
    returned: when AMI found
    type: string
    sample: "435210894375/test-server01-20151015-234343"
name:
    description: ami name of image
    returned: when AMI found
    type: string
    sample: "test-server01-20151015-234343"
owner_id:
    description: owner of image
    returned: when AMI found
    type: string
    sample: "435210894375"
platform:
    description: platform of image
    returned: when AMI found
    type: string
    sample: null
root_device_name:
    description: rood device name of image
    returned: when AMI found
    type: string
    sample: "/dev/xvda"
root_device_type:
    description: rood device type of image
    returned: when AMI found
    type: string
    sample: "ebs"
state:
    description: state of image
    returned: when AMI found
    type: string
    sample: "available"
tags:
    description: tags assigned to image
    returned: when AMI found
    type: dictionary of tags
    sample: "{
        'Environment': 'devel',
        'Name': 'test-server01',
        'Role': 'web'
    }"
virtualization_type:
    description: image virtualization type
    returned: when AMI found
    type: string
    sample: "hvm"


MAINTAINERS: Tom Bamford (@tombamford)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_AMI_SEARCH    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/_ec2_ami_search.py)

  Look up the most recent AMI on AWS for a given operating system. Returns `ami', `aki', `ari', `serial', `tag' If there
  is no AKI or ARI associated with an image, these will be `null'. Only supports images from cloud-images.ubuntu.com
  Example output: `{"ami": "ami-69f5a900", "changed": false, "aki": "aki-88aa75e1", "tag": "release", "ari": null,
  "serial": "20131024"}'

DEPRECATED: 
Use M(ec2_ami_find) instead.

Options (= is mandatory):

- arch
        CPU architecture
        (Choices: i386, amd64)[Default: amd64]
= distro
        Linux distribution (e.g., `ubuntu')
        (Choices: ubuntu)
- region
        EC2 region
        (Choices: ap-northeast-1, ap-southeast-1, ap-northeast-2, ap-southeast-2, ca-central-1, eu-central-1, eu-west-1,
        eu-west-2, sa-east-1, us-east-1, us-east-2, us-west-1, us-west-2, us-gov-west-1)[Default: us-east-1]
= release
        short name of the release (e.g., `precise')

- store
        Back-end store for instance
        (Choices: ebs, ebs-io1, ebs-ssd, instance-store)[Default: ebs]
- stream
        Type of release.
        (Choices: server, desktop)[Default: server]
- virt
        virutalization type
        (Choices: paravirtual, hvm)[Default: paravirtual]
EXAMPLES:
- name: Launch an Ubuntu 12.04 (Precise Pangolin) EC2 instance
  hosts: 127.0.0.1
  connection: local
  tasks:
  - name: Get the Ubuntu precise AMI
    ec2_ami_search:
      distro: ubuntu
      release: precise
      region: us-west-1
      store: instance-store
    register: ubuntu_image

  - name: Start the EC2 instance
    ec2:
      image: "{{ ubuntu_image.ami }}"
      instance_type: m1.small
      key_name: mykey


MAINTAINERS: Ansible Core Team (deprecated)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> EC2_ASG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_asg.py)

  Can create or delete AWS Autoscaling Groups Works with the ec2_lc module to manage Launch Configurations

Options (= is mandatory):

- availability_zones
        List of availability zone names in which to create the group.  Defaults to all the availability zones in the
        region if vpc_zone_identifier is not set.
        [Default: (null)]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- default_cooldown
        The number of seconds after a scaling activity completes before another can begin.
        [Default: 300 seconds]
- desired_capacity
        Desired number of instances in group, if unspecified then the current group value will be used.
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- health_check_period
        Length of time in seconds after a new EC2 instance comes into service that Auto Scaling starts checking its
        health.
        [Default: 500 seconds]
- health_check_type
        The service you want the health status from, Amazon EC2 or Elastic Load Balancer.
        (Choices: EC2, ELB)[Default: EC2]
= launch_config_name
        Name of the Launch configuration to use for the group. See the ec2_lc module for managing these.

- lc_check
        Check to make sure instances that are being replaced with replace_instances do not already have the current
        launch_config.
        [Default: True]
- load_balancers
        List of ELB names to use for the group
        [Default: (null)]
- max_size
        Maximum number of instances in group, if unspecified then the current group value will be used.
        [Default: (null)]
- min_size
        Minimum number of instances in group, if unspecified then the current group value will be used.
        [Default: (null)]
= name
        Unique name for group to be created or deleted

- notification_topic
        A SNS topic ARN to send auto scaling notifications to.
        [Default: None]
- notification_types
        A list of auto scaling events to trigger notifications on.
        [Default: [u'autoscaling:EC2_INSTANCE_LAUNCH', u'autoscaling:EC2_INSTANCE_LAUNCH_ERROR',
        u'autoscaling:EC2_INSTANCE_TERMINATE', u'autoscaling:EC2_INSTANCE_TERMINATE_ERROR']]
- placement_group
        Physical location of your cluster placement group created in Amazon EC2.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- replace_all_instances
        In a rolling fashion, replace all instances with an old launch configuration with one from the current launch
        configuration.
        [Default: False]
- replace_batch_size
        Number of instances you'd like to replace at a time.  Used with replace_all_instances.
        [Default: 1]
- replace_instances
        List of instance_ids belonging to the named ASG that you would like to terminate and be replaced with instances
        matching the current launch configuration.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        register or deregister the instance
        (Choices: present, absent)[Default: present]
- suspend_processes
        A list of scaling processes to suspend.
        (Choices: Launch, Terminate, HealthCheck, ReplaceUnhealthy, AZRebalance, AlarmNotification, ScheduledActions,
        AddToLoadBalancer)[Default: []]
- tags
        A list of tags to add to the Auto Scale Group. Optional key is 'propagate_at_launch', which defaults to true.
        [Default: None]
- termination_policies
        An ordered list of criteria used for selecting instances to be removed from the Auto Scaling group when reducing
        capacity.
        For 'Default', when used to create a new autoscaling group, the "Default"i value is used. When used to change an
        existent autoscaling group, the current termination policies are maintained.
        (Choices: OldestInstance, NewestInstance, OldestLaunchConfiguration, ClosestToNextInstanceHour, Default)[Default:
        Default]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_zone_identifier
        List of VPC subnets to use
        [Default: None]
- wait_for_instances
        Wait for the ASG instances to be in a ready state before exiting.  If instances are behind an ELB, it will wait
        until the ELB determines all instances have a lifecycle_state of  "InService" and  a health_status of "Healthy".
        [Default: True]
- wait_timeout
        how long before wait instances to become viable when replaced.  Used in conjunction with instance_ids option.
        [Default: 300]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Basic configuration

- ec2_asg:
    name: special
    load_balancers: [ 'lb1', 'lb2' ]
    availability_zones: [ 'eu-west-1a', 'eu-west-1b' ]
    launch_config_name: 'lc-1'
    min_size: 1
    max_size: 10
    desired_capacity: 5
    vpc_zone_identifier: [ 'subnet-abcd1234', 'subnet-1a2b3c4d' ]
    tags:
      - environment: production
        propagate_at_launch: no

# Rolling ASG Updates

# Below is an example of how to assign a new launch config to an ASG and terminate old instances.
#
# All instances in "myasg" that do not have the launch configuration named "my_new_lc" will be terminated in
# a rolling fashion with instances using the current launch configuration, "my_new_lc".
#
# This could also be considered a rolling deploy of a pre-baked AMI.
#
# If this is a newly created group, the instances will not be replaced since all instances
# will have the current launch configuration.

- name: create launch config
  ec2_lc:
    name: my_new_lc
    image_id: ami-lkajsf
    key_name: mykey
    region: us-east-1
    security_groups: sg-23423
    instance_type: m1.small
    assign_public_ip: yes

- ec2_asg:
    name: myasg
    launch_config_name: my_new_lc
    health_check_period: 60
    health_check_type: ELB
    replace_all_instances: yes
    min_size: 5
    max_size: 5
    desired_capacity: 5
    region: us-east-1

# To only replace a couple of instances instead of all of them, supply a list
# to "replace_instances":

- ec2_asg:
    name: myasg
    launch_config_name: my_new_lc
    health_check_period: 60
    health_check_type: ELB
    replace_instances:
    - i-b345231
    - i-24c2931
    min_size: 5
    max_size: 5
    desired_capacity: 5
    region: us-east-1


MAINTAINERS: Gareth Rushgrove (@garethr)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_ASG_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_asg_facts.py)

  Gather facts about ec2 Auto Scaling Groups (ASGs) in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- name
        The prefix or name of the auto scaling group(s) you are searching for.
        Note: This is a regular expression match with implicit '^' (beginning of string). Append '$' for a complete name
        match.
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- tags
        A dictionary/hash of tags in the format { tag1_name: 'tag1_value', tag2_name: 'tag2_value' } to match against the
        auto scaling group(s) you are searching for.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Find all groups
- ec2_asg_facts:
  register: asgs

# Find a group with matching name/prefix
- ec2_asg_facts:
    name: public-webserver-asg
  register: asgs

# Find a group with matching tags
- ec2_asg_facts:
    tags:
      project: webapp
      env: production
  register: asgs

# Find a group with matching name/prefix and tags
- ec2_asg_facts:
    name: myproject
    tags:
      env: production
  register: asgs

# Fail if no groups are found
- ec2_asg_facts:
    name: public-webserver-asg
  register: asgs
  failed_when: "{{ asgs.results | length == 0 }}"

# Fail if more than 1 group is found
- ec2_asg_facts:
    name: public-webserver-asg
  register: asgs
  failed_when: "{{ asgs.results | length > 1 }}"

RETURN VALUES:
---
auto_scaling_group_arn:
    description: The Amazon Resource Name of the ASG
    returned: success
    type: string
    sample: "arn:aws:autoscaling:us-west-2:1234567890:autoScalingGroup:10787c52-0bcb-427d-82ba-c8e4b008ed2e:autoScalingGroupName/public-webapp-production-1"
auto_scaling_group_name:
    description: Name of autoscaling group
    returned: success
    type: str
    sample: "public-webapp-production-1"
availability_zones:
    description: List of Availability Zones that are enabled for this ASG.
    returned: success
    type: list
    sample: ["us-west-2a", "us-west-2b", "us-west-2a"]
created_time:
    description: The date and time this ASG was created, in ISO 8601 format.
    returned: success
    type: string
    sample: "2015-11-25T00:05:36.309Z"
default_cooldown:
    description: The default cooldown time in seconds.
    returned: success
    type: int
    sample: 300
desired_capacity:
    description: The number of EC2 instances that should be running in this group.
    returned: success
    type: int
    sample: 3
health_check_period:
    description: Length of time in seconds after a new EC2 instance comes into service that Auto Scaling starts checking its health.
    returned: success
    type: int
    sample: 30
health_check_type:
    description: The service you want the health status from, one of "EC2" or "ELB".
    returned: success
    type: str
    sample: "ELB"
instances:
    description: List of EC2 instances and their status as it relates to the ASG.
    returned: success
    type: list
    sample: [
        {
            "availability_zone": "us-west-2a",
            "health_status": "Healthy",
            "instance_id": "i-es22ad25",
            "launch_configuration_name": "public-webapp-production-1",
            "lifecycle_state": "InService",
            "protected_from_scale_in": "false"
        }
    ]
launch_configuration_name:
    description: Name of launch configuration associated with the ASG.
    returned: success
    type: str
    sample: "public-webapp-production-1"
load_balancer_names:
    description: List of load balancers names attached to the ASG.
    returned: success
    type: list
    sample: ["elb-webapp-prod"]
max_size:
    description: Maximum size of group
    returned: success
    type: int
    sample: 3
min_size:
    description: Minimum size of group
    returned: success
    type: int
    sample: 1
new_instances_protected_from_scale_in:
    description: Whether or not new instances a protected from automatic scaling in.
    returned: success
    type: boolean
    sample: "false"
placement_group:
    description: Placement group into which instances are launched, if any.
    returned: success
    type: str
    sample: None
status:
    description: The current state of the group when DeleteAutoScalingGroup is in progress.
    returned: success
    type: str
    sample: None
tags:
    description: List of tags for the ASG, and whether or not each tag propagates to instances at launch.
    returned: success
    type: list
    sample: [
        {
            "key": "Name",
            "value": "public-webapp-production-1",
            "resource_id": "public-webapp-production-1",
            "resource_type": "auto-scaling-group",
            "propagate_at_launch": "true"
        },
        {
            "key": "env",
            "value": "production",
            "resource_id": "public-webapp-production-1",
            "resource_type": "auto-scaling-group",
            "propagate_at_launch": "true"
        }
    ]
termination_policies:
    description: A list of termination policies for the group.
    returned: success
    type: str
    sample: ["Default"]


MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_CUSTOMER_GATEWAY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_customer_gateway.py)

  Manage an AWS customer gateway

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- bgp_asn
        Border Gateway Protocol (BGP) Autonomous System Number (ASN), required when state=present.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= ip_address
        Internet-routable IP address for customers gateway, must be a static address.

= name
        Name of the customer gateway.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or terminate the Customer Gateway.
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * You cannot create more than one customer gateway with the same IP address. If you run an identical request more
        than one time, the first request creates the customer gateway, and subsequent requests return information
        about the existing customer gateway. The subsequent requests do not create new customer gateway resources.
  * Return values contain customer_gateway and customer_gateways keys which are identical dicts. You should use
        customer_gateway. See https://github.com/ansible/ansible-modules-extras/issues/2773 for details.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, python >= 2.6

EXAMPLES:

# Create Customer Gateway
- ec2_customer_gateway:
    bgp_asn: 12345
    ip_address: 1.2.3.4
    name: IndianapolisOffice
    region: us-east-1
  register: cgw

# Delete Customer Gateway
- ec2_customer_gateway:
    ip_address: 1.2.3.4
    name: IndianapolisOffice
    state: absent
    region: us-east-1
  register: cgw

RETURN VALUES:
gateway.customer_gateways:
    description: details about the gateway that was created.
    returned: success
    type: complex
    contains:
        bgp_asn:
            description: The Border Gateway Autonomous System Number.
            returned: when exists and gateway is available.
            sample: 65123
            type: string
        customer_gateway_id:
            description: gateway id assigned by amazon.
            returned: when exists and gateway is available.
            sample: cgw-cb6386a2
            type: string
        ip_address:
            description: ip address of your gateway device.
            returned: when exists and gateway is available.
            sample: 1.2.3.4
            type: string
        state:
            description: state of gateway.
            returned: when gateway exists and is available.
            state: available
            type: string
        tags:
            description: any tags on the gateway.
            returned: when gateway exists and is available, and when tags exist.
            state: available
            type: string
        type:
            description: encryption type.
            returned: when gateway exists and is available.
            sample: ipsec.1
            type: string


MAINTAINERS: Michael Baydoun (@MichaelBaydoun)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_EIP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_eip.py)

  This module can allocate or release an EIP. This module can associate/disassociate an EIP with instances or network
  interfaces.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- device_id
        The id of the device for the EIP. Can be an EC2 Instance id or Elastic Network Interface (ENI) id.
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- in_vpc
        allocate an EIP inside a VPC or not
        [Default: False]
- private_ip_address
        The primary or secondary private IP address to associate with the Elastic IP address.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- public_ip
        The IP address of a previously allocated EIP.
        If present and device is specified, the EIP is associated with the device.
        If absent and device is specified, the EIP is disassociated from the device.
        [Default: (null)]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- release_on_disassociation
        whether or not to automatically release the EIP when it is disassociated
        [Default: False]
- reuse_existing_ip_allowed
        Reuse an EIP that is not associated to a device (when available), instead of allocating a new one.
        [Default: False]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        If present, allocate an EIP or associate an existing EIP with a device.
        If absent, disassociate the EIP from the device and optionally release it.
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * This module will return `public_ip' on success, which will contain the public IP address associated with the
        device.
  * There may be a delay between the time the EIP is assigned and when the cloud instance is reachable via the new
        address. Use wait_for and pause to delay further playbook execution until the instance is reachable, if
        necessary.
  * This module returns multiple changed statuses on disassociation or release. It returns an overall status based
        on any changes occurring. It also returns individual changed statuses for disassociation and release.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

- name: associate an elastic IP with an instance
  ec2_eip:
    device_id: i-1212f003
    ip: 93.184.216.119

- name: associate an elastic IP with a device
  ec2_eip:
    device_id: eni-c8ad70f3
    ip: 93.184.216.119

- name: disassociate an elastic IP from an instance
  ec2_eip:
    device_id: i-1212f003
    ip: 93.184.216.119
    state: absent

- name: disassociate an elastic IP with a device
  ec2_eip:
    device_id: eni-c8ad70f3
    ip: 93.184.216.119
    state: absent

- name: allocate a new elastic IP and associate it with an instance
  ec2_eip:
    device_id: i-1212f003

- name: allocate a new elastic IP without associating it to anything
  ec2_eip:
    state: present
  register: eip

- name: output the IP
  debug:
    msg: "Allocated IP is {{ eip.public_ip }}"

- name: another way of allocating an elastic IP without associating it to anything
  ec2_eip:
    state: 'present'

- name: provision new instances with ec2
  ec2:
    keypair: mykey
    instance_type: c1.medium
    image: ami-40603AD1
    wait: yes
    group: webserver
    count: 3
  register: ec2

- name: associate new elastic IPs with each of the instances
  ec2_eip:
    device_id: "{{ item }}"
  with_items: "{{ ec2.instance_ids }}"

- name: allocate a new elastic IP inside a VPC in us-west-2
  ec2_eip:
    region: us-west-2
    in_vpc: yes
  register: eip

- name: output the IP
  debug:
    msg: "Allocated IP inside a VPC is {{ eip.public_ip }}"


MAINTAINERS: Rick Mendes (@rickmendes) <rmendes@illumina.com>

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_ELB    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_elb.py)

  This module de-registers or registers an AWS EC2 instance from the ELBs that it belongs to. Returns fact "ec2_elbs"
  which is a list of elbs attached to the instance if state=absent is passed as an argument. Will be marked changed when
  called only if there are ELBs found to operate on.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_elbs
        List of ELB names, required for registration. The ec2_elbs fact should be used if there was a previous de-
        register.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- enable_availability_zone
        Whether to enable the availability zone of the instance on the target ELB if the availability zone has not
        already been enabled. If set to no, the task will fail if the availability zone is not enabled on the ELB.
        (Choices: yes, no)[Default: True]
= instance_id
        EC2 Instance ID

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        register or deregister the instance
        (Choices: present, absent)
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        Wait for instance registration or deregistration to complete successfully before returning.
        (Choices: yes, no)[Default: True]
- wait_timeout
        Number of seconds to wait for an instance to change state. If 0 then this module may return an error if a
        transient error occurs. If non-zero then any transient errors are ignored until the timeout is reached. Ignored
        when wait=no.
        [Default: 0]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# basic pre_task and post_task example
pre_tasks:
  - name: Gathering ec2 facts
    action: ec2_facts
  - name: Instance De-register
    local_action:
      module: ec2_elb
      instance_id: "{{ ansible_ec2_instance_id }}"
      state: absent
roles:
  - myrole
post_tasks:
  - name: Instance Register
    local_action:
      module: ec2_elb
      instance_id: "{{ ansible_ec2_instance_id }}"
      ec2_elbs: "{{ item }}"
      state: present
    with_items: "{{ ec2_elbs }}"


MAINTAINERS: John Jarvis (@jarv)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_ELB_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_elb_facts.py)

  Gather facts about EC2 Elastic Load Balancers in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- names
        List of ELB names to gather facts about. Pass this option to gather facts about a set of ELBs, otherwise, all
        ELBs are returned.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.
# Output format tries to match ec2_elb_lb module input parameters

# Gather facts about all ELBs
- action:
    module: ec2_elb_facts
  register: elb_facts

- action:
    module: debug
    msg: "{{ item.dns_name }}"
  with_items: "{{ elb_facts.elbs }}"

# Gather facts about a particular ELB
- action:
    module: ec2_elb_facts
    names: frontend-prod-elb
  register: elb_facts

- action:
    module: debug
    msg: "{{ elb_facts.elbs.0.dns_name }}"

# Gather facts about a set of ELBs
- action:
    module: ec2_elb_facts
    names:
    - frontend-prod-elb
    - backend-prod-elb
  register: elb_facts

- action:
    module: debug
    msg: "{{ item.dns_name }}"
  with_items: "{{ elb_facts.elbs }}"



MAINTAINERS: Michael Schultz (github.com/mjschultz), Fernando Jose Pando (@nand0p)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_ELB_LB    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_elb_lb.py)

  Returns information about the load balancer. Will be marked changed when called only if state is changed.

Options (= is mandatory):

- access_logs
        An associative array of access logs configuration settings (see example)
        [Default: None]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- connection_draining_timeout
        Wait a specified timeout allowing connections to drain before terminating an instance
        [Default: (null)]
- cross_az_load_balancing
        Distribute load across all configured Availability Zones
        (Choices: yes, no)[Default: no]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- health_check
        An associative array of health check configuration settings (see example)
        [Default: None]
- idle_timeout
        ELB connections from clients and to servers are timed out after this amount of time
        [Default: (null)]
- instance_ids
        List of instance ids to attach to this ELB
        [Default: False]
- listeners
        List of ports/protocols for this ELB to listen on (see example)
        [Default: (null)]
= name
        The name of the ELB

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- purge_instance_ids
        Purge existing instance ids on ELB that are not found in instance_ids
        [Default: False]
- purge_listeners
        Purge existing listeners on ELB that are not found in listeners
        [Default: True]
- purge_subnets
        Purge existing subnet on ELB that are not found in subnets
        [Default: False]
- purge_zones
        Purge existing availability zones on ELB that are not found in zones
        [Default: False]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- scheme
        The scheme to use when creating the ELB. For a private VPC-visible ELB use 'internal'.
        [Default: internet-facing]
- security_group_ids
        A list of security groups to apply to the elb
        [Default: None]
- security_group_names
        A list of security group names to apply to the elb
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Create or destroy the ELB
        (Choices: present, absent)
- stickiness
        An associative array of stickiness policy settings. Policy will be applied to all listeners ( see example )
        [Default: (null)]
- subnets
        A list of VPC subnets to use when creating ELB. Zones should be empty if using this.
        [Default: None]
- tags
        An associative array of tags. To delete all tags, supply an empty dict.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        When specified, Ansible will check the status of the load balancer to ensure it has been successfully removed
        from AWS.
        (Choices: yes, no)[Default: False]
- wait_timeout
        Used in conjunction with wait. Number of seconds to wait for the elb to be terminated. A maximum of 600 seconds
        (10 minutes) is allowed.
        [Default: 60]
- zones
        List of availability zones to enable on this ELB
        [Default: (null)]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: None of these examples set aws_access_key, aws_secret_key, or region.
# It is assumed that their matching environment variables are set.

# Basic provisioning example (non-VPC)

- local_action:
    module: ec2_elb_lb
    name: "test-please-delete"
    state: present
    zones:
      - us-east-1a
      - us-east-1d
    listeners:
      - protocol: http # options are http, https, ssl, tcp
        load_balancer_port: 80
        instance_port: 80
        proxy_protocol: True
      - protocol: https
        load_balancer_port: 443
        instance_protocol: http # optional, defaults to value of protocol setting
        instance_port: 80
        # ssl certificate required for https or ssl
        ssl_certificate_id: "arn:aws:iam::123456789012:server-certificate/company/servercerts/ProdServerCert"

# Internal ELB example

- local_action:
    module: ec2_elb_lb
    name: "test-vpc"
    scheme: internal
    state: present
    instance_ids:
      - i-abcd1234
    purge_instance_ids: true
    subnets:
      - subnet-abcd1234
      - subnet-1a2b3c4d
    listeners:
      - protocol: http # options are http, https, ssl, tcp
        load_balancer_port: 80
        instance_port: 80

# Configure a health check and the access logs
- local_action:
    module: ec2_elb_lb
    name: "test-please-delete"
    state: present
    zones:
      - us-east-1d
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80
    health_check:
        ping_protocol: http # options are http, https, ssl, tcp
        ping_port: 80
        ping_path: "/index.html" # not required for tcp or ssl
        response_timeout: 5 # seconds
        interval: 30 # seconds
        unhealthy_threshold: 2
        healthy_threshold: 10
    access_logs:
        interval: 5 # minutes (defaults to 60)
        s3_location: "my-bucket" # This value is required if access_logs is set
        s3_prefix: "logs"

# Ensure ELB is gone
- local_action:
    module: ec2_elb_lb
    name: "test-please-delete"
    state: absent

# Ensure ELB is gone and wait for check (for default timeout)
- local_action:
    module: ec2_elb_lb
    name: "test-please-delete"
    state: absent
    wait: yes

# Ensure ELB is gone and wait for check with timeout value
- local_action:
    module: ec2_elb_lb
    name: "test-please-delete"
    state: absent
    wait: yes
    wait_timeout: 600

# Normally, this module will purge any listeners that exist on the ELB
# but aren't specified in the listeners parameter. If purge_listeners is
# false it leaves them alone
- local_action:
    module: ec2_elb_lb
    name: "test-please-delete"
    state: present
    zones:
      - us-east-1a
      - us-east-1d
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80
    purge_listeners: no

# Normally, this module will leave availability zones that are enabled
# on the ELB alone. If purge_zones is true, then any extraneous zones
# will be removed
- local_action:
    module: ec2_elb_lb
    name: "test-please-delete"
    state: present
    zones:
      - us-east-1a
      - us-east-1d
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80
    purge_zones: yes

# Creates a ELB and assigns a list of subnets to it.
- local_action:
    module: ec2_elb_lb
    state: present
    name: 'New ELB'
    security_group_ids: 'sg-123456, sg-67890'
    region: us-west-2
    subnets: 'subnet-123456,subnet-67890'
    purge_subnets: yes
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80

# Create an ELB with connection draining, increased idle timeout and cross availability
# zone load balancing
- local_action:
    module: ec2_elb_lb
    name: "New ELB"
    state: present
    connection_draining_timeout: 60
    idle_timeout: 300
    cross_az_load_balancing: "yes"
    region: us-east-1
    zones:
      - us-east-1a
      - us-east-1d
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80

# Create an ELB with load balancer stickiness enabled
- local_action:
    module: ec2_elb_lb
    name: "New ELB"
    state: present
    region: us-east-1
    zones:
      - us-east-1a
      - us-east-1d
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80
    stickiness:
      type: loadbalancer
      enabled: yes
      expiration: 300

# Create an ELB with application stickiness enabled
- local_action:
    module: ec2_elb_lb
    name: "New ELB"
    state: present
    region: us-east-1
    zones:
      - us-east-1a
      - us-east-1d
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80
    stickiness:
      type: application
      enabled: yes
      cookie: SESSIONID

# Create an ELB and add tags
- local_action:
    module: ec2_elb_lb
    name: "New ELB"
    state: present
    region: us-east-1
    zones:
      - us-east-1a
      - us-east-1d
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80
    tags:
      Name: "New ELB"
      stack: "production"
      client: "Bob"

# Delete all tags from an ELB
- local_action:
    module: ec2_elb_lb
    name: "New ELB"
    state: present
    region: us-east-1
    zones:
      - us-east-1a
      - us-east-1d
    listeners:
      - protocol: http
        load_balancer_port: 80
        instance_port: 80
    tags: {}


MAINTAINERS: Jim Dalton (@jsdalton)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_ENI    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_eni.py)

  Create and optionally attach an Elastic Network Interface (ENI) to an instance. If an ENI ID or private_ip is
  provided, the existing ENI (if any) will be modified. The 'attached' parameter controls the attachment status       of
  the network interface.

Options (= is mandatory):

- attached
        Specifies if network interface should be attached or detached from instance. If ommited, attachment status
        won't change
        [Default: True]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- delete_on_termination
        Delete the interface when the instance it is attached to is terminated. You can only specify this flag when the
        interface is being modified, not on creation.
        [Default: (null)]
- description
        Optional description of the ENI.
        [Default: None]
- device_index
        The index of the device for the network interface attachment on the instance.
        [Default: 0]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- eni_id
        The ID of the ENI
        [Default: None]
- force_detach
        Force detachment of the interface. This applies either when explicitly detaching the interface by setting
        instance_id to None or when deleting an interface with state=absent.
        [Default: False]
- instance_id
        Instance ID that you wish to attach ENI to. Since version 2.2, use the 'attached' parameter to attach or
        detach an ENI. Prior to 2.2, to detach an ENI from an instance, use 'None'.
        [Default: None]
- private_ip_address
        Private IP address.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- secondary_private_ip_address_count
        The number of secondary IP addresses to assign to the network interface. This option is mutually exclusive of
        secondary_private_ip_addresses
        [Default: (null)]
- secondary_private_ip_addresses
        A list of IP addresses to assign as secondary IP addresses to the network interface. This option is mutually
        exclusive of secondary_private_ip_address_count
        [Default: (null)]
- security_groups
        List of security groups associated with the interface. Only used when state=present. Since version 2.2, you
        can specify security groups by ID or by name or a combination of both. Prior to 2.2, you can specify only by ID.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- source_dest_check
        By default, interfaces perform source/destination checks. NAT instances however need this check to be disabled.
        You can only specify this flag when the interface is being modified, not on creation.
        [Default: (null)]
- state
        Create or delete ENI
        (Choices: present, absent)[Default: present]
= subnet_id
        ID of subnet in which to create the ENI. Only required when state=present.

- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Create an ENI. As no security group is defined, ENI will be created in default security group
- ec2_eni:
    private_ip_address: 172.31.0.20
    subnet_id: subnet-xxxxxxxx
    state: present

# Create an ENI and attach it to an instance
- ec2_eni:
    instance_id: i-xxxxxxx
    device_index: 1
    private_ip_address: 172.31.0.20
    subnet_id: subnet-xxxxxxxx
    state: present

# Create an ENI with two secondary addresses
- ec2_eni:
    subnet_id: subnet-xxxxxxxx
    state: present
    secondary_private_ip_address_count: 2

# Assign a secondary IP address to an existing ENI
# This will purge any existing IPs
- ec2_eni:
    subnet_id: subnet-xxxxxxxx
    eni_id: eni-yyyyyyyy
    state: present
    secondary_private_ip_addresses:
      - 172.16.1.1

# Remove any secondary IP addresses from an existing ENI
- ec2_eni:
    subnet_id: subnet-xxxxxxxx
    eni_id: eni-yyyyyyyy
    state: present
    secondary_private_ip_addresses:
      -

# Destroy an ENI, detaching it from any instance if necessary
- ec2_eni:
    eni_id: eni-xxxxxxx
    force_detach: yes
    state: absent

# Update an ENI
- ec2_eni:
    eni_id: eni-xxxxxxx
    description: "My new description"
    state: present

# Detach an ENI from an instance
- ec2_eni:
    eni_id: eni-xxxxxxx
    instance_id: None
    state: present

### Delete an interface on termination
# First create the interface
- ec2_eni:
    instance_id: i-xxxxxxx
    device_index: 1
    private_ip_address: 172.31.0.20
    subnet_id: subnet-xxxxxxxx
    state: present
  register: eni

# Modify the interface to enable the delete_on_terminaton flag
- ec2_eni:
    eni_id: "{{ eni.interface.id }}"
    delete_on_termination: true


RETURN VALUES:
interface:
  description: Network interface attributes
  returned: when state != absent
  type: dictionary
  contains:
    description:
      description: interface description
      type: string
      sample: Firewall network interface
    groups:
      description: list of security groups
      type: list of dictionaries
      sample: [ { "sg-f8a8a9da": "default" } ]
    id:
      description: network interface id
      type: string
      sample: "eni-1d889198"
    mac_address:
      description: interface's physical address
      type: string
      sample: "00:00:5E:00:53:23"
    owner_id:
      description: aws account id
      type: string
      sample: 812381371
    private_ip_address:
      description: primary ip address of this interface
      type: string
      sample: 10.20.30.40
    private_ip_addresses:
      description: list of all private ip addresses associated to this interface
      type: list of dictionaries
      sample: [ { "primary_address": true, "private_ip_address": "10.20.30.40" } ]
    source_dest_check:
      description: value of source/dest check flag
      type: boolean
      sample: True
    status:
      description: network interface status
      type: string
      sample: "pending"
    subnet_id:
      description: which vpc subnet the interface is bound
      type: string
      sample: subnet-b0a0393c
    vpc_id:
      description: which vpc this network interface is bound
      type: string
      sample: vpc-9a9a9da



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_ENI_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_eni_facts.py)

  Gather facts about ec2 ENI interfaces in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeNetworkInterfaces.html for possible filters.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all ENIs
- ec2_eni_facts:

# Gather facts about a particular ENI
- ec2_eni_facts:
    filters:
      network-interface-id: eni-xxxxxxx



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_facts.py)

  This module fetches data from the metadata servers in ec2 (aws) as per
  http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html. The module must be called from within
  the EC2 instance itself.

Options (= is mandatory):

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
Notes:
  * Parameters to filter on ec2_facts may be added later.
EXAMPLES:
# Conditional example
- name: Gather facts
  ec2_facts:

- name: Conditional
  debug:
    msg: "This instance is a t1.micro"
  when: ansible_ec2_instance_type == "t1.micro"


MAINTAINERS: Silviu Dicu (@silviud) <silviudicu@gmail.com>

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_group.py)

  maintains ec2 security groups. This module has a dependency on python-boto >= 2.5

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- description
        Description of the security group. Required when `state' is `present'.
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= name
        Name of the security group.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- purge_rules
        Purge existing rules on security group that are not found in rules
        [Default: true]
- purge_rules_egress
        Purge existing rules_egress on security group that are not found in rules_egress
        [Default: true]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- rules
        List of firewall inbound rules to enforce in this group (see example). If none are supplied, a default all-out
        rule is assumed. If an empty list is supplied, no inbound rules will be enabled. Rules list may include its own
        name in `group_name`. This allows idempotent loopback additions (e.g. allow group to acccess itself).
        [Default: (null)]
- rules_egress
        List of firewall outbound rules to enforce in this group (see example). If none are supplied, a default all-out
        rule is assumed. If an empty list is supplied, no outbound rules will be enabled.
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or delete a security group
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_id
        ID of the VPC to create the group in.
        [Default: (null)]
Notes:
  * If a rule declares a group_name and that group doesn't exist, it will be automatically created. In that case,
        group_desc should be provided as well. The module will refuse to create a depended-on group without a
        description.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
- name: example ec2 group
  ec2_group:
    name: example
    description: an example EC2 group
    vpc_id: 12345
    region: eu-west-1a
    aws_secret_key: SECRET
    aws_access_key: ACCESS
    rules:
      - proto: tcp
        from_port: 80
        to_port: 80
        cidr_ip: 0.0.0.0/0
      - proto: tcp
        from_port: 22
        to_port: 22
        cidr_ip: 10.0.0.0/8
      - proto: tcp
        from_port: 443
        to_port: 443
        group_id: amazon-elb/sg-87654321/amazon-elb-sg
      - proto: tcp
        from_port: 3306
        to_port: 3306
        group_id: 123412341234/sg-87654321/exact-name-of-sg
      - proto: udp
        from_port: 10050
        to_port: 10050
        cidr_ip: 10.0.0.0/8
      - proto: udp
        from_port: 10051
        to_port: 10051
        group_id: sg-12345678
      - proto: icmp
        from_port: 8 # icmp type, -1 = any type
        to_port:  -1 # icmp subtype, -1 = any subtype
        cidr_ip: 10.0.0.0/8
      - proto: all
        # the containing group name may be specified here
        group_name: example
    rules_egress:
      - proto: tcp
        from_port: 80
        to_port: 80
        cidr_ip: 0.0.0.0/0
        group_name: example-other
        # description to use if example-other needs to be created
        group_desc: other example EC2 group


MAINTAINERS: Andrew de Quincey (@adq)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_GROUP_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_group_facts.py)

  Gather facts about ec2 security groups in AWS.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeSecurityGroups.html for       possible
        filters. Filter names and values are case sensitive. You can also use underscores (_)       instead of dashes (-)
        in the filter keys, which will take precedence in case of conflict.
        [Default: {}]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * By default, the module will return all security groups. To limit results use the appropriate filters.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all security groups
- ec2_group_facts:

# Gather facts about all security groups in a specific VPC
- ec2_group_facts:
    filters:
      vpc-id: vpc-12345678

# Gather facts about all security groups in a specific VPC
- ec2_group_facts:
    filters:
      vpc-id: vpc-12345678

# Gather facts about a security group
- ec2_group_facts:
    filters:
      group-name: example-1

# Gather facts about a security group by id
- ec2_group_facts:
    filters:
      group-id: sg-12345678

# Gather facts about a security group with multiple filters, also mixing the use of underscores as filter keys
- ec2_group_facts:
    filters:
      group_id: sg-12345678
      vpc-id: vpc-12345678

# Gather facts about various security groups
- ec2_group_facts:
    filters:
      group-name:
        - example-1
        - example-2
        - example-3

# Gather facts about any security group with a tag key Name and value Example. The quotes around 'tag:name' are important because of the colon in the value
- ec2_group_facts:
    filters:
      "tag:Name": Example

RETURN VALUES:
security_groups:
    description: Security groups that match the provided filters. Each element consists of a dict with all the information related to that security group.
    type: list
    sample:


MAINTAINERS: Henrique Rodrigues (github.com/Sodki)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_KEY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_key.py)

  maintains ec2 key pairs. This module has a dependency on python-boto >= 2.5

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- force
        Force overwrite of already existing key pair if key has changed.
        [Default: True]
- key_material
        Public key material.
        [Default: (null)]
= name
        Name of the key pair.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        create or delete keypair
        [Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        Wait for the specified action to complete before returning.
        [Default: False]
- wait_timeout
        How long before wait gives up, in seconds
        [Default: 300]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: None of these examples set aws_access_key, aws_secret_key, or region.
# It is assumed that their matching environment variables are set.

# Creates a new ec2 key pair named `example` if not present, returns generated
# private key
- name: example ec2 key
  ec2_key:
    name: example

# Creates a new ec2 key pair named `example` if not present using provided key
# material.  This could use the 'file' lookup plugin to pull this off disk.
- name: example2 ec2 key
  ec2_key:
    name: example2
    key_material: 'ssh-rsa AAAAxyz...== me@example.com'
    state: present

# Given example2 is already existing, the key will not be replaced because the
# force flag was set to `false`
- name: example2 ec2 key
  ec2_key:
    name: example2
    key_material: 'ssh-rsa AAAAxyz...== me@example.com'
    force: false
    state: present

# Creates a new ec2 key pair named `example` if not present using provided key
# material
- name: example3 ec2 key
  ec2_key:
    name: example3
    key_material: "{{ item }}"
  with_file: /path/to/public_key.id_rsa.pub

# Removes ec2 key pair by name
- name: remove example key
  ec2_key:
    name: example
    state: absent


MAINTAINERS: Vincent Viallet (@zbal)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_LC    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_lc.py)

  Can create or delete AWS Autoscaling Configurations Works with the ec2_asg module to manage Autoscaling Groups

Options (= is mandatory):

- assign_public_ip
        Used for Auto Scaling groups that launch instances into an Amazon Virtual Private Cloud. Specifies whether to
        assign a public IP address to each instance launched in a Amazon VPC.
        [Default: (null)]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- classic_link_vpc_id
        Id of ClassicLink enabled VPC
        [Default: (null)]
- classic_link_vpc_security_groups
        A list of security group id's with which to associate the ClassicLink VPC instances.
        [Default: (null)]
- ebs_optimized
        Specifies whether the instance is optimized for EBS I/O (true) or not (false).
        [Default: False]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- image_id
        The AMI unique identifier to be used for the group
        [Default: (null)]
- instance_monitoring
        whether instances in group are launched with detailed monitoring.
        [Default: False]
- instance_profile_name
        The name or the Amazon Resource Name (ARN) of the instance profile associated with the IAM role for the
        instances.
        [Default: (null)]
= instance_type
        instance type to use for the instance
        [Default: None]
- kernel_id
        Kernel id for the EC2 instance
        [Default: (null)]
- key_name
        The SSH key name to be used for access to managed instances
        [Default: (null)]
= name
        Unique name for configuration

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- ramdisk_id
        A RAM disk id for the instances.
        [Default: (null)]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_groups
        A list of security groups to apply to the instances. For VPC instances, specify security group IDs. For
        EC2-Classic, specify either security group names or IDs.
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- spot_price
        The spot price you are bidding. Only applies for an autoscaling group with spot instances.
        [Default: (null)]
= state
        register or deregister the instance
        (Choices: present, absent)
- user_data
        opaque blob of data which is made available to the ec2 instance. Mutually exclusive with `user_data_path'.
        [Default: (null)]
- user_data_path
        Path to the file that contains userdata for the ec2 instances. Mutually exclusive with `user_data'.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- volumes
        a list of volume dicts, each containing device name and optionally ephemeral id or snapshot id. Size and type
        (and number of iops for io device type) must be specified for a new volume or a root volume, and may be passed
        for a snapshot volume. For any volume, a volume size less than 1 will be interpreted as a request not to create
        the volume.
        [Default: (null)]
Notes:
  * Amazon ASG Autoscaling Launch Configurations are immutable once created, so modifying the configuration after
        it is changed will not modify the launch configuration on AWS. You must create a new config and assign it
        to the ASG instead.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto >= 2.39.0, python >= 2.6

EXAMPLES:
- ec2_lc:
    name: special
    image_id: ami-XXX
    key_name: default
    security_groups: ['group', 'group2' ]
    instance_type: t1.micro
    volumes:
    - device_name: /dev/sda1
      volume_size: 100
      device_type: io1
      iops: 3000
      delete_on_termination: true
    - device_name: /dev/sdb
      ephemeral: ephemeral0



MAINTAINERS: Gareth Rushgrove (@garethr)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_LC_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_lc_facts.py)

  Gather facts about AWS Autoscaling Launch Configurations

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- name
        A name or a list of name to match.
        [Default: []]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- sort
        Optional attribute which with to sort the results.
        (Choices: launch_configuration_name, image_id, created_time, instance_type, kernel_id, ramdisk_id,
        key_name)[Default: None]
- sort_end
        Which result to end with (when sorting).
        Corresponds to Python slice notation.
        [Default: None]
- sort_order
        Order in which to sort results.
        Only used when the 'sort' parameter is specified.
        (Choices: ascending, descending)[Default: ascending]
- sort_start
        Which result to start with (when sorting).
        Corresponds to Python slice notation.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all launch configurations
- ec2_lc_facts:

# Gather facts about launch configuration with name "example"
- ec2_lc_facts:
    name: example

# Gather facts sorted by created_time from most recent to least recent
- ec2_lc_facts:
    sort: created_time
    sort_order: descending

RETURN VALUES:
block_device_mapping:
    description: Block device mapping for the instances of launch configuration
    type: list of block devices
    sample: "[{
        'device_name': '/dev/xvda':,
        'ebs': {
            'delete_on_termination': true,
            'volume_size': 8,
            'volume_type': 'gp2'
    }]"
classic_link_vpc_security_groups:
    description: IDs of one or more security groups for the VPC specified in classic_link_vpc_id
    type: string
    sample:
created_time:
    description: The creation date and time for the launch configuration
    type: string
    sample: "2016-05-27T13:47:44.216000+00:00"
ebs_optimized:
    description: EBS I/O optimized (true ) or not (false )
    type: bool
    sample: true,
image_id:
    description: ID of the Amazon Machine Image (AMI)
    type: string
    sample: "ami-12345678"
instance_monitoring:
    description: Launched with detailed monitoring or not
    type: dict
    sample: "{
        'enabled': true
    }"
instance_type:
    description: Instance type
    type: string
    sample: "t2.micro"
kernel_id:
    description: ID of the kernel associated with the AMI
    type: string
    sample:
key_name:
    description: Name of the key pair
    type: string
    sample: "user_app"
launch_configuration_arn:
    description: Amazon Resource Name (ARN) of the launch configuration
    type: string
    sample: "arn:aws:autoscaling:us-east-1:666612345678:launchConfiguration:ba785e3a-dd42-6f02-4585-ea1a2b458b3d:launchConfigurationName/lc-app"
launch_configuration_name:
    description: Name of the launch configuration
    type: string
    sample: "lc-app"
ramdisk_id:
    description: ID of the RAM disk associated with the AMI
    type: string
    sample:
security_groups:
    description: Security groups to associated
    type: list
    sample: "[
        'web'
    ]"
user_data:
    description: User data available
    type: string
    sample:


MAINTAINERS: Loïc Latreille (@psykotox)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_LC_FIND    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_lc_find.py)

  Returns list of matching Launch Configurations for a given name, along with other useful information Results can be
  sorted and sliced It depends on boto Based on the work by Tom Bamford (https://github.com/tombamford)

Options (= is mandatory):

- limit
        How many results to show.
        Corresponds to Python slice notation like list[:limit].
        [Default: None]
= name_regex
        A Launch Configuration to match
        It'll be compiled as regex

= region
        The AWS region to use.

- sort_order
        Order in which to sort results.
        (Choices: ascending, descending)[Default: ascending]
Requirements:  python >= 2.6, boto3

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Search for the Launch Configurations that start with "app"
- ec2_lc_find:
    name_regex: app.*
    sort_order: descending
    limit: 2

RETURN VALUES:
image_id:
    description: AMI id
    returned: when Launch Configuration was found
    type: string
    sample: "ami-0d75df7e"
user_data:
    description: User data used to start instance
    returned: when Launch Configuration was found
    type: string
    user_data: "ZXhwb3J0IENMT1VE"
name:
    description: Name of the AMI
    returned: when Launch Configuration was found
    type: string
    sample: "myapp-v123"
arn:
    description: Name of the AMI
    returned: when Launch Configuration was found
    type: string
    sample: "arn:aws:autoscaling:eu-west-1:12345:launchConfiguration:d82f050e-e315:launchConfigurationName/yourproject"
instance_type:
    description: Type of ec2 instance
    returned: when Launch Configuration was found
    type: string
    sample: "t2.small"
created_time:
    description: When it was created
    returned: when Launch Configuration was found
    type: string
    sample: "2016-06-29T14:59:22.222000+00:00"
ebs_optimized:
    description: Launch Configuration EBS optimized property
    returned: when Launch Configuration was found
    type: boolean
    sample: False
instance_monitoring:
    description: Launch Configuration instance monitoring property
    returned: when Launch Configuration was found
    type: string
    sample: {"Enabled": false}
classic_link_vpc_security_groups:
    description: Launch Configuration classic link vpc security groups property
    returned: when Launch Configuration was found
    type: list
    sample: []
block_device_mappings:
    description: Launch Configuration block device mappings property
    returned: when Launch Configuration was found
    type: list
    sample: []
keyname:
    description: Launch Configuration ssh key
    returned: when Launch Configuration was found
    type: string
    sample: mykey
security_groups:
    description: Launch Configuration security groups
    returned: when Launch Configuration was found
    type: list
    sample: []
kernel_id:
    description: Launch Configuration kernel to use
    returned: when Launch Configuration was found
    type: string
    sample: ''
ram_disk_id:
    description: Launch Configuration ram disk property
    returned: when Launch Configuration was found
    type: string
    sample: ''
associate_public_address:
    description: Assign public address or not
    returned: when Launch Configuration was found
    type: boolean
    sample: True
...


MAINTAINERS: Jose Armesto (@fiunchinho)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_METRIC_ALARM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_metric_alarm.py)

  Can create or delete AWS metric alarms. Metrics you wish to alarm on must already exist.

Options (= is mandatory):

- alarm_actions
        A list of the names action(s) taken when the alarm is in the 'alarm' status
        [Default: (null)]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- comparison
        Determines how the threshold value is compared
        (Choices: <=, <, >, >=)[Default: (null)]
- description
        A longer description of the alarm
        [Default: (null)]
- dimensions
        Describes to what the alarm is applied
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- evaluation_periods
        The number of times in which the metric is evaluated before final calculation
        [Default: (null)]
- insufficient_data_actions
        A list of the names of action(s) to take when the alarm is in the 'insufficient_data' status
        [Default: (null)]
- metric
        Name of the monitored metric (e.g. CPUUtilization)
        Metric must already exist
        [Default: (null)]
= name
        Unique name for the alarm

- namespace
        Name of the appropriate namespace ('AWS/EC2', 'System/Linux', etc.), which determines the category it will appear
        under in cloudwatch
        [Default: (null)]
- ok_actions
        A list of the names of action(s) to take when the alarm is in the 'ok' status
        [Default: (null)]
- period
        The time (in seconds) between metric evaluations
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        register or deregister the alarm
        (Choices: present, absent)
- statistic
        Operation applied to the metric
        Works in conjunction with period and evaluation_periods to determine the comparison value
        (Choices: SampleCount, Average, Sum, Minimum, Maximum)[Default: (null)]
- threshold
        Sets the min/max bound for triggering the alarm
        [Default: (null)]
- unit
        The threshold's unit of measurement
        (Choices: Seconds, Microseconds, Milliseconds, Bytes, Kilobytes, Megabytes, Gigabytes, Terabytes, Bits, Kilobits,
        Megabits, Gigabits, Terabits, Percent, Count, Bytes/Second, Kilobytes/Second, Megabytes/Second, Gigabytes/Second,
        Terabytes/Second, Bits/Second, Kilobits/Second, Megabits/Second, Gigabits/Second, Terabits/Second, Count/Second,
        None)[Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
  - name: create alarm
    ec2_metric_alarm:
      state: present
      region: ap-southeast-2
      name: "cpu-low"
      metric: "CPUUtilization"
      namespace: "AWS/EC2"
      statistic: Average
      comparison: "<="
      threshold: 5.0
      period: 300
      evaluation_periods: 3
      unit: "Percent"
      description: "This will alarm when a bamboo slave's cpu usage average is lower than 5% for 15 minutes "
      dimensions: {'InstanceId':'i-XXX'}
      alarm_actions: ["action1","action2"]




MAINTAINERS: Zacharie Eakin (@zeekin)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_REMOTE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_remote_facts.py)

  Gather facts about ec2 instances in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for possible filters.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all ec2 instances
- ec2_remote_facts:

# Gather facts about all running ec2 instances with a tag of Name:Example
- ec2_remote_facts:
    filters:
      instance-state-name: running
      "tag:Name": Example

# Gather facts about instance i-123456
- ec2_remote_facts:
    filters:
      instance-id: i-123456

# Gather facts about all instances in vpc-123456 that are t2.small type
- ec2_remote_facts:
    filters:
      vpc-id: vpc-123456
      instance-type: t2.small



MAINTAINERS: Michael Schuett (@michaeljs1990)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_SCALING_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_scaling_policy.py)

  Can create or delete scaling policies for autoscaling groups Referenced autoscaling groups must already exist

Options (= is mandatory):

- adjustment_type
        The type of change in capacity of the autoscaling group
        (Choices: ChangeInCapacity, ExactCapacity, PercentChangeInCapacity)[Default: (null)]
= asg_name
        Name of the associated autoscaling group

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- cooldown
        The minimum period of time between which autoscaling actions can take place
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- min_adjustment_step
        Minimum amount of adjustment when policy is triggered
        [Default: (null)]
= name
        Unique name for the scaling policy

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- scaling_adjustment
        The amount by which the autoscaling group is adjusted by the policy
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        register or deregister the policy
        (Choices: present, absent)
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
- ec2_scaling_policy:
    state: present
    region: US-XXX
    name: "scaledown-policy"
    adjustment_type: "ChangeInCapacity"
    asg_name: "slave-pool"
    scaling_adjustment: -1
    min_adjustment_step: 1
    cooldown: 300


MAINTAINERS: Zacharie Eakin (@zeekin)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_SNAPSHOT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_snapshot.py)

  creates an EC2 snapshot from an existing EBS volume

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- description
        description to be applied to the snapshot
        [Default: (null)]
- device_name
        device name of a mounted volume to be snapshotted
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- instance_id
        instance that has the required volume to snapshot mounted
        [Default: (null)]
- last_snapshot_min_age
        If the volume's most recent snapshot has started less than `last_snapshot_min_age' minutes ago, a new snapshot
        will not be created.
        [Default: 0]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- snapshot_id
        snapshot id to remove
        [Default: (null)]
- snapshot_tags
        a hash/dictionary of tags to add to the snapshot
        [Default: (null)]
- state
        whether to add or create a snapshot
        (Choices: absent, present)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- volume_id
        volume from which to take the snapshot
        [Default: (null)]
- wait
        wait for the snapshot to be ready
        (Choices: yes, no)[Default: True]
- wait_timeout
        how long before wait gives up, in seconds
        specify 0 to wait forever
        [Default: 0]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Simple snapshot of volume using volume_id
- ec2_snapshot:
    volume_id: vol-abcdef12
    description: snapshot of /data from DB123 taken 2013/11/28 12:18:32

# Snapshot of volume mounted on device_name attached to instance_id
- ec2_snapshot:
    instance_id: i-12345678
    device_name: /dev/sdb1
    description: snapshot of /data from DB123 taken 2013/11/28 12:18:32

# Snapshot of volume with tagging
- ec2_snapshot:
    instance_id: i-12345678
    device_name: /dev/sdb1
    snapshot_tags:
        frequency: hourly
        source: /data

# Remove a snapshot
- local_action:
    module: ec2_snapshot
    snapshot_id: snap-abcd1234
    state: absent

# Create a snapshot only if the most recent one is older than 1 hour
- local_action:
    module: ec2_snapshot
    volume_id: vol-abcdef12
    last_snapshot_min_age: 60


MAINTAINERS: Will Thames (@willthames)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_SNAPSHOT_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_snapshot_facts.py)

  Gather facts about ec2 volume snapshots in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeSnapshots.html for possible filters. Filter
        names and values are case sensitive.
        [Default: {}]
- owner_ids
        If you specify one or more snapshot owners, only snapshots from the specified owners and for which you have
        access are returned.
        [Default: []]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- restorable_by_user_ids
        If you specify a list of restorable users, only snapshots with create snapshot permissions for those users are
        returned.
        [Default: []]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- snapshot_ids
        If you specify one or more snapshot IDs, only snapshots that have the specified IDs are returned.
        [Default: []]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * By default, the module will return all snapshots, including public ones. To limit results to snapshots owned by
        the account use the filter 'owner-id'.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all snapshots, including public ones
- ec2_snapshot_facts:

# Gather facts about all snapshots owned by the account 0123456789
- ec2_snapshot_facts:
    filters:
      owner-id: 0123456789

# Or alternatively...
- ec2_snapshot_facts:
    owner_ids:
      - 0123456789

# Gather facts about a particular snapshot using ID
- ec2_snapshot_facts:
    filters:
      snapshot-id: snap-00112233

# Or alternatively...
- ec2_snapshot_facts:
    snapshot_ids:
      - snap-00112233

# Gather facts about any snapshot with a tag key Name and value Example
- ec2_snapshot_facts:
    filters:
      "tag:Name": Example

# Gather facts about any snapshot with an error status
- ec2_snapshot_facts:
    filters:
      status: error


RETURN VALUES:
snapshot_id:
    description: The ID of the snapshot. Each snapshot receives a unique identifier when it is created.
    type: string
    sample: snap-01234567
volume_id:
    description: The ID of the volume that was used to create the snapshot.
    type: string
    sample: vol-01234567
state:
    description: The snapshot state (completed, pending or error).
    type: string
    sample: completed
state_message:
    description: Encrypted Amazon EBS snapshots are copied asynchronously. If a snapshot copy operation fails (for example, if the proper AWS Key Management Service (AWS KMS) permissions are not obtained) this field displays error state details to help you diagnose why the error occurred.
    type: string
    sample:
start_time:
    description: The time stamp when the snapshot was initiated.
    type: datetime
    sample: 2015-02-12T02:14:02+00:00
progress:
    description: The progress of the snapshot, as a percentage.
    type: string
    sample: 100%
owner_id:
    description: The AWS account ID of the EBS snapshot owner.
    type: string
    sample: 099720109477
description:
    description: The description for the snapshot.
    type: string
    sample: My important backup
volume_size:
    description: The size of the volume, in GiB.
    type: integer
    sample: 8
owner_alias:
    description: The AWS account alias (for example, amazon, self) or AWS account ID that owns the snapshot.
    type: string
    sample: 033440102211
tags:
    description: Any tags assigned to the snapshot.
    type: dict
    sample: "{ 'my_tag_key': 'my_tag_value' }"
encrypted:
    description: Indicates whether the snapshot is encrypted.
    type: boolean
    sample: True
kms_key_id:
    description: The full ARN of the AWS Key Management Service (AWS KMS) customer master key (CMK) that was used to     protect the volume encryption key for the parent volume.
    type: string
    sample: 74c9742a-a1b2-45cb-b3fe-abcdef123456
data_encryption_key_id:
    description: The data encryption key identifier for the snapshot. This value is a unique identifier that     corresponds to the data encryption key that was used to encrypt the original volume or snapshot copy.
    type: string
    sample: "arn:aws:kms:ap-southeast-2:012345678900:key/74c9742a-a1b2-45cb-b3fe-abcdef123456"



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_TAG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_tag.py)

  Creates, removes and lists tags from any EC2 resource.  The resource is referenced by its resource id (e.g. an instance
  being i-XXXXXXX). It is designed to be used with complex args (tags), see the examples.  This module has a dependency
  on python-boto.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
= resource
        The EC2 resource id.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Whether the tags should be present or absent on the resource. Use list to interrogate the tags of an instance.
        (Choices: present, absent, list)[Default: present]
= tags
        a hash/dictionary of tags to add to the resource; '{"key":"value"}' and '{"key":"value","key":"value"}'
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
- name: Ensure tags are present on a resource
  ec2_tag:
    region: eu-west-1
    resource: vol-XXXXXX
    state: present
    tags:
      Name: ubervol
      env: prod

- name: Ensure one dbserver is running
  ec2:
    count_tags:
      Name: dbserver
      Env: production
    exact_count: 1
    group: '{{ security_group }}'
    keypair: '{{ keypair }}'
    image: '{{ image_id }}'
    instance_tags:
      Name: dbserver
      Env: production
    instance_type: '{{ instance_type }}'
    region: eu-west-1
    volumes:
      - device_name: /dev/xvdb
        device_type: standard
        volume_size: 10
        delete_on_termination: True
    wait: True
  register: ec2

- name: Retrieve all volumes for a queried instance
  ec2_vol:
    instance: '{{ item.id }}'
    region: eu-west-1
    state: list
  with_items: '{{ ec2.tagged_instances }}'
  register: ec2_vol

- name: Ensure all volumes are tagged
  ec2_tag:
    region:  eu-west-1
    resource: '{{ item.id }}'
    state: present
    tags:
      Name: dbserver
      Env: production
  with_items:
    - ec2_vol.volumes

- name: Get EC2 facts
  action: ec2_facts

- name: Retrieve all tags on an instance
  ec2_tag:
    region: '{{ ansible_ec2_placement_region }}'
    resource: '{{ ansible_ec2_instance_id }}'
    state: list
  register: ec2_tags

- name: List tags, such as Name and env
  debug:
    msg: '{{ ec2_tags.tags.Name }} {{ ec2_tags.tags.env }}'


MAINTAINERS: Lester Wade (@lwade)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VOL    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vol.py)

  creates an EBS volume and optionally attaches it to an instance. If both an instance ID and a device name is given and
  the instance has a device at the device name, then no volume is created and no attachment is made. This module has a
  dependency on python-boto.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- delete_on_termination
        When set to "yes", the volume will be deleted upon instance termination.
        (Choices: yes, no)[Default: no]
- device_name
        device id to override device mapping. Assumes /dev/sdf for Linux/UNIX and /dev/xvdf for Windows.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- encrypted
        Enable encryption at rest for this volume.
        [Default: False]
- id
        volume id if you wish to attach an existing volume (requires instance) or remove an existing volume
        [Default: None]
- instance
        instance ID if you wish to attach the volume. Since 1.9 you can set to None to detach.
        [Default: None]
- iops
        the provisioned IOPs you want to associate with this volume (integer).
        [Default: 100]
- kms_key_id
        Specify the id of the KMS key to use.
        [Default: None]
- name
        volume Name tag if you wish to attach an existing volume (requires instance)
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- snapshot
        snapshot ID on which to base the volume
        [Default: None]
- state
        whether to ensure the volume is present or absent, or to list existing volumes (The `list' option was added in
        version 1.8).
        (Choices: absent, present, list)[Default: present]
- tags
        tag:value pairs to add to the volume after creation
        [Default: {}]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- volume_size
        size of volume (in GB) to create.
        [Default: None]
- volume_type
        Type of EBS volume; standard (magnetic), gp2 (SSD), io1 (Provisioned IOPS), st1 (Throughput Optimized HDD), sc1
        (Cold HDD). "Standard" is the old EBS default and continues to remain the Ansible default for backwards
        compatibility.
        [Default: standard]
- zone
        zone in which to create the volume, if unset uses the zone the instance is in (if set)
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Simple attachment action
- ec2_vol:
    instance: XXXXXX
    volume_size: 5
    device_name: sdd

# Example using custom iops params
- ec2_vol:
    instance: XXXXXX
    volume_size: 5
    iops: 100
    device_name: sdd

# Example using snapshot id
- ec2_vol:
    instance: XXXXXX
    snapshot: "{{ snapshot }}"

# Playbook example combined with instance launch
- ec2:
    keypair: "{{ keypair }}"
    image: "{{ image }}"
    wait: yes
    count: 3
  register: ec2
- ec2_vol:
    instance: "{{ item.id }} "
    volume_size: 5
  with_items: "{{ ec2.instances }}"
  register: ec2_vol

# Example: Launch an instance and then add a volume if not already attached
#   * Volume will be created with the given name if not already created.
#   * Nothing will happen if the volume is already attached.
#   * Requires Ansible 2.0

- ec2:
    keypair: "{{ keypair }}"
    image: "{{ image }}"
    zone: YYYYYY
    id: my_instance
    wait: yes
    count: 1
  register: ec2

- ec2_vol:
    instance: "{{ item.id }}"
    name: my_existing_volume_Name_tag
    device_name: /dev/xvdf
  with_items: "{{ ec2.instances }}"
  register: ec2_vol

# Remove a volume
- ec2_vol:
    id: vol-XXXXXXXX
    state: absent

# Detach a volume (since 1.9)
- ec2_vol:
    id: vol-XXXXXXXX
    instance: None

# List volumes for an instance
- ec2_vol:
    instance: i-XXXXXX
    state: list

# Create new volume using SSD storage
- ec2_vol:
    instance: XXXXXX
    volume_size: 50
    volume_type: gp2
    device_name: /dev/xvdf

# Attach an existing volume to instance. The volume will be deleted upon instance termination.
- ec2_vol:
    instance: XXXXXX
    id: XXXXXX
    device_name: /dev/sdf
    delete_on_termination: yes

RETURN VALUES:
device:
    description: device name of attached volume
    returned: when success
    type: string
    sample: "/def/sdf"
volume_id:
    description: the id of volume
    returned: when success
    type: string
    sample: "vol-35b333d9"
volume_type:
    description: the volume type
    returned: when success
    type: string
    sample: "standard"
volume:
    description: a dictionary containing detailed attributes of the volume
    returned: when success
    type: string
    sample: {
        "attachment_set": {
            "attach_time": "2015-10-23T00:22:29.000Z",
            "deleteOnTermination": "false",
            "device": "/dev/sdf",
            "instance_id": "i-8356263c",
            "status": "attached"
        },
        "create_time": "2015-10-21T14:36:08.870Z",
        "encrypted": false,
        "id": "vol-35b333d9",
        "iops": null,
        "size": 1,
        "snapshot_id": "",
        "status": "in-use",
        "tags": {
            "env": "dev"
        },
        "type": "standard",
        "zone": "us-east-1b"
    }


MAINTAINERS: Lester Wade (@lwade)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VOL_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vol_facts.py)

  Gather facts about ec2 volumes in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeVolumes.html for possible filters.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all volumes
- ec2_vol_facts:

# Gather facts about a particular volume using volume ID
- ec2_vol_facts:
    filters:
      volume-id: vol-00112233

# Gather facts about any volume with a tag key Name and value Example
- ec2_vol_facts:
    filters:
      "tag:Name": Example

# Gather facts about any volume that is attached
- ec2_vol_facts:
    filters:
      attachment.status: attached


RETURN VALUES:
 

MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_VPC    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/_ec2_vpc.py)

  Create or terminates AWS virtual private clouds.  This module has a dependency on python-boto.

DEPRECATED: 
Deprecated in 2.3. Use M(ec2_vpc_net) along with supporting modules including M(ec2_vpc_igw), M(ec2_vpc_route_table), M(ec2_vpc_subnet), M(ec2_vpc_dhcp_options), M(ec2_vpc_nat_gateway), M(ec2_vpc_nacl).

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- cidr_block
        The cidr block representing the VPC, e.g. `10.0.0.0/16', required when `state=present'.
        [Default: (null)]
- dns_hostnames
        Toggles the "Enable DNS hostname support for instances" flag.
        (Choices: yes, no)[Default: yes]
- dns_support
        Toggles the "Enable DNS resolution" flag.
        (Choices: yes, no)[Default: yes]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- instance_tenancy
        The supported tenancy options for instances launched into the VPC.
        (Choices: default, dedicated)[Default: default]
- internet_gateway
        Toggle whether there should be an Internet gateway attached to the VPC.
        (Choices: yes, no)[Default: no]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
= resource_tags
        A dictionary array of resource tags of the form `{ tag1: value1, tag2: value2 }'. - Tags in this list are used in
        conjunction with CIDR block to uniquely identify a VPC in lieu of vpc_id. Therefore, if CIDR/Tag combination does
        not exist, a new VPC will be created.  VPC tags not on this list will be ignored. Prior to 1.7, specifying a
        resource tag was optional.

- route_tables
        A dictionary array of route tables to add of the form: `{ subnets: [172.22.2.0/24, 172.22.3.0/24,], routes: [{
        dest: 0.0.0.0/0, gw: igw},], resource_tags: ... }'. Where the subnets list is those subnets the route table
        should be associated with, and the routes list is a list of routes to be in the table.  The special keyword for
        the gw of igw specifies that you should the route should go through the internet gateway attached to the VPC. gw
        also accepts instance-ids, interface-ids, and vpc-peering-connection-ids in addition igw. resource_tags is
        optional and uses dictionary form: `{ "Name": "public", ... }'. This module is currently unable to affect the
        "main" route table due to some limitations in boto, so you must explicitly define the associated subnets or they
        will be attached to the main table implicitly. As of 1.8, if the route_tables parameter is not specified, no
        existing routes will be modified.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Create or terminate the VPC.
        (Choices: present, absent)
- subnets
        A dictionary array of subnets to add of the form `{ cidr: ..., az: ... , resource_tags: ... }'.
        Where `az' is the desired availability zone of the subnet, optional.
        Tags `resource_tags' use dictionary form `{ "Environment":"Dev", "Tier":"Web", ...}', optional.
        `resource_tags' see resource_tags for VPC below. The main difference is subnet tags not specified here will be
        deleted.
        All VPC subnets not in this list will be removed as well.
        As of 1.8, if the subnets parameter is not specified, no existing subnets will be modified.'
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_id
        A VPC id to terminate when `state=absent'.
        [Default: None]
- wait
        Wait for the VPC to be in state 'available' before returning.
        (Choices: yes, no)[Default: no]
- wait_timeout
        How long before wait gives up, in seconds.
        [Default: 300]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: None of these examples set aws_access_key, aws_secret_key, or region.
# It is assumed that their matching environment variables are set.

# Basic creation example:
    - ec2_vpc:
        state: present
        cidr_block: 172.23.0.0/16
        resource_tags: { "Environment":"Development" }
        region: us-west-2
# Full creation example with subnets and optional availability zones.
# The absence or presence of subnets deletes or creates them respectively.
    - ec2_vpc:
        state: present
        cidr_block: 172.22.0.0/16
        resource_tags: { "Environment":"Development" }
        subnets:
          - cidr: 172.22.1.0/24
            az: us-west-2c
            resource_tags: { "Environment":"Dev", "Tier" : "Web" }
          - cidr: 172.22.2.0/24
            az: us-west-2b
            resource_tags: { "Environment":"Dev", "Tier" : "App" }
          - cidr: 172.22.3.0/24
            az: us-west-2a
            resource_tags: { "Environment":"Dev", "Tier" : "DB" }
        internet_gateway: True
        route_tables:
          - subnets:
              - 172.22.2.0/24
              - 172.22.3.0/24
            routes:
              - dest: 0.0.0.0/0
                gw: igw
          - subnets:
              - 172.22.1.0/24
            routes:
              - dest: 0.0.0.0/0
                gw: igw
        region: us-west-2
      register: vpc

# Removal of a VPC by id
    - ec2_vpc:
        state: absent
        vpc_id: vpc-aaaaaaa
        region: us-west-2
# If you have added elements not managed by this module, e.g. instances, NATs, etc then
# the delete will fail until those dependencies are removed.


MAINTAINERS: Carson Gee (@carsongee)

METADATA:
	Status: ['deprecated']
	Supported_by: curated
> EC2_VPC_DHCP_OPTIONS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_dhcp_options.py)

  This module removes, or creates DHCP option sets, and can associate them to a VPC. Optionally, a new DHCP Options set
  can be created that converges a VPC's existing DHCP option set with values provided. When dhcp_options_id is provided,
  the module will 1. remove (with state='absent') 2. ensure tags are applied (if state='present' and tags are provided 3.
  attach it to a VPC (if state='present' and a vpc_id is provided. If any of the optional values are missing, they will
  either be treated as a no-op (i.e., inherit what already exists for the VPC) To remove existing options while
  inheriting, supply an empty value (e.g. set ntp_servers to [] if you want to remove them from the VPC's options) Most
  of the options should be self-explanatory.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- delete_old
        Whether to delete the old VPC DHCP option set when associating a new one. This is primarily useful for
        debugging/development purposes when you want to quickly roll back to the old option set. Note that this setting
        will be ignored, and the old DHCP option set will be preserved, if it is in use by any other VPC. (Otherwise, AWS
        will return an error.)
        [Default: True]
- dhcp_options_id
        The resource_id of an existing DHCP options set. If this is specified, then it will override other settings,
        except tags (which will be updated to match)
        [Default: None]
- dns_servers
        A list of hosts to set the DNS servers for the VPC to. (Should be a list of IP addresses rather than host names.)
        [Default: None]
- domain_name
        The domain name to set in the DHCP option sets
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- inherit_existing
        For any DHCP options not specified in these parameters, whether to inherit them from the options set already
        applied to vpc_id, or to reset them to be empty.
        [Default: False]
- netbios_name_servers
        List of hosts to advertise as NetBIOS servers.
        [Default: None]
- netbios_node_type
        NetBIOS node type to advertise in the DHCP options. The AWS recommendation is to use 2 (when using netbios name
        services) http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_DHCP_Options.html
        [Default: None]
- ntp_servers
        List of hosts to advertise as NTP servers for the VPC.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        create/assign or remove the DHCP options. If state is set to absent, then a DHCP options set matched either by
        id, or tags and options will be removed if possible.
        (Choices: absent, present)[Default: present]
- tags
        Tags to be applied to a VPC options set if a new one is created, or if the resource_id is provided. (options must
        match)
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_id
        VPC ID to associate with the requested DHCP option set. If no vpc id is provided, and no matching option set is
        found then a new DHCP option set is created.
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, python >= 2.6

EXAMPLES:
# Completely overrides the VPC DHCP options associated with VPC vpc-123456 and deletes any existing
# DHCP option set that may have been attached to that VPC.
- ec2_vpc_dhcp_options:
    domain_name: "foo.example.com"
    region: us-east-1
    dns_servers:
        - 10.0.0.1
        - 10.0.1.1
    ntp_servers:
        - 10.0.0.2
        - 10.0.1.2
    netbios_name_servers:
        - 10.0.0.1
        - 10.0.1.1
    netbios_node_type: 2
    vpc_id: vpc-123456
    delete_old: True
    inherit_existing: False


# Ensure the DHCP option set for the VPC has 10.0.0.4 and 10.0.1.4 as the specified DNS servers, but
# keep any other existing settings. Also, keep the old DHCP option set around.
- ec2_vpc_dhcp_options:
    region: us-east-1
    dns_servers:
      - "{{groups['dns-primary']}}"
      - "{{groups['dns-secondary']}}"
    vpc_id: vpc-123456
    inherit_existing: True
    delete_old: False


## Create a DHCP option set with 4.4.4.4 and 8.8.8.8 as the specified DNS servers, with tags
## but do not assign to a VPC
- ec2_vpc_dhcp_options:
    region: us-east-1
    dns_servers:
      - 4.4.4.4
      - 8.8.8.8
    tags:
      Name: google servers
      Environment: Test

## Delete a DHCP options set that matches the tags and options specified
- ec2_vpc_dhcp_options:
    region: us-east-1
    dns_servers:
      - 4.4.4.4
      - 8.8.8.8
    tags:
      Name: google servers
      Environment: Test
  state: absent

## Associate a DHCP options set with a VPC by ID
- ec2_vpc_dhcp_options:
    region: us-east-1
    dhcp_options_id: dopt-12345678
    vpc_id: vpc-123456


RETURN VALUES:
new_options:
    description: The DHCP options created, associated or found
    returned: when appropriate
    type: dict
    sample:
      domain-name-servers:
        - 10.0.0.1
        - 10.0.1.1
      netbois-name-servers:
        - 10.0.0.1
        - 10.0.1.1
      netbios-node-type: 2
      domain-name: "my.example.com"
dhcp_options_id:
    description: The aws resource id of the primary DCHP options set created, found or removed
    type: string
    returned: when available
changed:
    description: Whether the dhcp options were changed
    type: bool
    returned: always


MAINTAINERS: Joel Thompson (@joelthompson)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_DHCP_OPTIONS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_dhcp_options_facts.py)

  Gather facts about dhcp options sets in AWS

Options (= is mandatory):

- DhcpOptionsIds
        Get details of specific DHCP Option ID
        Provide this value as a list
        [Default: None]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeRouteTables.html for possible filters.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# # Note: These examples do not set authentication details, see the AWS Guide for details.

- name: Gather facts about all DHCP Option sets for an account or profile
  ec2_vpc_dhcp_options_facts:
    region: ap-southeast-2
    profile: production
  register: dhcp_facts

- name: Gather facts about a filtered list of DHCP Option sets
  ec2_vpc_dhcp_options_facts:
    region: ap-southeast-2
    profile: production
    filters:
        "tag:Name": "abc-123"
  register: dhcp_facts

- name: Gather facts about a specific DHCP Option set by DhcpOptionId
  ec2_vpc_dhcp_options_facts:
    region: ap-southeast-2
    profile: production
    DhcpOptionsIds: dopt-123fece2
  register: dhcp_facts


RETURN VALUES:
dhcp_options:
    description: The dhcp option sets for the account
    returned: always
    type: list

changed:
    description: True if listing the dhcp options succeeds
    type: bool
    returned: always


MAINTAINERS: Nick Aslanidis (@naslanidis)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_VPC_IGW    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_igw.py)

  Manage an AWS VPC Internet gateway

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or terminate the IGW
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
= vpc_id
        The VPC ID for the VPC in which to manage the Internet Gateway.
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Ensure that the VPC has an Internet Gateway.
# The Internet Gateway ID is can be accessed via {{igw.gateway_id}} for use in setting up NATs etc.
ec2_vpc_igw:
  vpc_id: vpc-abcdefgh
  state: present
register: igw



MAINTAINERS: Robert Estelle (@erydo)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_IGW_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_igw_facts.py)

  Gather facts about internet gateways in AWS.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeRouteTables.html for possible filters.
        [Default: None]
- internet_gateway_ids
        Get details of specific Internet Gateway ID. Provide this value as a list.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# # Note: These examples do not set authentication details, see the AWS Guide for details.

- name: Gather facts about all Internet Gateways for an account or profile
  ec2_vpc_igw_facts:
    region: ap-southeast-2
    profile: production
  register: igw_facts

- name: Gather facts about a filtered list of Internet Gateways
  ec2_vpc_igw_facts:
    region: ap-southeast-2
    profile: production
    filters:
        "tag:Name": "igw-123"
  register: igw_facts

- name: Gather facts about a specific internet gateway by InternetGatewayId
  ec2_vpc_igw_facts:
    region: ap-southeast-2
    profile: production
    internet_gateway_ids: igw-c1231234
  register: igw_facts

RETURN VALUES:
internet_gateways:
    description: The internet gateways for the account.
    returned: always
    type: list
    sample: [
        {
            "attachments": [
                {
                    "state": "available",
                    "vpc_id": "vpc-02123b67"
                }
            ],
            "internet_gateway_id": "igw-2123634d",
            "tags": [
                {
                    "key": "Name",
                    "value": "test-vpc-20-igw"
                }
            ]
        }
    ]

changed:
    description: True if listing the internet gateways succeeds.
    type: bool
    returned: always
    sample: "false"


MAINTAINERS: Nick Aslanidis (@naslanidis)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_VPC_NACL    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_nacl.py)

  Read the AWS documentation for Network ACLS http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- egress
        A list of rules for outgoing traffic.
        Each rule must be specified as a list.
        [Default: (null)]
- ingress
        List of rules for incoming traffic.
        Each rule must be specified as a list.
        [Default: (null)]
= name
        Tagged name identifying a network ACL.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Creates or modifies an existing NACL
        Deletes a NACL and reassociates subnets to the default NACL
        (Choices: present, absent)[Default: present]
- subnets
        The list of subnets that should be associated with the network ACL.
        Must be specified as a list
        Each subnet can be specified as subnet ID, or its tagged name.
        [Default: (null)]
- tags
        Dictionary of tags to look for and apply when creating a network ACL.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
= vpc_id
        VPC id of the requesting VPC.

Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, json, python >= 2.6

EXAMPLES:

# Complete example to create and delete a network ACL
# that allows SSH, HTTP and ICMP in, and all traffic out.
- name: "Create and associate production DMZ network ACL with DMZ subnets"
  ec2_vpc_nacl:
    vpc_id: vpc-12345678
    name: prod-dmz-nacl
    region: ap-southeast-2
    subnets: ['prod-dmz-1', 'prod-dmz-2']
    tags:
      CostCode: CC1234
      Project: phoenix
      Description: production DMZ
    ingress: [
        # rule no, protocol, allow/deny, cidr, icmp_code, icmp_type,
        #                                             port from, port to
        [100, 'tcp', 'allow', '0.0.0.0/0', null, null, 22, 22],
        [200, 'tcp', 'allow', '0.0.0.0/0', null, null, 80, 80],
        [300, 'icmp', 'allow', '0.0.0.0/0', 0, 8],
    ]
    egress: [
        [100, 'all', 'allow', '0.0.0.0/0', null, null, null, null]
    ]
    state: 'present'

- name: "Remove the ingress and egress rules - defaults to deny all"
  ec2_vpc_nacl:
    vpc_id: vpc-12345678
    name: prod-dmz-nacl
    region: ap-southeast-2
    subnets:
      - prod-dmz-1
      - prod-dmz-2
    tags:
      CostCode: CC1234
      Project: phoenix
      Description: production DMZ
    state: present

- name: "Remove the NACL subnet associations and tags"
  ec2_vpc_nacl:
    vpc_id: 'vpc-12345678'
    name: prod-dmz-nacl
    region: ap-southeast-2
    state: present

- name: "Delete nacl and subnet associations"
  ec2_vpc_nacl:
    vpc_id: vpc-12345678
    name: prod-dmz-nacl
    state: absent

RETURN VALUES:
task:
  description: The result of the create, or delete action.
  returned: success
  type: dictionary


MAINTAINERS: Mike Mochan(@mmochan)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_NACL_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_nacl_facts.py)

  Gather facts about Network ACLs in an AWS VPC

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeNetworkAcls.html for possible filters. Filter
        names and values are case sensitive.
        [Default: {}]
- nacl_ids
        A list of Network ACL IDs to retrieve facts about.
        [Default: []]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * By default, the module will return all Network ACLs.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all Network ACLs:
- name: Get All NACLs
  register: all_nacls
  ec2_vpc_nacl_facts:
    region: us-west-2

# Retrieve default Network ACLs:
- name: Get Default NACLs
  register: default_nacls
  ec2_vpc_nacl_facts:
    region: us-west-2
    filters:
      'default': 'true'

RETURN VALUES:
nacl:
    description: Returns an array of complex objects as described below.
    returned: success
    type: list of complex
    contains:
        nacl_id:
            description: The ID of the Network Access Control List.
            returned: always
            type: string
        vpc_id:
            description: The ID of the VPC that the NACL is attached to.
            returned: always
            type: string
        is_default:
            description: True if the NACL is the default for its VPC.
            returned: always
            type: boolean
        tags:
            description: A dict of tags associated with the NACL.
            returned: always
            type: dict
        subnets:
            description: A list of subnet IDs that are associated with the NACL.
            returned: always
            type: list of string
        ingress:
            description: A list of NACL ingress rules.
            returned: always
            type: list of list
        egress:
            description: A list of NACL egress rules.
            returned: always
            type: list of list


MAINTAINERS: Brad Davidson (@brandond)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_NAT_GATEWAY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_nat_gateway.py)

  Ensure the state of AWS VPC NAT Gateways based on their id, allocation and subnet ids.

Options (= is mandatory):

- allocation_id
        The id of the elastic IP allocation. If this is not passed and the eip_address is not passed. An EIP is generated
        for this NAT Gateway.
        [Default: None]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- client_token
        Optional unique token to be used during create to ensure idempotency. When specifying this option, ensure you
        specify the eip_address parameter as well otherwise any subsequent runs will fail.
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- eip_address
        The elastic IP address of the EIP you want attached to this NAT Gateway. If this is not passed and the
        allocation_id is not passed, an EIP is generated for this NAT Gateway.
        [Default: (null)]
- if_exist_do_not_create
        if a NAT Gateway exists already in the subnet_id, then do not create a new one.
        [Default: False]
- nat_gateway_id
        The id AWS dynamically allocates to the NAT Gateway on creation. This is required when the absent option is
        present.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- release_eip
        Deallocate the EIP from the VPC.
        Option is only valid with the absent state.
        You should use this with the wait option. Since you can not release an address while a delete operation is
        happening.
        [Default: True]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Ensure NAT Gateway is present or absent.
        (Choices: present, absent)[Default: present]
- subnet_id
        The id of the subnet to create the NAT Gateway in. This is required with the present option.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        Wait for operation to complete before returning.
        [Default: False]
- wait_timeout
        How many seconds to wait for an operation to complete before timing out.
        [Default: 300]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

- name: Create new nat gateway with client token.
  ec2_vpc_nat_gateway:
    state: present
    subnet_id: subnet-12345678
    eip_address: 52.1.1.1
    region: ap-southeast-2
    client_token: abcd-12345678
  register: new_nat_gateway

- name: Create new nat gateway using an allocation-id.
  ec2_vpc_nat_gateway:
    state: present
    subnet_id: subnet-12345678
    allocation_id: eipalloc-12345678
    region: ap-southeast-2
  register: new_nat_gateway

- name: Create new nat gateway, using an EIP address  and wait for available status.
  ec2_vpc_nat_gateway:
    state: present
    subnet_id: subnet-12345678
    eip_address: 52.1.1.1
    wait: yes
    region: ap-southeast-2
  register: new_nat_gateway

- name: Create new nat gateway and allocate new EIP.
  ec2_vpc_nat_gateway:
    state: present
    subnet_id: subnet-12345678
    wait: yes
    region: ap-southeast-2
  register: new_nat_gateway

- name: Create new nat gateway and allocate new EIP if a nat gateway does not yet exist in the subnet.
  ec2_vpc_nat_gateway:
    state: present
    subnet_id: subnet-12345678
    wait: yes
    region: ap-southeast-2
    if_exist_do_not_create: true
  register: new_nat_gateway

- name: Delete nat gateway using discovered nat gateways from facts module.
  ec2_vpc_nat_gateway:
    state: absent
    region: ap-southeast-2
    wait: yes
    nat_gateway_id: "{{ item.NatGatewayId }}"
    release_eip: yes
  register: delete_nat_gateway_result
  with_items: "{{ gateways_to_remove.result }}"

- name: Delete nat gateway and wait for deleted status.
  ec2_vpc_nat_gateway:
    state: absent
    nat_gateway_id: nat-12345678
    wait: yes
    wait_timeout: 500
    region: ap-southeast-2

- name: Delete nat gateway and release EIP.
  ec2_vpc_nat_gateway:
    state: absent
    nat_gateway_id: nat-12345678
    release_eip: yes
    wait: yes
    wait_timeout: 300
    region: ap-southeast-2

RETURN VALUES:
create_time:
  description: The ISO 8601 date time formatin UTC.
  returned: In all cases.
  type: string
  sample: "2016-03-05T05:19:20.282000+00:00'"
nat_gateway_id:
  description: id of the VPC NAT Gateway
  returned: In all cases.
  type: string
  sample: "nat-0d1e3a878585988f8"
subnet_id:
  description: id of the Subnet
  returned: In all cases.
  type: string
  sample: "subnet-12345"
state:
  description: The current state of the NAT Gateway.
  returned: In all cases.
  type: string
  sample: "available"
vpc_id:
  description: id of the VPC.
  returned: In all cases.
  type: string
  sample: "vpc-12345"
nat_gateway_addresses:
  description: List of dictionairies containing the public_ip, network_interface_id, private_ip, and allocation_id.
  returned: In all cases.
  type: string
  sample: [
      {
          'public_ip': '52.52.52.52',
          'network_interface_id': 'eni-12345',
          'private_ip': '10.0.0.100',
          'allocation_id': 'eipalloc-12345'
      }
  ]


MAINTAINERS: Allen Sanabria (@linuxdynasty), Jon Hadfield (@jonhadfield), Karen Cheng(@Etherdaemon)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_VPC_NAT_GATEWAY_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_nat_gateway_facts.py)

  Gets various details related to AWS VPC Managed Nat Gateways

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeNatGateways.html for possible filters.
        [Default: None]
- nat_gateway_ids
        Get details of specific nat gateway IDs
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# Simple example of listing all nat gateways
- name: List all managed nat gateways in ap-southeast-2
  ec2_vpc_nat_gateway_facts:
    region: ap-southeast-2
  register: all_ngws

- name: Debugging the result
  debug:
    msg: "{{ all_ngws.result }}"

- name: Get details on specific nat gateways
  ec2_vpc_nat_gateway_facts:
    nat_gateway_ids:
      - nat-1234567891234567
      - nat-7654321987654321
    region: ap-southeast-2
  register: specific_ngws

- name: Get all nat gateways with specific filters
  ec2_vpc_nat_gateway_facts:
    region: ap-southeast-2
    filters:
      state: ['pending']
  register: pending_ngws

- name: Get nat gateways with specific filter
  ec2_vpc_nat_gateway_facts:
    region: ap-southeast-2
    filters:
      subnet-id: subnet-12345678
      state: ['available']
  register: existing_nat_gateways

RETURN VALUES:
result:
  description: The result of the describe, converted to ansible snake case style.
    See http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.Client.describe_nat_gateways for the response.
  returned: success
  type: list


MAINTAINERS: Karen Cheng(@Etherdaemon)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_VPC_NET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_net.py)

  Create or terminate AWS virtual private clouds.  This module has a dependency on python-boto.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
= cidr_block
        The CIDR of the VPC

- dhcp_opts_id
        the id of the DHCP options to use for this vpc
        [Default: None]
- dns_hostnames
        Whether to enable AWS hostname support.
        (Choices: yes, no)[Default: True]
- dns_support
        Whether to enable AWS DNS support.
        (Choices: yes, no)[Default: True]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- multi_ok
        By default the module will not create another VPC if there is another VPC with the same name and CIDR block.
        Specify this as true if you want duplicate VPCs created.
        [Default: False]
= name
        The name to give your VPC. This is used in combination with the cidr_block parameter to determine if a VPC
        already exists.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        The state of the VPC. Either absent or present.
        (Choices: present, absent)[Default: present]
- tags
        The tags you want attached to the VPC. This is independent of the name value, note if you pass a 'Name' key it
        would override the Name of the VPC if it's different.
        [Default: None]
- tenancy
        Whether to be default or dedicated tenancy. This cannot be changed after the VPC has been created.
        (Choices: default, dedicated)[Default: default]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Create a VPC with dedicate tenancy and a couple of tags

- ec2_vpc_net:
    name: Module_dev2
    cidr_block: 10.10.0.0/16
    region: us-east-1
    tags:
      module: ec2_vpc_net
      this: works
    tenancy: dedicated



MAINTAINERS: Jonathan Davila (@defionscode)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_NET_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_net_facts.py)

  Gather facts about ec2 VPCs in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeVpcs.html for possible filters.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all VPCs
- ec2_vpc_net_facts:

# Gather facts about a particular VPC using VPC ID
- ec2_vpc_net_facts:
    filters:
      vpc-id: vpc-00112233

# Gather facts about any VPC with a tag key Name and value Example
- ec2_vpc_net_facts:
    filters:
      "tag:Name": Example



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_PEER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_peer.py)

  Read the AWS documentation for VPC Peering Connections http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-
  peering.html

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- peer_owner_id
        The AWS account number for cross account peering.
        [Default: (null)]
- peer_vpc_id
        VPC id of the accepting VPC.
        [Default: (null)]
- peering_id
        Peering connection id.
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create, delete, accept, reject a peering connection.
        (Choices: present, absent, accept, reject)[Default: present]
- tags
        Dictionary of tags to look for and apply when creating a Peering Connection.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_id
        VPC id of the requesting VPC.
        [Default: (null)]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, json, python >= 2.6

EXAMPLES:
# Complete example to create and accept a local peering connection.
- name: Create local account VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    vpc_id: vpc-12345678
    peer_vpc_id: vpc-87654321
    state: present
    tags:
      Name: Peering connection for VPC 21 to VPC 22
      CostCode: CC1234
      Project: phoenix
  register: vpc_peer

- name: Accept local VPC peering request
  ec2_vpc_peer:
    region: ap-southeast-2
    peering_id: "{{ vpc_peer.peering_id }}"
    state: accept
  register: action_peer

# Complete example to delete a local peering connection.
- name: Create local account VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    vpc_id: vpc-12345678
    peer_vpc_id: vpc-87654321
    state: present
    tags:
      Name: Peering connection for VPC 21 to VPC 22
      CostCode: CC1234
      Project: phoenix
  register: vpc_peer

- name: delete a local VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    peering_id: "{{ vpc_peer.peering_id }}"
    state: absent
  register: vpc_peer

  # Complete example to create and accept a cross account peering connection.
- name: Create cross account VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    vpc_id: vpc-12345678
    peer_vpc_id: vpc-12345678
    peer_owner_id: 123456789102
    state: present
    tags:
      Name: Peering connection for VPC 21 to VPC 22
      CostCode: CC1234
      Project: phoenix
  register: vpc_peer

- name: Accept peering connection from remote account
  ec2_vpc_peer:
    region: ap-southeast-2
    peering_id: "{{ vpc_peer.peering_id }}"
    profile: bot03_profile_for_cross_account
    state: accept
  register: vpc_peer

# Complete example to create and reject a local peering connection.
- name: Create local account VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    vpc_id: vpc-12345678
    peer_vpc_id: vpc-87654321
    state: present
    tags:
      Name: Peering connection for VPC 21 to VPC 22
      CostCode: CC1234
      Project: phoenix
  register: vpc_peer

- name: Reject a local VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    peering_id: "{{ vpc_peer.peering_id }}"
    state: reject

# Complete example to create and accept a cross account peering connection.
- name: Create cross account VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    vpc_id: vpc-12345678
    peer_vpc_id: vpc-12345678
    peer_owner_id: 123456789102
    state: present
    tags:
      Name: Peering connection for VPC 21 to VPC 22
      CostCode: CC1234
      Project: phoenix
  register: vpc_peer

- name: Accept a cross account VPC peering connection request
  ec2_vpc_peer:
    region: ap-southeast-2
    peering_id: "{{ vpc_peer.peering_id }}"
    profile: bot03_profile_for_cross_account
    state: accept
    tags:
      Name: Peering connection for VPC 21 to VPC 22
      CostCode: CC1234
      Project: phoenix

# Complete example to create and reject a cross account peering connection.
- name: Create cross account VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    vpc_id: vpc-12345678
    peer_vpc_id: vpc-12345678
    peer_owner_id: 123456789102
    state: present
    tags:
      Name: Peering connection for VPC 21 to VPC 22
      CostCode: CC1234
      Project: phoenix
  register: vpc_peer

- name: Reject a cross account VPC peering Connection
  ec2_vpc_peer:
    region: ap-southeast-2
    peering_id: "{{ vpc_peer.peering_id }}"
    profile: bot03_profile_for_cross_account
    state: reject


RETURN VALUES:
task:
  description: The result of the create, accept, reject or delete action.
  returned: success
  type: dictionary


MAINTAINERS: Mike Mochan(@mmochan)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_ROUTE_TABLE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_route_table.py)

  Manage route tables for AWS virtual private clouds

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- lookup
        Look up route table by either tags or by route table ID. Non-unique tag lookup will fail. If no tags are specifed
        then no lookup for an existing route table is performed and a new route table will be created. To change tags of
        a route table, you must look up by id.
        (Choices: tag, id)[Default: tag]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- propagating_vgw_ids
        Enable route propagation from virtual gateways specified by ID.
        [Default: None]
- purge_routes
        Purge existing routes that are not found in routes.
        [Default: true]
- purge_subnets
        Purge existing subnets that are not found in subnets.
        [Default: true]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- route_table_id
        The ID of the route table to update or delete.
        [Default: None]
- routes
        List of routes in the route table. Routes are specified as dicts containing the keys 'dest' and one of
        'gateway_id', 'instance_id', 'interface_id', or 'vpc_peering_connection_id'. If 'gateway_id' is specified, you
        can refer to the VPC's IGW by using the value 'igw'. Routes are required for present states.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or destroy the VPC route table
        (Choices: present, absent)[Default: present]
= subnets
        An array of subnets to add to this route table. Subnets may be specified by either subnet ID, Name tag, or by a
        CIDR such as '10.0.0.0/24'.

- tags
        A dictionary of resource tags of the form: { tag1: value1, tag2: value2 }. Tags are used to uniquely identify
        route tables within a VPC when the route_table_id is not supplied.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
= vpc_id
        VPC ID of the VPC in which to create the route table.

Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Basic creation example:
- name: Set up public subnet route table
  ec2_vpc_route_table:
    vpc_id: vpc-1245678
    region: us-west-1
    tags:
      Name: Public
    subnets:
      - "{{ jumpbox_subnet.subnet.id }}"
      - "{{ frontend_subnet.subnet.id }}"
      - "{{ vpn_subnet.subnet_id }}"
    routes:
      - dest: 0.0.0.0/0
        gateway_id: "{{ igw.gateway_id }}"
  register: public_route_table

- name: Set up NAT-protected route table
  ec2_vpc_route_table:
    vpc_id: vpc-1245678
    region: us-west-1
    tags:
      Name: Internal
    subnets:
      - "{{ application_subnet.subnet.id }}"
      - 'Database Subnet'
      - '10.0.0.0/8'
    routes:
      - dest: 0.0.0.0/0
        instance_id: "{{ nat.instance_id }}"
  register: nat_route_table



MAINTAINERS: Robert Estelle (@erydo), Rob White (@wimnat)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_ROUTE_TABLE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_route_table_facts.py)

  Gather facts about ec2 VPC route tables in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeRouteTables.html for possible filters.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all VPC route tables
- ec2_vpc_route_table_facts:

# Gather facts about a particular VPC route table using route table ID
- ec2_vpc_route_table_facts:
    filters:
      route-table-id: rtb-00112233

# Gather facts about any VPC route table with a tag key Name and value Example
- ec2_vpc_route_table_facts:
    filters:
      "tag:Name": Example

# Gather facts about any VPC route table within VPC with ID vpc-abcdef00
- ec2_vpc_route_table_facts:
    filters:
      vpc-id: vpc-abcdef00



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_VPC_SUBNET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_subnet.py)

  Manage subnets in AWS virtual private clouds

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- az
        The availability zone for the subnet. Only required when state=present.
        [Default: None]
- cidr
        The CIDR block for the subnet. E.g. 192.0.2.0/24. Only required when state=present.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or remove the subnet
        (Choices: present, absent)[Default: present]
- tags
        A dict of tags to apply to the subnet. Any tags currently applied to the subnet and not present here will be
        removed.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_id
        VPC ID of the VPC in which to create the subnet.
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

- name: Create subnet for database servers
  ec2_vpc_subnet:
    state: present
    vpc_id: vpc-123456
    cidr: 10.0.1.16/28
    resource_tags:
      Name: Database Subnet
  register: database_subnet

- name: Remove subnet for database servers
  ec2_vpc_subnet:
    state: absent
    vpc_id: vpc-123456
    cidr: 10.0.1.16/28



MAINTAINERS: Robert Estelle (@erydo)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_SUBNET_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_subnet_facts.py)

  Gather facts about ec2 VPC subnets in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeSubnets.html for possible filters.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Gather facts about all VPC subnets
- ec2_vpc_subnet_facts:

# Gather facts about a particular VPC subnet using ID
- ec2_vpc_subnet_facts:
    filters:
      subnet-id: subnet-00112233

# Gather facts about any VPC subnet with a tag key Name and value Example
- ec2_vpc_subnet_facts:
    filters:
      "tag:Name": Example

# Gather facts about any VPC subnet within VPC with ID vpc-abcdef00
- ec2_vpc_subnet_facts:
    filters:
      vpc-id: vpc-abcdef00

# Gather facts about a set of VPC subnets, publicA, publicB and publicC within a
# VPC with ID vpc-abcdef00 and then use the jinja map function to return the
# subnet_ids as a list.

- ec2_vpc_subnet_facts:
    filters:
      vpc-id: vpc-abcdef00
      "tag:Name": "{{ item }}"
  with_items:
    - publicA
    - publicB
    - publicC
  register: subnet_facts

- set_fact:
    subnet_ids: "{{ subnet_facts.results|map(attribute='subnets.0.id')|list }}"


MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_VGW    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_vgw.py)

  Creates AWS VPN Virtual Gateways Deletes AWS VPN Virtual Gateways Attaches Virtual Gateways to VPCs Detaches Virtual
  Gateways from VPCs

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- name
        name of the vgw to be created or deleted
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        present to ensure resource is created.
        absent to remove resource
        (Choices: present, absent)[Default: present]
- tags
        dictionary of resource tags
        [Default: None]
- type
        type of the virtual gateway to be created
        (Choices: ipsec.1)[Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_id
        the vpc-id of a vpc to attach or detach
        [Default: (null)]
- vpn_gateway_id
        vpn gateway id of an existing virtual gateway
        [Default: (null)]
- wait_timeout
        number of seconds to wait for status during vpc attach and detach
        [Default: 320]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
- name: Create a new vgw attached to a specific VPC
  ec2_vpc_vgw:
    state: present
    region: ap-southeast-2
    profile: personal
    vpc_id: vpc-12345678
    name: personal-testing
    type: ipsec.1
  register: created_vgw

- name: Create a new unattached vgw
  ec2_vpc_vgw:
    state: present
    region: ap-southeast-2
    profile: personal
    name: personal-testing
    type: ipsec.1
    tags:
      environment: production
      owner: ABC
  register: created_vgw

- name: Remove a new vgw using the name
  ec2_vpc_vgw:
    state: absent
    region: ap-southeast-2
    profile: personal
    name: personal-testing
    type: ipsec.1
  register: deleted_vgw

- name: Remove a new vgw using the vpn_gateway_id
  ec2_vpc_vgw:
    state: absent
    region: ap-southeast-2
    profile: personal
    vpn_gateway_id: vgw-3a9aa123
  register: deleted_vgw

RETURN VALUES:
result:
  description: The result of the create, or delete action.
  returned: success
  type: dictionary


MAINTAINERS: Nick Aslanidis (@naslanidis)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> EC2_VPC_VGW_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_vpc_vgw_facts.py)

  Gather facts about virtual gateways in AWS.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- filters
        A dict of filters to apply. Each dict item consists of a filter key and a filter value. See
        http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeRouteTables.html for possible filters.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpn_gateway_ids
        Get details of a specific Virtual Gateway ID. This value should be provided as a list.
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# # Note: These examples do not set authentication details, see the AWS Guide for details.

- name: Gather facts about all virtual gateways for an account or profile
  ec2_vpc_vgw_facts:
    region: ap-southeast-2
    profile: production
  register: vgw_facts

- name: Gather facts about a filtered list of Virtual Gateways
  ec2_vpc_vgw_facts:
    region: ap-southeast-2
    profile: production
    filters:
        "tag:Name": "main-virt-gateway"
  register: vgw_facts

- name: Gather facts about a specific virtual gateway by VpnGatewayIds
  ec2_vpc_vgw_facts:
    region: ap-southeast-2
    profile: production
    vpn_gateway_ids: vgw-c432f6a7
  register: vgw_facts

RETURN VALUES:
virtual_gateways:
    description: The virtual gateways for the account.
    returned: always
    type: list
    sample: [
        {
            "state": "available",
            "tags": [
                {
                    "key": "Name",
                    "value": "TEST-VGW"
                }
            ],
            "type": "ipsec.1",
            "vpc_attachments": [
                {
                    "state": "attached",
                    "vpc_id": "vpc-22a93c74"
                }
            ],
            "vpn_gateway_id": "vgw-23e3d64e"
        }
    ]

changed:
    description: True if listing the virtual gateways succeeds.
    returned: always
    type: bool
    sample: "false"


MAINTAINERS: Nick Aslanidis (@naslanidis)

METADATA:
	Status: ['preview']
	Supported_by: community
> EC2_WIN_PASSWORD    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ec2_win_password.py)

  Gets the default administrator password from any EC2 Windows instance.  The instance is referenced by its id (e.g.
  i-XXXXXXX). This module has a dependency on python-boto.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= instance_id
        The instance id to get the password data from.

= key_file
        Path to the file containing the key pair used on the instance.

- key_passphrase
        The passphrase for the instance key pair. The key must use DES or 3DES encryption for this module to decrypt it.
        You can use openssl to convert your password protected keys if they do not use DES or 3DES. ex) openssl rsa -in
        current_key -out new_key -des3.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        Whether or not to wait for the password to be available before returning.
        (Choices: yes, no)[Default: no]
- wait_timeout
        Number of seconds to wait before giving up.
        [Default: 120]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Example of getting a password
tasks:
- name: get the Administrator password
  ec2_win_password:
    profile: my-boto-profile
    instance_id: i-XXXXXX
    region: us-east-1
    key_file: "~/aws-creds/my_test_key.pem"

# Example of getting a password with a password protected key
tasks:
- name: get the Administrator password
  ec2_win_password:
    profile: my-boto-profile
    instance_id: i-XXXXXX
    region: us-east-1
    key_file: "~/aws-creds/my_protected_test_key.pem"
    key_passphrase: "secret"

# Example of waiting for a password
tasks:
- name: get the Administrator password
  ec2_win_password:
    profile: my-boto-profile
    instance_id: i-XXXXXX
    region: us-east-1
    key_file: "~/aws-creds/my_test_key.pem"
    wait: yes
    wait_timeout: 45


MAINTAINERS: Rick Mendes (@rickmendes)

METADATA:
	Status: ['preview']
	Supported_by: community
> ECS_CLUSTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ecs_cluster.py)

  Creates or terminates ecs clusters.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- delay
        Number of seconds to wait
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= name
        The cluster name

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- repeat
        The number of times to wait for the cluster to have an instance
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        The desired state of the cluster
        (Choices: present, absent, has_instances)
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * When deleting a cluster, the information returned is the state of the cluster prior to deletion.
  * It will also wait for a cluster to have instances registered to it.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Cluster creation
- ecs_cluster:
    name: default
    state: present

# Cluster deletion
- ecs_cluster:
    name: default
    state: absent

- name: Wait for register
  ecs_cluster:
    name: "{{ new_cluster }}"
    state: has_instances
    delay: 10
    repeat: 10
  register: task_output


RETURN VALUES:
activeServicesCount:
    description: how many services are active in this cluster
    returned: 0 if a new cluster
    type: int
clusterArn:
    description: the ARN of the cluster just created
    type: string (ARN)
    sample: arn:aws:ecs:us-west-2:172139249013:cluster/test-cluster-mfshcdok
clusterName:
    description: name of the cluster just created (should match the input argument)
    type: string
    sample: test-cluster-mfshcdok
pendingTasksCount:
    description: how many tasks are waiting to run in this cluster
    returned: 0 if a new cluster
    type: int
registeredContainerInstancesCount:
    description: how many container instances are available in this cluster
    returned: 0 if a new cluster
    type: int
runningTasksCount:
    description: how many tasks are running in this cluster
    returned: 0 if a new cluster
    type: int
status:
    description: the status of the new cluster
    returned: ACTIVE
    type: string


MAINTAINERS: Mark Chance(@Java1Guy)

METADATA:
	Status: ['preview']
	Supported_by: community
> ECS_ECR    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ecs_ecr.py)

  Manage Elastic Container Registry repositories

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- delete_policy
        if yes, remove the policy from the repository
        [Default: False]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- force_set_policy
        if no, prevents setting a policy that would prevent you from setting another policy in the future.
        [Default: False]
= name
        the name of the repository

- policy
        JSON or dict that represents the new policy
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- registry_id
        AWS account id associated with the registry.
        If not specified, the default registry is assumed.
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        create or destroy the repository
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# If the repository does not exist, it is created. If it does exist, would not
# affect any policies already on it.
- name: ecr-repo
  ecs_ecr: name=super/cool

- name: destroy-ecr-repo
  ecs_ecr: name=old/busted state=absent

- name: Cross account ecr-repo
  ecs_ecr: registry_id=999999999999 name=cross/account

- name: set-policy as object
  ecs_ecr:
    name: needs-policy-object
    policy:
      Version: '2008-10-17'
      Statement:
        - Sid: read-only
          Effect: Allow
          Principal:
            AWS: '{{ read_only_arn }}'
          Action:
            - ecr:GetDownloadUrlForLayer
            - ecr:BatchGetImage
            - ecr:BatchCheckLayerAvailability

- name: set-policy as string
  ecs_ecr:
    name: needs-policy-string
    policy: "{{ lookup('template', 'policy.json.j2') }}"

- name: delete-policy
  ecs_ecr:
    name: needs-no-policy
    delete_policy: yes

RETURN VALUES:
state:
    type: string
    description: The asserted state of the repository (present, absent)
created:
    type: boolean
    description: If true, the repository was created
name:
    type: string
    description: The name of the repository
    returned: "when state == 'absent'"
repository:
    type: dict
    description: The created or updated repository
    returned: "when state == 'present'"
    sample:
        createdAt: '2017-01-17T08:41:32-06:00'
        registryId: '999999999999'
        repositoryArn: arn:aws:ecr:us-east-1:999999999999:repository/ecr-test-1484664090
        repositoryName: ecr-test-1484664090
        repositoryUri: 999999999999.dkr.ecr.us-east-1.amazonaws.com/ecr-test-1484664090


MAINTAINERS: David M. Lee (@leedm777)

METADATA:
	Status: ['preview']
	Supported_by: community
> ECS_SERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ecs_service.py)

  Creates or terminates ecs services.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- client_token
        Unique, case-sensitive identifier you provide to ensure the idempotency of the request. Up to 32 ASCII characters
        are allowed.
        [Default: (null)]
- cluster
        The name of the cluster in which the service exists
        [Default: (null)]
- delay
        The time to wait before checking that the service is available
        [Default: 10]
- deployment_configuration
        Optional parameters that control the deployment_configuration; format is '{"maximum_percent":<integer>,
        "minimum_healthy_percent":<integer>}
        [Default: (null)]
- desired_count
        The count of how many instances of the service. This parameter is required when state=present
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- load_balancers
        The list of ELBs defined for this service
        [Default: (null)]
= name
        The name of the service

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- repeat
        The number of times to check that the service is available
        [Default: 10]
- role
        The name or full Amazon Resource Name (ARN) of the IAM role that allows your Amazon ECS container agent to make
        calls to your load balancer on your behalf. This parameter is only required if you are using a load balancer with
        your service.
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        The desired state of the service
        (Choices: present, absent, deleting)
- task_definition
        The task definition the service will run. This parameter is required when state=present
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * the service role specified must be assumable (i.e. have a trust relationship for the ecs service,
        ecs.amazonaws.com)
  * for details of the parameters and returns see
        http://boto3.readthedocs.org/en/latest/reference/services/ecs.html
  * An IAM role must have been previously created
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, json, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.
- ecs_service:
    state: present
    name: console-test-service
    cluster: new_cluster
    task_definition: new_cluster-task:1"
    desired_count: 0

# Basic provisioning example
- ecs_service:
    name: default
    state: present
    cluster: new_cluster

# Simple example to delete
- ecs_service:
    name: default
    state: absent
    cluster: new_cluster

# With custom deployment configuration
- ecs_service:
    name: test-service
    cluster: test-cluster
    task_definition: test-task-definition
    desired_count: 3
    deployment_configuration:
      minimum_healthy_percent: 75
      maximum_percent: 150
    state: present

RETURN VALUES:
service:
    description: Details of created service.
    returned: when creating a service
    type: complex
    contains:
        clusterArn:
            description: The Amazon Resource Name (ARN) of the of the cluster that hosts the service.
            returned: always
            type: string
        desiredCount:
            description: The desired number of instantiations of the task definition to keep running on the service.
            returned: always
            type: int
        loadBalancers:
            description: A list of load balancer objects
            returned: always
            type: complex
            contains:
                loadBalancerName:
                    description: the name
                    returned: always
                    type: string
                containerName:
                    description: The name of the container to associate with the load balancer.
                    returned: always
                    type: string
                containerPort:
                    description: The port on the container to associate with the load balancer.
                    returned: always
                    type: int
        pendingCount:
            description: The number of tasks in the cluster that are in the PENDING state.
            returned: always
            type: int
        runningCount:
            description: The number of tasks in the cluster that are in the RUNNING state.
            returned: always
            type: int
        serviceArn:
            description: The Amazon Resource Name (ARN) that identifies the service. The ARN contains the arn:aws:ecs namespace, followed by the region of the service, the AWS account ID of the service owner, the service namespace, and then the service name. For example, arn:aws:ecs:region :012345678910 :service/my-service .
            returned: always
            type: string
        serviceName:
            description: A user-generated string used to identify the service
            returned: always
            type: string
        status:
            description: The valid values are ACTIVE, DRAINING, or INACTIVE.
            returned: always
            type: string
        taskDefinition:
            description: The ARN of a task definition to use for tasks in the service.
            returned: always
            type: string
        deployments:
            description: list of service deployments
            returned: always
            type: list of complex
        deploymentConfiguration:
            description: dictionary of deploymentConfiguration
            returned: always
            type: complex
            contains:
                maximumPercent:
                    description: maximumPercent param
                    returned: always
                    type: int
                minimumHealthyPercent:
                    description: minimumHealthyPercent param
                    returned: always
                    type: int
        events:
            description: lost of service events
            returned: always
            type: list of complex
ansible_facts:
    description: Facts about deleted service.
    returned: when deleting a service
    type: complex
    contains:
        service:
            description: Details of deleted service in the same structure described above for service creation.
            returned: when service existed and was deleted
            type: complex


MAINTAINERS: Darek Kaczynski (@kaczynskid), Zac Blazic (@zacblazic), Mark Chance (@java1guy), Stephane Maarek (@simplesteph)

METADATA:
	Status: ['preview']
	Supported_by: community
> ECS_SERVICE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ecs_service_facts.py)

  Lists or describes services in ecs.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- cluster
        The cluster ARNS in which to list the services.
        [Default: default]
- details
        Set this to true if you want detailed information about the services.
        (Choices: true, false)[Default: false]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- service
        The service to get details for (required if details is true)
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * for details of the parameters and returns see
        http://boto3.readthedocs.org/en/latest/reference/services/ecs.html
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, json, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Basic listing example
- ecs_service_facts:
    cluster: test-cluster
    service: console-test-service
    details: true

# Basic listing example
- ecs_service_facts:
    cluster: test-cluster

RETURN VALUES:
services:
    description: When details is false, returns an array of service ARNs, otherwise an array of complex objects as described below.
    returned: success
    type: list of complex
    contains:
        clusterArn:
            description: The Amazon Resource Name (ARN) of the of the cluster that hosts the service.
            returned: always
            type: string
        desiredCount:
            description: The desired number of instantiations of the task definition to keep running on the service.
            returned: always
            type: int
        loadBalancers:
            description: A list of load balancer objects
            returned: always
            type: complex
            contains:
                loadBalancerName:
                    description: the name
                    returned: always
                    type: string
                containerName:
                    description: The name of the container to associate with the load balancer.
                    returned: always
                    type: string
                containerPort:
                    description: The port on the container to associate with the load balancer.
                    returned: always
                    type: int
        pendingCount:
            description: The number of tasks in the cluster that are in the PENDING state.
            returned: always
            type: int
        runningCount:
            description: The number of tasks in the cluster that are in the RUNNING state.
            returned: always
            type: int
        serviceArn:
            description: The Amazon Resource Name (ARN) that identifies the service. The ARN contains the arn:aws:ecs namespace, followed by the region of the service, the AWS account ID of the service owner, the service namespace, and then the service name. For example, arn:aws:ecs:region :012345678910 :service/my-service .
            returned: always
            type: string
        serviceName:
            description: A user-generated string used to identify the service
            returned: always
            type: string
        status:
            description: The valid values are ACTIVE, DRAINING, or INACTIVE.
            returned: always
            type: string
        taskDefinition:
            description: The ARN of a task definition to use for tasks in the service.
            returned: always
            type: string
        deployments:
            description: list of service deployments
            returned: always
            type: list of complex
        events:
            description: lost of service events
            returned: always
            type: list of complex


MAINTAINERS: Darek Kaczynski (@kaczynskid), Mark Chance (@java1guy)

METADATA:
	Status: ['preview']
	Supported_by: community
> ECS_TASK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ecs_task.py)

  Creates or deletes instances of task definitions.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- cluster
        The name of the cluster to run the task on
        [Default: (null)]
- container_instances
        The list of container instances on which to deploy the task
        [Default: (null)]
- count
        How many new instances to start
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= operation
        Which task operation to execute
        (Choices: run, start, stop)
- overrides
        A dictionary of values to pass to the new instances
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- started_by
        A value showing who or what started the task (for informational purposes)
        [Default: (null)]
- task
        The task to stop
        [Default: (null)]
- task_definition
        The task definition to start or run
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, json, python >= 2.6

EXAMPLES:
# Simple example of run task
- name: Run task
  ecs_task:
    operation: run
    cluster: console-sample-app-static-cluster
    task_definition: console-sample-app-static-taskdef
    count: 1
    started_by: ansible_user
  register: task_output

# Simple example of start task

- name: Start a task
  ecs_task:
      operation: start
      cluster: console-sample-app-static-cluster
      task_definition: console-sample-app-static-taskdef
      task: "arn:aws:ecs:us-west-2:172139249013:task/3f8353d1-29a8-4689-bbf6-ad79937ffe8a"
      container_instances:
      - arn:aws:ecs:us-west-2:172139249013:container-instance/79c23f22-876c-438a-bddf-55c98a3538a8
      started_by: ansible_user
  register: task_output

- name: Stop a task
  ecs_task:
      operation: stop
      cluster: console-sample-app-static-cluster
      task_definition: console-sample-app-static-taskdef
      task: "arn:aws:ecs:us-west-2:172139249013:task/3f8353d1-29a8-4689-bbf6-ad79937ffe8a"

RETURN VALUES:
task:
    description: details about the tast that was started
    returned: success
    type: complex
    contains:
        taskArn:
            description: The Amazon Resource Name (ARN) that identifies the task.
            returned: always
            type: string
        clusterArn:
            description: The Amazon Resource Name (ARN) of the of the cluster that hosts the task.
            returned: only when details is true
            type: string
        taskDefinitionArn:
            description: The Amazon Resource Name (ARN) of the task definition.
            returned: only when details is true
            type: string
        containerInstanceArn:
            description: The Amazon Resource Name (ARN) of the container running the task.
            returned: only when details is true
            type: string
        overrides:
            description: The container overrides set for this task.
            returned: only when details is true
            type: list of complex
        lastStatus:
            description: The last recorded status of the task.
            returned: only when details is true
            type: string
        desiredStatus:
            description: The desired status of the task.
            returned: only when details is true
            type: string
        containers:
            description: The container details.
            returned: only when details is true
            type: list of complex
        startedBy:
            description: The used who started the task.
            returned: only when details is true
            type: string
        stoppedReason:
            description: The reason why the task was stopped.
            returned: only when details is true
            type: string
        createdAt:
            description: The timestamp of when the task was created.
            returned: only when details is true
            type: string
        startedAt:
            description: The timestamp of when the task was started.
            returned: only when details is true
            type: string
        stoppedAt:
            description: The timestamp of when the task was stopped.
            returned: only when details is true
            type: string


MAINTAINERS: Mark Chance(@Java1Guy)

METADATA:
	Status: ['preview']
	Supported_by: community
> ECS_TASKDEFINITION    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/ecs_taskdefinition.py)

  Registers or deregisters task definitions in the Amazon Web Services (AWS) EC2 Container Service (ECS)

Options (= is mandatory):

- arn
        The arn of the task description to delete
        [Default: (null)]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- containers
        A list of containers definitions
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- family
        A Name that would be given to the task definition
        [Default: (null)]
- network_mode
        The Docker networking mode to use for the containers in the task.
        (Choices: bridge, host, none)[Default: bridge]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- revision
        A revision number for the task definition
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        State whether the task definition should exist or be deleted
        (Choices: present, absent)
- task_role_arn
        The Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this
        task are granted the permissions that are specified in this role.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- volumes
        A list of names of volumes to be attached
        [Default: (null)]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, json, python >= 2.6

EXAMPLES:
- name: Create task definition
  ecs_taskdefinition:
    containers:
    - name: simple-app
      cpu: 10
      essential: true
      image: "httpd:2.4"
      memory: 300
      mountPoints:
      - containerPath: /usr/local/apache2/htdocs
        sourceVolume: my-vol
      portMappings:
      - containerPort: 80
        hostPort: 80
    - name: busybox
      command:
        - /bin/sh -c "while true; do echo '<html><head><title>Amazon ECS Sample App</title></head><body><div><h1>Amazon ECS Sample App</h1><h2>Congratulations!</h2><p>Your application is now running on a container in Amazon ECS.</p>' > top; /bin/date > date ; echo '</div></body></html>' > bottom; cat top date bottom > /usr/local/apache2/htdocs/index.html ; sleep 1; done"
      cpu: 10
      entryPoint:
      - sh
      - "-c"
      essential: false
      image: busybox
      memory: 200
      volumesFrom:
      - sourceContainer: simple-app
    volumes:
    - name: my-vol
    family: test-cluster-taskdef
    state: present
  register: task_output

RETURN VALUES:
taskdefinition:
    description: a reflection of the input parameters
    type: dict inputs plus revision, status, taskDefinitionArn


MAINTAINERS: Mark Chance(@Java1Guy)

METADATA:
	Status: ['preview']
	Supported_by: community
> EFS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/efs.py)

  Module allows create, search and destroy Amazon EFS file systems

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- id
        ID of Amazon EFS. Either name or ID required for delete.
        [Default: None]
- name
        Creation Token of Amazon EFS file system. Required for create. Either name or ID required for delete.
        [Default: None]
- performance_mode
        File system's performance mode to use. Only takes effect during creation.
        (Choices: general_purpose, max_io)[Default: general_purpose]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Allows to create, search and destroy Amazon EFS file system
        (Choices: present, absent)[Default: present]
- tags
        List of tags of Amazon EFS. Should be defined as dictionary In case of 'present' state with list of tags and
        existing EFS (matched by 'name'), tags of EFS will be replaced with provided data.
        [Default: None]
- targets
        List of mounted targets. It should be a list of dictionaries, every dictionary should include next attributes: -
        subnet_id - Mandatory. The ID of the subnet to add the mount target in. - ip_address - Optional. A valid IPv4
        address within the address range of the specified subnet. - security_groups - Optional. List of security group
        IDs, of the form 'sg-xxxxxxxx'. These must be for the same VPC as subnet specified This data may be modified for
        existing EFS using state 'present' and new list of mount targets.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        In case of 'present' state should wait for EFS 'available' life cycle state (of course, if current state not
        'deleting' or 'deleted') In case of 'absent' state should wait for EFS 'deleted' life cycle state
        (Choices: yes, no)[Default: no]
- wait_timeout
        How long the module should wait (in seconds) for desired state before returning. Zero means wait as long as
        necessary.
        [Default: 0]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# EFS provisioning
- efs:
    state: present
    name: myTestEFS
    tags:
        name: myTestNameTag
        purpose: file-storage
    targets:
        - subnet_id: subnet-748c5d03
          security_groups: [ "sg-1a2b3c4d" ]

# Modifying EFS data
- efs:
    state: present
    name: myTestEFS
    tags:
        name: myAnotherTestTag
    targets:
        - subnet_id: subnet-7654fdca
          security_groups: [ "sg-4c5d6f7a" ]

# Deleting EFS
- efs:
    state: absent
    name: myTestEFS

RETURN VALUES:
creation_time:
    description: timestamp of creation date
    returned:
    type: datetime
    sample: 2015-11-16 07:30:57-05:00
creation_token:
    description: EFS creation token
    returned:
    type: UUID
    sample: console-88609e04-9a0e-4a2e-912c-feaa99509961
file_system_id:
    description: ID of the file system
    returned:
    type: unique ID
    sample: fs-xxxxxxxx
life_cycle_state:
    description: state of the EFS file system
    returned:
    type: str
    sample: creating, available, deleting, deleted
mount_point:
    description: url of file system
    returned:
    type: str
    sample: .fs-xxxxxxxx.efs.us-west-2.amazonaws.com:/
mount_targets:
    description: list of mount targets
    returned:
    type: list of dicts
    sample:
        [
            {
                "file_system_id": "fs-a7ad440e",
                "ip_address": "172.31.17.173",
                "life_cycle_state": "available",
                "mount_target_id": "fsmt-d8907871",
                "network_interface_id": "eni-6e387e26",
                "owner_id": "740748460359",
                "security_groups": [
                    "sg-a30b22c6"
                ],
                "subnet_id": "subnet-e265c895"
            },
            ...
        ]
name:
    description: name of the file system
    returned:
    type: str
    sample: my-efs
number_of_mount_targets:
    description: the number of targets mounted
    returned:
    type: int
    sample: 3
owner_id:
    description: AWS account ID of EFS owner
    returned:
    type: str
    sample: XXXXXXXXXXXX
size_in_bytes:
    description: size of the file system in bytes as of a timestamp
    returned:
    type: dict
    sample:
        {
            "timestamp": "2015-12-21 13:59:59-05:00",
            "value": 12288
        }
performance_mode:
    description: performance mode of the file system
    returned:
    type: str
    sample: "generalPurpose"
tags:
    description: tags on the efs instance
    returned:
    type: dict
    sample:
        {
            "name": "my-efs",
            "key": "Value"
        }



MAINTAINERS: Ryan Sydnor (@ryansydnor), Artem Kazakov (@akazakov)

METADATA:
	Status: ['preview']
	Supported_by: curated
> EFS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/efs_facts.py)

  Module searches Amazon EFS file systems

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- id
        ID of Amazon EFS.
        [Default: None]
- name
        Creation Token of Amazon EFS file system.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- tags
        List of tags of Amazon EFS. Should be defined as dictionary
        [Default: None]
- targets
        List of mounted targets. It should be a list of dictionaries, every dictionary should include next attributes: -
        SubnetId - Mandatory. The ID of the subnet to add the mount target in. - IpAddress - Optional. A valid IPv4
        address within the address range of the specified subnet. - SecurityGroups - Optional. List of security group
        IDs, of the form 'sg-xxxxxxxx'. These must be for the same VPC as subnet specified.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# find all existing efs
- efs_facts:
  register: result

- efs_facts:
    name: myTestNameTag

- efs_facts:
    id: fs-1234abcd

# Searching all EFS instances with tag Name = 'myTestNameTag', in subnet 'subnet-1a2b3c4d' and with security group 'sg-4d3c2b1a'
- efs_facts:
    tags:
        name: myTestNameTag
    targets:
        - subnet-1a2b3c4d
        - sg-4d3c2b1a

RETURN VALUES:
creation_time:
    description: timestamp of creation date
    returned:
    type: datetime
    sample: 2015-11-16 07:30:57-05:00
creation_token:
    description: EFS creation token
    returned:
    type: UUID
    sample: console-88609e04-9a0e-4a2e-912c-feaa99509961
file_system_id:
    description: ID of the file system
    returned:
    type: unique ID
    sample: fs-xxxxxxxx
life_cycle_state:
    description: state of the EFS file system
    returned:
    type: str
    sample: creating, available, deleting, deleted
mount_point:
    description: url of file system
    returned:
    type: str
    sample: .fs-xxxxxxxx.efs.us-west-2.amazonaws.com:/
mount_targets:
    description: list of mount targets
    returned:
    type: list of dicts
    sample:
        [
            {
                "file_system_id": "fs-a7ad440e",
                "ip_address": "172.31.17.173",
                "life_cycle_state": "available",
                "mount_target_id": "fsmt-d8907871",
                "network_interface_id": "eni-6e387e26",
                "owner_id": "740748460359",
                "security_groups": [
                    "sg-a30b22c6"
                ],
                "subnet_id": "subnet-e265c895"
            },
            ...
        ]
name:
    description: name of the file system
    returned:
    type: str
    sample: my-efs
number_of_mount_targets:
    description: the number of targets mounted
    returned:
    type: int
    sample: 3
owner_id:
    description: AWS account ID of EFS owner
    returned:
    type: str
    sample: XXXXXXXXXXXX
size_in_bytes:
    description: size of the file system in bytes as of a timestamp
    returned:
    type: dict
    sample:
        {
            "timestamp": "2015-12-21 13:59:59-05:00",
            "value": 12288
        }
performance_mode:
    description: performance mode of the file system
    returned:
    type: str
    sample: "generalPurpose"
tags:
    description: tags on the efs instance
    returned:
    type: dict
    sample:
        {
            "name": "my-efs",
            "key": "Value"
        }



MAINTAINERS: Ryan Sydnor (@ryansydnor)

METADATA:
	Status: ['preview']
	Supported_by: curated
> EJABBERD_USER    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ejabberd_user.py)

  This module provides user management for ejabberd servers

Options (= is mandatory):

= host
        the ejabberd host associated with this username

- logging
        enables or disables the local syslog facility for this module
        (Choices: true, false, yes, no)[Default: False]
- password
        the password to assign to the username
        [Default: (null)]
- state
        describe the desired state of the user to be managed
        (Choices: present, absent)[Default: present]
= username
        the name of the user to manage

Notes:
  * Password parameter is required for state == present only
  * Passwords must be stored in clear text for this release
  * The ejabberd configuration file must include mod_admin_extra as a module.
Requirements:  ejabberd with mod_admin_extra

EXAMPLES:
# Example playbook entries using the ejabberd_user module to manage users state.

- name: create a user if it does not exists
  ejabberd_user:
    username: test
    host: server
    password: password

- name: delete a user if it exists
  ejabberd_user:
    username: test
    host: server
    state: absent


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> ELASTICACHE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/elasticache.py)

  Manage cache clusters in Amazon Elasticache. Returns information about the specified cache cluster.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- cache_engine_version
        The version number of the cache engine
        [Default: None]
- cache_parameter_group
        The name of the cache parameter group to associate with this cache cluster. If this argument is omitted, the
        default cache parameter group for the specified engine will be used.
        [Default: None]
- cache_port
        The port number on which each of the cache nodes will accept connections
        [Default: None]
- cache_security_groups
        A list of cache security group names to associate with this cache cluster. Must be an empty list if inside a vpc
        [Default: None]
- cache_subnet_group
        The subnet group name to associate with. Only use if inside a vpc. Required if inside a vpc
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- engine
        Name of the cache engine to be used.
        (Choices: redis, memcached)[Default: memcached]
- hard_modify
        Whether to destroy and recreate an existing cache cluster if necessary in order to modify its state
        (Choices: yes, no)[Default: False]
= name
        The cache cluster identifier

- node_type
        The compute and memory capacity of the nodes in the cache cluster
        [Default: cache.m1.small]
- num_nodes
        The initial number of cache nodes that the cache cluster will have. Required when state=present.
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_group_ids
        A list of vpc security group names to associate with this cache cluster. Only use if inside a vpc
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        `absent' or `present' are idempotent actions that will create or destroy a cache cluster as needed. `rebooted'
        will reboot the cluster, resulting in a momentary outage.
        (Choices: present, absent, rebooted)
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        Wait for cache cluster result before returning
        (Choices: yes, no)[Default: True]
- zone
        The EC2 Availability Zone in which the cache cluster will be created
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: None of these examples set aws_access_key, aws_secret_key, or region.
# It is assumed that their matching environment variables are set.

# Basic example
- elasticache:
    name: "test-please-delete"
    state: present
    engine: memcached
    cache_engine_version: 1.4.14
    node_type: cache.m1.small
    num_nodes: 1
    cache_port: 11211
    cache_security_groups:
      - default
    zone: us-east-1d


# Ensure cache cluster is gone
- elasticache:
    name: "test-please-delete"
    state: absent

# Reboot cache cluster
- elasticache:
    name: "test-please-delete"
    state: rebooted



MAINTAINERS: Jim Dalton (@jsdalton)

METADATA:
	Status: ['preview']
	Supported_by: community
> ELASTICACHE_PARAMETER_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/elasticache_parameter_group.py)

  Manage cache security groups in Amazon Elasticache. Returns information about the specified cache cluster.

Options (= is mandatory):

- description
        A user-specified description for the cache parameter group.
        [Default: (null)]
= group_family
        The name of the cache parameter group family that the cache parameter group can be used with.
        (Choices: memcached1.4, redis2.6, redis2.8, redis3.2)
= name
        A user-specified name for the cache parameter group.

= state
        Idempotent actions that will create/modify, destroy, or reset a cache parameter group as needed.
        (Choices: present, absent, reset)
- values
        A user-specified list of parameters to reset or modify for the cache parameter group.
        [Default: None]
EXAMPLES:
# Note: None of these examples set aws_access_key, aws_secret_key, or region.
# It is assumed that their matching environment variables are set.
---
- hosts: localhost
  connection: local
  tasks:
    - name: 'Create a test parameter group'
      elasticache_parameter_group:
        name: 'test-param-group'
        group_family: 'redis3.2'
        description: 'This is a cache parameter group'
        state: 'present'
    - name: 'Modify a test parameter group'
      elasticache_parameter_group:
        name: 'test-param-group'
        values:
          - ['activerehashing', 'yes']
          - ['client-output-buffer-limit-normal-hard-limit', 4]
        state: 'present'
    - name: 'Reset all modifiable parameters for the test parameter group'
      elasticache_parameter_group:
        name: 'test-param-group'
        state: reset
    - name: 'Delete a test parameter group'
      elasticache_parameter_group:
        name: 'test-param-group'
        state: 'absent'

RETURN VALUES:
elasticache:
  description: cache parameter group information and response metadata
  returned: always
  type: dict
  sample:
    cache_parameter_group:
      cache_parameter_group_family: redis3.2
      cache_parameter_group_name: test-please-delete
      description: "initial description"
    response_metadata:
      http_headers:
        content-length: "562"
        content-type: text/xml
        date: "Mon, 06 Feb 2017 22:14:08 GMT"
        x-amzn-requestid: 947291f9-ecb9-11e6-85bd-3baa4eca2cc1
      http_status_code: 200
      request_id: 947291f9-ecb9-11e6-85bd-3baa4eca2cc1
      retry_attempts: 0
changed:
  description: if the cache parameter group has changed
  returned: always
  type: bool
  sample:
    changed: true


MAINTAINERS: Sloane Hertel (@s-hertel)

METADATA:
	Status: ['preview']
	Supported_by: community
> ELASTICACHE_SNAPSHOT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/elasticache_snapshot.py)

  Manage cache snapshots in Amazon Elasticache. Returns information about the specified snapshot.

Options (= is mandatory):

- bucket
        The s3 bucket to which the snapshot is exported
        [Default: None]
- cluster_id
        The name of an existing cache cluster in the replication group to make the snapshot.
        [Default: None]
= name
        The name of the snapshot we want to create, copy, delete

- replication_id
        The name of the existing replication group to make the snapshot.
        [Default: None]
- state
        Actions that will create, destroy, or copy a snapshot.
        (Choices: present, absent, copy)[Default: (null)]
- target
        The name of a snapshot copy
        [Default: None]
EXAMPLES:
# Note: None of these examples set aws_access_key, aws_secret_key, or region.
# It is assumed that their matching environment variables are set.
---
- hosts: localhost
  connection: local
  tasks:
    - name: 'Create a snapshot'
      elasticache_snapshot:
        name: 'test-snapshot'
        state: 'present'
        cluster_id: '{{ cluster }}'
        replication_id: '{{ replication }}'

RETURN VALUES:
response_metadata:
  description: response metadata about the snapshot
  returned: always
  type: dict
  sample:
    http_headers:
      content-length: 1490
      content-type: text/xml
      date: Tue, 07 Feb 2017 16:43:04 GMT
      x-amzn-requestid: 7f436dea-ed54-11e6-a04c-ab2372a1f14d
    http_status_code: 200
    request_id: 7f436dea-ed54-11e6-a04c-ab2372a1f14d
    retry_attempts: 0
snapshot:
  description: snapshot data
  returned: always
  type: dict
  sample:
    auto_minor_version_upgrade: true
    cache_cluster_create_time: 2017-02-01T17:43:58.261000+00:00
    cache_cluster_id: test-please-delete
    cache_node_type: cache.m1.small
    cache_parameter_group_name: default.redis3.2
    cache_subnet_group_name: default
    engine: redis
    engine_version: 3.2.4
    node_snapshots:
      cache_node_create_time: 2017-02-01T17:43:58.261000+00:00
      cache_node_id: 0001
      cache_size:
    num_cache_nodes: 1
    port: 11211
    preferred_availability_zone: us-east-1d
    preferred_maintenance_window: wed:03:00-wed:04:00
    snapshot_name: deletesnapshot
    snapshot_retention_limit: 0
    snapshot_source: manual
    snapshot_status: creating
    snapshot_window: 10:00-11:00
    vpc_id: vpc-c248fda4
changed:
  description: if a snapshot has been created, deleted, or copied
  returned: always
  type: bool
  sample:
    changed: true


MAINTAINERS: Sloane Hertel (@s-hertel)

METADATA:
	Status: ['preview']
	Supported_by: community
> ELASTICACHE_SUBNET_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/elasticache_subnet_group.py)

  Creates, modifies, and deletes Elasticache subnet groups. This module has a dependency on python-boto >= 2.5.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- description
        Elasticache subnet group description. Only set when a new group is added.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= name
        Database subnet group identifier.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Specifies whether the subnet should be present or absent.
        (Choices: present, absent)[Default: present]
- subnets
        List of subnet IDs that make up the Elasticache subnet group.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Add or change a subnet group
- elasticache_subnet_group:
    state: present
    name: norwegian-blue
    description: My Fancy Ex Parrot Subnet Group
    subnets:
      - subnet-aaaaaaaa
      - subnet-bbbbbbbb

# Remove a subnet group
- elasticache_subnet_group:
    state: absent
    name: norwegian-blue


MAINTAINERS: Tim Mahoney (@timmahoney)

METADATA:
	Status: ['preview']
	Supported_by: community
> ELASTICSEARCH_PLUGIN    (/usr/lib/python2.7/site-packages/ansible/modules/database/misc/elasticsearch_plugin.py)

  Manages Elasticsearch plugins.

Options (= is mandatory):

= name
        Name of the plugin to install. In ES 2.x, the name can be an url or file location

- plugin_bin
        Location of the plugin binary
        [Default: /usr/share/elasticsearch/bin/plugin]
- plugin_dir
        Your configured plugin directory specified in Elasticsearch
        [Default: /usr/share/elasticsearch/plugins/]
- proxy_host
        Proxy host to use during plugin installation
        [Default: None]
- proxy_port
        Proxy port to use during plugin installation
        [Default: None]
- state
        Desired state of a plugin.
        (Choices: present, absent)[Default: present]
- timeout
        Timeout setting: 30s, 1m, 1h...
        [Default: 1m]
- url
        Set exact URL to download the plugin from (Only works for ES 1.x)
        [Default: None]
- version
        Version of the plugin to be installed. If plugin exists with previous version, it will NOT be updated
        [Default: None]
EXAMPLES:
# Install Elasticsearch head plugin
- elasticsearch_plugin:
    state: present
    name: mobz/elasticsearch-head

# Install specific version of a plugin
- elasticsearch_plugin:
    state: present
    name: com.github.kzwang/elasticsearch-image
    version: '1.2.0'

# Uninstall Elasticsearch head plugin
- elasticsearch_plugin:
    state: absent
    name: mobz/elasticsearch-head


MAINTAINERS: Mathew Davies (@ThePixelDeveloper)

METADATA:
	Status: ['preview']
	Supported_by: community
> EOS_BANNER    (/usr/lib/python2.7/site-packages/ansible/modules/network/eos/eos_banner.py)

  This will configure both login and motd banners on remote devices running Arista EOS.  It allows playbooks to add or
  remote banner text from the active running configuration.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
= banner
        Specifies which banner that should be configured on the remote device.
        (Choices: login, banner)[Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- state
        Specifies whether or not the configuration is present in the current devices active running configuration.
        (Choices: present, absent)[Default: present]
- text
        The banner text that should be present in the remote device running configuration.  This argument accepts a
        multiline string. Requires `state=present'.
        [Default: None]
EXAMPLES:
- name: configure the login banner
  eos_banner:
    banner: login
    text: |
      this is my login banner
      that contains a multiline
      string
    state: present

- name: remove the motd banner
  eos_banner:
    banner: motd
    state: absent

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - banner login
    - this is my login banner
    - that contains a multiline
    - string
    - EOF
session_name:
  description: The EOS config session name used to load the configuration
  returned: if changes
  type: str
  sample: ansible_1479315771


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> EOS_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/eos/eos_command.py)

  Sends an arbitrary set of commands to an EOS node and returns the results read from the device.  This module includes
  an argument that will cause the module to wait for a specific condition before returning or timing out if the condition
  is not met.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
= commands
        The commands to send to the remote EOS device over the configured provider.  The resulting output from the
        command is returned.  If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of `retries' has been exceeded.

- interval
        Configures the interval in seconds to wait between retries of the command.  If the command does not pass the
        specified conditional, the interval indicates how to long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the `wait_for' must be
        satisfied.  If the value is set to `any' then only one of the values must be satisfied.
        (Choices: any, all)[Default: all]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should be tried before it is considered failed.  The command is run on
        the target device every retry and evaluated against the `wait_for' conditionals.
        [Default: 10]
- wait_for
        Specifies what to evaluate from the output of the command and what conditionals to apply.  This argument will
        cause the task to wait for a particular conditional to be true before moving forward.   If the conditional is not
        true by the configured retries, the task fails.  See examples.
        [Default: None]
EXAMPLES:
- name: run show version on remote devices
  eos_command:
    commands: show version

- name: run show version and check to see if output contains Arista
  eos_command:
    commands: show version
    wait_for: result[0] contains Arista

- name: run multiple commands on remote nodes
  eos_command:
    commands:
      - show version
      - show interfaces

- name: run multiple commands and evaluate the output
  eos_command:
    commands:
      - show version
      - show interfaces
    wait_for:
      - result[0] contains Arista
      - result[1] contains Loopback0

- name: run commands and specify the output format
  eos_command:
    commands:
      - command: show version
        output: json

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']
stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]
failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> EOS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/eos/eos_config.py)

  Arista EOS configurations use a simple block indent file syntax for segmenting configuration into sections.  This
  module provides an implementation for working with eos configuration sections in a deterministic way.  This module
  works with either CLI or eAPI transports.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- backup
        This argument will cause the module to create a full backup of the current `running-config' from the remote
        device before any changes are made.  The backup file is written to the `backup' folder in the playbook root
        directory.  If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuration to use as the base config for comparison.
        [Default: None]
- defaults
        The `defaults' argument will influence how the running-config is collected from the device.  When the value is
        set to true, the command used to collect the running-config is append with the all keyword.  When the value is
        set to false, the command is issued without the all keyword
        [Default: False]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        Note this argument should be considered deprecated.  To achieve the equivalent, set the `match=none' which is
        idempotent.  This argument will be removed in a future release.
        (Choices: yes, no)[Default: False]
- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  If match is set to `exact', command lines must be an equal match.  Finally, if
        match is set to `none', the module will not attempt to compare the source configuration with the running
        configuration on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If the
        parents argument is omitted, the commands are checked against the set of top level or global commands.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct.
        (Choices: line, block, config)[Default: line]
- save
        The `save' argument instructs the module to save the running-config to startup-config.  This operation is
        performed after any changes are made to the current running config.  If no changes are made, the configuration is
        still saved to the startup config.  This option will always cause the module to return changed.
        [Default: False]
- src
        The `src' argument provides a path to the configuration file to load into the remote system.  The path can either
        be a full system path to the configuration file if the value starts with / or relative to the root of the
        implemented role or playbook. This argument is mutually exclusive with the `lines' and `parents' arguments.
        [Default: None]
EXAMPLES:
- eos_config:
    lines: hostname {{ inventory_hostname }}

- eos_config:
    lines:
      - 10 permit ip 1.1.1.1/32 any log
      - 20 permit ip 2.2.2.2/32 any log
      - 30 permit ip 3.3.3.3/32 any log
      - 40 permit ip 4.4.4.4/32 any log
      - 50 permit ip 5.5.5.5/32 any log
    parents: ip access-list test
    before: no ip access-list test
    match: exact

- eos_config:
    lines:
      - 10 permit ip 1.1.1.1/32 any log
      - 20 permit ip 2.2.2.2/32 any log
      - 30 permit ip 3.3.3.3/32 any log
      - 40 permit ip 4.4.4.4/32 any log
    parents: ip access-list test
    before: no ip access-list test
    replace: block

- name: load configuration from file
  eos_config:
    src: eos.cfg

RETURN VALUES:
commands:
  description: The set of commands that will be pushed to the remote device
  returned: Only when lines is specified.
  type: list
  sample: ['hostname switch01', 'interface Ethernet1', 'no shutdown']
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/eos_config.2016-07-16@22:28:34


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> EOS_EAPI    (/usr/lib/python2.7/site-packages/ansible/modules/network/eos/eos_eapi.py)

  Use to enable or disable eAPI access, and set the port and state of http, https, local_http and unix-socket servers.
  When enabling eAPI access the default is to enable HTTP on port 80, enable HTTPS on port 443, disable local HTTP, and
  disable Unix socket server. Use the options listed below to override the default configuration. Requires EOS v4.12 or
  greater.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuration to use as the base config for comparison.
        [Default: nul]
- http
        The `http' argument controls the operating state of the HTTP transport protocol when eAPI is present in the
        running-config. When the value is set to True, the HTTP protocol is enabled and when the value is set to False,
        the HTTP protocol is disabled. By default, when eAPI is first configured, the HTTP protocol is disabled.
        (Choices: yes, no)[Default: False]
- http_port
        Configures the HTTP port that will listen for connections when the HTTP transport protocol is enabled.  This
        argument accepts integer values in the valid range of 1 to 65535.
        [Default: 80]
- https
        The `https' argument controls the operating state of the HTTPS transport protocol when eAPI is present in the
        running-config. When the value is set to True, the HTTPS protocol is enabled and when the value is set to False,
        the HTTPS protocol is disabled. By default, when eAPI is first configured, the HTTPS protocol is enabled.
        (Choices: yes, no)[Default: True]
- https_port
        Configures the HTTP port that will listen for connections when the HTTP transport protocol is enabled.  This
        argument accepts integer values in the valid range of 1 to 65535.
        [Default: 443]
- local_http
        The `local_http' argument controls the operating state of the local HTTP transport protocol when eAPI is present
        in the running-config.  When the value is set to True, the HTTP protocol is enabled and restricted to connections
        from localhost only.  When the value is set to False, the HTTP local protocol is disabled.
        Note is value is independent of the `http' argument
        (Choices: yes, no)[Default: False]
- local_http_port
        Configures the HTTP port that will listen for connections when the HTTP transport protocol is enabled.  This
        argument accepts integer values in the valid range of 1 to 65535.
        [Default: 8080]
- provider
        A dict object containing connection details.
        [Default: None]
- socket
        The `socket' argument controls the operating state of the UNIX Domain Socket used to receive eAPI requests.  When
        the value of this argument is set to True, the UDS will listen for eAPI requests.  When the value is set to
        False, the UDS will not be available to handle requests.  By default when eAPI is first configured, the UDS is
        disabled.
        (Choices: yes, no)[Default: False]
- state
        The `state' argument controls the operational state of eAPI on the remote device.  When this argument is set to
        `started', eAPI is enabled to receive requests and when this argument is `stopped', eAPI is disabled and will not
        receive requests.
        (Choices: started, stopped)[Default: started]
- vrf
        The `vrf' argument will configure eAPI to listen for connections in the specified VRF.  By default, eAPI
        transports will listen for connections in the global table.  This value requires the VRF to already be created
        otherwise the task will fail.
        [Default: default]
Requirements:  EOS v4.12 or greater

EXAMPLES:
- name: Enable eAPI access with default configuration
  eos_eapi:
    state: started

- name: Enable eAPI with no HTTP, HTTPS at port 9443, local HTTP at port 80, and socket enabled
  eos_eapi:
    state: started
    http: false
    https_port: 9443
    local_http: yes
    local_http_port: 80
    socket: yes

- name: Shutdown eAPI access
  eos_eapi:
    state: stopped

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - management api http-commands
    - protocol http port 81
    - no protocol https
urls:
  description: Hash of URL endpoints eAPI is listening on per interface
  returned: when eAPI is started
  type: dict
  sample: {'Management1': ['http://172.26.10.1:80']}
session_name:
  description: The EOS config session name used to load the configuration
  returned: when changed is True
  type: str
  sample: ansible_1479315771


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> EOS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/eos/eos_facts.py)

  Collects a base set of device facts from a remote device that is running eos.  This module prepends all of the base
  network fact keys with `ansible_net_<fact>'.  The facts module will always collect a base set of facts from the device
  and can enable or disable collection of additional facts.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- gather_subset
        When supplied, this argument will restrict the facts collected to a given subset.  Possible values for this
        argument include all, hardware, config, and interfaces.  Can specify a list of values to include a larger subset.
        Values can also be used with an initial `[!]' to specify that a specific subset should not be collected.
        [Default: !config]
- provider
        A dict object containing connection details.
        [Default: None]
EXAMPLES:
# Collect all facts from the device
- eos_facts:
    gather_subset: all

# Collect only the config and default facts
- eos_facts:
    gather_subset:
      - config

# Do not collect hardware facts
- eos_facts:
    gather_subset:
      - "!hardware"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the device
  returned: always
  type: list

# default
ansible_net_model:
  description: The model name returned from the device
  returned: always
  type: str
ansible_net_serialnum:
  description: The serial number of the remote device
  returned: always
  type: str
ansible_net_version:
  description: The operating system version running on the remote device
  returned: always
  type: str
ansible_net_hostname:
  description: The configured hostname of the device
  returned: always
  type: str
ansible_net_image:
  description: The image file the device is running
  returned: always
  type: str
ansible_net_fqdn:
  description: The fully qualified domain name of the device
  returned: always
  type: str

# hardware
ansible_net_filesystems:
  description: All file system names available on the device
  returned: when hardware is configured
  type: list
ansible_net_memfree_mb:
  description: The available free memory on the remote device in Mb
  returned: when hardware is configured
  type: int
ansible_net_memtotal_mb:
  description: The total memory on the remote device in Mb
  returned: when hardware is configured
  type: int

# config
ansible_net_config:
  description: The current active config from the device
  returned: when config is configured
  type: str

# interfaces
ansible_net_all_ipv4_addresses:
  description: All IPv4 addresses configured on the device
  returned: when interfaces is configured
  type: list
ansible_net_all_ipv6_addresses:
  description: All IPv6 addresses configured on the device
  returned: when interfaces is configured
  type: list
ansible_net_interfaces:
  description: A hash of all interfaces running on the system
  returned: when interfaces is configured
  type: dict
ansible_net_neighbors:
  description: The list of LLDP neighbors from the remote device
  returned: when interfaces is configured
  type: dict


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> EOS_SYSTEM    (/usr/lib/python2.7/site-packages/ansible/modules/network/eos/eos_system.py)

  This module provides declarative management of node system attributes on Arista EOS devices.  It provides an option to
  configure host system parameters or remove those parameters from the device active configuration.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- domain_name
        Configure the IP domain name on the remote device to the provided value. Value should be in the dotted name form
        and will be appended to the `hostname' to create a fully-qualified domain name.
        [Default: (null)]
- domain_search
        Provides the list of domain suffixes to append to the hostname for the purpose of doing name resolution. This
        argument accepts a list of names and will be reconciled with the current active configuration on the running
        node.
        [Default: (null)]
- hostname
        Configure the device hostname parameter. This option takes an ASCII string value.
        [Default: (null)]
- lookup_source
        Provides one or more source interfaces to use for performing DNS lookups.  The interface provided in
        `lookup_source' can only exist in a single VRF.  This argument accepts either a list of interface names or a list
        of hashes that configure the interface name and VRF name.  See examples.
        [Default: (null)]
- name_servers
        List of DNS name servers by IP address to use to perform name resolution lookups.  This argument accepts either a
        list of DNS servers or a list of hashes that configure the name server and VRF name.  See examples.
        [Default: (null)]
- provider
        A dict object containing connection details.
        [Default: None]
- state
        State of the configuration values in the device's current active configuration.  When set to `present', the
        values should be configured in the device active configuration and when set to `absent' the values should not be
        in the device active configuration
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: configure hostname and domain-name
  eos_system:
    hostname: eos01
    domain_name: test.example.com

- name: remove configuration
  eos_system:
    state: absent

- name: configure DNS lookup sources
  eos_system:
    lookup_source: Management1

- name: configure DNS lookup sources with VRF support
  eos_system:
      lookup_source:
        - interface: Management1
          vrf: mgmt
        - interface: Ethernet1
          vrf: myvrf

- name: configure name servers
  eos_system:
    name_servers:
      - 8.8.8.8
      - 8.8.4.4

- name: configure name servers with VRF support
  eos_system:
    name_servers:
      - { server: 8.8.8.8, vrf: mgmt }
      - { server: 8.8.4.4, vrf: mgmt }

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - hostname eos01
    - ip domain-name test.example.com
session_name:
  description: The EOS config session name used to load the configuration
  returned: changed
  type: str
  sample: ansible_1479315771


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> EOS_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/eos/_eos_template.py)

  Manages network device configurations over SSH or eos_local.  This module allows implementers to work with the device
  running-config.  It provides a way to push a set of commands onto a network device by evaluating the current running-
  config and only pushing configuration commands that are not already configured.  The config source can be a set of
  commands or a template.

DEPRECATED: 
Deprecated in 2.2. Use M(eos_config) instead

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- backup
        When this argument is configured true, the module will backup the running-config from the node prior to making
        any changes. The backup file will be written to backup_{{ hostname }} in the root of the playbook directory.
        (Choices: yes, no)[Default: False]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuration to use as the base config for comparison.
        [Default: None]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        (Choices: yes, no)[Default: False]
- include_defaults
        By default when the [eos_template] connects to the remote device to retrieve the configuration it will issue the
        `show running-config' command.  If this option is set to True then the issued command will be `show running-
        config all'.
        (Choices: yes, no)[Default: False]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        This argument will cause the provided configuration to be replaced on the destination node.   The use of the
        replace argument will always cause the task to set changed to true and will implies `force=true'.  This argument
        is only valid with `transport=eos_local'.
        (Choices: yes, no)[Default: False]
= src
        The path to the config source.  The source can be either a file with config or a template that will be merged
        during runtime.  By default the task will search for the source file in role or playbook root folder in templates
        directory.

EXAMPLES:
- name: Push a configuration onto the device
  eos_template:
    src: config.j2

- name: Forceable push a configuration onto the device
  eos_template:
    src: config.j2
    force: yes

- name: Provide the base configuration for comparison
  eos_template:
    src: candidate_config.txt
    config: current_config.txt

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['...', '...']

responses:
  description: The set of responses from issuing the commands on the device
  returned: when not check_mode
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> EOS_USER    (/usr/lib/python2.7/site-packages/ansible/modules/network/eos/eos_user.py)

  This module provides declarative management of the local usernames configured on Arista EOS devices.  It allows
  playbooks to manage either individual usernames or the collection of usernames in the current running config.  It also
  supports purging usernames from the configuration that are not explicitly defined.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- nopassword
        Defines the username without assigning a password.  This will allow the user to login to the system without being
        authenticated by a password.
        [Default: (null)]
- privilege
        The `privilege' argument configures the privilege level of the user when logged into the system.  This argument
        accepts integer values in the range of 1 to 15.
        [Default: (null)]
- provider
        A dict object containing connection details.
        [Default: None]
- purge
        Instructs the module to consider the resource definition absolute.  It will remove any previously configured
        usernames on the device with the exception of the `admin` user which cannot be deleted per EOS constraints.
        [Default: False]
- role
        Configures the role for the username in the device running configuration.  The argument accepts a string value
        defining the role name.  This argument does not check if the role has been configured on the device.
        [Default: (null)]
- sshkey
        Specifies the SSH public key to configure for the given username.  This argument accepts a valid SSH key value.
        [Default: (null)]
- state
        Configures the state of the username definition as it relates to the device operational configuration.  When set
        to `present', the username(s) should be configured in the device active configuration and when set to `absent'
        the username(s) should not be in the device active configuration
        (Choices: present, absent)[Default: present]
- update_password
        Since passwords are encrypted in the device running config, this argument will instruct the module when to change
        the password.  When set to `always', the password will always be updated in the device and when set to
        `on_create' the password will be updated only if the username is created.
        (Choices: on_create, always)[Default: always]
- username
        The username to be configured on the remote Arista EOS device.  This argument accepts a stringv value and is
        mutually exclusive with the `users' argument. Please note that this option is not same as `provider username'.
        [Default: (null)]
- users
        The set of username objects to be configured on the remote Arista EOS device.  The list entries can either be the
        username or a hash of username and properties.  This argument is mutually exclusive with the `username' argument.
        [Default: (null)]
EXAMPLES:
- name: create a new user
  eos_user:
    username: ansible
    sshkey: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
    state: present

- name: remove all users except admin
  eos_user:
    purge: yes

- name: set multiple users to privilege level 15
  eos_user:
    users:
      - username: netop
      - username: netend
    privilege: 15
    state: present

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - username ansible secret password
    - username admin secret admin
session_name:
  description: The EOS config session name used to load the configuration
  returned: when changed is True
  type: str
  sample: ansible_1479315771


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> EXECUTE_LAMBDA    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/execute_lambda.py)

  This module executes AWS Lambda functions, allowing synchronous and asynchronous invocation.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- dry_run
        Do not *actually* invoke the function. A `DryRun' call will check that the caller has permissions to call the
        function, especially for checking cross-account permissions.
        [Default: False]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- function_arn
        The name of the function to be invoked
        [Default: None]
- name
        The name of the function to be invoked. This can only be used for invocations within the calling account. To
        invoke a function in another account, use `function_arn' to specify the full ARN.
        [Default: None]
- payload
        A dictionary in any form to be provided as input to the Lambda function.
        [Default: {}]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- tail_log
        If `tail_log=true', the result of the task will include the last 4 KB of the CloudWatch log for the function
        execution. Log tailing only works if you use synchronous invocation `wait=true'. This is usually used for
        development or testing Lambdas.
        [Default: False]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- version_qualifier
        Which version/alias of the function to run. This defaults to the `LATEST' revision, but can be set to any
        existing version or alias. See https;//docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html for details.
        [Default: LATEST]
- wait
        Whether to wait for the function results or not. If `wait' is false, the task will not return any results. To
        wait for the Lambda function to complete, set `wait=true' and the result will be available in the `output' key.
        [Default: True]
Notes:
  * Async invocation will always return an empty `output' key.
  * Synchronous invocation may result in a function timeout, resulting in an empty `output' key.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
- execute_lambda:
    name: test-function
    # the payload is automatically serialized and sent to the function
    payload:
      foo: bar
      value: 8
  register: response

# Test that you have sufficient permissions to execute a Lambda function in
# another account
- execute_lambda:
    function_arn: arn:aws:lambda:us-east-1:123456789012:function/some-function
    dry_run: true

- execute_lambda:
    name: test-function
    payload:
      foo: bar
      value: 8
    wait: true
    tail_log: true
  register: response
  # the response will have a `logs` key that will contain a log (up to 4KB) of the function execution in Lambda.

- execute_lambda:
    name: test-function
    version_qualifier: PRODUCTION

RETURN VALUES:
output:
    description: Function output if wait=true and the function returns a value
    returned: success
    type: dict
    sample: "{ 'output': 'something' }"
logs:
    description: The last 4KB of the function logs. Only provided if I(tail_log) is true
    type: string
status:
    description: C(StatusCode) of API call exit (200 for synchronous invokes, 202 for async)
    type: int
    sample: 200


MAINTAINERS: Ryan Scott Brown (@ryansb) <ryansb@redhat.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> EXO_DNS_DOMAIN    (/usr/lib/python2.7/site-packages/ansible/modules/network/exoscale/exo_dns_domain.py)

  Create and remove domain records.

Options (= is mandatory):

- api_key
        API key of the Exoscale DNS API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the Exoscale DNS API.
        [Default: None]
- api_timeout
        HTTP timeout to Exoscale DNS API.
        [Default: 10]
= name
        Name of the record.

- state
        State of the resource.
        (Choices: present, absent)[Default: present]
- validate_certs
        Validate SSL certs of the Exoscale DNS API.
        [Default: True]
Notes:
  * As Exoscale DNS uses the same API key and secret for all services, we reuse the config used for Exscale Compute
        based on CloudStack. The config is read from several locations, in the following order. The
        `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' environment variables. A `CLOUDSTACK_CONFIG' environment variable
        pointing to an `.ini' file, A `cloudstack.ini' file in the current working directory. A `.cloudstack.ini'
        file in the users home directory. Optionally multiple credentials and endpoints can be specified using ini
        sections in `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'.
  * This module does not support multiple A records and will complain properly if you try.
  * More information Exoscale DNS can be found on https://community.exoscale.ch/documentation/dns/.
  * This module supports check mode and diff.
Requirements:  python >= 2.6

EXAMPLES:
# Create a domain.
- local_action:
    module: exo_dns_domain
    name: example.com

# Remove a domain.
- local_action:
    module: exo_dns_domain
    name: example.com
    state: absent

RETURN VALUES:
---
exo_dns_domain:
    description: API domain results
    returned: success
    type: complex
    contains:
        account_id:
            description: Your account ID
            returned: success
            type: int
            sample: 34569
        auto_renew:
            description: Whether domain is auto renewed or not
            returned: success
            type: bool
            sample: false
        created_at:
            description: When the domain was created
            returned: success
            type: string
            sample: "2016-08-12T15:24:23.989Z"
        expires_on:
            description: When the domain expires
            returned: success
            type: string
            sample: "2016-08-12T15:24:23.989Z"
        id:
            description: ID of the domain
            returned: success
            type: int
            sample: "2016-08-12T15:24:23.989Z"
        lockable:
            description: Whether the domain is lockable or not
            returned: success
            type: bool
            sample: true
        name:
            description: Domain name
            returned: success
            type: string
            sample: example.com
        record_count:
            description: Number of records related to this domain
            returned: success
            type: int
            sample: 5
        registrant_id:
            description: ID of the registrant
            returned: success
            type: int
            sample: null
        service_count:
            description: Number of services
            returned: success
            type: int
            sample: 0
        state:
            description: State of the domain
            returned: success
            type: string
            sample: "hosted"
        token:
            description: Token
            returned: success
            type: string
            sample: "r4NzTRp6opIeFKfaFYvOd6MlhGyD07jl"
        unicode_name:
            description: Domain name as unicode
            returned: success
            type: string
            sample: "example.com"
        updated_at:
            description: When the domain was updated last.
            returned: success
            type: string
            sample: "2016-08-12T15:24:23.989Z"
        user_id:
            description: ID of the user
            returned: success
            type: int
            sample: null
        whois_protected:
            description: Wheter the whois is protected or not
            returned: success
            type: bool
            sample: false


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> EXO_DNS_RECORD    (/usr/lib/python2.7/site-packages/ansible/modules/network/exoscale/exo_dns_record.py)

  Create, update and delete records.

Options (= is mandatory):

- api_key
        API key of the Exoscale DNS API.
        [Default: None]
- api_region
        Name of the ini section in the `cloustack.ini' file.
        [Default: cloudstack]
- api_secret
        Secret key of the Exoscale DNS API.
        [Default: None]
- api_timeout
        HTTP timeout to Exoscale DNS API.
        [Default: 10]
- content
        Content of the record.
        Required if `state=present' or `name=""'
        [Default: None]
= domain
        Domain the record is related to.

- multiple
        Whether there are more than one records with similar `name'.
        Only allowed with `record_type=A'.
        `content' will not be updated as it is used as key to find the record.
        [Default: None]
- name
        Name of the record.
        [Default: ]
- prio
        Priority of the record.
        [Default: None]
- record_type
        Type of the record.
        (Choices: A, ALIAS, CNAME, MX, SPF, URL, TXT, NS, SRV, NAPTR, PTR, AAAA, SSHFP, HINFO, POOL)[Default: A]
- state
        State of the record.
        (Choices: present, absent)[Default: present]
- ttl
        TTL of the record in seconds.
        [Default: 3600]
- validate_certs
        Validate SSL certs of the Exoscale DNS API.
        [Default: True]
Notes:
  * As Exoscale DNS uses the same API key and secret for all services, we reuse the config used for Exscale Compute
        based on CloudStack. The config is read from several locations, in the following order. The
        `CLOUDSTACK_KEY', `CLOUDSTACK_SECRET' environment variables. A `CLOUDSTACK_CONFIG' environment variable
        pointing to an `.ini' file, A `cloudstack.ini' file in the current working directory. A `.cloudstack.ini'
        file in the users home directory. Optionally multiple credentials and endpoints can be specified using ini
        sections in `cloudstack.ini'. Use the argument `api_region' to select the section name, default section is
        `cloudstack'.
  * This module does not support multiple A records and will complain properly if you try.
  * More information Exoscale DNS can be found on https://community.exoscale.ch/documentation/dns/.
  * This module supports check mode and diff.
Requirements:  python >= 2.6

EXAMPLES:
# Create or update an A record.
- local_action:
    module: exo_dns_record
    name: web-vm-1
    domain: example.com
    content: 1.2.3.4

# Update an existing A record with a new IP.
- local_action:
    module: exo_dns_record
    name: web-vm-1
    domain: example.com
    content: 1.2.3.5

# Create another A record with same name.
- local_action:
    module: exo_dns_record
    name: web-vm-1
    domain: example.com
    content: 1.2.3.6
    multiple: yes

# Create or update a CNAME record.
- local_action:
    module: exo_dns_record
    name: www
    domain: example.com
    record_type: CNAME
    content: web-vm-1

# Create or update a MX record.
- local_action:
    module: exo_dns_record
    domain: example.com
    record_type: MX
    content: mx1.example.com
    prio: 10

# delete a MX record.
- local_action:
    module: exo_dns_record
    domain: example.com
    record_type: MX
    content: mx1.example.com
    state: absent

# Remove a record.
- local_action:
    module: exo_dns_record
    name: www
    domain: example.com
    state: absent

RETURN VALUES:
---
exo_dns_record:
    description: API record results
    returned: success
    type: complex
    contains:
        content:
            description: value of the record
            returned: success
            type: string
            sample: 1.2.3.4
        created_at:
            description: When the record was created
            returned: success
            type: string
            sample: "2016-08-12T15:24:23.989Z"
        domain:
            description: Name of the domain
            returned: success
            type: string
            sample: example.com
        domain_id:
            description: ID of the domain
            returned: success
            type: int
            sample: 254324
        id:
            description: ID of the record
            returned: success
            type: int
            sample: 254324
        name:
            description: name of the record
            returned: success
            type: string
            sample: www
        parent_id:
            description: ID of the parent
            returned: success
            type: int
            sample: null
        prio:
            description: Priority of the record
            returned: success
            type: int
            sample: 10
        record_type:
            description: Priority of the record
            returned: success
            type: string
            sample: A
        system_record:
            description: Whether the record is a system record or not
            returned: success
            type: bool
            sample: false
        ttl:
            description: Time to live of the record
            returned: success
            type: int
            sample: 3600
        updated_at:
            description: When the record was updated
            returned: success
            type: string
            sample: "2016-08-12T15:24:23.989Z"


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> EXPECT    (/usr/lib/python2.7/site-packages/ansible/modules/commands/expect.py)

  The `expect' module executes a command and responds to prompts The given command will be executed on all selected
  nodes. It will not be processed through the shell, so variables like `$HOME' and operations like `"<"', `">"', `"|"',
  and `"&"' will not work

Options (= is mandatory):

- chdir
        cd into this directory before running the command
        [Default: (null)]
= command
        the command module takes command to run.

- creates
        a filename, when it already exists, this step will *not* be run.
        [Default: (null)]
- echo
        Whether or not to echo out your response strings
        [Default: False]
- removes
        a filename, when it does not exist, this step will *not* be run.
        [Default: (null)]
= responses
        Mapping of expected string/regex and string to respond with. If the response is a list, successive matches return
        successive responses. List functionality is new in 2.1.

- timeout
        Amount of time in seconds to wait for the expected strings
        [Default: 30]
Notes:
  * If you want to run a command through the shell (say you are using `<', `>', `|', etc), you must specify a shell
        in the command such as `/bin/bash -c "/path/to/something | grep else"'
  * The question, or key, under `responses' is a python regex match. Case insensitive searches are indicated with a
        prefix of `?i'
  * By default, if a question is encountered multiple times, it's string response will be repeated. If you need
        different responses for successive question matches, instead of a string response, use a list of strings as
        the response. The list functionality is new in 2.1
Requirements:  python >= 2.6, pexpect >= 3.3

EXAMPLES:
# Case insensitve password string match
- expect:
    command: passwd username
    responses:
      (?i)password: "MySekretPa$$word"

# Generic question with multiple different responses
- expect:
    command: /path/to/custom/command
    responses:
      Question:
        - response1
        - response2
        - response3


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> FACTER    (/usr/lib/python2.7/site-packages/ansible/modules/system/facter.py)

  Runs the `facter' discovery program (https://github.com/puppetlabs/facter) on the remote system, returning JSON data
  that can be useful for inventory purposes.

Requirements:  facter, ruby-json

EXAMPLES:
# Example command-line invocation
ansible www.example.net -m facter


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['preview']
	Supported_by: community
> FAIL    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/fail.py)

  This module fails the progress with a custom message. It can be useful for bailing out when a certain condition is met
  using `when'.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- msg
        The customized message used for failing execution. If omitted, fail will simply bail out with a generic message.
        [Default: 'Failed as requested from task']
EXAMPLES:
# Example playbook using fail and when together
- fail:
    msg: "The system may not be provisioned according to the CMDB status."
  when: cmdb_status != "to-be-staged"


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> FETCH    (/usr/lib/python2.7/site-packages/ansible/modules/files/fetch.py)

  This module works like [copy], but in reverse. It is used for fetching files from remote machines and storing them
  locally in a file tree, organized by hostname. Note that this module is written to transfer log files that might not be
  present, so a missing remote file won't be an error unless fail_on_missing is set to 'yes'.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

= dest
        A directory to save the file into. For example, if the `dest' directory is `/backup' a `src' file named
        `/etc/profile' on host `host.example.com', would be saved into `/backup/host.example.com/etc/profile'
        [Default: None]
- fail_on_missing
        When set to 'yes', the task will fail if the source file is missing.
        (Choices: yes, no)[Default: no]
- flat
        Allows you to override the default behavior of appending hostname/path/to/file to the destination.  If dest ends
        with '/', it will use the basename of the source file, similar to the copy module. Obviously this is only handy
        if the filenames are unique.
        [Default: (null)]
= src
        The file on the remote system to fetch. This `must' be a file, not a directory. Recursive fetching may be
        supported in a later release.
        [Default: None]
- validate_checksum
        Verify that the source and destination checksums match after the files are fetched.
        (Choices: yes, no)[Default: yes]
Notes:
  * When running fetch with `become', the [slurp] module will also be used to fetch the contents of the file for
        determining the remote checksum. This effectively doubles the transfer size, and depending on the file size
        can consume all available memory on the remote or local hosts causing a `MemoryError'. Due to this it is
        advisable to run this module without `become' whenever possible.
EXAMPLES:
# Store file into /tmp/fetched/host.example.com/tmp/somefile
- fetch:
    src: /tmp/somefile
    dest: /tmp/fetched

# Specifying a path directly
- fetch:
    src: /tmp/somefile
    dest: /tmp/prefix-{{ inventory_hostname }}
    flat: yes

# Specifying a destination path
- fetch:
    src: /tmp/uniquefile
    dest: /tmp/special/
    flat: yes

# Storing in a path relative to the playbook
- fetch:
    src: /tmp/uniquefile
    dest: special/prefix-{{ inventory_hostname }}
    flat: yes


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> FILE    (/usr/lib/python2.7/site-packages/ansible/modules/files/file.py)

  Sets attributes of files, symlinks, and directories, or removes files/symlinks/directories. Many other modules support
  the same options as the `file' module - including [copy], [template], and [assemble].

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- follow
        This flag indicates that filesystem links, if they exist, should be followed.
        (Choices: yes, no)[Default: no]
- force
        force the creation of the symlinks in two cases: the source file does not exist (but will appear later); the
        destination exists and is a file (so, we need to unlink the "path" file and create symlink to the "src" file in
        place of it).
        (Choices: yes, no)[Default: no]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
= path
        path to the file being managed.  Aliases: `dest', `name'
        [Default: []]
- recurse
        recursively set the specified file attributes (applies only to state=directory)
        (Choices: yes, no)[Default: no]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- src
        path of the file to link to (applies only to `state=link'). Will accept absolute, relative and nonexisting paths.
        Relative paths are not expanded.
        [Default: None]
- state
        If `directory', all immediate subdirectories will be created if they do not exist, since 1.7 they will be created
        with the supplied permissions. If `file', the file will NOT be created if it does not exist, see the [copy] or
        [template] module if you want that behavior.  If `link', the symbolic link will be created or changed. Use `hard'
        for hardlinks. If `absent', directories will be recursively deleted, and files or symlinks will be unlinked. Note
        that `file' will not fail if the `path' does not exist as the state did not change. If `touch' (new in 1.4), an
        empty file will be created if the `path' does not exist, while an existing file or directory will receive updated
        file access and modification times (similar to the way `touch` works from the command line).
        (Choices: file, link, directory, hard, touch, absent)[Default: file]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
Notes:
  * See also [copy], [template], [assemble]
EXAMPLES:
# change file ownership, group and mode. When specifying mode using octal numbers, first digit should always be 0.
- file:
    path: /etc/foo.conf
    owner: foo
    group: foo
    mode: 0644
- file:
    src: /file/to/link/to
    dest: /path/to/symlink
    owner: foo
    group: foo
    state: link
- file:
    src: '/tmp/{{ item.src }}'
    dest: '{{ item.dest }}'
    state: link
  with_items:
    - { src: 'x', dest: 'y' }
    - { src: 'z', dest: 'k' }

# touch a file, using symbolic modes to set the permissions (equivalent to 0644)
- file:
    path: /etc/foo.conf
    state: touch
    mode: "u=rw,g=r,o=r"

# touch the same file, but add/remove some permissions
- file:
    path: /etc/foo.conf
    state: touch
    mode: "u+rw,g-wx,o-rwx"

# create a directory if it doesn't exist
- file:
    path: /etc/some_directory
    state: directory
    mode: 0755


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> FILESYSTEM    (/usr/lib/python2.7/site-packages/ansible/modules/system/filesystem.py)

  This module creates file system.

Options (= is mandatory):

= dev
        Target block device.

- force
        If yes, allows to create new filesystem on devices that already has filesystem.
        (Choices: yes, no)[Default: no]
= fstype
        File System type to be created.
        reiserfs support was added in 2.2.

- opts
        List of options to be passed to mkfs command.
        [Default: (null)]
- resizefs
        If yes, if the block device and filessytem size differ, grow the filesystem into the space. Note, XFS Will only
        grow if mounted.
        (Choices: yes, no)[Default: no]
Notes:
  * uses mkfs command
EXAMPLES:
# Create a ext2 filesystem on /dev/sdb1.
- filesystem:
    fstype: ext2
    dev: /dev/sdb1

# Create a ext4 filesystem on /dev/sdb1 and check disk blocks.
- filesystem:
    fstype: ext4
    dev: /dev/sdb1
    opts: -cc


MAINTAINERS: Alexander Bulimov (@abulimov)

METADATA:
	Status: ['preview']
	Supported_by: community
> FIND    (/usr/lib/python2.7/site-packages/ansible/modules/files/find.py)

  Return a list of files based on specific criteria. Multiple criteria are AND'd together.

Options (= is mandatory):

- age
        Select files whose age is equal to or greater than the specified time. Use a negative age to find files equal to
        or less than the specified time. You can choose seconds, minutes, hours, days, or weeks by specifying the first
        letter of any of those words (e.g., "1w").
        [Default: None]
- age_stamp
        Choose the file property against which we compare age. Default is mtime.
        (Choices: atime, mtime, ctime)[Default: mtime]
- contains
        One or more regex patterns which should be matched against the file content
        [Default: None]
- file_type
        Type of file to select
        The 'link' and 'any' choices were added in version 2.3
        (Choices: file, directory, link, any)[Default: file]
- follow
        Set this to true to follow symlinks in path for systems with python 2.6+
        (Choices: True, False)[Default: False]
- get_checksum
        Set this to true to retrieve a file's sha1 checksum
        (Choices: True, False)[Default: False]
- hidden
        Set this to true to include hidden files, otherwise they'll be ignored.
        (Choices: True, False)[Default: False]
= paths
        List of paths of directories to search. All paths must be fully qualified.

- patterns
        One or more (shell or regex) patterns, which type is controlled by `use_regex' option.
        The patterns restrict the list of files to be returned to those whose basenames match at least one of the
        patterns specified. Multiple patterns can be specified using a list.
        [Default: *]
- recurse
        If target is a directory, recursively descend into the directory looking for files.
        (Choices: yes, no)[Default: no]
- size
        Select files whose size is equal to or greater than the specified size. Use a negative size to find files equal
        to or less than the specified size. Unqualified values are in bytes, but b, k, m, g, and t can be appended to
        specify bytes, kilobytes, megabytes, gigabytes, and terabytes, respectively. Size is not evaluated for
        directories.
        [Default: None]
- use_regex
        If false the patterns are file globs (shell) if true they are python regexes
        (Choices: True, False)[Default: False]
EXAMPLES:
# Recursively find /tmp files older than 2 days
- find:
    paths: "/tmp"
    age: "2d"
    recurse: yes

# Recursively find /tmp files older than 4 weeks and equal or greater than 1 megabyte
- find:
    paths: "/tmp"
    age: "4w"
    size: "1m"
    recurse: yes

# Recursively find /var/tmp files with last access time greater than 3600 seconds
- find:
    paths: "/var/tmp"
    age: "3600"
    age_stamp: atime
    recurse: yes

# find /var/log files equal or greater than 10 megabytes ending with .old or .log.gz
- find:
    paths: "/var/tmp"
    patterns: "*.old,*.log.gz"
    size: "10m"

# find /var/log files equal or greater than 10 megabytes ending with .old or .log.gz via regex
# Note that yaml double quotes require escaping backslashes but yaml single
# quotes do not.
- find:
    paths: "/var/tmp"
    patterns: "^.*?\\.(?:old|log\\.gz)$"
    size: "10m"
    use_regex: True

RETURN VALUES:
files:
    description: all matches found with the specified criteria (see stat module for full output of each dictionary)
    returned: success
    type: list of dictionaries
    sample: [
        { path: "/var/tmp/test1",
          mode: "0644",
          "...": "...",
          checksum: 16fac7be61a6e4591a33ef4b729c5c3302307523
        },
        { path: "/var/tmp/test2",
          "...": "..."
        },
        ]
matched:
    description: number of matches
    returned: success
    type: string
    sample: 14
examined:
    description: number of filesystem objects looked at
    returned: success
    type: string
    sample: 34


MAINTAINERS: Brian Coca (based on Ruggero Marchei's Tidy)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> FIREWALLD    (/usr/lib/python2.7/site-packages/ansible/modules/system/firewalld.py)

  This module allows for addition or deletion of services and ports either tcp or udp in either running or permanent
  firewalld rules.

Options (= is mandatory):

- immediate
        Should this configuration be applied immediately, if set as permanent
        [Default: False]
- interface
        The interface you would like to add/remove to/from a zone in firewalld
        [Default: None]
- masquerade
        The masquerade setting you would like to enable/disable to/from zones within firewalld
        [Default: None]
- permanent
        Should this configuration be in the running firewalld configuration or persist across reboots. As of Ansible
        version 2.3, permanent operations can operate on firewalld configs when it's not running (requires firewalld >=
        3.0.9)
        [Default: None]
- port
        Name of a port or port range to add/remove to/from firewalld. Must be in the form PORT/PROTOCOL or PORT-
        PORT/PROTOCOL for port ranges.
        [Default: None]
- rich_rule
        Rich rule to add/remove to/from firewalld.
        [Default: None]
- service
        Name of a service to add/remove to/from firewalld - service must be listed in output of firewall-cmd --get-
        services.
        [Default: None]
- source
        The source/network you would like to add/remove to/from firewalld
        [Default: None]
= state
        Should this port accept(enabled) or reject(disabled) connections.
        (Choices: enabled, disabled)
- timeout
        The amount of time the rule should be in effect for when non-permanent.
        [Default: 0]
- zone
        The firewalld zone to add/remove to/from (NOTE: default zone can be configured per system but "public" is default
        from upstream. Available choices can be extended based on per-system configs, listed here are "out of the box"
        defaults).
        (Choices: work, drop, internal, external, trusted, home, dmz, public, block)[Default: system-default(public)]
Notes:
  * Not tested on any Debian based system.
  * Requires the python2 bindings of firewalld, which may not be installed by default if the distribution switched
        to python 3
Requirements:  firewalld >= 0.2.11

EXAMPLES:
- firewalld:
    service: https
    permanent: true
    state: enabled

- firewalld:
    port: 8081/tcp
    permanent: true
    state: disabled

- firewalld:
    port: 161-162/udp
    permanent: true
    state: enabled

- firewalld:
    zone: dmz
    service: http
    permanent: true
    state: enabled

- firewalld:
    rich_rule: 'rule service name="ftp" audit limit value="1/m" accept'
    permanent: true
    state: enabled

- firewalld:
    source: 192.0.2.0/24
    zone: internal
    state: enabled

- firewalld:
    zone: trusted
    interface: eth2
    permanent: true
    state: enabled

- firewalld:
    masquerade: yes
    state: enabled
    permanent: true
    zone: dmz


MAINTAINERS: Adam Miller (@maxamillion)

METADATA:
	Status: ['preview']
	Supported_by: community
> FLOWADM    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/flowadm.py)

  Create/modify/remove networking bandwidth and associated resources for a type of traffic on a particular link.

Options (= is mandatory):

- dsfield
        - Identifies the 8-bit differentiated services field (as defined in RFC 2474). The optional dsfield_mask is used
        to state the bits of interest in the differentiated services field when comparing with the dsfield value. Both
        values must be in hexadecimal.
        [Default: (null)]
- link
        Specifiies a link to configure flow on.
        [Default: (null)]
- local_ip
        Identifies a network flow by the local IP address.
        [Default: (null)]
- local_port
        Identifies a service specified by the local port.
        [Default: (null)]
- maxbw
        - Sets the full duplex bandwidth for the flow. The bandwidth is specified as an integer with one of the scale
        suffixes(K, M, or G for Kbps, Mbps, and Gbps). If no units are specified, the input value will be read as Mbps.
        [Default: (null)]
= name
        - A flow is defined as a set of attributes based on Layer 3 and Layer 4 headers, which can be used to identify a
        protocol, service, or a zone.

- priority
        Sets the relative priority for the flow.
        (Choices: low, medium, high)[Default: medium]
- remove_ip
        Identifies a network flow by the remote IP address.
        [Default: (null)]
- state
        Create/delete/enable/disable an IP address on the network interface.
        (Choices: absent, present, resetted)[Default: present]
- temporary
        Specifies that the configured flow is temporary. Temporary flows do not persist across reboots.
        (Choices: true, false)[Default: False]
- transport
        - Specifies a Layer 4 protocol to be used. It is typically used in combination with `local_port' to identify the
        service that needs special attention.
        [Default: (null)]
EXAMPLES:
# Limit SSH traffic to 100M via vnic0 interface
- flowadm:
    link: vnic0
    flow: ssh_out
    transport: tcp
    local_port: 22
    maxbw: 100M
    state: present

# Reset flow properties
- flowadm:
    name: dns
    state: resetted

# Configure policy for EF PHB (DSCP value of 101110 from RFC 2598) with a bandwidth of 500 Mbps and a high priority.
- flowadm:
    link: bge0
    dsfield: '0x2e:0xfc'
    maxbw: 500M
    priority: high
    flow: efphb-flow
    state: present

RETURN VALUES:
name:
    description: flow name
    returned: always
    type: string
    sample: "http_drop"
link:
    description: flow's link
    returned: if link is defined
    type: string
    sample: "vnic0"
state:
    description: state of the target
    returned: always
    type: string
    sample: "present"
temporary:
    description: flow's persistence
    returned: always
    type: boolean
    sample: "True"
priority:
    description: flow's priority
    returned: if priority is defined
    type: string
    sample: "low"
transport:
    description: flow's transport
    returned: if transport is defined
    type: string
    sample: "tcp"
maxbw:
    description: flow's maximum bandwidth
    returned: if maxbw is defined
    type: string
    sample: "100M"
local_Ip:
    description: flow's local IP address
    returned: if local_ip is defined
    type: string
    sample: "10.0.0.42"
local_port:
    description: flow's local port
    returned: if local_port is defined
    type: int
    sample: 1337
remote_Ip:
    description: flow's remote IP address
    returned: if remote_ip is defined
    type: string
    sample: "10.0.0.42"
dsfield:
    description: flow's differentiated services value
    returned: if dsfield is defined
    type: string
    sample: "0x2e:0xfc"


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> FLOWDOCK    (/usr/lib/python2.7/site-packages/ansible/modules/notification/flowdock.py)

  Send a message to a flowdock team inbox or chat using the push API (see https://www.flowdock.com/api/team-inbox and
  https://www.flowdock.com/api/chat)

Options (= is mandatory):

- external_user_name
        (chat only - required) Name of the "user" sending the message
        [Default: (null)]
- from_address
        (inbox only - required) Email address of the message sender
        [Default: (null)]
- from_name
        (inbox only) Name of the message sender
        [Default: (null)]
- link
        (inbox only) Link associated with the message. This will be used to link the message subject in Team Inbox.
        [Default: (null)]
= msg
        Content of the message

- project
        (inbox only) Human readable identifier for more detailed message categorization
        [Default: (null)]
- reply_to
        (inbox only) Email address for replies
        [Default: (null)]
- source
        (inbox only - required) Human readable identifier of the application that uses the Flowdock API
        [Default: (null)]
- subject
        (inbox only - required) Subject line of the message
        [Default: (null)]
- tags
        tags of the message, separated by commas
        [Default: (null)]
= token
        API token.

= type
        Whether to post to 'inbox' or 'chat'
        (Choices: inbox, chat)
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- flowdock:
    type: inbox
    token: AAAAAA
    from_address: user@example.com
    source: my cool app
    msg: test from ansible
    subject: test subject

- flowdock:
    type: chat
    token: AAAAAA
    external_user_name: testuser
    msg: test from ansible
    tags: tag1,tag2,tag3


MAINTAINERS: Matt Coddington (@mcodd)

METADATA:
	Status: ['preview']
	Supported_by: community
> FOREMAN    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/foreman/foreman.py)

  Allows the management of Foreman resources inside your Foreman server

Options (= is mandatory):

= entity
        The Foreman resource that the action will be performed on (e.g. organization, host)

= params
        Parameters associated to the entity resource to set or edit in dictionary format (e.g. name, description)

= password
        Password for user accessing Foreman server

= server_url
        URL of Foreman server

= username
        Username on Foreman server

Requirements:  nailgun >= 0.28.0, python >= 2.6, datetime

EXAMPLES:
- name: "Create CI Organization"
  local_action:
      module: foreman
      username: "admin"
      password: "admin"
      server_url: "https://fakeserver.com"
      entity: "organization"
      params:
        name: "My Cool New Organization"

RETURN VALUES:
 

MAINTAINERS: Eric D Helms (@ehelms)

METADATA:
	Status: ['preview']
	Supported_by: community
> FORTIOS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/fortios/fortios_config.py)

  This module provides management of FortiOS Devices configuration.

Options (= is mandatory):

- backup
        This argument will cause the module to create a backup of the current `running-config' from the remote device
        before any changes are made.  The backup file is written to the i(backup) folder.
        (Choices: yes, no)[Default: False]
- backup_filename
        Specifies the backup filename. If omitted filename will be formated like HOST_config.YYYY-MM-DD@HH:MM:SS
        [Default: (null)]
- backup_path
        Specifies where to store backup files. Required if `backup=yes'.
        [Default: (null)]
- filter
        Only for partial backup, you can restrict by giving expected configuration path (ex. firewall address).
        [Default: ]
= host
        Specifies the DNS hostname or IP address for connecting to the remote fortios device.

= password
        Specifies the password used to authenticate to the remote device.

- src
        The `src' argument provides a path to the configuration file to load into the remote device.
        [Default: (null)]
- timeout
        Timeout in seconds for connecting to the remote device.
        [Default: 60]
= username
        Configures the username used to authenticate to the remote device.

- vdom
        Specifies on which vdom to apply configuration
        [Default: (null)]
Notes:
  * This module requires pyFG python library
EXAMPLES:
- name: Backup current config
  fortios_config:
    host: 192.168.0.254
    username: admin
    password: password
    backup: yes

- name: Backup only address objects
  fortios_config:
    host: 192.168.0.254
    username: admin
    password: password
    backup: yes
    backup_path: /tmp/forti_backup/
    filter: "firewall address"

- name: Update configuration from file
  fortios_config:
    host: 192.168.0.254
    username: admin
    password: password
    src: new_configuration.conf


RETURN VALUES:
running_config:
  description: full config string
  returned: always
  type: string
change_string:
  description: The commands really executed by the module
  returned: only if config changed
  type: string


MAINTAINERS: Benjamin Jolivot (@bjolivot)

METADATA:
	Status: ['preview']
	Supported_by: community
> FORTIOS_IPV4_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/network/fortios/fortios_ipv4_policy.py)

  This module provides management of firewall IPv4 policies on FortiOS devices.

Options (= is mandatory):

- application_list
        Specifies Application Control name.
        [Default: (null)]
- av_profile
        Specifies Antivirus profile name.
        [Default: (null)]
- backup
        This argument will cause the module to create a backup of the current `running-config' from the remote device
        before any changes are made.  The backup file is written to the i(backup) folder.
        (Choices: yes, no)[Default: False]
- backup_filename
        Specifies the backup filename. If omitted filename will be formated like HOST_config.YYYY-MM-DD@HH:MM:SS
        [Default: (null)]
- backup_path
        Specifies where to store backup files. Required if `backup=yes'.
        [Default: (null)]
- comment
        free text to describe policy.
        [Default: (null)]
- dst_addr
        Specifies destination address (or group) object name(s). Required when `state=present'.
        [Default: (null)]
- dst_addr_negate
        Negate destination address param.
        (Choices: true, false)[Default: False]
- dst_intf
        Specifies destination interface name.
        [Default: any]
- fixedport
        Use fixed port for nat.
        (Choices: true, false)[Default: False]
= host
        Specifies the DNS hostname or IP address for connecting to the remote fortios device.

= id
        Policy ID. Warning: policy ID number is different than Policy sequence number. The policy ID is the number
        assigned at policy creation. The sequence number represents the order in which the Fortigate will evaluate the
        rule for policy enforcement, and also the order in which rules are listed in the GUI and CLI. These two numbers
        do not necessarily correlate: this module is based off policy ID. TIP: policy ID can be viewed in the GUI by
        adding 'ID' to the display columns

- ips_sensor
        Specifies IPS Sensor profile name.
        [Default: (null)]
- nat
        Enable or disable Nat.
        (Choices: true, false)[Default: False]
= password
        Specifies the password used to authenticate to the remote device.

- policy_action
        Specifies accept or deny action policy. Required when `state=present'.
        (Choices: accept, deny)[Default: (null)]
- poolname
        Specifies NAT pool name.
        [Default: (null)]
- schedule
        defines policy schedule.
        [Default: always]
- service
        Specifies policy service(s), could be a list (ex: ['MAIL','DNS']). Required when `state=present'.
        [Default: (null)]
- service_negate
        Negate policy service(s) defined in service value.
        (Choices: true, false)[Default: False]
- src_addr
        Specifies source address (or group) object name(s). Required when `state=present'.
        [Default: (null)]
- src_addr_negate
        Negate source address param.
        (Choices: true, false)[Default: False]
- src_intf
        Specifies source interface name.
        [Default: any]
- state
        Specifies if policy `id' need to be added or deleted.
        (Choices: present, absent)[Default: present]
- timeout
        Timeout in seconds for connecting to the remote device.
        [Default: 60]
= username
        Configures the username used to authenticate to the remote device.

- vdom
        Specifies on which vdom to apply configuration
        [Default: (null)]
- webfilter_profile
        Specifies Webfilter profile name.
        [Default: (null)]
Notes:
  * This module requires pyFG library.
EXAMPLES:
- name: Allow external DNS call
  fortios_ipv4_policy:
    host: 192.168.0.254
    username: admin
    password: password
    id: 42
    srcaddr: internal_network
    dstaddr: all
    service: dns
    nat: True
    state: present
    policy_action: accept

- name: Public Web
  fortios_ipv4_policy:
    host: 192.168.0.254
    username: admin
    password: password
    id: 42
    srcaddr: all
    dstaddr: webservers
    services:
      - http
      - https
    state: present
    policy_action: accept

RETURN VALUES:
firewall_address_config:
  description: full firewall adresses config string
  returned: always
  type: string
change_string:
  description: The commands executed by the module
  returned: only if config changed
  type: string
msg_error_list:
  description: "List of errors returned by CLI (use -vvv for better readability)."
  returned: only when error
  type: string


MAINTAINERS: Benjamin Jolivot (@bjolivot)

METADATA:
	Status: ['preview']
	Supported_by: community
> GC_STORAGE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gc_storage.py)

  This module allows users to manage their objects/buckets in Google Cloud Storage.  It allows upload and download
  operations and can set some canned permissions. It also allows retrieval of URLs for objects for use in playbooks, and
  retrieval of string contents of objects.  This module requires setting the default project in GCS prior to playbook
  usage.  See https://developers.google.com/storage/docs/reference/v1/apiversion1 for information about setting the
  default project.

Options (= is mandatory):

= bucket
        Bucket name.

- dest
        The destination file path when downloading an object/key with a GET operation.
        [Default: (null)]
- expiration
        Time limit (in seconds) for the URL generated and returned by GCA when performing a mode=put or mode=get_url
        operation. This url is only available when public-read is the acl for the object.
        [Default: None]
- force
        Forces an overwrite either locally on the filesystem or remotely with the object/key. Used with PUT and GET
        operations.
        [Default: True]
= gs_access_key
        GS access key. If not set then the value of the GS_ACCESS_KEY_ID environment variable is used.
        [Default: None]
= gs_secret_key
        GS secret key. If not set then the value of the GS_SECRET_ACCESS_KEY environment variable is used.
        [Default: None]
- headers
        Headers to attach to object.
        [Default: {}]
= mode
        Switches the module behaviour between upload, download, get_url (return download url) , get_str (download object
        as string), create (bucket) and delete (bucket).
        (Choices: get, put, get_url, get_str, delete, create)[Default: None]
- object
        Keyname of the object inside the bucket. Can be also be used to create "virtual directories" (see examples).
        [Default: None]
- permission
        This option let's the user set the canned permissions on the object/bucket that are created. The permissions that
        can be set are 'private', 'public-read', 'authenticated-read'.
        [Default: private]
- src
        The source file path when performing a PUT operation.
        [Default: None]
Requirements:  python >= 2.6, boto >= 2.9

EXAMPLES:
- name: Upload some content
  gc_storage:
    bucket: mybucket
    object: key.txt
    src: /usr/local/myfile.txt
    mode: put
    permission: public-read

- name: Upload some headers
  gc_storage:
    bucket: mybucket
    object: key.txt
    src: /usr/local/myfile.txt
    headers: '{"Content-Encoding": "gzip"}'

- name: Download some content
  gc_storage:
    bucket: mybucket
    object: key.txt
    dest: /usr/local/myfile.txt
    mode: get

- name: Download an object as a string to use else where in your playbook
  gc_storage:
    bucket: mybucket
    object: key.txt
    mode: get_str

- name: Create an empty bucket
  gc_storage:
    bucket: mybucket
    mode: create

- name: Create a bucket with key as directory
  gc_storage:
    bucket: mybucket
    object: /my/directory/path
    mode: create

- name: Delete a bucket and all contents
  gc_storage:
    bucket: mybucket
    mode: delete


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['preview']
	Supported_by: community
> GCDNS_RECORD    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gcdns_record.py)

  Creates or removes resource records in Google Cloud DNS.

Options (= is mandatory):

- credentials_file
        The path to the JSON file associated with the service account email.
        [Default: None]
- overwrite
        Whether an attempt to overwrite an existing record should succeed or fail. The behavior of this option depends on
        `state'.
        If `state' is `present' and `overwrite' is `True', this module will replace an existing resource record of the
        same name with the provided `record_data'. If `state' is `present' and `overwrite' is `False', this module will
        fail if there is an existing resource record with the same name and type, but different resource data.
        If `state' is `absent' and `overwrite' is `True', this module will remove the given resource record
        unconditionally. If `state' is `absent' and `overwrite' is `False', this module will fail if the provided
        record_data do not match exactly with the existing resource record's record_data.
        (Choices: True, False)[Default: False]
- pem_file
        The path to the PEM file associated with the service account email.
        This option is deprecated and may be removed in a future release. Use `credentials_file' instead.
        [Default: None]
- project_id
        The Google Cloud Platform project ID to use.
        [Default: None]
= record
        The fully-qualified domain name of the resource record.

- record_data
        The record_data to use for the resource record.
        `record_data' must be specified if `state' is `present' or `overwrite' is `True', or the module will fail.
        Valid record_data vary based on the record's `type'. In addition, resource records that contain a DNS domain name
        in the value field (e.g., CNAME, PTR, SRV, .etc) MUST include a trailing dot in the value.
        Individual string record_data for TXT records must be enclosed in double quotes.
        For resource records that have the same name but different record_data (e.g., multiple A records), they must be
        defined as multiple list entries in a single record.
        [Default: (null)]
- service_account_email
        The e-mail address for a service account with access to Google Cloud DNS.
        [Default: None]
- state
        Whether the given resource record should or should not be present.
        (Choices: present, absent)[Default: present]
- ttl
        The amount of time in seconds that a resource record will remain cached by a caching resolver.
        [Default: 300]
= type
        The type of resource record to add.
        (Choices: A, AAAA, CNAME, SRV, TXT, SOA, NS, MX, SPF, PTR)
- zone
        The DNS domain name of the zone (e.g., example.com).
        One of either `zone' or `zone_id' must be specified as an option, or the module will fail.
        If both `zone' and `zone_id' are specifed, `zone_id' will be used.
        [Default: (null)]
- zone_id
        The Google Cloud ID of the zone (e.g., example-com).
        One of either `zone' or `zone_id' must be specified as an option, or the module will fail.
        These usually take the form of domain names with the dots replaced with dashes. A zone ID will never have any
        dots in it.
        `zone_id' can be faster than `zone' in projects with a large number of zones.
        If both `zone' and `zone_id' are specifed, `zone_id' will be used.
        [Default: (null)]
Notes:
  * See also [gcdns_zone].
  * This modules's underlying library does not support in-place updates for DNS resource records. Instead, resource
        records are quickly deleted and recreated.
  * SOA records are technically supported, but their functionality is limited to verifying that a zone's existing
        SOA record matches a pre-determined value. The SOA record cannot be updated.
  * Root NS records cannot be updated.
  * NAPTR records are not supported.
Requirements:  python >= 2.6, apache-libcloud >= 0.19.0

EXAMPLES:
# Create an A record.
- gcdns_record:
    record: 'www1.example.com'
    zone: 'example.com'
    type: A
    value: '1.2.3.4'

# Update an existing record.
- gcdns_record:
    record: 'www1.example.com'
    zone: 'example.com'
    type: A
    overwrite: true
    value: '5.6.7.8'

# Remove an A record.
- gcdns_record:
    record: 'www1.example.com'
    zone_id: 'example-com'
    state: absent
    type: A
    value: '5.6.7.8'

# Create a CNAME record.
- gcdns_record:
    record: 'www.example.com'
    zone_id: 'example-com'
    type: CNAME
    value: 'www.example.com.'    # Note the trailing dot

# Create an MX record with a custom TTL.
- gcdns_record:
    record: 'example.com'
    zone: 'example.com'
    type: MX
    ttl: 3600
    value: '10 mail.example.com.'    # Note the trailing dot

# Create multiple A records with the same name.
- gcdns_record:
    record: 'api.example.com'
    zone_id: 'example-com'
    type: A
    record_data:
      - '192.0.2.23'
      - '10.4.5.6'
      - '198.51.100.5'
      - '203.0.113.10'

# Change the value of an existing record with multiple record_data.
- gcdns_record:
    record: 'api.example.com'
    zone: 'example.com'
    type: A
    overwrite: true
    record_data:           # WARNING: All values in a record will be replaced
      - '192.0.2.23'
      - '192.0.2.42'    # The changed record
      - '198.51.100.5'
      - '203.0.113.10'

# Safely remove a multi-line record.
- gcdns_record:
    record: 'api.example.com'
    zone_id: 'example-com'
    state: absent
    type: A
    record_data:           # NOTE: All of the values must match exactly
      - '192.0.2.23'
      - '192.0.2.42'
      - '198.51.100.5'
      - '203.0.113.10'

# Unconditionally remove a record.
- gcdns_record:
    record: 'api.example.com'
    zone_id: 'example-com'
    state: absent
    overwrite: true   # overwrite is true, so no values are needed
    type: A

# Create an AAAA record
- gcdns_record:
    record: 'www1.example.com'
    zone: 'example.com'
    type: AAAA
    value: 'fd00:db8::1'

# Create a PTR record
- gcdns_record:
    record: '10.5.168.192.in-addr.arpa'
    zone: '5.168.192.in-addr.arpa'
    type: PTR
    value: 'api.example.com.'    # Note the trailing dot.

# Create an NS record
- gcdns_record:
    record: 'subdomain.example.com'
    zone: 'example.com'
    type: NS
    ttl: 21600
    record_data:
      - 'ns-cloud-d1.googledomains.com.'    # Note the trailing dots on values
      - 'ns-cloud-d2.googledomains.com.'
      - 'ns-cloud-d3.googledomains.com.'
      - 'ns-cloud-d4.googledomains.com.'

# Create a TXT record
- gcdns_record:
    record: 'example.com'
    zone_id: 'example-com'
    type: TXT
    record_data:
      - '"v=spf1 include:_spf.google.com -all"'   # A single-string TXT value
      - '"hello " "world"'    # A multi-string TXT value

RETURN VALUES:
overwrite:
    description: Whether to the module was allowed to overwrite the record
    returned: success
    type: boolean
    sample: True
record:
    description: Fully-qualified domain name of the resource record
    returned: success
    type: string
    sample: mail.example.com.
state:
    description: Whether the record is present or absent
    returned: success
    type: string
    sample: present
ttl:
    description: The time-to-live of the resource record
    returned: success
    type: int
    sample: 300
type:
    description: The type of the resource record
    returned: success
    type: string
    sample: A
record_data:
    description: The resource record values
    returned: success
    type: list
    sample: ['5.6.7.8', '9.10.11.12']
zone:
    description: The dns name of the zone
    returned: success
    type: string
    sample: example.com.
zone_id:
    description: The Google Cloud DNS ID of the zone
    returned: success
    type: string
    sample: example-com


MAINTAINERS: William Albert (@walbert947)

METADATA:
	Status: ['preview']
	Supported_by: community
> GCDNS_ZONE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gcdns_zone.py)

  Creates or removes managed zones in Google Cloud DNS.

Options (= is mandatory):

- credentials_file
        The path to the JSON file associated with the service account email.
        [Default: None]
- description
        An arbitrary text string to use for the zone description.
        [Default: ]
- pem_file
        The path to the PEM file associated with the service account email.
        This option is deprecated and may be removed in a future release. Use `credentials_file' instead.
        [Default: None]
- project_id
        The Google Cloud Platform project ID to use.
        [Default: None]
- service_account_email
        The e-mail address for a service account with access to Google Cloud DNS.
        [Default: None]
- state
        Whether the given zone should or should not be present.
        (Choices: present, absent)[Default: present]
= zone
        The DNS domain name of the zone.
        This is NOT the Google Cloud DNS zone ID (e.g., example-com). If you attempt to specify a zone ID, this module
        will attempt to create a TLD and will fail.

Notes:
  * See also [gcdns_record].
  * Zones that are newly created must still be set up with a domain registrar before they can be used.
Requirements:  python >= 2.6, apache-libcloud >= 0.19.0

EXAMPLES:
# Basic zone creation example.
- name: Create a basic zone with the minimum number of parameters.
  gcdns_zone: zone=example.com

# Zone removal example.
- name: Remove a zone.
  gcdns_zone: zone=example.com state=absent

# Zone creation with description
- name: Creating a zone with a description
  gcdns_zone: zone=example.com description="This is an awesome zone"

RETURN VALUES:
description:
    description: The zone's description
    returned: success
    type: string
    sample: This is an awesome zone
state:
    description: Whether the zone is present or absent
    returned: success
    type: string
    sample: present
zone:
    description: The zone's DNS name
    returned: success
    type: string
    sample: example.com.


MAINTAINERS: William Albert (@walbert947)

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce.py)

  Creates or terminates Google Compute Engine (GCE) instances.  See https://cloud.google.com/compute for an overview.
  Full install/configuration instructions for the gce* modules can be found in the comments of ansible/test/gce_tests.py.

Options (= is mandatory):

- credentials_file
        path to the JSON file associated with the service account email
        [Default: None]
- disk_auto_delete
        if set boot disk will be removed after instance destruction
        [Default: true]
- disk_size
        The size of the boot disk created for this instance (in GB)
        [Default: 10]
- disks
        a list of persistent disks to attach to the instance; a string value gives the name of the disk; alternatively, a
        dictionary value can define 'name' and 'mode' ('READ_ONLY' or 'READ_WRITE'). The first entry will be the boot
        disk (which must be READ_WRITE).
        [Default: None]
- external_ip
        type of external ip, ephemeral by default; alternatively, a fixed gce ip or ip name can be given. Specify 'none'
        if no external ip is desired.
        [Default: ephemeral]
- image
        image string to use for the instance (default will follow latest stable debian image)
        [Default: debian-8]
- instance_names
        a comma-separated list of instance names to create or destroy
        [Default: None]
- ip_forward
        set to true if the instance can forward ip packets (useful for gateways)
        [Default: false]
- machine_type
        machine type to use for the instance, use 'n1-standard-1' by default
        [Default: n1-standard-1]
- metadata
        a hash/dictionary of custom data for the instance; '{"key":"value", ...}'
        [Default: None]
- name
        either a name of a single instance or when used with 'num_instances', the base name of a cluster of nodes
        [Default: (null)]
- network
        name of the network, 'default' will be used if not specified
        [Default: default]
- num_instances
        can be used with 'name', specifies the number of nodes to provision using 'name' as a base name
        [Default: (null)]
- pem_file
        path to the pem file associated with the service account email This option is deprecated. Use 'credentials_file'.
        [Default: None]
- persistent_boot_disk
        if set, create the instance with a persistent boot disk
        [Default: false]
- preemptible
        if set to true, instances will be preemptible and time-limited. (requires libcloud >= 0.20.0)
        [Default: false]
- project_id
        your GCE project ID
        [Default: None]
- service_account_email
        service account email
        [Default: None]
- service_account_permissions
        service account permissions (see https://cloud.google.com/sdk/gcloud/reference/compute/instances/create, --scopes
        section for detailed information)
        (Choices: bigquery, cloud-platform, compute-ro, compute-rw, useraccounts-ro, useraccounts-rw, datastore, logging-
        write, monitoring, sql-admin, storage-full, storage-ro, storage-rw, taskqueue, userinfo-email)[Default: None]
- state
        desired state of the resource
        (Choices: active, present, absent, deleted, started, stopped, terminated)[Default: present]
- subnetwork
        name of the subnetwork in which the instance should be created
        [Default: None]
- tags
        a comma-separated list of tags to associate with the instance
        [Default: None]
= zone
        the GCE zone to use
        [Default: us-central1-a]
Notes:
  * Either `instance_names' or `name' is required.
  * JSON credentials strongly preferred.
Requirements:  python >= 2.6, apache-libcloud >= 0.13.3, >= 0.17.0 if using JSON credentials, >= 0.20.0 if using
        preemptible option

EXAMPLES:
# Basic provisioning example.  Create a single Debian 8 instance in the
# us-central1-a Zone of the n1-standard-1 machine type.
# Create multiple instances by specifying multiple names, seperated by
# commas in the instance_names field
# (e.g. my-test-instance1,my-test-instance2)
    gce:
      instance_names: my-test-instance1
      zone: us-central1-a
      machine_type: n1-standard-1
      image: debian-8
      state: present
      service_account_email: "your-sa@your-project-name.iam.gserviceaccount.com"
      credentials_file: "/path/to/your-key.json"
      project_id: "your-project-name"
      disk_size: 32

# Create a single Debian 8 instance in the us-central1-a Zone
# Use existing disks, custom network/subnetwork, set service account permissions
# add tags and metadata.
    gce:
      instance_names: my-test-instance
      zone: us-central1-a
      machine_type: n1-standard-1
      state: present
      metadata: '{"db":"postgres", "group":"qa", "id":500}'
      tags:
        - http-server
        - my-other-tag
      disks:
        - name: disk-2
          mode: READ_WRITE
        - name: disk-3
          mode: READ_ONLY
      disk_auto_delete: false
      network: foobar-network
      subnetwork: foobar-subnetwork-1
      preemptible: true
      ip_forward: true
      service_account_permissions:
        - storage-full
        - taskqueue
        - bigquery
      service_account_email: "your-sa@your-project-name.iam.gserviceaccount.com"
      credentials_file: "/path/to/your-key.json"
      project_id: "your-project-name"

---
# Example Playbook
- name: Compute Engine Instance Examples
  hosts: localhost
  vars:
    service_account_email: "your-sa@your-project-name.iam.gserviceaccount.com"
    credentials_file: "/path/to/your-key.json"
    project_id: "your-project-name"
  tasks:
    - name: create multiple instances
      # Basic provisioning example.  Create multiple Debian 8 instances in the
      # us-central1-a Zone of n1-standard-1 machine type.
      gce:
        instance_names: test1,test2,test3
        zone: us-central1-a
        machine_type: n1-standard-1
        image: debian-8
        state: present
        service_account_email: "{{ service_account_email }}"
        credentials_file: "{{ credentials_file }}"
        project_id: "{{ project_id }}"
        metadata : '{ "startup-script" : "apt-get update" }'
      register: gce

    - name: Save host data
      add_host:
        hostname: "{{ item.public_ip }}"
        groupname: gce_instances_ips
      with_items: "{{ gce.instance_data }}"

    - name: Wait for SSH for instances
      wait_for:
        delay: 1
        host: "{{ item.public_ip }}"
        port: 22
        state: started
        timeout: 30
      with_items: "{{ gce.instance_data }}"

    - name: Configure Hosts
      hosts: gce_instances_ips
      become: yes
      become_method: sudo
      roles:
        - my-role-one
        - my-role-two
      tags:
        - config

    - name: delete test-instances
      # Basic termination of instance.
      gce:
        service_account_email: "{{ service_account_email }}"
        credentials_file: "{{ credentials_file }}"
        project_id: "{{ project_id }}"
        instance_names: "{{ gce.instance_names }}"
        zone: us-central1-a
        state: absent
      tags:
        - delete


MAINTAINERS: Eric Johnson (@erjohnso) <erjohnso@google.com>, Tom Melendez (@supertom) <supertom@google.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_EIP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_eip.py)

  Create (reserve) or Destroy (release) Regional or Global IP Addresses. See https://cloud.google.com/compute/docs
  /configure-instance-ip-addresses#reserve_new_static for more on reserving static addresses.

Options (= is mandatory):

= name
        Name of Address.

= region
        Region to create the address in. Set to 'global' to create a global address.

- state
        The state the address should be in. `present' or `absent' are the only valid options.
        (Choices: present, absent)[Default: present]
Notes:
  * Global addresses can only be used with Global Forwarding Rules.
Requirements:  python >= 2.6, apache-libcloud >= 0.19.0

EXAMPLES:
# Create a Global external IP address
gce_eip:
  service_account_email: "{{ service_account_email }}"
  credentials_file: "{{ credentials_file }}"
  project_id: "{{ project_id }}"
  name: my-global-ip
  region: global
  state: present

# Create a Regional external IP address
gce_eip:
  service_account_email: "{{ service_account_email }}"
  credentials_file: "{{ credentials_file }}"
  project_id: "{{ project_id }}"
  name: my-global-ip
  region: us-east1
  state: present

RETURN VALUES:
address:
    description: IP address being operated on
    returned: always
    type: string
    sample: "35.186.222.233"
name:
    description: name of the address being operated on
    returned: always
    type: string
    sample: "my-address"
region:
    description: Which region an address belongs.
    returned: always
    type: string
    sample: "global"


MAINTAINERS: Tom Melendez (@supertom) <tom@supertom.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_IMG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_img.py)

  This module can create and delete GCE private images from gzipped compressed tarball containing raw disk data or from
  existing detached disks in any zone. https://cloud.google.com/compute/docs/images

Options (= is mandatory):

- description
        an optional description
        [Default: None]
- family
        an optional family name
        [Default: None]
= name
        the name of the image to create or delete
        [Default: None]
- pem_file
        path to the pem file associated with the service account email
        [Default: None]
- project_id
        your GCE project ID
        [Default: None]
- service_account_email
        service account email
        [Default: None]
- source
        the source disk or the Google Cloud Storage URI to create the image from
        [Default: None]
- state
        desired state of the image
        (Choices: present, absent)[Default: present]
- timeout
        timeout for the operation
        [Default: 180]
- zone
        the zone of the disk specified by source
        [Default: us-central1-a]
Requirements:  python >= 2.6, apache-libcloud

EXAMPLES:
# Create an image named test-image from the disk 'test-disk' in zone us-central1-a.
- gce_img:
    name: test-image
    source: test-disk
    zone: us-central1-a
    state: present

# Create an image named test-image from a tarball in Google Cloud Storage.
- gce_img:
    name: test-image
    source: https://storage.googleapis.com/bucket/path/to/image.tgz

# Alternatively use the gs scheme
- gce_img:
    name: test-image
    source: gs://bucket/path/to/image.tgz

# Delete an image named test-image.
- gce_img:
    name: test-image
    state: absent


MAINTAINERS: Tom Melendez (supertom)

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_INSTANCE_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_instance_template.py)

  Creates or destroy Google instance templates of Compute Engine of Google Cloud Platform.

Options (= is mandatory):

- automatic_restart
        Defines whether the instance should be automatically restarted when it is terminated by Compute Engine.
        [Default: None]
- can_ip_forward
        Set to True to allow instance to send/receive non-matching src/dst packets.
        [Default: False]
- credentials_file
        path to the JSON file associated with the service account email
        [Default: None]
- description
        description of instance template
        [Default: None]
- disk_auto_delete
        Indicate that the boot disk should be deleted when the Node is deleted.
        [Default: True]
- disk_type
        Specify a `pd-standard' disk or `pd-ssd' for an SSD disk.
        [Default: pd-standard]
- disks
        a list of persistent disks to attach to the instance; a string value gives the name of the disk; alternatively, a
        dictionary value can define 'name' and 'mode' ('READ_ONLY' or 'READ_WRITE'). The first entry will be the boot
        disk (which must be READ_WRITE).
        [Default: None]
- external_ip
        The external IP address to use. If `ephemeral', a new non-static address will be used.  If `None', then no
        external address will be used.  To use an existing static IP address specify adress name.
        [Default: ephemeral]
- image
        The image to use to create the instance. Cannot specify both both `image' and `source'.
        [Default: None]
- image_family
        The image family to use to create the instance. If `image' has been used `image_family' is ignored. Cannot
        specify both `image' and `source'.
        [Default: None]
- metadata
        a hash/dictionary of custom data for the instance; '{"key":"value", ...}'
        [Default: None]
= name
        The name of the GCE instance template.
        [Default: None]
- network
        The network to associate with the instance.
        [Default: default]
- nic_gce_struct
        Support passing in the GCE-specific formatted networkInterfaces[] structure.
        [Default: None]
- pem_file
        path to the pem file associated with the service account email This option is deprecated. Use 'credentials_file'.
        [Default: None]
- preemptible
        Defines whether the instance is preemptible.
        [Default: None]
- project_id
        your GCE project ID
        [Default: None]
- service_account_email
        service account email
        [Default: None]
- service_account_permissions
        service account permissions (see https://cloud.google.com/sdk/gcloud/reference/compute/instances/create, --scopes
        section for detailed information)
        (Choices: bigquery, cloud-platform, compute-ro, compute-rw, useraccounts-ro, useraccounts-rw, datastore, logging-
        write, monitoring, sql-admin, storage-full, storage-ro, storage-rw, taskqueue, userinfo-email)[Default: None]
- size
        The desired machine type for the instance template.
        [Default: f1-micro]
- source
        A source disk to attach to the instance. Cannot specify both `image' and `source'.
        [Default: None]
- state
        The desired state for the instance template.
        (Choices: present, absent)[Default: present]
- subnetwork
        The Subnetwork resource name for this instance.
        [Default: None]
- tags
        a comma-separated list of tags to associate with the instance
        [Default: None]
Notes:
  * JSON credentials strongly preferred.
Requirements:  python >= 2.6, apache-libcloud >= 0.13.3, >= 0.17.0 if using JSON credentials, >= 0.20.0 if using
        preemptible option

EXAMPLES:
# Usage
- name: create instance template named foo
  gce_instance_template:
    name: foo
    size: n1-standard-1
    image_family: ubuntu-1604-lts
    state: present
    project_id: "your-project-name"
    credentials_file: "/path/to/your-key.json"
    service_account_email: "your-sa@your-project-name.iam.gserviceaccount.com"

# Example Playbook
- name: Compute Engine Instance Template Examples
  hosts: localhost
  vars:
    service_account_email: "your-sa@your-project-name.iam.gserviceaccount.com"
    credentials_file: "/path/to/your-key.json"
    project_id: "your-project-name"
  tasks:
    - name: create instance template
      gce_instance_template:
        name: my-test-instance-template
        size: n1-standard-1
        image_family: ubuntu-1604-lts
        state: present
        project_id: "{{ project_id }}"
        credentials_file: "{{ credentials_file }}"
        service_account_email: "{{ service_account_email }}"
    - name: delete instance template
      gce_instance_template:
        name: my-test-instance-template
        size: n1-standard-1
        image_family: ubuntu-1604-lts
        state: absent
        project_id: "{{ project_id }}"
        credentials_file: "{{ credentials_file }}"
        service_account_email: "{{ service_account_email }}"

RETURN VALUES:


MAINTAINERS: Gwenael Pellen (@GwenaelPellenArkeup) <gwenael.pellen@arkeup.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_LB    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_lb.py)

  This module can create and destroy Google Compute Engine `loadbalancer' and `httphealthcheck' resources.  The primary
  LB resource is the `load_balancer' resource and the health check parameters are all prefixed with `httphealthcheck'.
  The full documentation for Google Compute Engine load balancing is at https://developers.google.com/compute/docs/load-
  balancing/.  However, the ansible module simplifies the configuration by following the libcloud model. Full
  install/configuration instructions for the gce* modules can be found in the comments of ansible/test/gce_tests.py.

Options (= is mandatory):

- credentials_file
        path to the JSON file associated with the service account email
        [Default: None]
- external_ip
        the external static IPv4 (or auto-assigned) address for the LB
        [Default: None]
- httphealthcheck_healthy_count
        number of consecutive successful checks before marking a node healthy
        [Default: 2]
- httphealthcheck_host
        host header to pass through on HTTP check requests
        [Default: None]
- httphealthcheck_interval
        the duration in seconds between each health check request
        [Default: 5]
- httphealthcheck_name
        the name identifier for the HTTP health check
        [Default: None]
- httphealthcheck_path
        the url path to use for HTTP health checking
        [Default: /]
- httphealthcheck_port
        the TCP port to use for HTTP health checking
        [Default: 80]
- httphealthcheck_timeout
        the timeout in seconds before a request is considered a failed check
        [Default: 5]
- httphealthcheck_unhealthy_count
        number of consecutive failed checks before marking a node unhealthy
        [Default: 2]
- members
        a list of zone/nodename pairs, e.g ['us-central1-a/www-a', ...]
        [Default: (null)]
- name
        name of the load-balancer resource
        [Default: None]
- pem_file
        path to the pem file associated with the service account email This option is deprecated. Use 'credentials_file'.
        [Default: None]
- port_range
        the port (range) to forward, e.g. 80 or 8000-8888 defaults to all ports
        [Default: None]
- project_id
        your GCE project ID
        [Default: None]
- protocol
        the protocol used for the load-balancer packet forwarding, tcp or udp
        (Choices: tcp, udp)[Default: tcp]
- region
        the GCE region where the load-balancer is defined
        [Default: (null)]
- service_account_email
        service account email
        [Default: None]
- state
        desired state of the LB
        (Choices: active, present, absent, deleted)[Default: present]
Requirements:  python >= 2.6, apache-libcloud >= 0.13.3, >= 0.17.0 if using JSON credentials

EXAMPLES:
# Simple example of creating a new LB, adding members, and a health check
- local_action:
    module: gce_lb
    name: testlb
    region: us-central1
    members: ["us-central1-a/www-a", "us-central1-b/www-b"]
    httphealthcheck_name: hc
    httphealthcheck_port: 80
    httphealthcheck_path: "/up"


MAINTAINERS: Eric Johnson (@erjohnso) <erjohnso@google.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_MIG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_mig.py)

  Create, Update or Destroy a Managed Instance Group (MIG).  See https://cloud.google.com/compute/docs/instance-groups
  for an overview. Full install/configuration instructions for the gce* modules can be found in the comments of
  ansible/test/gce_tests.py.

Options (= is mandatory):

- autoscaling
        A dictionary of configuration for the autoscaler. 'enabled (bool)', 'name (str)' and policy.max_instances (int)
        are required fields if autoscaling is used. See https://cloud.google.com/compute/docs/reference/beta/autoscalers
        for more information on Autoscaling.
        [Default: None]
- credentials_file
        Path to the JSON file associated with the service account email
        [Default: None]
= name
        Name of the Managed Instance Group.

- named_ports
        Define named ports that backend services can forward data to.  Format is a a list of name:port dictionaries.
        [Default: None]
- project_id
        GCE project ID
        [Default: None]
- service_account_email
        service account email
        [Default: None]
- size
        Size of Managed Instance Group.  If MIG already exists, it will be resized to the number provided here.  Required
        for creating MIGs.
        [Default: (null)]
- state
        desired state of the resource
        (Choices: absent, present)[Default: present]
- template
        Instance Template to be used in creating the VMs.  See https://cloud.google.com/compute/docs/instance-templates
        to learn more about Instance Templates.  Required for creating MIGs.
        [Default: (null)]
= zone
        The GCE zone to use for this Managed Instance Group.

Notes:
  * Resizing and Recreating VM are also supported.
  * An existing instance template is required in order to create a Managed Instance Group.
Requirements:  python >= 2.6, apache-libcloud >= 1.2.0

EXAMPLES:
# Following playbook creates, rebuilds instances, resizes and then deletes a MIG.
# Notes:
# - Two valid Instance Templates must exist in your GCE project in order to run
#   this playbook.  Change the fields to match the templates used in your
#   project.
# - The use of the 'pause' module is not required, it is just for convenience.
- name: Managed Instance Group Example
  hosts: localhost
  gather_facts: False
  tasks:
    - name: Create MIG
      gce_mig:
        name: ansible-mig-example
        zone: us-central1-c
        state: present
        size: 1
        template: my-instance-template-1
        named_ports:
        - name: http
          port: 80
        - name: foobar
          port: 82

    - name: Pause for 30 seconds
      pause:
        seconds: 30

    - name: Recreate MIG Instances with Instance Template change.
      gce_mig:
        name: ansible-mig-example
        zone: us-central1-c
        state: present
        template: my-instance-template-2-small
        recreate_instances: yes

    - name: Pause for 30 seconds
      pause:
        seconds: 30

    - name: Resize MIG
      gce_mig:
        name: ansible-mig-example
        zone: us-central1-c
        state: present
        size: 3

    - name: Update MIG with Autoscaler
      gce_mig:
        name: ansible-mig-example
        zone: us-central1-c
        state: present
        size: 3
        template: my-instance-template-2-small
        recreate_instances: yes
        autoscaling:
          enabled: yes
          name: my-autoscaler
          policy:
            min_instances: 2
            max_instances: 5
            cool_down_period: 37
            cpu_utilization:
              target: .39
            load_balancing_utilization:
              target: 0.4

    - name: Pause for 30 seconds
      pause:
        seconds: 30

    - name: Delete MIG
      gce_mig:
        name: ansible-mig-example
        zone: us-central1-c
        state: absent
        autoscaling:
          enabled: no
          name: my-autoscaler

RETURN VALUES:
zone:
    description: Zone in which to launch MIG.
    returned: always
    type: string
    sample: "us-central1-b"

template:
    description: Instance Template to use for VMs.  Must exist prior to using with MIG.
    returned: changed
    type: string
    sample: "my-instance-template"

name:
    description: Name of the Managed Instance Group.
    returned: changed
    type: string
    sample: "my-managed-instance-group"

named_ports:
    description: list of named ports acted upon
    returned: when named_ports are initially set or updated
    type: list
    sample: [{ "name": "http", "port": 80 }, { "name": "foo", "port": 82 }]

size:
    description: Number of VMs in Managed Instance Group.
    returned: changed
    type: integer
    sample: 4

created_instances:
    description: Names of instances created.
    returned: When instances are created.
    type: list
    sample: ["ansible-mig-new-0k4y", "ansible-mig-new-0zk5", "ansible-mig-new-kp68"]

deleted_instances:
    description: Names of instances deleted.
    returned: When instances are deleted.
    type: list
    sample: ["ansible-mig-new-0k4y", "ansible-mig-new-0zk5", "ansible-mig-new-kp68"]

resize_created_instances:
    description: Names of instances created during resizing.
    returned: When a resize results in the creation of instances.
    type: list
    sample: ["ansible-mig-new-0k4y", "ansible-mig-new-0zk5", "ansible-mig-new-kp68"]

resize_deleted_instances:
    description: Names of instances deleted during resizing.
    returned: When a resize results in the deletion of instances.
    type: list
    sample: ["ansible-mig-new-0k4y", "ansible-mig-new-0zk5", "ansible-mig-new-kp68"]

recreated_instances:
    description: Names of instances recreated.
    returned: When instances are recreated.
    type: list
    sample: ["ansible-mig-new-0k4y", "ansible-mig-new-0zk5", "ansible-mig-new-kp68"]

created_autoscaler:
    description: True if Autoscaler was attempted and created.  False otherwise.
    returned: When the creation of an Autoscaler was attempted.
    type: bool
    sample: true

updated_autoscaler:
    description: True if an Autoscaler update was attempted and succeeded.
                 False returned if update failed.
    returned: When the update of an Autoscaler was attempted.
    type: bool
    sample: true

deleted_autoscaler:
    description: True if an Autoscaler delete attempted and succeeded.
                 False returned if delete failed.
    returned: When the delete of an Autoscaler was attempted.
    type: bool
    sample: true

set_named_ports:
    description: True if the named_ports have been set
    returned: named_ports have been set
    type: bool
    sample: true

updated_named_ports:
    description: True if the named_ports have been updated
    returned: named_ports have been updated
    type: bool
    sample: true


MAINTAINERS: Tom Melendez (@supertom) <tom@supertom.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_NET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_net.py)

  This module can create and destroy Google Compute Engine networks and firewall rules
  https://cloud.google.com/compute/docs/networking. The `name' parameter is reserved for referencing a network while the
  `fwname' parameter is used to reference firewall rules. IPv4 Address ranges must be specified using the CIDR
  http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing format. Full install/configuration instructions for the
  gce* modules can be found in the comments of ansible/test/gce_tests.py.

Options (= is mandatory):

- allowed
        the protocol:ports to allow ('tcp:80' or 'tcp:80,443' or 'tcp:80-800;udp:1-25') this parameter is mandatory when
        creating or updating a firewall rule
        [Default: None]
- credentials_file
        path to the JSON file associated with the service account email
        [Default: None]
- fwname
        name of the firewall rule
        [Default: None]
- ipv4_range
        the IPv4 address range in CIDR notation for the network this parameter is not mandatory when you specified
        existing network in name parameter, but when you create new network, this parameter is mandatory
        [Default: (null)]
- mode
        network mode for Google Cloud "legacy" indicates a network with an IP address range "auto" automatically
        generates subnetworks in different regions "custom" uses networks to group subnets of user specified IP address
        ranges https://cloud.google.com/compute/docs/networking#network_types
        (Choices: legacy, auto, custom)[Default: legacy]
- name
        name of the network
        [Default: None]
- pem_file
        path to the pem file associated with the service account email This option is deprecated. Use 'credentials_file'.
        [Default: None]
- project_id
        your GCE project ID
        [Default: None]
- service_account_email
        service account email
        [Default: None]
- src_range
        the source IPv4 address range in CIDR notation
        [Default: None]
- src_tags
        the source instance tags for creating a firewall rule
        [Default: None]
- state
        desired state of the network or firewall
        (Choices: active, present, absent, deleted)[Default: present]
- subnet_desc
        description of subnet to create
        [Default: None]
- subnet_name
        name of subnet to create
        [Default: None]
- subnet_region
        region of subnet to create
        [Default: None]
- target_tags
        the target instance tags for creating a firewall rule
        [Default: None]
Requirements:  python >= 2.6, apache-libcloud >= 0.13.3, >= 0.17.0 if using JSON credentials

EXAMPLES:
# Create a 'legacy' Network
- name: Create Legacy Network
  gce_net:
    name: legacynet
    ipv4_range: '10.24.17.0/24'
    mode: legacy
    state: present

# Create an 'auto' Network
- name: Create Auto Network
  gce_net:
    name: autonet
    mode: auto
    state: present

# Create a 'custom' Network
- name: Create Custom Network
  gce_net:
    name: customnet
    mode: custom
    subnet_name: "customsubnet"
    subnet_region: us-east1
    ipv4_range: '10.240.16.0/24'
    state: "present"

# Create Firewall Rule with Source Tags
- name: Create Firewall Rule w/Source Tags
  gce_net:
    name: default
    fwname: "my-firewall-rule"
    allowed: tcp:80
    state: "present"
    src_tags: "foo,bar"

# Create Firewall Rule with Source Range
- name: Create Firewall Rule w/Source Range
  gce_net:
    name: default
    fwname: "my-firewall-rule"
    allowed: tcp:80
    state: "present"
    src_range: ['10.1.1.1/32']

# Create Custom Subnetwork
- name: Create Custom Subnetwork
  gce_net:
    name: privatenet
    mode: custom
    subnet_name: subnet_example
    subnet_region: us-central1
    ipv4_range: '10.0.0.0/16'

RETURN VALUES:
allowed:
    description: Rules (ports and protocols) specified by this firewall rule.
    returned: When specified
    type: string
    sample: "tcp:80;icmp"

fwname:
    description: Name of the firewall rule.
    returned: When specified
    type: string
    sample: "my-fwname"

ipv4_range:
    description: IPv4 range of the specified network or subnetwork.
    returned: when specified or when a subnetwork is created
    type: string
    sample: "10.0.0.0/16"

name:
    description: Name of the network.
    returned: always
    type: string
    sample: "my-network"

src_range:
    description: IP address blocks a firewall rule applies to.
    returned: when specified
    type: list
    sample: [ '10.1.1.12/8' ]

src_tags:
    description: Instance Tags firewall rule applies to.
    returned: when specified while creating a firewall rule
    type: list
    sample: [ 'foo', 'bar' ]

state:
    description: State of the item operated on.
    returned: always
    type: string
    sample: "present"

subnet_name:
    description: Name of the subnetwork.
    returned: when specified or when a subnetwork is created
    type: string
    sample: "my-subnetwork"

subnet_region:
    description: Region of the specified subnet.
    returned: when specified or when a subnetwork is created
    type: string
    sample: "us-east1"

target_tags:
    description: Instance Tags with these tags receive traffic allowed by firewall rule.
    returned: when specified while creating a firewall rule
    type: list
    sample: [ 'foo', 'bar' ]


MAINTAINERS: Eric Johnson (@erjohnso) <erjohnso@google.com>, Tom Melendez (@supertom) <supertom@google.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_PD    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_pd.py)

  This module can create and destroy unformatted GCE persistent disks
  https://developers.google.com/compute/docs/disks#persistentdisks. It also supports attaching and detaching disks from
  running instances. Full install/configuration instructions for the gce* modules can be found in the comments of
  ansible/test/gce_tests.py.

Options (= is mandatory):

- credentials_file
        path to the JSON file associated with the service account email
        [Default: None]
- delete_on_termination
        If yes, deletes the volume when instance is terminated
        (Choices: yes, no)[Default: False]
- detach_only
        do not destroy the disk, merely detach it from an instance
        (Choices: yes, no)[Default: no]
- disk_type
        type of disk provisioned
        (Choices: pd-standard, pd-ssd)[Default: pd-standard]
- image
        the source image to use for the disk
        [Default: None]
- instance_name
        instance name if you wish to attach or detach the disk
        [Default: None]
- mode
        GCE mount mode of disk, READ_ONLY (default) or READ_WRITE
        (Choices: READ_WRITE, READ_ONLY)[Default: READ_ONLY]
= name
        name of the disk
        [Default: None]
- pem_file
        path to the pem file associated with the service account email This option is deprecated. Use 'credentials_file'.
        [Default: None]
- project_id
        your GCE project ID
        [Default: None]
- service_account_email
        service account email
        [Default: None]
- size_gb
        whole integer size of disk (in GB) to create, default is 10 GB
        [Default: 10]
- snapshot
        the source snapshot to use for the disk
        [Default: None]
- state
        desired state of the persistent disk
        (Choices: active, present, absent, deleted)[Default: present]
- zone
        zone in which to create the disk
        [Default: us-central1-b]
Requirements:  python >= 2.6, apache-libcloud >= 0.13.3, >= 0.17.0 if using JSON credentials

EXAMPLES:
# Simple attachment action to an existing instance
- local_action:
    module: gce_pd
    instance_name: notlocalhost
    size_gb: 5
    name: pd


MAINTAINERS: Eric Johnson (@erjohnso) <erjohnso@google.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_SNAPSHOT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_snapshot.py)

  Manages snapshots for GCE instances. This module manages snapshots for the storage volumes of a GCE compute instance.
  If there are multiple volumes, each snapshot will be prepended with the disk name

Options (= is mandatory):

= credentials_file
        The path to the credentials file associated with the service account

- disks
        A list of disks to create snapshots for. If none is provided, all of the volumes will be snapshotted
        [Default: all]
= instance_name
        The GCE instance to snapshot

= project_id
        The GCP project ID to use

= service_account_email
        GCP service account email for the project where the instance resides

- snapshot_name
        The name of the snapshot to manage
        [Default: (null)]
- state
        Whether a snapshot should be `present' or `absent'
        (Choices: present, absent)[Default: present]
Requirements:  python >= 2.6, apache-libcloud >= 0.19.0

EXAMPLES:
- name: Create gce snapshot
  gce_snapshot:
    instance_name: example-instance
    snapshot_name: example-snapshot
    state: present
    service_account_email: project_name@appspot.gserviceaccount.com
    credentials_file: /path/to/credentials
    project_id: project_name
  delegate_to: localhost

- name: Delete gce snapshot
  gce_snapshot:
    instance_name: example-instance
    snapshot_name: example-snapshot
    state: absent
    service_account_email: project_name@appspot.gserviceaccount.com
    credentials_file: /path/to/credentials
    project_id: project_name
  delegate_to: localhost

# This example creates snapshots for only two of the available disks as
# disk0-example-snapshot and disk1-example-snapshot
- name: Create snapshots of specific disks
  gce_snapshot:
    instance_name: example-instance
    snapshot_name: example-snapshot
    state: present
    disks:
      - disk0
      - disk1
    service_account_email: project_name@appspot.gserviceaccount.com
    credentials_file: /path/to/credentials
    project_id: project_name
  delegate_to: localhost

RETURN VALUES:
snapshots_created:
    description: List of newly created snapshots
    returned: When snapshots are created
    type: list
    sample: "[disk0-example-snapshot, disk1-example-snapshot]"

snapshots_deleted:
    description: List of destroyed snapshots
    returned: When snapshots are deleted
    type: list
    sample: "[disk0-example-snapshot, disk1-example-snapshot]"

snapshots_existing:
    description: List of snapshots that already existed (no-op)
    returned: When snapshots were already present
    type: list
    sample: "[disk0-example-snapshot, disk1-example-snapshot]"

snapshots_absent:
    description: List of snapshots that were already absent (no-op)
    returned: When snapshots were already absent
    type: list
    sample: "[disk0-example-snapshot, disk1-example-snapshot]"


MAINTAINERS: Rob Wagner (@robwagner33)

METADATA:
	Status: ['preview']
	Supported_by: community
> GCE_TAG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gce_tag.py)

  This module can add or remove tags https://cloud.google.com/compute/docs/label-or-tag-resources#tags to/from GCE
  instances.  Use 'instance_pattern' to update multiple instances in a specify zone

Options (= is mandatory):

- instance_name
        The name of the GCE instance to add/remove tags.  Required if instance_pattern is not specified.
        [Default: None]
- instance_pattern
        The pattern of GCE instance names to match for adding/removing tags.  Full-Python regex is supported. See
        https://docs.python.org/2/library/re.html for details. If instance_name is not specified, this field is required.
        [Default: None]
- pem_file
        path to the pem file associated with the service account email
        [Default: None]
- project_id
        your GCE project ID
        [Default: None]
- service_account_email
        service account email
        [Default: None]
- state
        desired state of the tags
        (Choices: present, absent)[Default: present]
= tags
        comma-separated list of tags to add or remove
        [Default: None]
- zone
        the zone of the disk specified by source
        [Default: us-central1-a]
Notes:
  * Either `instance_name' or `instance_pattern' is required.
Requirements:  python >= 2.6, apache-libcloud >= 0.17.0

EXAMPLES:
# Add tags 'http-server', 'https-server', 'staging' to instance name 'staging-server' in zone us-central1-a.
- gce_tag:
    instance_name: staging-server
    tags: http-server,https-server,staging
    zone: us-central1-a
    state: present

# Remove tags 'foo', 'bar' from instance 'test-server' in default zone (us-central1-a)
- gce_tag:
    instance_name: test-server
    tags: foo,bar
    state: absent

# Add tags 'foo', 'bar' to instances in zone that match pattern
- gce_tag:
    instance_pattern: test-server-*
    tags: foo,bar
    zone: us-central1-a
    state: present



MAINTAINERS: Do Hoang Khiem (dohoangkhiem@gmail.com), Tom Melendez (@supertom)

METADATA:
	Status: ['preview']
	Supported_by: community
> GCONFTOOL2    (/usr/lib/python2.7/site-packages/ansible/modules/system/gconftool2.py)

  This module allows for the manipulation of GNOME 2 Configuration via gconftool-2.  Please see the gconftool-2(1) man
  pages for more details.

Options (= is mandatory):

- config_source
        Specify a configuration source to use rather than the default path. See man gconftool-2(1)
        [Default: (null)]
- direct
        Access the config database directly, bypassing server.  If direct is specified then the config_source must be
        specified as well. See man gconftool-2(1)
        (Choices: yes, no)[Default: False]
= key
        A GConf preference key is an element in the GConf repository that corresponds to an application preference. See
        man gconftool-2(1)

= state
        The action to take upon the key/value.
        (Choices: get, present, absent)
- value
        Preference keys typically have simple values such as strings, integers, or lists of strings and integers. This is
        ignored if the state is "get". See man gconftool-2(1)
        [Default: (null)]
- value_type
        The type of value being set. This is ignored if the state is "get".
        (Choices: int, bool, float, string)[Default: (null)]
EXAMPLES:
- name: Change the widget font to "Serif 12"
  gconftool2:
    key: "/desktop/gnome/interface/font_name"
    value_type: "string"
    value: "Serif 12"

RETURN VALUES:
  key:
    description: The key specified in the module parameters
    returned: success
    type: string
    sample: "/desktop/gnome/interface/font_name"
  value_type:
    description: The type of the value that was changed
    returned: success
    type: string
    sample: "string"
  value:
    description: The value of the preference key after executing the module
    returned: success
    type: string
    sample: "Serif 12"
...


MAINTAINERS: Kenneth D. Evensen (@kevensen)

METADATA:
	Status: ['preview']
	Supported_by: community
> GCPUBSUB    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gcpubsub.py)

  Create and Delete Topics/Subscriptions, Publish and pull messages on PubSub. See https://cloud.google.com/pubsub/docs
  for an overview.

Options (= is mandatory):

- ack_deadline
        Subfield of subscription. Not required. Default deadline for subscriptions to ACK the message before it is
        resent. See examples.
        [Default: (null)]
- name
        Subfield of subscription. Required if subscription is specified. See examples.
        [Default: (null)]
- publish
        List of dictionaries describing messages and attributes to be published.  Dictionary is in
        message(str):attributes(dict) format. Only message is required.
        [Default: (null)]
- pull
        Subfield of subscription. Not required. If specified, messages will be retrieved from topic via the provided
        subscription name. max_messages (int; default None; max number of messages to pull), message_ack (bool; default
        False; acknowledge the message) and return_immediately (bool; default True, don't wait for messages to appear).
        If the messages are acknowledged, changed is set to True, otherwise, changed is False.
        [Default: (null)]
- push_endpoint
        Subfield of subscription.  Not required.  If specified, message will be sent to an endpoint. See
        https://cloud.google.com/pubsub/docs/advanced#push_endpoints for more information.
        [Default: (null)]
- state
        State of the topic or queue (absent, present). Applies to the most granular resource. Remove the most granular
        resource.  If subcription is specified we remove it.  If only topic is specified, that is what is removed. Note
        that a topic can be removed without first removing the subscription.
        [Default: present]
- subscription
        Dictionary containing a subscripton name associated with a topic (required), along with optional ack_deadline,
        push_endpoint and pull. For pulling from a subscription, message_ack (bool), max_messages (int) and
        return_immediate are available as subfields.  See subfields name, push_endpoint and ack_deadline for more
        information.
        [Default: (null)]
= topic
        GCP pubsub topic name.  Only the name, not the full path, is required.

Notes:
  * Subscription pull happens before publish.  You cannot publish and pull in the same task.
Requirements:  python >= 2.6, google-auth >= 0.5.0, google-cloud-pubsub >= 0.22.0

EXAMPLES:
# Create a topic and publish a message to it
# (Message will be pushed; there is no check to see if the message was pushed before
# Topics:
## Create Topic
gcpubsub:
  topic: ansible-topic-example
  state: present

## Delete Topic
### Subscriptions associated with topic are not deleted.
gcpubsub:
  topic: ansible-topic-example
  state: absent

## Messages: publish multiple messages, with attributes (key:value available with the message)
### setting absent will keep the messages from being sent
gcpubsub:
  topic: "{{ topic_name }}"
  state: present
  publish:
    - message: "this is message 1"
      attributes:
        mykey1: myvalue
        mykey2: myvalu2
        mykey3: myvalue3
    - message: "this is message 2"
      attributes:
        server: prod
        sla: "99.9999"
        owner: fred

# Subscriptions
## Create Subscription (pull)
gcpubsub:
  topic: ansible-topic-example
  subscription:
  - name: mysub
  state: present

## Create Subscription with ack_deadline and push endpoint
### pull is default, ack_deadline is not required
gcpubsub:
  topic: ansible-topic-example
  subscription:
  - name: mysub
    ack_deadline: "60"
    push_endpoint: http://pushendpoint.example.com
  state: present

## Subscription change from push to pull
### setting push_endpoint to "None" converts subscription to pull.
gcpubsub:
  topic: ansible-topic-example
  subscription:
    name: mysub
    push_endpoint: "None"

## Delete subscription
### Topic will not be deleted
gcpubsub:
  topic: ansible-topic-example
  subscription:
  - name: mysub
  state: absent

## Pull messages from subscription
### only pull keyword is required.
gcpubsub:
  topic: ansible-topic-example
  subscription:
    name: ansible-topic-example-sub
    pull:
      message_ack: yes
      max_messages: "100"

RETURN VALUES:
publish:
    description: List of dictionaries describing messages and attributes to be published.  Dictionary is in message(str):attributes(dict) format. Only message is required.
    returned: Only when specified
    type: list of dictionary
    sample: "publish: ['message': 'my message', attributes: {'key1': 'value1'}]"

pulled_messages:
    description: list of dictionaries containing message info.  Fields are ack_id, attributes, data, message_id.
    returned: Only when subscription.pull is specified
    type: list of dictionary
    sample: [{ "ack_id": "XkASTCcYREl...","attributes": {"key1": "val1",...}, "data": "this is message 1", "message_id": "49107464153705"},..]

state:
    description: The state of the topic or subscription. Value will be either 'absent' or 'present'.
    returned: Always
    type: str
    sample: "present"

subscription:
    description: Name of subscription.
    returned: When subscription fields are specified
    type: str
    sample: "mysubscription"

topic:
    description: Name of topic.
    returned: Always
    type: str
    sample: "mytopic"


MAINTAINERS: Tom Melendez (@supertom) <tom@supertom.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCPUBSUB_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gcpubsub_facts.py)

  List Topics/Subscriptions from Google PubSub.  Use the gcpubsub module for topic/subscription management. See
  https://cloud.google.com/pubsub/docs for an overview.

Options (= is mandatory):

- state
        list is the only valid option.
        [Default: (null)]
- topic
        GCP pubsub topic name.  Only the name, not the full path, is required.
        [Default: (null)]
= view
        Choices are 'topics' or 'subscriptions'

Notes:
  * list state enables user to list topics or subscriptions in the project.  See examples for details.
Requirements:  python >= 2.6, google-auth >= 0.5.0, google-cloud-pubsub >= 0.22.0

EXAMPLES:
## List all Topics in a project
gcpubsub_facts:
  view: topics
  state: list

## List all Subscriptions in a project
gcpubsub_facts:
  view: subscriptions
  state: list

## List all Subscriptions for a Topic in a project
gcpubsub_facts:
  view: subscriptions
  topic: my-topic
  state: list

RETURN VALUES:
subscriptions:
    description: List of subscriptions.
    returned: When view is set to subscriptions.
    type: list
    sample: ["mysubscription", "mysubscription2"]
topic:
    description: Name of topic. Used to filter subscriptions.
    returned: Always
    type: str
    sample: "mytopic"
topics:
    description: List of topics.
    returned: When view is set to topics.
    type: list
    sample: ["mytopic", "mytopic2"]


MAINTAINERS: Tom Melendez (@supertom) <tom@supertom.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GCSPANNER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/google/gcspanner.py)

  Create and Delete Instances/Databases on Spanner. See https://cloud.google.com/spanner/docs for an overview.

Options (= is mandatory):

= configuration
        Configuration the instance should use. Examples are us-central1, asia-east1 and europe-west1.

- database_name
        Name of database contained on the instance.
        [Default: (null)]
- force_instance_delete
        To delete an instance, this argument must exist and be true (along with state being equal to absent).
        [Default: False]
- instance_display_name
        Name of Instance to display.  If not specified, instance_id will be used instead.
        [Default: (null)]
= instance_id
        GCP spanner instance name.

- node_count
        Number of nodes in the instance.  If not specified while creating an instance, node_count will be set to 1.
        [Default: (null)]
- state
        State of the instance or database (absent, present). Applies to the most granular resource. If a database_name is
        specified we remove it.  If only instance_id is specified, that is what is removed.
        [Default: present]
Notes:
  * Changing the configuration on an existing instance is not supported.
Requirements:  python >= 2.6, google-auth >= 0.5.0, google-cloud-spanner >= 0.23.0

EXAMPLES:
# Create instance.
gcspanner:
  instance_id: "{{ instance_id }}"
  configuration: "{{ configuration }}"
  state: present
  node_count: 1

# Create database.
gcspanner:
  instance_id: "{{ instance_id }}"
  configuration: "{{ configuration }}"
  database_name: "{{ database_name }}"
  state: present

# Delete instance (and all databases)
gcspanner:
  instance_id: "{{ instance_id }}"
  configuration: "{{ configuration }}"
  state: absent
  force_instance_delete: yes

RETURN VALUES:
state:
    description: The state of the instance or database. Value will be either 'absent' or 'present'.
    returned: Always
    type: str
    sample: "present"

database_name:
    description: Name of database.
    returned: When database name is specified
    type: str
    sample: "mydatabase"

instance_id:
    description: Name of instance.
    returned: Always
    type: str
    sample: "myinstance"

previous_values:
   description: List of dictionaries containing previous values prior to update.
   returned: When an instance update has occurred and a field has been modified.
   type: dict
   sample: "'previous_values': { 'instance': { 'instance_display_name': 'my-instance', 'node_count': 1 } }"

updated:
   description: Boolean field to denote an update has occurred.
   returned: When an update has occurred.
   type: bool
   sample: True


MAINTAINERS: Tom Melendez (@supertom) <tom@supertom.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> GEM    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/gem.py)

  Manage installation and uninstallation of Ruby gems.

Options (= is mandatory):

- build_flags
        Allow adding build flags for gem compilation
        [Default: (null)]
- env_shebang
        Rewrite the shebang line on installed scripts to use /usr/bin/env.
        [Default: no]
- executable
        Override the path to the gem executable
        [Default: (null)]
- gem_source
        The path to a local gem used as installation source.
        [Default: (null)]
- include_dependencies
        Whether to include dependencies or not.
        (Choices: yes, no)[Default: yes]
- include_doc
        Install with or without docs.
        [Default: no]
= name
        The name of the gem to be managed.

- pre_release
        Allow installation of pre-release versions of the gem.
        [Default: no]
- repository
        The repository from which the gem will be installed
        [Default: (null)]
- state
        The desired state of the gem. `latest' ensures that the latest version is installed.
        (Choices: present, absent, latest)[Default: present]
- user_install
        Install gem in user's local gems cache or for all users
        [Default: yes]
- version
        Version of the gem to be installed/removed.
        [Default: (null)]
EXAMPLES:
# Installs version 1.0 of vagrant.
- gem:
    name: vagrant
    version: 1.0
    state: present

# Installs latest available version of rake.
- gem:
    name: rake
    state: latest

# Installs rake version 1.0 from a local gem on disk.
- gem:
    name: rake
    gem_source: /path/to/gems/rake-1.0.gem
    state: present


MAINTAINERS: Ansible Core Team, Johan Wiren

METADATA:
	Status: ['preview']
	Supported_by: community
> GET_URL    (/usr/lib/python2.7/site-packages/ansible/modules/network/basics/get_url.py)

  Downloads files from HTTP, HTTPS, or FTP to the remote server. The remote server `must' have direct access to the
  remote resource. By default, if an environment variable `<protocol>_proxy' is set on the target host, requests will be
  sent through that proxy. This behaviour can be overridden by setting a variable for this task (see `setting the
  environment <http://docs.ansible.com/playbooks_environment.html>`_), or by using the use_proxy option. HTTP redirects
  can redirect from HTTP to HTTPS so you should be sure that your proxy environment for both protocols is correct.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- checksum
        If a checksum is passed to this parameter, the digest of the destination file will be calculated after it is
        downloaded to ensure its integrity and verify that the transfer completed successfully. Format:
        <algorithm>:<checksum>, e.g.: checksum="sha256:D98291AC[...]B6DC7B97" If you worry about portability, only the
        sha1 algorithm is available on all platforms and python versions.  The third party hashlib library can be
        installed for access to additional algorithms. Additionally, if a checksum is passed to this parameter, and the
        file exist under the `dest' location, the destination_checksum would be calculated, and if checksum equals
        destination_checksum, the file download would be skipped (unless `force' is true).
        [Default: None]
= dest
        absolute path of where to download the file to.
        If `dest' is a directory, either the server provided filename or, if none provided, the base name of the URL on
        the remote server will be used. If a directory, `force' has no effect. If `dest' is a directory, the file will
        always be downloaded (regardless of the force option), but replaced only if the contents changed.

- force
        If `yes' and `dest' is not a directory, will download the file every time and replace the file if the contents
        change. If `no', the file will only be downloaded if the destination does not exist. Generally should be `yes'
        only for small local files. Prior to 0.6, this module behaved as if `yes' was the default.
        (Choices: yes, no)[Default: no]
- force_basic_auth
        httplib2, the library used by the uri module only sends authentication information when a webservice responds to
        an initial request with a 401 status. Since some basic auth services do not properly send a 401, logins will
        fail. This option forces the sending of the Basic authentication header upon initial request.
        (Choices: yes, no)[Default: no]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- headers
        Add custom HTTP headers to a request in the format "key:value,key:value"
        [Default: None]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- others
        all arguments accepted by the [file] module also work here
        [Default: (null)]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- sha256sum
        If a SHA-256 checksum is passed to this parameter, the digest of the destination file will be calculated after it
        is downloaded to ensure its integrity and verify that the transfer completed successfully. This option is
        deprecated. Use 'checksum'.
        [Default: None]
- timeout
        Timeout in seconds for URL request
        [Default: 10]
- tmp_dest
        absolute path of where temporary file is downloaded to.
        Defaults to TMPDIR, TEMP or TMP env variables or a platform specific value
        https://docs.python.org/2/library/tempfile.html#tempfile.tempdir
        [Default: ]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
= url
        HTTP, HTTPS, or FTP URL in the form (http|https|ftp)://[user[:pass]]@host.domain[:port]/path

- url_password
        The password for use in HTTP basic authentication. If the `url_username' parameter is not specified, the
        `url_password' parameter will not be used.
        [Default: (null)]
- url_username
        The username for use in HTTP basic authentication. This parameter can be used without `url_password' for sites
        that allow empty passwords.
        [Default: (null)]
- use_proxy
        if `no', it will not use a proxy, even if one is defined in an environment variable on the target hosts.
        (Choices: yes, no)[Default: yes]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- name: download foo.conf
  get_url:
    url: http://example.com/path/file.conf
    dest: /etc/foo.conf
    mode: 0440

- name: download file and force basic auth
  get_url:
    url: http://example.com/path/file.conf
    dest: /etc/foo.conf
    force_basic_auth: yes

- name: download file with custom HTTP headers
  get_url:
    url: http://example.com/path/file.conf
    dest: /etc/foo.conf
    headers: 'key:value,key:value'

- name: download file with check (sha256)
  get_url:
    url: http://example.com/path/file.conf
    dest: /etc/foo.conf
    checksum: sha256:b5bb9d8014a0f9b1d61e21e796d78dccdf1352f23cd32812f4850b878ae4944c

- name: download file with check (md5)
  get_url:
    url: http://example.com/path/file.conf
    dest: /etc/foo.conf
    checksum: md5:66dffb5228a211e61d6d7ef4a86f5758

- name: download file from a file path
  get_url:
    url: "file:///tmp/afile.txt"
    dest: /tmp/afilecopy.txt


MAINTAINERS: Jan-Piet Mens (@jpmens)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> GETENT    (/usr/lib/python2.7/site-packages/ansible/modules/system/getent.py)

  Runs getent against one of it's various databases and returns information into the host's facts, in a getent_<database>
  prefixed variable

Options (= is mandatory):

= database
        the name of a getent database supported by the target system (passwd, group, hosts, etc).

- fail_key
        If a supplied key is missing this will make the task fail if True
        [Default: True]
- key
        key from which to return values from the specified database, otherwise the full contents are returned.
        [Default: ]
- split
        character used to split the database values into lists/arrays such as ':' or '  ', otherwise  it will try to pick
        one depending on the database
        [Default: None]
Notes:
  * Not all databases support enumeration, check system documentation for details
EXAMPLES:
# get root user info
- getent:
    database: passwd
    key: root
- debug:
    var: getent_passwd

# get all groups
- getent:
    database: group
    split: ':'
- debug:
    var: getent_group

# get all hosts, split by tab
- getent:
    database: hosts
- debug:
    var: getent_hosts

# get http service info, no error if missing
- getent:
    database: services
    key: http
    fail_key: False
- debug:
    var: getent_services

# get user password hash (requires sudo/root)
- getent:
    database: shadow
    key: www-data
    split: ':'
- debug:
    var: getent_shadow



MAINTAINERS: Brian Coca (@bcoca)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> GIT    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/git.py)

  Manage `git' checkouts of repositories to deploy files or software.

Options (= is mandatory):

- accept_hostkey
        if `yes', adds the hostkey for the repo url if not already added. If ssh_opts contains "-o
        StrictHostKeyChecking=no", this parameter is ignored.
        (Choices: yes, no)[Default: no]
- bare
        if `yes', repository will be created as a bare repo, otherwise it will be a standard repo with a workspace.
        (Choices: yes, no)[Default: no]
- clone
        If `no', do not clone the repository if it does not exist locally
        (Choices: yes, no)[Default: yes]
- depth
        Create a shallow clone with a history truncated to the specified number or revisions. The minimum possible value
        is `1', otherwise ignored. Needs `git>=1.9.1' to work correctly.
        [Default: None]
= dest
        Absolute path of where the repository should be checked out to. This parameter is required, unless `clone' is set
        to `no' This change was made in version 1.8.3. Prior to this version, the `dest' parameter was always required.

- executable
        Path to git executable to use. If not supplied, the normal mechanism for resolving binary paths will be used.
        [Default: None]
- force
        If `yes', any modified files in the working repository will be discarded.  Prior to 0.7, this was always 'yes'
        and could not be disabled.  Prior to 1.9, the default was `yes`
        (Choices: yes, no)[Default: no]
- key_file
        Specify an optional private key file to use for the checkout.
        [Default: None]
- recursive
        if `no', repository will be cloned without the --recursive option, skipping sub-modules.
        (Choices: yes, no)[Default: yes]
- reference
        Reference repository (see "git clone --reference ...")
        [Default: None]
- refspec
        Add an additional refspec to be fetched. If version is set to a `SHA-1' not reachable from any branch or tag,
        this option may be necessary to specify the ref containing the `SHA-1'. Uses the same syntax as the 'git fetch'
        command. An example value could be "refs/meta/config".
        [Default: None]
- remote
        Name of the remote.
        [Default: origin]
= repo
        git, SSH, or HTTP(S) protocol address of the git repository.

- ssh_opts
        Creates a wrapper script and exports the path as GIT_SSH which git then automatically uses to override ssh
        arguments. An example value could be "-o StrictHostKeyChecking=no"
        [Default: None]
- track_submodules
        if `yes', submodules will track the latest commit on their master branch (or other branch specified in
        .gitmodules).  If `no', submodules will be kept at the revision specified by the main project. This is equivalent
        to specifying the --remote flag to git submodule update.
        (Choices: yes, no)[Default: no]
- umask
        The umask to set before doing any checkouts, or any other repository maintenance.
        [Default: None]
- update
        If `no', do not retrieve new revisions from the origin repository
        (Choices: yes, no)[Default: yes]
- verify_commit
        if `yes', when cloning or checking out a `version' verify the signature of a GPG signed commit. This requires
        `git' version>=2.1.0 to be installed. The commit MUST be signed and the public key MUST be trusted in the GPG
        trustdb.
        (Choices: yes, no)[Default: no]
- version
        What version of the repository to check out.  This can be the the literal string `HEAD', a branch name, a tag
        name. It can also be a `SHA-1' hash, in which case `refspec' needs to be specified if the given revision is not
        already available.
        [Default: HEAD]
Notes:
  * If the task seems to be hanging, first verify remote host is in `known_hosts'. SSH will prompt user to
        authorize the first contact with a remote host.  To avoid this prompt, one solution is to use the option
        accept_hostkey. Another solution is to add the remote host public key in `/etc/ssh/ssh_known_hosts' before
        calling the git module, with the following command: ssh-keyscan -H remote_host.com >>
        /etc/ssh/ssh_known_hosts.
Requirements:  git>=1.7.1 (the command line tool)

EXAMPLES:
# Example git checkout from Ansible Playbooks
- git:
    repo: git://foosball.example.org/path/to/repo.git
    dest: /srv/checkout
    version: release-0.22

# Example read-write git checkout from github
- git:
    repo: ssh://git@github.com/mylogin/hello.git
    dest: /home/mylogin/hello

# Example just ensuring the repo checkout exists
- git:
    repo: git://foosball.example.org/path/to/repo.git
    dest: /srv/checkout
    update: no

# Example just get information about the repository whether or not it has
# already been cloned locally.
- git:
    repo: git://foosball.example.org/path/to/repo.git
    dest: /srv/checkout
    clone: no
    update: no

# Example checkout a github repo and use refspec to fetch all pull requests
- git:
    repo: https://github.com/ansible/ansible-examples.git
    dest: /src/ansible-examples
    refspec: '+refs/pull/*:refs/heads/*'

RETURN VALUES:
after:
    description: last commit revision of the repository retrived during the update
    returned: success
    type: string
    sample: 4c020102a9cd6fe908c9a4a326a38f972f63a903
before:
    description: commit revision before the repository was updated, "null" for new repository
    returned: success
    type: string
    sample: 67c04ebe40a003bda0efb34eacfb93b0cafdf628
remote_url_changed:
    description: Contains True or False whether or not the remote URL was changed.
    returned: success
    type: boolean
    sample: True
warnings:
    description: List of warnings if requested features were not available due to a too old git version.
    returned: error
    type: string
    sample: Your git version is too old to fully support the depth argument. Falling back to full checkouts.


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['preview']
	Supported_by: core
> GIT_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/git_config.py)

  The `git_config' module changes git configuration by invoking 'git config'. This is needed if you don't want to use
  [template] for the entire git config file (e.g. because you need to change just `user.email' in /etc/.git/config).
  Solutions involving [command] are cumbersone or don't work correctly in check mode.

Options (= is mandatory):

- list_all
        List all settings (optionally limited to a given `scope')
        (Choices: yes, no)[Default: False]
- name
        The name of the setting. If no value is supplied, the value will be read from the config if it has been set.
        [Default: None]
- repo
        Path to a git repository for reading and writing values from a specific repo.
        [Default: None]
- scope
        Specify which scope to read/set values from. This is required when setting config values. If this is set to
        local, you must also specify the repo parameter. It defaults to system only when not using `list_all'=yes.
        (Choices: local, global, system)[Default: None]
- value
        When specifying the name of a single setting, supply a value to set that setting to the given value.
        [Default: None]
Requirements:  git

EXAMPLES:
# Set some settings in ~/.gitconfig
- git_config:
    name: alias.ci
    scope: global
    value: commit

- git_config:
    name: alias.st
    scope: global
    value: status

# Or system-wide:
- git_config:
    name: alias.remotev
    scope: system
    value: remote -v

- git_config:
    name: core.editor
    scope: global
    value: vim

# scope=system is the default
- git_config:
    name: alias.diffc
    value: diff --cached

- git_config:
    name: color.ui
    value: auto

# Make etckeeper not complain when invoked by cron
- git_config:
    name: user.email
    repo: /etc
    scope: local
    value: 'root@{{ ansible_fqdn }}'

# Read individual values from git config
- git_config:
    name: alias.ci
    scope: global

# scope: system is also assumed when reading values, unless list_all=yes
- git_config:
    name: alias.diffc

# Read all values from git config
- git_config:
    list_all: yes
    scope: global

# When list_all=yes and no scope is specified, you get configuration from all scopes
- git_config:
    list_all: yes

# Specify a repository to include local settings
- git_config:
    list_all: yes
    repo: /path/to/repo.git

RETURN VALUES:
---
config_value:
  description: When list_all=no and value is not set, a string containing the value of the setting in name
  returned: success
  type: string
  sample: "vim"

config_values:
  description: When list_all=yes, a dict containing key/value pairs of multiple configuration settings
  returned: success
  type: dictionary
  sample:
    core.editor: "vim"
    color.ui: "auto"
    alias.diffc: "diff --cached"
    alias.remotev: "remote -v"


MAINTAINERS: Marius Gedminas, Matthew Gamble

METADATA:
	Status: ['preview']
	Supported_by: community
> GITHUB_HOOKS    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/github_hooks.py)

  Adds service hooks and removes service hooks that have an error status.

Options (= is mandatory):

= action
        This tells the githooks module what you want it to do.
        (Choices: create, cleanall, list, clean504)
- content_type
        Content type to use for requests made to the webhook
        (Choices: json, form)[Default: json]
- hookurl
        When creating a new hook, this is the url that you want github to post to. It is only required when creating a
        new hook.
        [Default: (null)]
= oauthkey
        The oauth key provided by github. It can be found/generated on github under "Edit Your Profile" >> "Applications"
        >> "Personal Access Tokens"

= repo
        This is the API url for the repository you want to manage hooks for. It should be in the form of:
        https://api.github.com/repos/user:/repo:. Note this is different than the normal repo url.

= user
        Github username.

- validate_certs
        If `no', SSL certificates for the target repo will not be validated. This should only be used on personally
        controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
# Example creating a new service hook. It ignores duplicates.
- github_hooks:
    action: create
    hookurl: http://11.111.111.111:2222
    user: '{{ gituser }}'
    oauthkey: '{{ oauthkey }}'
    repo: https://api.github.com/repos/pcgentry/Github-Auto-Deploy

# Cleaning all hooks for this repo that had an error on the last update. Since this works for all hooks in a repo it is probably best that this would be called from a handler.
- github_hooks:
    action: cleanall
    user: '{{ gituser }}'
    oauthkey: '{{ oauthkey }}'
    repo: '{{ repo }}'
  delegate_to: localhost


MAINTAINERS: Phillip Gentry, CX Inc (@pcgentry)

METADATA:
	Status: ['preview']
	Supported_by: community
> GITHUB_KEY    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/github_key.py)

  Creates, removes, or updates GitHub access keys.

Options (= is mandatory):

- force
        The default is `yes', which will replace the existing remote key if it's different than `pubkey'. If `no', the
        key will only be set if no key with the given `name' exists.
        (Choices: yes, no)[Default: yes]
= name
        SSH key name

- pubkey
        SSH public key value. Required when `state=present'.
        [Default: none]
- state
        Whether to remove a key, ensure that it exists, or update its value.
        (Choices: present, absent)[Default: present]
= token
        GitHub Access Token with permission to list and create public keys.

EXAMPLES:
- name: Read SSH public key to authorize
  shell: cat /home/foo/.ssh/id_rsa.pub
  register: ssh_pub_key

- name: Authorize key with GitHub
  local_action:
    module: github_key
    name: Access Key for Some Machine
    token: '{{ github_access_token }}'
    pubkey: '{{ ssh_pub_key.stdout }}'

RETURN VALUES:
deleted_keys:
    description: An array of key objects that were deleted. Only present on state=absent
    type: list
    returned: When state=absent
    sample: [{'id': 0, 'key': 'BASE64 encoded key', 'url': 'http://example.com/github key', 'created_at': 'YYYY-MM-DDTHH:MM:SZ', 'read_only': False}]
matching_keys:
    description: An array of keys matching the specified name. Only present on state=present
    type: list
    returned: When state=present
    sample: [{'id': 0, 'key': 'BASE64 encoded key', 'url': 'http://example.com/github key', 'created_at': 'YYYY-MM-DDTHH:MM:SZ', 'read_only': False}]
key:
    description: Metadata about the key just created. Only present on state=present
    type: dict
    returned: success
    sample: {'id': 0, 'key': 'BASE64 encoded key', 'url': 'http://example.com/github key', 'created_at': 'YYYY-MM-DDTHH:MM:SZ', 'read_only': False}


MAINTAINERS: Robert Estelle (@erydo)

METADATA:
	Status: ['preview']
	Supported_by: community
> GITHUB_RELEASE    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/github_release.py)

  Fetch metadata about Github Releases

Options (= is mandatory):

= action
        Action to perform
        (Choices: latest_release)
= repo
        Repository name

= token
        Github Personal Access Token for authenticating

= user
        The GitHub account that owns the repository

Requirements:  github3.py >= 1.0.0a3

EXAMPLES:
- name: Get latest release of test/test
  github:
    token: tokenabc1234567890
    user: testuser
    repo: testrepo
    action: latest_release

RETURN VALUES:
latest_release:
    description: Version of the latest release
    type: string
    returned: success
    sample: 1.1.0


MAINTAINERS: Adrian Moisey (@adrianmoisey)

METADATA:
	Status: ['preview']
	Supported_by: community
> GITLAB_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/gitlab_group.py)

  When the group does not exists in Gitlab, it will be created. When the group does exists and state=absent, the group
  will be deleted.

Options (= is mandatory):

- login_password
        Gitlab password for login_user
        [Default: None]
- login_token
        Gitlab token for logging in.
        [Default: None]
- login_user
        Gitlab user name.
        [Default: None]
= name
        Name of the group you want to create.

- path
        The path of the group you want to create, this will be server_url/group_path
        If not supplied, the group_name will be used.
        [Default: None]
= server_url
        Url of Gitlab server, with protocol (http or https).

- state
        create or delete group.
        Possible values are present and absent.
        (Choices: present, absent)[Default: present]
- validate_certs
        When using https if SSL certificate needs to be verified.
        [Default: True]
Requirements:  pyapi-gitlab python module

EXAMPLES:
- name: Delete Gitlab Group
  gitlab_group:
    server_url: http://gitlab.example.com
    validate_certs: False
    login_token: WnUzDsxjy8230-Dy_k
    name: my_first_group
    state: absent
  delegate_to: localhost

- name: Create Gitlab Group
  gitlab_group:
    server_url: https://gitlab.example.com
    validate_certs: True
    login_user: dj-wasabi
    login_password: MySecretPassword
    name: my_first_group
    path: my_first_group
    state: present
  delegate_to: localhost

RETURN VALUES:
 

MAINTAINERS: Werner Dijkerman (@dj-wasabi)

METADATA:
	Status: ['preview']
	Supported_by: community
> GITLAB_PROJECT    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/gitlab_project.py)

  When the project does not exists in Gitlab, it will be created. When the project does exists and state=absent, the
  project will be deleted. When changes are made to the project, the project will be updated.

Options (= is mandatory):

- description
        An description for the project.
        [Default: None]
- group
        The name of the group of which this projects belongs to.
        When not provided, project will belong to user which is configured in 'login_user' or 'login_token'
        When provided with username, project will be created for this user. 'login_user' or 'login_token' needs admin
        rights.
        [Default: None]
- import_url
        Git repository which will me imported into gitlab.
        Gitlab server needs read access to this git repository.
        [Default: False]
- issues_enabled
        Whether you want to create issues or not.
        Possible values are true and false.
        [Default: True]
- login_password
        Gitlab password for login_user
        [Default: None]
- login_token
        Gitlab token for logging in.
        [Default: None]
- login_user
        Gitlab user name.
        [Default: None]
- merge_requests_enabled
        If merge requests can be made or not.
        Possible values are true and false.
        [Default: True]
= name
        The name of the project

- path
        The path of the project you want to create, this will be server_url/<group>/path
        If not supplied, name will be used.
        [Default: None]
- public
        If the project is public available or not.
        Setting this to true is same as setting visibility_level to 20.
        Possible values are true and false.
        [Default: False]
= server_url
        Url of Gitlab server, with protocol (http or https).

- snippets_enabled
        If creating snippets should be available or not.
        Possible values are true and false.
        [Default: True]
- state
        create or delete project.
        Possible values are present and absent.
        (Choices: present, absent)[Default: present]
- validate_certs
        When using https if SSL certificate needs to be verified.
        [Default: True]
- visibility_level
        Private. visibility_level is 0. Project access must be granted explicitly for each user.
        Internal. visibility_level is 10. The project can be cloned by any logged in user.
        Public. visibility_level is 20. The project can be cloned without any authentication.
        Possible values are 0, 10 and 20.
        [Default: 0]
- wiki_enabled
        If an wiki for this project should be available or not.
        Possible values are true and false.
        [Default: True]
Requirements:  pyapi-gitlab python module

EXAMPLES:
- name: Delete Gitlab Project
  gitlab_project:
    server_url: http://gitlab.example.com
    validate_certs: False
    login_token: WnUzDsxjy8230-Dy_k
    name: my_first_project
    state: absent
  delegate_to: localhost

- name: Create Gitlab Project in group Ansible
  gitlab_project:
    server_url: https://gitlab.example.com
    validate_certs: True
    login_user: dj-wasabi
    login_password: MySecretPassword
    name: my_first_project
    group: ansible
    issues_enabled: False
    wiki_enabled: True
    snippets_enabled: True
    import_url: http://git.example.com/example/lab.git
    state: present
  delegate_to: localhost

RETURN VALUES:
 

MAINTAINERS: Werner Dijkerman (@dj-wasabi)

METADATA:
	Status: ['preview']
	Supported_by: community
> GITLAB_USER    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/gitlab_user.py)

  When the user does not exists in Gitlab, it will be created. When the user does exists and state=absent, the user will
  be deleted. When changes are made to user, the user will be updated.

Options (= is mandatory):

- access_level
        The access level to the group. One of the following can be used.
        guest
        reporter
        developer
        master
        owner
        [Default: None]
= email
        The email that belongs to the user.

- group
        Add user as an member to this group.
        [Default: None]
- login_password
        Gitlab password for login_user
        [Default: None]
- login_token
        Gitlab token for logging in.
        [Default: None]
- login_user
        Gitlab user name.
        [Default: None]
= name
        Name of the user you want to create

= password
        The password of the user.

= server_url
        Url of Gitlab server, with protocol (http or https).

- sshkey_file
        The ssh key itself.
        [Default: None]
- sshkey_name
        The name of the sshkey
        [Default: None]
- state
        create or delete group.
        Possible values are present and absent.
        (Choices: present, absent)[Default: present]
= username
        The username of the user.

- validate_certs
        When using https if SSL certificate needs to be verified.
        [Default: True]
Requirements:  pyapi-gitlab python module, administrator rights on the Gitlab server

EXAMPLES:
- name: Delete Gitlab User
  gitlab_user:
    server_url: http://gitlab.example.com
    validate_certs: False
    login_token: WnUzDsxjy8230-Dy_k
    username: myusername
    state: absent
  delegate_to: localhost

- name: Create Gitlab User
  gitlab_user:
    server_url: https://gitlab.dj-wasabi.local
    validate_certs: True
    login_user: dj-wasabi
    login_password: MySecretPassword
    name: My Name
    username: myusername
    password: mysecretpassword
    email: me@example.com
    sshkey_name: MySSH
    sshkey_file: ssh-rsa AAAAB3NzaC1yc...
    state: present
  delegate_to: localhost

RETURN VALUES:
 

MAINTAINERS: Werner Dijkerman (@dj-wasabi)

METADATA:
	Status: ['preview']
	Supported_by: community
> GLANCE_IMAGE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_glance_image.py)

  Add or Remove images from the glance repository.

DEPRECATED: 
Deprecated in 1.10. Use M(os_image) instead.

Options (= is mandatory):

- auth_url
        The keystone url for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
- container_format
        The format of the container
        [Default: bare]
- copy_from
        A url from where the image can be downloaded, mutually exclusive with file parameter
        [Default: None]
- disk_format
        The format of the disk that is getting uploaded
        [Default: qcow2]
- endpoint_type
        The name of the glance service's endpoint URL type
        (Choices: publicURL, internalURL)[Default: publicURL]
- file
        The path to the file which has to be uploaded, mutually exclusive with copy_from
        [Default: None]
- is_public
        Whether the image can be accessed publicly
        [Default: yes]
= login_password
        Password of login user
        [Default: yes]
= login_tenant_name
        The tenant name of the login user
        [Default: yes]
= login_username
        login username to authenticate to keystone
        [Default: admin]
- min_disk
        The minimum disk space required to deploy this image
        [Default: None]
- min_ram
        The minimum ram required to deploy this image
        [Default: None]
= name
        Name that has to be given to the image
        [Default: None]
- owner
        The owner of the image
        [Default: None]
- region_name
        Name of the region
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- timeout
        The time to wait for the image process to complete in seconds
        [Default: 180]
Requirements:  python >= 2.6, python-glanceclient, python-keystoneclient

EXAMPLES:
- name: Upload an image from an HTTP URL
  glance_image:
    login_username: admin
    login_password: passme
    login_tenant_name: admin
    name: cirros
    container_format: bare
    disk_format: qcow2
    state: present
    copy_from: http://launchpad.net/cirros/trunk/0.3.0/+download/cirros-0.3.0-x86_64-disk.img


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> GLUSTER_VOLUME    (/usr/lib/python2.7/site-packages/ansible/modules/system/gluster_volume.py)

  Create, remove, start, stop and tune GlusterFS volumes

Options (= is mandatory):

- arbiter
        Arbiter count for volume
        [Default: None]
- bricks
        Brick paths on servers. Multiple brick paths can be separated by commas
        [Default: None]
- cluster
        List of hosts to use for probing and brick setup
        [Default: None]
- directory
        Directory for limit-usage
        [Default: None]
- disperses
        Disperse count for volume
        [Default: None]
- force
        If brick is being created in the root partition, module will fail. Set force to true to override this behaviour
        [Default: None]
- host
        Override local hostname (for peer probing purposes)
        [Default: None]
= name
        The volume name

- options
        A dictionary/hash with options/settings for the volume
        [Default: None]
- quota
        Quota value for limit-usage (be sure to use 10.0MB instead of 10MB, see quota list)
        [Default: None]
- rebalance
        Controls whether the cluster is rebalanced after changes
        (Choices: yes, no)[Default: no]
- redundancies
        Redundancy count for volume
        [Default: None]
- replicas
        Replica count for volume
        [Default: None]
- start_on_create
        Controls whether the volume is started after creation or not, defaults to yes
        (Choices: yes, no)[Default: yes]
= state
        Use present/absent ensure if a volume exists or not, use started/stopped to control it's availability.
        (Choices: present, absent, started, stopped)
- stripes
        Stripe count for volume
        [Default: None]
- transport
        Transport type for volume
        (Choices: tcp, rdma, tcp,rdma)[Default: tcp]
Notes:
  * Requires cli tools for GlusterFS on servers
  * Will add new bricks, but not remove them
EXAMPLES:
- name: create gluster volume
  gluster_volume:
    state: present
    name: test1
    bricks: /bricks/brick1/g1
    rebalance: yes
    cluster:
      - 192.0.2.10
      - 192.0.2.11
  run_once: true

- name: tune
  gluster_volume:
    state: present
    name: test1
    options:
      performance.cache-size: 256MB

- name: start gluster volume
  gluster_volume:
    state: started
    name: test1

- name: limit usage
  gluster_volume:
    state: present
    name: test1
    directory: /foo
    quota: 20.0MB

- name: stop gluster volume
  gluster_volume:
    state: stopped
    name: test1

- name: remove gluster volume
  gluster_volume:
    state: absent
    name: test1

- name: create gluster volume with multiple bricks
  gluster_volume:
    state: present
    name: test2
    bricks: /bricks/brick1/g2,/bricks/brick2/g2
    cluster:
      - 192.0.2.10
      - 192.0.2.11
  run_once: true


MAINTAINERS: Taneli Leppä (@rosmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/system/group.py)

  Manage presence of groups on a host.

Options (= is mandatory):

- gid
        Optional `GID' to set for the group.
        [Default: (null)]
= name
        Name of the group to manage.

- state
        Whether the group should be present or not on the remote host.
        (Choices: present, absent)[Default: present]
- system
        If `yes', indicates that the group created is a system group.
        (Choices: yes, no)[Default: no]
Requirements:  groupadd, groupdel, groupmod

EXAMPLES:
# Example group command from Ansible Playbooks
- group:
    name: somegroup
    state: present


MAINTAINERS: Stephen Fromm (@sfromm)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> GROUP_BY    (/usr/lib/python2.7/site-packages/ansible/modules/inventory/group_by.py)

  Use facts to create ad-hoc groups that can be used later in a playbook.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

= key
        The variables whose values will be used as groups

Notes:
  * Spaces in group names are converted to dashes '-'.
EXAMPLES:
# Create groups based on the machine architecture
- group_by:
    key: machine_{{ ansible_machine }}

# Create groups like 'kvm-host'
- group_by:
    key: virt_{{ ansible_virtualization_type }}_{{ ansible_virtualization_role }}


MAINTAINERS: Jeroen Hoekx (@jhoekx)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> GROVE    (/usr/lib/python2.7/site-packages/ansible/modules/notification/grove.py)

  The `grove' module sends a message for a service to a Grove.io channel.

Options (= is mandatory):

= channel_token
        Token of the channel to post to.

- icon_url
        Icon for the service
        [Default: (null)]
= message
        Message content

- service
        Name of the service (displayed as the "user" in the message)
        [Default: ansible]
- url
        Service URL for the web client
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- grove: >
    channel_token=6Ph62VBBJOccmtTPZbubiPzdrhipZXtg
    service=my-app
    message=deployed {{ target }}


MAINTAINERS: Jonas Pfenniger (@zimbatm)

METADATA:
	Status: ['preview']
	Supported_by: community
> HALL    (/usr/lib/python2.7/site-packages/ansible/modules/notification/hall.py)

  The `hall' module connects to the https://hall.com messaging API and allows you to deliver notication messages to
  rooms.

Options (= is mandatory):

= msg
        The message you wish to deliver as a notifcation

- picture
        The full URL to the image you wish to use for the Icon of the message. Defaults to http://cdn2.hubspot.net/hub/33
        0046/file-769078210-png/Official_Logos/ansible_logo_black_square_small.png?t=1421076128627
        [Default: (null)]
= room_token
        Room token provided to you by setting up the Ansible room integation on https://hall.com

= title
        The title of the message

EXAMPLES:
- name: Send Hall notifiation
  hall:
    room_token: <hall room integration token>
    title: Nginx
    msg: 'Created virtual host file on {{ inventory_hostname }}'
  delegate_to: loclahost

- name: Send Hall notification if EC2 servers were created.
  hall:
    room_token: <hall room integration token>
    title: Server Creation
    msg: 'Created EC2 instance {{ item.id }} of type {{ item.instance_type }}.\nInstance can be reached at {{ item.public_ip }} in the {{ item.region }} region.'
  delegate_to: loclahost
  when: ec2.instances|length > 0
  with_items: '{{ ec2.instances }}'


MAINTAINERS: Billy Kimble (@bkimble) <basslines@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> HAPROXY    (/usr/lib/python2.7/site-packages/ansible/modules/network/haproxy.py)

  Enable, disable, and set weights for HAProxy backend servers using socket commands.

Options (= is mandatory):

- backend
        Name of the HAProxy backend pool.
        [Default: auto-detected]
- fail_on_not_found
        Fail whenever trying to enable/disable a backend host that does not exist
        [Default: False]
= host
        Name of the backend host to change.
        [Default: None]
- shutdown_sessions
        When disabling a server, immediately terminate all the sessions attached to the specified server. This can be
        used to terminate long-running sessions after a server is put into maintenance mode.
        [Default: False]
- socket
        Path to the HAProxy socket file.
        [Default: /var/run/haproxy.sock]
= state
        Desired state of the provided backend host.
        (Choices: enabled, disabled)[Default: None]
- wait
        Wait until the server reports a status of 'UP' when `state=enabled`, or status of 'MAINT' when `state=disabled`.
        [Default: False]
- wait_interval
        Number of seconds to wait between retries.
        [Default: 5]
- wait_retries
        Number of times to check for status after changing the state.
        [Default: 25]
- weight
        The value passed in argument. If the value ends with the `%` sign, then the new weight will be relative to the
        initially configured weight. Relative weights are only permitted between 0 and 100% and absolute weights are
        permitted between 0 and 256.
        [Default: None]
Notes:
  * Enable and disable commands are restricted and can only be issued on sockets configured for level 'admin'. For
        example, you can add the line 'stats socket /var/run/haproxy.sock level admin' to the general section of
        haproxy.cfg. See http://haproxy.1wt.eu/download/1.5/doc/configuration.txt.
EXAMPLES:
# disable server in 'www' backend pool
- haproxy:
    state: disabled
    host: '{{ inventory_hostname }}'
    backend: www

# disable server without backend pool name (apply to all available backend pool)
- haproxy:
    state: disabled
    host: '{{ inventory_hostname }}'

# disable server, provide socket file
- haproxy:
    state: disabled
    host: '{{ inventory_hostname }}'
    socket: /var/run/haproxy.sock
    backend: www

# disable server, provide socket file, wait until status reports in maintenance
- haproxy:
    state: disabled
    host: '{{ inventory_hostname }}'
    socket: /var/run/haproxy.sock
    backend: www
    wait: yes

# disable backend server in 'www' backend pool and drop open sessions to it
- haproxy:
    state: disabled
    host: '{{ inventory_hostname }}'
    backend: www
    socket: /var/run/haproxy.sock
    shutdown_sessions: true

# disable server without backend pool name (apply to all available backend pool) but fail when the backend host is not found
- haproxy:
    state: disabled
    host: '{{ inventory_hostname }}'
    fail_on_not_found: yes

# enable server in 'www' backend pool
- haproxy:
    state: enabled
    host: '{{ inventory_hostname }}'
    backend: www

# enable server in 'www' backend pool wait until healthy
- haproxy:
    state: enabled
    host: '{{ inventory_hostname }}'
    backend: www
    wait: yes

# enable server in 'www' backend pool wait until healthy. Retry 10 times with intervals of 5 seconds to retrieve the health
- haproxy:
    state: enabled
    host: '{{ inventory_hostname }}'
    backend: www
    wait: yes
    wait_retries: 10
    wait_interval: 5

# enable server in 'www' backend pool with change server(s) weight
- haproxy:
    state: enabled
    host: '{{ inventory_hostname }}'
    socket: /var/run/haproxy.sock
    weight: 10
    backend: www


MAINTAINERS: Ravi Bhure (@ravibhure)

METADATA:
	Status: ['preview']
	Supported_by: community
> HG    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/hg.py)

  Manages Mercurial (hg) repositories. Supports SSH, HTTP/S and local address.

Options (= is mandatory):

- clone
        If `no', do not clone the repository if it does not exist locally.
        (Choices: yes, no)[Default: yes]
= dest
        Absolute path of where the repository should be cloned to. This parameter is required, unless clone and update
        are set to no
        [Default: None]
- executable
        Path to hg executable to use. If not supplied, the normal mechanism for resolving binary paths will be used.
        [Default: None]
- force
        Discards uncommitted changes. Runs `hg update -C'.  Prior to 1.9, the default was `yes`.
        (Choices: yes, no)[Default: no]
- purge
        Deletes untracked files. Runs `hg purge'.
        (Choices: yes, no)[Default: no]
= repo
        The repository address.
        [Default: None]
- revision
        Equivalent `-r' option in hg command which could be the changeset, revision number, branch name or even tag.
        [Default: None]
- update
        If `no', do not retrieve new revisions from the origin repository
        (Choices: yes, no)[Default: yes]
Notes:
  * If the task seems to be hanging, first verify remote host is in `known_hosts'. SSH will prompt user to
        authorize the first contact with a remote host.  To avoid this prompt, one solution is to add the remote
        host public key in `/etc/ssh/ssh_known_hosts' before calling the hg module, with the following command:
        ssh-keyscan remote_host.com >> /etc/ssh/ssh_known_hosts.
EXAMPLES:
# Ensure the current working copy is inside the stable branch and deletes untracked files if any.
- hg:
    repo: https://bitbucket.org/user/repo1
    dest: /home/user/repo1
    revision: stable
    purge: yes

# Example just get information about the repository whether or not it has
# already been cloned locally.
- hg:
    repo: git://bitbucket.org/user/repo
    dest: /srv/checkout
    clone: no
    update: no


MAINTAINERS: Yeukhon Wong (@yeukhon)

METADATA:
	Status: ['preview']
	Supported_by: community
> HIPCHAT    (/usr/lib/python2.7/site-packages/ansible/modules/notification/hipchat.py)

  Send a message to a Hipchat room, with options to control the formatting.

Options (= is mandatory):

- api
        API url if using a self-hosted hipchat server. For Hipchat API version 2 use the default URI with `/v2' instead
        of `/v1'.
        [Default: https://api.hipchat.com/v1]
- color
        Background color for the message.
        (Choices: yellow, red, green, purple, gray, random)[Default: yellow]
- from
        Name the message will appear to be sent from. Max length is 15 characters - above this it will be truncated.
        [Default: Ansible]
= msg
        The message body.
        [Default: None]
- msg_format
        Message format.
        (Choices: text, html)[Default: text]
- notify
        If true, a notification will be triggered for users in the room.
        (Choices: yes, no)[Default: yes]
= room
        ID or name of the room.

= token
        API token.

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- hipchat:
    room: notif
    msg: Ansible task finished

# Use Hipchat API version 2
- hipchat:
    api: https://api.hipchat.com/v2/
    token: OAUTH2_TOKEN
    room: notify
    msg: Ansible task finished


MAINTAINERS: WAKAYAMA Shirou (@shirou), BOURDEL Paul (@pb8226)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> HOMEBREW    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/homebrew.py)

  Manages Homebrew packages

Options (= is mandatory):

- install_options
        options flags to install a package
        [Default: None]
- name
        name of package to install/remove
        [Default: None]
- path
        ':' separated list of paths to search for 'brew' executable. Since A package (`formula' in homebrew parlance)
        location is prefixed relative to the actual path of `brew' command, providing an alternative `brew' path enables
        managing different set of packages in an alternative location in the system.
        [Default: /usr/local/bin]
- state
        state of the package
        (Choices: head, latest, present, absent, linked, unlinked)[Default: present]
- update_homebrew
        update homebrew itself first
        (Choices: yes, no)[Default: False]
- upgrade_all
        upgrade all homebrew packages
        (Choices: yes, no)[Default: False]
Requirements:  python >= 2.6

EXAMPLES:
# Install formula foo with 'brew' in default path (C(/usr/local/bin))
- homebrew:
    name: foo
    state: present

# Install formula foo with 'brew' in alternate path C(/my/other/location/bin)
- homebrew:
    name: foo
    path: /my/other/location/bin
    state: present

# Update homebrew first and install formula foo with 'brew' in default path
- homebrew:
    name: foo
    state: present
    update_homebrew: yes

# Update homebrew first and upgrade formula foo to latest available with 'brew' in default path
- homebrew:
    name: foo
    state: latest
    update_homebrew: yes

# Update homebrew and upgrade all packages
- homebrew:
    update_homebrew: yes
    upgrade_all: yes

# Miscellaneous other examples
- homebrew:
    name: foo
    state: head

- homebrew:
    name: foo
    state: linked

- homebrew:
    name: foo
    state: absent

- homebrew:
    name: foo,bar
    state: absent

- homebrew:
    name: foo
    state: present
    install_options: with-baz,enable-debug


MAINTAINERS: Indrajit Raychaudhuri (@indrajitr), Daniel Jaouen (@danieljaouen), Andrew Dunham (@andrew-d)

METADATA:
	Status: ['preview']
	Supported_by: community
> HOMEBREW_CASK    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/homebrew_cask.py)

  Manages Homebrew casks.

Options (= is mandatory):

- install_options
        options flags to install a package
        [Default: None]
= name
        name of cask to install/remove

- path
        ':' separated list of paths to search for 'brew' executable.
        [Default: /usr/local/bin]
- state
        state of the cask
        (Choices: present, absent)[Default: present]
- update_homebrew
        update homebrew itself first. Note that `brew cask update' is a synonym for `brew update'.
        (Choices: yes, no)[Default: False]
Requirements:  python >= 2.6

EXAMPLES:
- homebrew_cask:
    name: alfred
    state: present

- homebrew_cask:
    name: alfred
    state: absent

- homebrew_cask:
    name: alfred
    state: present
    install_options: 'appdir=/Applications'

- homebrew_cask:
    name: alfred
    state: present
    install_options: 'debug,appdir=/Applications'

- homebrew_cask:
    name: alfred
    state: absent
    install_options: force


MAINTAINERS: Indrajit Raychaudhuri (@indrajitr), Daniel Jaouen (@danieljaouen), Enric Lluelles (@enriclluelles)

METADATA:
	Status: ['preview']
	Supported_by: community
> HOMEBREW_TAP    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/homebrew_tap.py)

  Tap external Homebrew repositories.

Options (= is mandatory):

= name
        The GitHub user/organization repository to tap.

- state
        state of the repository.
        (Choices: present, absent)[Default: present]
- url
        The optional git URL of the repository to tap. The URL is not assumed to be on GitHub, and the protocol doesn't
        have to be HTTP. Any location and protocol that git can handle is fine.
        `name' option may not be a list of multiple taps (but a single tap instead) when this option is provided.
        [Default: (null)]
Requirements:  homebrew

EXAMPLES:
- homebrew_tap:
    name: homebrew/dupes

- homebrew_tap:
    name: homebrew/dupes
    state: absent

- homebrew_tap:
    name: homebrew/dupes,homebrew/science
    state: present

- homebrew_tap:
    name: telemachus/brew
    url: 'https://bitbucket.org/telemachus/brew'


MAINTAINERS: Indrajit Raychaudhuri (@indrajitr), Daniel Jaouen (@danieljaouen)

METADATA:
	Status: ['preview']
	Supported_by: community
> HONEYBADGER_DEPLOYMENT    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/honeybadger_deployment.py)

  Notify Honeybadger.io about app deployments (see http://docs.honeybadger.io/article/188-deployment-tracking)

Options (= is mandatory):

= environment
        The environment name, typically 'production', 'staging', etc.

- repo
        URL of the project repository
        [Default: None]
- revision
        A hash, number, tag, or other identifier showing what revision was deployed
        [Default: None]
= token
        API token.

- url
        Optional URL to submit the notification to.
        [Default: https://api.honeybadger.io/v1/deploys]
- user
        The username of the person doing the deployment
        [Default: None]
- validate_certs
        If `no', SSL certificates for the target url will not be validated. This should only be used on personally
        controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- honeybadger_deployment:
    token: AAAAAA
    environment: staging
    user: ansible
    revision: b6826b8
    repo: 'git@github.com:user/repo.git'

RETURN VALUES:
 

MAINTAINERS: Benjamin Curtis (@stympy)

METADATA:
	Status: ['preview']
	Supported_by: community
> HOSTNAME    (/usr/lib/python2.7/site-packages/ansible/modules/system/hostname.py)

  Set system's hostname, supports most OSs/Distributions, including those using systemd. Note, this module does *NOT*
  modify `/etc/hosts'. You need to modify it yourself using other modules like template or replace. Windows, HP-UX and
  AIX are not currently supported

Options (= is mandatory):

= name
        Name of the host

Requirements:  hostname

EXAMPLES:
- hostname:
    name: web01


MAINTAINERS: Adrian Likins (@alikins), Hideki Saito (@saito-hideki)

METADATA:
	Status: ['preview']
	Supported_by: community
> HPILO_BOOT    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/hpilo/hpilo_boot.py)

  This module boots a system through its HP iLO interface. The boot media can be one of: cdrom, floppy, hdd, network or
  usb. This module requires the hpilo python module.

Options (= is mandatory):

- force
        Whether to force a reboot (even when the system is already booted).
        As a safeguard, without force, hpilo_boot will refuse to reboot a server that is already running.
        (Choices: yes, no)[Default: False]
= host
        The HP iLO hostname/address that is linked to the physical system.

- image
        The URL of a cdrom, floppy or usb boot media image. protocol://username:password@hostname:port/filename
        protocol is either 'http' or 'https'
        username:password is optional
        port is optional
        [Default: (null)]
- login
        The login name to authenticate to the HP iLO interface.
        [Default: Administrator]
- media
        The boot media to boot the system from
        (Choices: cdrom, floppy, hdd, network, normal, usb)[Default: network]
- password
        The password to authenticate to the HP iLO interface.
        [Default: admin]
- state
        The state of the boot media.
        no_boot: Do not boot from the device
        boot_once: Boot from the device once and then notthereafter
        boot_always: Boot from the device each time the serveris rebooted
        connect: Connect the virtual media device and set to boot_always
        disconnect: Disconnects the virtual media device and set to no_boot
        poweroff: Power off the server
        (Choices: boot_always, boot_once, connect, disconnect, no_boot, poweroff)[Default: boot_once]
Notes:
  * To use a USB key image you need to specify floppy as boot media.
  * This module ought to be run from a system that can access the HP iLO interface directly, either by using
        `local_action' or using `delegate_to'.
Requirements:  hpilo

EXAMPLES:
- name: Task to boot a system using an ISO from an HP iLO interface only if the system is an HP server
  hpilo_boot:
    host: YOUR_ILO_ADDRESS
    login: YOUR_ILO_LOGIN
    password: YOUR_ILO_PASSWORD
    media: cdrom
    image: http://some-web-server/iso/boot.iso
  when: cmdb_hwmodel.startswith('HP ')
  delegate_to: localhost

- name: Power off a server
  hpilo_boot:
    host: YOUR_ILO_HOST
    login: YOUR_ILO_LOGIN
    password: YOUR_ILO_PASSWORD
    state: poweroff
  delegate_to: localhost

RETURN VALUES:
# Default return values


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['preview']
	Supported_by: community
> HPILO_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/hpilo/hpilo_facts.py)

  This module gathers facts for a specific system using its HP iLO interface. These facts include hardware and network
  related information useful for provisioning (e.g. macaddress, uuid). This module requires the hpilo python module.

Options (= is mandatory):

= host
        The HP iLO hostname/address that is linked to the physical system.

- login
        The login name to authenticate to the HP iLO interface.
        [Default: Administrator]
- password
        The password to authenticate to the HP iLO interface.
        [Default: admin]
Notes:
  * This module ought to be run from a system that can access the HP iLO interface directly, either by using
        `local_action' or using `delegate_to'.
Requirements:  hpilo

EXAMPLES:
# Task to gather facts from a HP iLO interface only if the system is an HP server
- hpilo_facts:
    host: YOUR_ILO_ADDRESS
    login: YOUR_ILO_LOGIN
    password: YOUR_ILO_PASSWORD
  when: cmdb_hwmodel.startswith('HP ')
  delegate_to: localhost

- fail:
    msg: 'CMDB serial ({{ cmdb_serialno }}) does not match hardware serial ({{ hw_system_serial }}) !'
  when: cmdb_serialno != hw_system_serial

RETURN VALUES:
# Typical output of HP iLO_facts for a physical system
hw_bios_date:
    description: BIOS date
    returned: always
    type: string
    sample: 05/05/2011

hw_bios_version:
    description: BIOS version
    returned: always
    type: string
    sample: P68

hw_ethX:
    description: Interface information (for each interface)
    returned: always
    type: dictionary of information (macaddress)
    sample:
      - macaddress: 00:11:22:33:44:55
        macaddress_dash: 00-11-22-33-44-55

hw_eth_ilo:
    description: Interface information (for the iLO network interface)
    returned: always
    type: dictionary of information (macaddress)
    sample:
      - macaddress: 00:11:22:33:44:BA
      - macaddress_dash: 00-11-22-33-44-BA

hw_product_name:
    description: Product name
    returned: always
    type: string
    sample: ProLiant DL360 G7

hw_product_uuid:
    description: Product UUID
    returned: always
    type: string
    sample: ef50bac8-2845-40ff-81d9-675315501dac

hw_system_serial:
    description: System serial number
    returned: always
    type: string
    sample: ABC12345D6

hw_uuid:
    description: Hardware UUID
    returned: always
    type: string
    sample: 123456ABC78901D2


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['preview']
	Supported_by: community
> HPONCFG    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/hpilo/hponcfg.py)

  This modules configures the HP iLO interface using hponcfg.

Options (= is mandatory):

- minfw
        The minimum firmware level needed
        [Default: (null)]
= path
        The XML file as accepted by hponcfg

Notes:
  * You need a working hponcfg on the target system.
Requirements:  hponcfg tool

EXAMPLES:
- name: Example hponcfg configuration XML
  copy:
    content: |
      <ribcl VERSION="2.0">
        <login USER_LOGIN="user" PASSWORD="password">
          <rib_info MODE="WRITE">
            <mod_global_settings>
              <session_timeout value="0"/>
              <ssh_status value="Y"/>
              <ssh_port value="22"/>
              <serial_cli_status value="3"/>
              <serial_cli_speed value="5"/>
            </mod_global_settings>
          </rib_info>
        </login>
      </ribcl>
    dest: /tmp/enable-ssh.xml

- name: Configure HP iLO using enable-ssh.xml
  hponcfg:
    src: /tmp/enable-ssh.xml


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['preview']
	Supported_by: community
> HTPASSWD    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/htpasswd.py)

  Add and remove username/password entries in a password file using htpasswd. This is used by web servers such as Apache
  and Nginx for basic authentication.

Options (= is mandatory):

- create
        Used with `state=present'. If specified, the file will be created if it does not already exist. If set to "no",
        will fail if the file does not exist
        (Choices: yes, no)[Default: yes]
- crypt_scheme
        Encryption scheme to be used.  As well as the four choices listed here, you can also use any other hash supported
        by passlib, such as md5_crypt and sha256_crypt, which are linux passwd hashes.  If you do so the password file
        will not be compatible with Apache or Nginx
        (Choices: apr_md5_crypt, des_crypt, ldap_sha1, plaintext)[Default: apr_md5_crypt]
= name
        User name to add or remove

- password
        Password associated with user.
        Must be specified if user does not exist yet.
        [Default: (null)]
= path
        Path to the file that contains the usernames and passwords

- state
        Whether the user entry should be present or not
        (Choices: present, absent)[Default: present]
Notes:
  * This module depends on the `passlib' Python library, which needs to be installed on all target systems.
  * On Debian, Ubuntu, or Fedora: install `python-passlib'.
  * On RHEL or CentOS: Enable EPEL, then install `python-passlib'.
Requirements:  passlib>=1.6

EXAMPLES:
# Add a user to a password file and ensure permissions are set
- htpasswd:
    path: /etc/nginx/passwdfile
    name: janedoe
    password: '9s36?;fyNp'
    owner: root
    group: www-data
    mode: 0640

# Remove a user from a password file
- htpasswd:
    path: /etc/apache2/passwdfile
    name: foobar
    state: absent

# Add a user to a password file suitable for use by libpam-pwdfile
- htpasswd:
    path: /etc/mail/passwords
    name: alex
    password: oedu2eGh
    crypt_scheme: md5_crypt


MAINTAINERS: Ansible Core Team

METADATA:
	Status: ['preview']
	Supported_by: community
> IAM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/iam.py)

  Allows for the management of IAM users, user API keys, groups, roles.

Options (= is mandatory):

- access_key_ids
        A list of the keys that you want impacted by the access_key_state parameter.
        [Default: (null)]
- access_key_state
        When type is user, it creates, removes, deactivates or activates a user's access key(s). Note that actions apply
        only to keys specified.
        (Choices: create, remove, active, inactive)[Default: None]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- groups
        A list of groups the user should belong to. When update, will gracefully remove groups not listed.
        [Default: None]
= iam_type
        Type of IAM resource
        (Choices: user, group, role)[Default: None]
- key_count
        When access_key_state is create it will ensure this quantity of keys are present. Defaults to 1.
        [Default: 1]
= name
        Name of IAM resource to create or identify

- new_name
        When state is update, will replace name with new_name on IAM resource
        [Default: None]
- new_path
        When state is update, will replace the path with new_path on the IAM resource
        [Default: None]
- password
        When type is user and state is present, define the users login password. Also works with update. Note that always
        returns changed.
        [Default: None]
- path
        When creating or updating, specify the desired path of the resource. If state is present, it will replace the
        current path to match what is passed in when they do not match.
        [Default: /]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Whether to create, delete or update the IAM resource. Note, roles cannot be updated.
        (Choices: present, absent, update)[Default: None]
- trust_policy
        The inline (JSON or YAML) trust policy document that grants an entity permission to assume the role. Mutually
        exclusive with `trust_policy_filepath'.
        [Default: None]
- trust_policy_filepath
        The path to the trust policy document that grants an entity permission to assume the role. Mutually exclusive
        with `trust_policy'.
        [Default: None]
- update_password
        `always' will update passwords if they differ.  `on_create' will only set the password for newly created users.
        (Choices: always, on_create)[Default: always]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * Currently boto does not support the removal of Managed Policies, the module will error out if your
        user/group/role has managed policies when you try to do state=absent. They will need to be removed
        manually.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Basic user creation example
tasks:
- name: Create two new IAM users with API keys
  iam:
    iam_type: user
    name: "{{ item }}"
    state: present
    password: "{{ temp_pass }}"
    access_key_state: create
  with_items:
    - jcleese
    - mpython

# Advanced example, create two new groups and add the pre-existing user
# jdavila to both groups.
task:
- name: Create Two Groups, Mario and Luigi
  iam:
    iam_type: group
    name: "{{ item }}"
    state: present
  with_items:
     - Mario
     - Luigi
  register: new_groups

- name:
  iam:
    iam_type: user
    name: jdavila
    state: update
    groups: "{{ item.created_group.group_name }}"
  with_items: "{{ new_groups.results }}"

# Example of role with custom trust policy for Lambda service
- name: Create IAM role with custom trust relationship
  iam:
    iam_type: role
    name: AAALambdaTestRole
    state: present
    trust_policy:
      Version: '2012-10-17'
      Statement:
      - Action: sts:AssumeRole
        Effect: Allow
        Principal:
          Service: lambda.amazonaws.com



MAINTAINERS: Jonathan I. Davila (@defionscode), Paul Seiffert (@seiffert)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> IAM_CERT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/iam_cert.py)

  Allows for the management of server certificates

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- cert
        The path to the certificate body in PEM encoded format.
        [Default: (null)]
- cert_chain
        The path to the CA certificate chain in PEM encoded format.
        [Default: None]
- dup_ok
        By default the module will not upload a certificate that is already uploaded into AWS. If set to True, it will
        upload the certificate as long as the name is unique.
        [Default: False]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- key
        The path to the private key of the certificate in PEM encoded format.
        [Default: (null)]
= name
        Name of certificate to add, update or remove.

- new_name
        When present, this will update the name of the cert with the value passed here.
        [Default: (null)]
- new_path
        When present, this will update the path of the cert with the value passed here.
        [Default: (null)]
- path
        When creating or updating, specify the desired path of the certificate
        [Default: /]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Whether to create, delete certificate. When present is specified it will attempt to make an update if new_path or
        new_name is specified.
        (Choices: present, absent)[Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, python >= 2.6

EXAMPLES:
# Basic server certificate upload
tasks:
- name: Upload Certificate
  iam_cert:
    name: very_ssl
    state: present
    cert: somecert.pem
    key: privcertkey
    cert_chain: myverytrustedchain



MAINTAINERS: Jonathan I. Davila

METADATA:
	Status: ['preview']
	Supported_by: community
> IAM_MFA_DEVICE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/iam_mfa_device_facts.py)

  List the MFA (Multi-Factor Authentication) devices registered for a user

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- user_name
        The name of the user whose MFA devices will be listed
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# List MFA devices (more details: http://docs.aws.amazon.com/IAM/latest/APIReference/API_ListMFADevices.html)
iam_mfa_device_facts:
register: mfa_devices

# Assume an existing role (more details: http://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html)
sts_assume_role:
  mfa_serial_number: "{{ mfa_devices.mfa_devices[0].serial_number }}"
  role_arn: "arn:aws:iam::123456789012:role/someRole"
  role_session_name: "someRoleSession"
register: assumed_role

RETURN VALUES:
mfa_devices:
    description: The MFA devices registered for the given user
    returned: always
    type: list
    sample:
      - enable_date: "2016-03-11T23:25:36+00:00"
        serial_number: arn:aws:iam::085120003701:mfa/pwnall
        user_name: pwnall
      - enable_date: "2016-03-11T23:25:37+00:00"
        serial_number: arn:aws:iam::085120003702:mfa/pwnall
        user_name: pwnall


MAINTAINERS: Victor Costan (@pwnall)

METADATA:
	Status: ['preview']
	Supported_by: community
> IAM_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/iam_policy.py)

  Allows uploading or removing IAM policies for IAM users, groups or roles.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= iam_name
        Name of IAM resource you wish to target for policy actions. In other words, the user name, group name or role
        name.

= iam_type
        Type of IAM resource
        (Choices: user, group, role)[Default: None]
- policy_document
        The path to the properly json formatted policy file (mutually exclusive with `policy_json')
        [Default: (null)]
- policy_json
        A properly json formatted policy as string (mutually exclusive with `policy_document', see
        https://github.com/ansible/ansible/issues/7005#issuecomment-42894813 on how to use it properly)
        [Default: (null)]
= policy_name
        The name label for the policy to create or remove.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- skip_duplicates
        By default the module looks for any policies that match the document you pass in, if there is a match it will not
        make a new policy object with the same rules. You can override this by specifying false which would allow for two
        policy objects with different names but same rules.
        [Default: /]
= state
        Whether to create or delete the IAM policy.
        (Choices: present, absent)[Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * Currently boto does not support the removal of Managed Policies, the module will not work removing/adding
        managed policies.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Create a policy with the name of 'Admin' to the group 'administrators'
tasks:
- name: Assign a policy called Admin to the administrators group
  iam_policy:
    iam_type: group
    iam_name: administrators
    policy_name: Admin
    state: present
    policy_document: admin_policy.json

# Advanced example, create two new groups and add a READ-ONLY policy to both
# groups.
task:
- name: Create Two Groups, Mario and Luigi
  iam:
    iam_type: group
    name: "{{ item }}"
    state: present
  with_items:
     - Mario
     - Luigi
  register: new_groups

- name: Apply READ-ONLY policy to new groups that have been recently created
  iam_policy:
    iam_type: group
    iam_name: "{{ item.created_group.group_name }}"
    policy_name: "READ-ONLY"
    policy_document: readonlypolicy.json
    state: present
  with_items: "{{ new_groups.results }}"

# Create a new S3 policy with prefix per user
tasks:
- name: Create S3 policy from template
  iam_policy:
    iam_type: user
    iam_name: "{{ item.user }}"
    policy_name: "s3_limited_access_{{ item.prefix }}"
    state: present
    policy_json: " {{ lookup( 'template', 's3_policy.json.j2') }} "
    with_items:
      - user: s3_user
        prefix: s3_user_prefix



MAINTAINERS: Jonathan I. Davila (@defionscode)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> IAM_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/iam_role.py)

  Manage AWS IAM roles

Options (= is mandatory):

- assume_role_policy_document
        The trust relationship policy document that grants an entity permission to assume the role.  This parameter is
        required when state: present.
        [Default: (null)]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= managed_policy
        A list of managed policy ARNs (can't use friendly names due to AWS API limitation) to attach to the role. To
        embed an inline policy, use [iam_policy]. To remove existing policies, use an empty list item.

= name
        The name of the role to create.

- path
        The path to the role. For more information about paths, see
        http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_identifiers.html.
        [Default: /]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Create or remove the IAM role
        (Choices: present, absent)
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Create a role
- iam_role:
    name: mynewrole
    assume_role_policy_document: "{{ lookup('file','policy.json') }}"
    state: present

# Create a role and attach a managed policy called "PowerUserAccess"
- iam_role:
    name: mynewrole
    assume_role_policy_document: "{{ lookup('file','policy.json') }}"
    state: present
    managed_policy:
      - arn:aws:iam::aws:policy/PowerUserAccess

# Keep the role created above but remove all managed policies
- iam_role:
    name: mynewrole
    assume_role_policy_document: "{{ lookup('file','policy.json') }}"
    state: present
    managed_policy:
      -

# Delete the role
- iam_role:
    name: mynewrole
    assume_role_policy_document: "{{ lookup('file','policy.json') }}"
    state: absent


RETURN VALUES:
path:
    description: the path to the role
    type: string
    sample: /
role_name:
    description: the friendly name that identifies the role
    type: string
    sample: myrole
role_id:
    description: the stable and unique string identifying the role
    type: string
    sample: ABCDEFF4EZ4ABCDEFV4ZC
arn:
    description: the Amazon Resource Name (ARN) specifying the role
    type: string
    sample: "arn:aws:iam::1234567890:role/mynewrole"
create_date:
    description: the date and time, in ISO 8601 date-time format, when the role was created
    type: string
    sample: "2016-08-14T04:36:28+00:00"
assume_role_policy_document:
    description: the policy that grants an entity permission to assume the role
    type: string
    sample: {
                'statement': [
                    {
                        'action': 'sts:AssumeRole',
                        'effect': 'Allow',
                        'principal': {
                            'service': 'ec2.amazonaws.com'
                        },
                        'sid': ''
                    }
                ],
                'version': '2012-10-17'
            }
attached_policies:
    description: a list of dicts containing the name and ARN of the managed IAM policies attached to the role
    type: list
    sample: [
        {
            'policy_arn': 'arn:aws:iam::aws:policy/PowerUserAccess',
            'policy_name': 'PowerUserAccess'
        }
    ]


MAINTAINERS: Rob White, @wimnat

METADATA:
	Status: ['preview']
	Supported_by: community
> IAM_SERVER_CERTIFICATE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/iam_server_certificate_facts.py)

  Retrieve the attributes of a server certificate

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= name
        The name of the server certificate you are retrieving attributes for.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, python >= 2.6

EXAMPLES:
# Retrieve server certificate
- iam_server_certificate_facts:
    name: production-cert
  register: server_cert

# Fail if the server certificate name was not found
- iam_server_certificate_facts:
    name: production-cert
  register: server_cert
  failed_when: "{{ server_cert.results | length == 0 }}"

RETURN VALUES:
server_certificate_id:
    description: The 21 character certificate id
    returned: success
    type: str
    sample: "ADWAJXWTZAXIPIMQHMJPO"
certificate_body:
    description: The asn1der encoded PEM string
    returned: success
    type: str
    sample: "-----BEGIN CERTIFICATE-----
bunch of random data
-----END CERTIFICATE-----"
server_certificate_name:
    description: The name of the server certificate
    returned: success
    type: str
    sample: "server-cert-name"
arn:
    description: The Amazon resource name of the server certificate
    returned: success
    type: str
    sample: "arn:aws:iam::911277865346:server-certificate/server-cert-name"
path:
    description: The path of the server certificate
    returned: success
    type: str
    sample: "/"
expiration:
    description: The date and time this server certificate will expire, in ISO 8601 format.
    returned: success
    type: str
    sample: "2017-06-15T12:00:00+00:00"
upload_date:
    description: The date and time this server certificate was uploaded, in ISO 8601 format.
    returned: success
    type: str
    sample: "2015-04-25T00:36:40+00:00"


MAINTAINERS: Allen Sanabria (@linuxdynasty)

METADATA:
	Status: ['preview']
	Supported_by: community
> ICINGA2_FEATURE    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/icinga2_feature.py)

  Enable or disable an Icinga2 feature

Options (= is mandatory):

= name
        This is the feature name to enable or disable.

- state
        Apply feature state.
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: Enable ido-pgsql feature
  icinga2_feature:
    name: ido-pgsql
    state: present

RETURN VALUES:
#


MAINTAINERS: Loic Blot (@nerzhul)

METADATA:
	Status: ['preview']
	Supported_by: community
> IMGADM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/smartos/imgadm.py)

  Manage SmartOS virtual machine images through imgadm(1M)

Options (= is mandatory):

- force
        Force a given operation (where supported by imgadm(1M)).
        (Choices: True, False)[Default: (null)]
- pool
        zpool to import to or delete images from.
        [Default: zones]
- source
        URI for the image source.
        [Default: (null)]
= state
        State the object operated on should be in. `imported' is an alias for for `present' and `deleted' for `absent'.
        When set to `vacuumed' and `uuid' to `*', it will remove all unused images.
        (Choices: present, absent, deleted, imported, updated, vacuumed)
- type
        Type for image sources.
        (Choices: imgapi, docker, dsapi)[Default: imgapi]
- uuid
        Image UUID. Can either be a full UUID or `*' for all images.
        [Default: (null)]
Requirements:  python >= 2.6

EXAMPLES:
- name: Import an image
  imgadm:
    uuid: '70e3ae72-96b6-11e6-9056-9737fd4d0764'
    state: imported

- name: Delete an image
  imgadm:
    uuid: '70e3ae72-96b6-11e6-9056-9737fd4d0764'
    state: deleted

- name: Update all images
  imgadm:
    uuid: '*'
    state: updated

- name: Update a single image
  imgadm:
    uuid: '70e3ae72-96b6-11e6-9056-9737fd4d0764'
    state: updated

- name: Add a source
  imgadm:
    source: 'https://datasets.project-fifo.net'
    state: present

- name: Add a Docker source
  imgadm:
    source: 'https://docker.io'
    type: docker
    state: present

- name: Remove a source
  imgadm:
    source: 'https://docker.io'
    state: absent

RETURN VALUES:
source:
    description: Source that is managed.
    returned: When not managing an image.
    type: string
    sample: https://datasets.project-fifo.net
uuid:
    description: UUID for an image operated on.
    returned: When not managing an image source.
    type: string
    sample: 70e3ae72-96b6-11e6-9056-9737fd4d0764
state:
    description: State of the target, after execution.
    returned: success
    type: string
    sample: 'present'


MAINTAINERS: Jasper Lievisse Adriaanse (@jasperla)

METADATA:
	Status: ['preview']
	Supported_by: community
> INCLUDE    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/include.py)

  Includes a file with a list of plays or tasks to be executed in the current playbook. Files with a list of plays can
  only be included at the top level, lists of tasks can only be included where tasks normally run (in play). Before 2.0
  all includes were 'static', executed at play compile time. Static includes are not subject to most directives, for
  example, loops or conditionals, they are applied instead to each inherited task. Since 2.0 task includes are dynamic
  and behave more like real tasks.  This means they can be looped, skipped and use variables from any source. Ansible
  tries to auto detect this, use the `static` directive (new in 2.1) to bypass autodetection.

Options (= is mandatory):

- free-form
        This module allows you to specify the name of the file directly w/o any other options.
        [Default: (null)]
Notes:
  * This is really not a module, though it appears as such, this is a feature of the Ansible Engine, as such it
        cannot be overridden the same way a module can.
EXAMPLES:
# include a play after another play
- hosts: localhost
  tasks:
    - debug:
        msg: "play1"

- include: otherplays.yml


# include task list in play
- hosts: all
  tasks:
    - debug:
        msg: task1

    - include: stuff.yml

    - debug:
        msg: task10

# dyanmic include task list in play
- hosts: all
  tasks:
    - debug:
        msg: task1

    - include: "{{ hostvar }}.yml"
      static: no
      when: hostvar is defined

RETURN VALUES:
# this module does not return anything except plays or tasks to execute


MAINTAINERS: Ansible Core Team (@ansible)

METADATA:
	Status: ['preview']
	Supported_by: core
> INCLUDE_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/include_role.py)

  Loads and executes a role as a task, this frees roles from the `role:` directive and allows them to be treated more as
  tasks.

Options (= is mandatory):

- allow_duplicates
        Overrides the role's metadata setting to allow using a role more than once with the same parameters.
        [Default: True]
- defaults_from
        File to load from a Role's defaults/ directory.
        [Default: main]
= name
        The name of the role to be executed.

- private
        If True the variables from defaults/ and vars/ in a role will not be made available to the rest of the play.
        [Default: None]
- tasks_from
        File to load from a Role's tasks/ directory.
        [Default: main]
- vars_from
        File to load from a Role's vars/ directory.
        [Default: main]
Notes:
  * Handlers are made available to the whole play.
  * simple dependencies seem to work fine.
  * As with `include' this task can be static or dynamic, If static it implies that it won't need templating nor
        loops nor conditionals and will show included tasks in the --list options. Ansible will try to autodetect
        what is needed, but you can set `static` to `yes` or `no` at task level to control this.
EXAMPLES:
- include_role:
    name: myrole

- name: Run tasks/other.yml instead of 'main'
  include_role:
    name: myrole
    tasks_from: other

- name: Pass variables to role
  include_role:
    name: myrole
  vars:
    rolevar1: 'value from task'

- name: Use role in loop
  include_role:
    name: myrole
  with_items:
    - '{{ roleinput1 }}'
    - '{{ roleinput2 }}'
  loop_control:
    loop_var: roleinputvar

- name: conditional role
  include_role:
    name: myrole
  when: not idontwanttorun

RETURN VALUES:
# this module does not return anything except tasks to execute


MAINTAINERS: Ansible Core Team (@ansible)

METADATA:
	Status: ['preview']
	Supported_by: core
> INCLUDE_VARS    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/include_vars.py)

  Loads variables from a YAML/JSON files dynamically from within a file or from a directory recursively during task
  runtime. If loading a directory, the files are sorted alphabetically before being loaded.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- depth
        When using `dir', this module will, by default, recursively go through each sub directory and load up the
        variables. By explicitly setting the depth, this module will only go as deep as the depth.
        [Default: 0]
- dir
        The directory name from which the variables should be loaded.
        If the path is relative, it will look for the file in vars/ subdirectory of a role or relative to playbook.
        [Default: None]
- extensions
        List of file extensions to read when using `dir'.
        [Default: [u'yaml', u'yml', u'json']]
- file
        The file name from which variables should be loaded.
        If the path is relative, it will look for the file in vars/ subdirectory of a role or relative to playbook.
        [Default: (null)]
- files_matching
        Limit the files that are loaded within any directory to this regular expression.
        [Default: None]
- free-form
        This module allows you to specify the 'file' option directly w/o any other options. There is no 'free-form'
        option, this is just an indicator, see example below.
        [Default: (null)]
- ignore_files
        List of file names to ignore.
        [Default: None]
- name
        The name of a variable into which assign the included vars, if omitted (null) they will be made top level vars.
        [Default: None]
EXAMPLES:
- name: Include vars of stuff.yml into the 'stuff' variable (2.2).
  include_vars:
    file: stuff.yml
    name: stuff

- name: Conditionally decide to load in variables into 'plans' when x is 0, otherwise do not. (2.2)
  include_vars:
    file: contingency_plan.yml
    name: plans
  when: x == 0

- name: Load a variable file based on the OS type, or a default if not found. Using free-form to specify the file.
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution }}.yml"
    - "{{ ansible_os_family }}.yml"
    - "default.yml"

- name: bare include (free-form)
  include_vars: myvars.yml

- name: Include all .json and .jsn files in vars/all and all nested directories (2.3)
  include_vars:
    dir: 'vars/all'
    extensions:
        - json
        - jsn

- name: Include all default extension files in vars/all and all nested directories and save the output in test. (2.2)
  include_vars:
    dir: 'vars/all'
    name: test

- name: Include default extension files in vars/services (2.2)
  include_vars:
    dir: 'vars/services'
    depth: 1

- name: Include only files matching bastion.yml (2.2)
  include_vars:
    dir: 'vars'
    files_matching: 'bastion.yml'

- name: Include all .yml files except bastion.yml (2.3)
  include_vars:
    dir: 'vars'
    ignore_files: 'bastion.yml'
    extensions: ['yml']


MAINTAINERS: Allen Sanabria (@linuxdynasty)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> INFINI_EXPORT    (/usr/lib/python2.7/site-packages/ansible/modules/storage/infinidat/infini_export.py)

  This module creates, deletes or modifies NFS exports on Infinibox.

Options (= is mandatory):

- client_list
        List of dictionaries with client entries. See examples. Check infini_export_client module to modify individual
        NFS client entries for export.
        [Default: All Hosts(*), RW, no_root_squash: True]
= filesystem
        Name of exported file system.

- inner_path
        Internal path of the export.
        [Default: /]
= name
        Export name. Should always start with `/'. (ex. name=/data)

- password
        Infinibox User password.
        [Default: (null)]
- state
        Creates/Modifies export when present and removes when absent.
        (Choices: present, absent)[Default: present]
= system
        Infinibox Hostname or IPv4 Address.

- user
        Infinibox User username with sufficient priveledges ( see notes ).
        [Default: (null)]
Notes:
  * This module requires infinisdk python library
  * You must set INFINIBOX_USER and INFINIBOX_PASSWORD environment variables if user and password arguments are not
        passed to the module directly
  * Ansible uses the infinisdk configuration file `~/.infinidat/infinisdk.ini' if no credentials are provided. See
        http://infinisdk.readthedocs.io/en/latest/getting_started.html
Requirements:  python >= 2.7, infinisdk

EXAMPLES:
- name: Export bar filesystem under foo pool as /data
  infini_export:
    name: /data01
    filesystem: foo
    user: admin
    password: secret
    system: ibox001

- name: Export and specify client list explicitly
  infini_export:
    name: /data02
    filesystem: foo
    client_list:
      - client: 192.168.0.2
        access: RW
        no_root_squash: True
      - client: 192.168.0.100
        access: RO
        no_root_squash: False
      - client: 192.168.0.10-192.168.0.20
        access: RO
        no_root_squash: False
    system: ibox001
    user: admin
    password: secret

RETURN VALUES:


MAINTAINERS: Gregory Shulov (@GR360RY)

METADATA:
	Status: ['preview']
	Supported_by: community
> INFINI_EXPORT_CLIENT    (/usr/lib/python2.7/site-packages/ansible/modules/storage/infinidat/infini_export_client.py)

  This module creates, deletes or modifys NFS client(s) for existing exports on Infinibox.

Options (= is mandatory):

- access_mode
        Read Write or Read Only Access.
        (Choices: RW, RO)[Default: RW]
= client
        Client IP or Range. Ranges can be defined as follows 192.168.0.1-192.168.0.254.

= export
        Name of the export.

- no_root_squash
        Don't squash root user to anonymous. Will be set to "no" on creation if not specified explicitly.
        (Choices: yes, no)[Default: False]
- password
        Infinibox User password.
        [Default: (null)]
- state
        Creates/Modifies client when present and removes when absent.
        (Choices: present, absent)[Default: present]
= system
        Infinibox Hostname or IPv4 Address.

- user
        Infinibox User username with sufficient priveledges ( see notes ).
        [Default: (null)]
Notes:
  * This module requires infinisdk python library
  * You must set INFINIBOX_USER and INFINIBOX_PASSWORD environment variables if user and password arguments are not
        passed to the module directly
  * Ansible uses the infinisdk configuration file `~/.infinidat/infinisdk.ini' if no credentials are provided. See
        http://infinisdk.readthedocs.io/en/latest/getting_started.html
Requirements:  python >= 2.7, infinisdk

EXAMPLES:
- name: Make sure nfs client 10.0.0.1 is configured for export. Allow root access
  infini_export_client:
    client: 10.0.0.1
    access_mode: RW
    no_root_squash: yes
    export: /data
    user: admin
    password: secret
    system: ibox001

- name: Add multiple clients with RO access. Squash root priviledges
  infini_export_client:
    client: "{{ item }}"
    access_mode: RO
    no_root_squash: no
    export: /data
    user: admin
    password: secret
    system: ibox001
  with_items:
    - 10.0.0.2
    - 10.0.0.3

RETURN VALUES:


MAINTAINERS: Gregory Shulov (@GR360RY)

METADATA:
	Status: ['preview']
	Supported_by: community
> INFINI_FS    (/usr/lib/python2.7/site-packages/ansible/modules/storage/infinidat/infini_fs.py)

  This module creates, deletes or modifies filesystems on Infinibox.

Options (= is mandatory):

= name
        File system name.

- password
        Infinibox User password.
        [Default: (null)]
= pool
        Pool that will host file system.

- size
        File system size in MB, GB or TB units. See examples.
        [Default: (null)]
- state
        Creates/Modifies file system when present or removes when absent.
        (Choices: present, absent)[Default: present]
= system
        Infinibox Hostname or IPv4 Address.

- user
        Infinibox User username with sufficient priveledges ( see notes ).
        [Default: (null)]
Notes:
  * This module requires infinisdk python library
  * You must set INFINIBOX_USER and INFINIBOX_PASSWORD environment variables if user and password arguments are not
        passed to the module directly
  * Ansible uses the infinisdk configuration file `~/.infinidat/infinisdk.ini' if no credentials are provided. See
        http://infinisdk.readthedocs.io/en/latest/getting_started.html
Requirements:  python >= 2.7, infinisdk

EXAMPLES:
- name: Create new file system named foo under pool named bar
  infini_fs:
    name: foo
    size: 1TB
    pool: bar
    state: present
    user: admin
    password: secret
    system: ibox001

RETURN VALUES:


MAINTAINERS: Gregory Shulov (@GR360RY)

METADATA:
	Status: ['preview']
	Supported_by: community
> INFINI_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/storage/infinidat/infini_host.py)

  This module creates, deletes or modifies hosts on Infinibox.

Options (= is mandatory):

= name
        Host Name

- password
        Infinibox User password.
        [Default: (null)]
- state
        Creates/Modifies Host when present or removes when absent
        (Choices: present, absent)[Default: present]
= system
        Infinibox Hostname or IPv4 Address.

- user
        Infinibox User username with sufficient priveledges ( see notes ).
        [Default: (null)]
- volume
        Volume name to map to the host
        [Default: (null)]
- wwns
        List of wwns of the host
        [Default: (null)]
Notes:
  * This module requires infinisdk python library
  * You must set INFINIBOX_USER and INFINIBOX_PASSWORD environment variables if user and password arguments are not
        passed to the module directly
  * Ansible uses the infinisdk configuration file `~/.infinidat/infinisdk.ini' if no credentials are provided. See
        http://infinisdk.readthedocs.io/en/latest/getting_started.html
Requirements:  python >= 2.7, infinisdk

EXAMPLES:
- name: Create new new host
  infini_host:
    name: foo.example.com
    user: admin
    password: secret
    system: ibox001

- name: Make sure host bar is available with wwn ports
  infini_host:
    name: bar.example.com
    wwns:
      - "00:00:00:00:00:00:00"
      - "11:11:11:11:11:11:11"
    system: ibox01
    user: admin
    password: secret

- name: Map host foo.example.com to volume bar
  infini_host:
    name: foo.example.com
    volume: bar
    system: ibox01
    user: admin
    password: secret

RETURN VALUES:


MAINTAINERS: Gregory Shulov (@GR360RY)

METADATA:
	Status: ['preview']
	Supported_by: community
> INFINI_POOL    (/usr/lib/python2.7/site-packages/ansible/modules/storage/infinidat/infini_pool.py)

  This module to creates, deletes or modifies pools on Infinibox.

Options (= is mandatory):

= name
        Pool Name

- password
        Infinibox User password.
        [Default: (null)]
- size
        Pool Physical Capacity in MB, GB or TB units. If pool size is not set on pool creation, size will be equal to
        1TB. See examples.
        [Default: (null)]
- ssd_cache
        Enable/Disable SSD Cache on Pool
        (Choices: yes, no)[Default: True]
- state
        Creates/Modifies Pool when present or removes when absent
        (Choices: present, absent)[Default: present]
= system
        Infinibox Hostname or IPv4 Address.

- user
        Infinibox User username with sufficient priveledges ( see notes ).
        [Default: (null)]
- vsize
        Pool Virtual Capacity in MB, GB or TB units. If pool vsize is not set on pool creation, Virtual Capacity will be
        equal to Physical Capacity. See examples.
        [Default: (null)]
Notes:
  * Infinibox Admin level access is required for pool modifications
  * This module requires infinisdk python library
  * You must set INFINIBOX_USER and INFINIBOX_PASSWORD environment variables if user and password arguments are not
        passed to the module directly
  * Ansible uses the infinisdk configuration file `~/.infinidat/infinisdk.ini' if no credentials are provided. See
        http://infinisdk.readthedocs.io/en/latest/getting_started.html
Requirements:  python >= 2.7, infinisdk

EXAMPLES:
- name: Make sure pool foo exists. Set pool physical capacity to 10TB
  infini_pool:
    name: foo
    size: 10TB
    vsize: 10TB
    user: admin
    password: secret
    system: ibox001

- name: Disable SSD Cache on pool
  infini_pool:
    name: foo
    ssd_cache: no
    user: admin
    password: secret
    system: ibox001

RETURN VALUES:


MAINTAINERS: Gregory Shulov (@GR360RY)

METADATA:
	Status: ['preview']
	Supported_by: community
> INFINI_VOL    (/usr/lib/python2.7/site-packages/ansible/modules/storage/infinidat/infini_vol.py)

  This module creates, deletes or modifies volume on Infinibox.

Options (= is mandatory):

= name
        Volume Name

- password
        Infinibox User password.
        [Default: (null)]
= pool
        Pool that volume will reside on

- size
        Volume size in MB, GB or TB units. See examples.
        [Default: (null)]
- state
        Creates/Modifies volume when present or removes when absent
        (Choices: present, absent)[Default: present]
= system
        Infinibox Hostname or IPv4 Address.

- user
        Infinibox User username with sufficient priveledges ( see notes ).
        [Default: (null)]
Notes:
  * This module requires infinisdk python library
  * You must set INFINIBOX_USER and INFINIBOX_PASSWORD environment variables if user and password arguments are not
        passed to the module directly
  * Ansible uses the infinisdk configuration file `~/.infinidat/infinisdk.ini' if no credentials are provided. See
        http://infinisdk.readthedocs.io/en/latest/getting_started.html
Requirements:  python >= 2.7, infinisdk

EXAMPLES:
- name: Create new volume named foo under pool named bar
  infini_vol:
    name: foo
    size: 1TB
    pool: bar
    state: present
    user: admin
    password: secret
    system: ibox001

RETURN VALUES:


MAINTAINERS: Gregory Shulov (@GR360RY)

METADATA:
	Status: ['preview']
	Supported_by: community
> INFLUXDB_DATABASE    (/usr/lib/python2.7/site-packages/ansible/modules/database/influxdb/influxdb_database.py)

  Manage InfluxDB databases

Options (= is mandatory):

= database_name
        Name of the database that will be created/destroyed

= hostname
        The hostname or IP address on which InfluxDB server is listening

- password
        Password that will be used to authenticate against InfluxDB server
        [Default: root]
- port
        The port on which InfluxDB server is listening
        [Default: 8086]
- state
        Determines if the database should be created or destroyed
        (Choices: present, absent)[Default: present]
- username
        Username that will be used to authenticate against InfluxDB server
        [Default: root]
Requirements:  python >= 2.6, influxdb >= 0.9

EXAMPLES:
# Example influxdb_database command from Ansible Playbooks
- name: Create database
  influxdb_database:
      hostname: "{{influxdb_ip_address}}"
      database_name: "{{influxdb_database_name}}"
      state: present

- name: Destroy database
  influxdb_database:
      hostname: "{{influxdb_ip_address}}"
      database_name: "{{influxdb_database_name}}"
      state: absent

- name: Create database using custom credentials
  influxdb_database:
      hostname: "{{influxdb_ip_address}}"
      username: "{{influxdb_username}}"
      password: "{{influxdb_password}}"
      database_name: "{{influxdb_database_name}}"
      state: present

RETURN VALUES:
#only defaults


MAINTAINERS: Kamil Szczygiel (@kamsz)

METADATA:
	Status: ['preview']
	Supported_by: community
> INFLUXDB_RETENTION_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/database/influxdb/influxdb_retention_policy.py)

  Manage InfluxDB retention policies

Options (= is mandatory):

= database_name
        Name of the database where retention policy will be created

= default
        Sets the retention policy as default retention policy

= duration
        Determines how long InfluxDB should keep the data

= hostname
        The hostname or IP address on which InfluxDB server is listening

- password
        Password that will be used to authenticate against InfluxDB server
        [Default: root]
= policy_name
        Name of the retention policy

- port
        The port on which InfluxDB server is listening
        [Default: 8086]
= replication
        Determines how many independent copies of each point are stored in the cluster

- username
        Username that will be used to authenticate against InfluxDB server
        [Default: root]
Requirements:  python >= 2.6, influxdb >= 0.9

EXAMPLES:
# Example influxdb_retention_policy command from Ansible Playbooks
- name: create 1 hour retention policy
  influxdb_retention_policy:
      hostname: "{{influxdb_ip_address}}"
      database_name: "{{influxdb_database_name}}"
      policy_name: test
      duration: 1h
      replication: 1

- name: create 1 day retention policy
  influxdb_retention_policy:
      hostname: "{{influxdb_ip_address}}"
      database_name: "{{influxdb_database_name}}"
      policy_name: test
      duration: 1d
      replication: 1

- name: create 1 week retention policy
  influxdb_retention_policy:
      hostname: "{{influxdb_ip_address}}"
      database_name: "{{influxdb_database_name}}"
      policy_name: test
      duration: 1w
      replication: 1

- name: create infinite retention policy
  influxdb_retention_policy:
      hostname: "{{influxdb_ip_address}}"
      database_name: "{{influxdb_database_name}}"
      policy_name: test
      duration: INF
      replication: 1

RETURN VALUES:
#only defaults


MAINTAINERS: Kamil Szczygiel (@kamsz)

METADATA:
	Status: ['preview']
	Supported_by: community
> INI_FILE    (/usr/lib/python2.7/site-packages/ansible/modules/files/ini_file.py)

  Manage (add, remove, change) individual settings in an INI-style file without having to manage the file as a whole
  with, say, [template] or [assemble]. Adds missing sections if they don't exist. Before version 2.0, comments are
  discarded when the source file is read, and therefore will not show up in the destination file. Since version 2.3, this
  module adds missing ending newlines to files to keep in line with the POSIX standard, even when no other modifications
  need to be applied.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- create
        If set to 'no', the module will fail if the file does not already exist. By default it will create the file if it
        is missing.
        (Choices: yes, no)[Default: yes]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- no_extra_spaces
        Do not insert spaces before and after '=' symbol
        [Default: False]
- option
        If set (required for changing a `value'), this is the name of the option.
        May be omitted if adding/removing a whole `section'.
        [Default: None]
- others
        All arguments accepted by the [file] module also work here
        [Default: (null)]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
= path
        Path to the INI-style file; this file is created if required.
        Before 2.3 this option was only usable as `dest'.
        [Default: None]
= section
        Section name in INI file. This is added if `state=present' automatically when a single value is being set.
        If left empty or set to `null`, the `option' will be placed before the first `section'. Using `null` is also
        required if the config format does not support sections.
        [Default: None]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- state
        If set to `absent' the option or section will be removed if present instead of created.
        (Choices: present, absent)[Default: present]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- value
        The string value to be associated with an `option'. May be omitted when removing an `option'.
        [Default: None]
Notes:
  * While it is possible to add an `option' without specifying a `value', this makes no sense.
  * As of Ansible 2.3, the `dest' option has been changed to `path' as default, but `dest' still works as well.
EXAMPLES:
# Before 2.3, option 'dest' was used instead of 'path'
- name: Ensure "fav=lemonade is in section "[drinks]" in specified file
  ini_file:
    path: /etc/conf
    section: drinks
    option: fav
    value: lemonade
    mode: 0600
    backup: yes

- ini_file:
    path: /etc/anotherconf
    section: drinks
    option: temperature
    value: cold
    backup: yes


MAINTAINERS: Jan-Piet Mens (@jpmens), Ales Nosek (@noseka1)

METADATA:
	Status: ['preview']
	Supported_by: community
> IOS_BANNER    (/usr/lib/python2.7/site-packages/ansible/modules/network/ios/ios_banner.py)

  This will configure both login and motd banners on remote devices running Cisco IOS.  It allows playbooks to add or
  remote banner text from the active running configuration.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
= banner
        Specifies which banner that should be configured on the remote device.
        (Choices: login, banner)[Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- state
        Specifies whether or not the configuration is present in the current devices active running configuration.
        (Choices: present, absent)[Default: present]
- text
        The banner text that should be present in the remote device running configuration.  This argument accepts a
        multiline string. Requires `state=present'.
        [Default: None]
EXAMPLES:
- name: configure the login banner
  ios_banner:
    banner: login
    text: |
      this is my login banner
      that contains a multiline
      string
    state: present

- name: remove the motd banner
  ios_banner:
    banner: motd
    state: absent

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - banner login
    - this is my login banner
    - that contains a multiline
    - string


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: community
> IOS_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/ios/ios_command.py)

  Sends arbitrary commands to an ios node and returns the results read from the device. This module includes an argument
  that will cause the module to wait for a specific condition before returning or timing out if the condition is not met.
  This module does not support running commands in configuration mode. Please use [ios_config] to configure IOS devices.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
= commands
        List of commands to send to the remote ios device over the configured provider. The resulting output from the
        command is returned. If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of retries has expired.

- interval
        Configures the interval in seconds to wait between retries of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the wait_for must be satisfied.
        If the value is set to `any' then only one of the values must be satisfied.
        (Choices: any, all)[Default: all]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should by tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditions.
        [Default: 10]
- wait_for
        List of conditions to evaluate against the output of the command. The task will wait for each condition to be
        true before moving forward. If the conditional is not true within the configured number of retries, the task
        fails. See examples.
        [Default: None]
EXAMPLES:
tasks:
  - name: run show version on remote devices
    ios_command:
      commands: show version

  - name: run show version and check to see if output contains IOS
    ios_command:
      commands: show version
      wait_for: result[0] contains IOS

  - name: run multiple commands on remote nodes
    ios_command:
      commands:
        - show version
        - show interfaces

  - name: run multiple commands and evaluate the output
    ios_command:
      commands:
        - show version
        - show interfaces
      wait_for:
        - result[0] contains IOS
        - result[1] contains Loopback0

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']
stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]
failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/ios/ios_config.py)

  Cisco IOS configurations use a simple block indent file syntax for segmenting configuration into sections.  This module
  provides an implementation for working with IOS configuration sections in a deterministic way.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- backup
        This argument will cause the module to create a full backup of the current `running-config' from the remote
        device before any changes are made.  The backup file is written to the `backup' folder in the playbook root
        directory.  If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- config
        The `config' argument allows the playbook designer to supply the base configuration to be used to validate
        configuration changes necessary.  If this argument is provided, the module will not download the running-config
        from the remote node.
        [Default: None]
- defaults
        This argument specifies whether or not to collect all defaults when getting the remote device running config.
        When enabled, the module will get the current config by issuing the command `show running-config all'.
        (Choices: yes, no)[Default: False]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        Note this argument should be considered deprecated.  To achieve the equivalent, set the `match=none' which is
        idempotent.  This argument will be removed in a future release.
        (Choices: true, false)[Default: False]
- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  If match is set to `exact', command lines must be an equal match.  Finally, if
        match is set to `none', the module will not attempt to compare the source configuration with the running
        configuration on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- multiline_delimiter
        This argument is used when pushing a multiline configuration element to the IOS device.  It specifies the
        character to use as the delimiting character.  This only applies to the configuration action.
        [Default: @]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If the
        parents argument is omitted, the commands are checked against the set of top level or global commands.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct.
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running- config to the startup-config at the conclusion of
        the module running.  If check mode is specified, this argument is ignored.
        (Choices: yes, no)[Default: False]
- src
        Specifies the source path to the file that contains the configuration or configuration template to load.  The
        path to the source file can either be the full path on the Ansible control host or a relative path from the
        playbook or role root directory.  This argument is mutually exclusive with `lines'.
        [Default: None]
EXAMPLES:
- name: configure top level configuration
  ios_config:
    lines: hostname {{ inventory_hostname }}

- name: configure interface settings
  ios_config:
    lines:
      - description test interface
      - ip address 172.31.1.1 255.255.255.0
    parents: interface Ethernet1

- name: load new acl into device
  ios_config:
    lines:
      - 10 permit ip host 1.1.1.1 any log
      - 20 permit ip host 2.2.2.2 any log
      - 30 permit ip host 3.3.3.3 any log
      - 40 permit ip host 4.4.4.4 any log
      - 50 permit ip host 5.5.5.5 any log
    parents: ip access-list extended test
    before: no ip access-list extended test
    match: exact

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: Only when lines is specified.
  type: list
  sample: ['...', '...']
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/ios_config.2016-07-16@22:28:34


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/ios/ios_facts.py)

  Collects a base set of device facts from a remote device that is running IOS.  This module prepends all of the base
  network fact keys with `ansible_net_<fact>'.  The facts module will always collect a base set of facts from the device
  and can enable or disable collection of additional facts.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- gather_subset
        When supplied, this argument will restrict the facts collected to a given subset.  Possible values for this
        argument include all, hardware, config, and interfaces.  Can specify a list of values to include a larger subset.
        Values can also be used with an initial `[!]' to specify that a specific subset should not be collected.
        [Default: !config]
- provider
        A dict object containing connection details.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: cisco
    password: cisco
    transport: cli

---
# Collect all facts from the device
- ios_facts:
    gather_subset: all
    provider: "{{ cli }}"

# Collect only the config and default facts
- ios_facts:
    gather_subset:
      - config
    provider: "{{ cli }}"

# Do not collect hardware facts
- ios_facts:
    gather_subset:
      - "!hardware"
    provider: "{{ cli }}"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the device
  returned: always
  type: list

# default
ansible_net_model:
  description: The model name returned from the device
  returned: always
  type: str
ansible_net_serialnum:
  description: The serial number of the remote device
  returned: always
  type: str
ansible_net_version:
  description: The operating system version running on the remote device
  returned: always
  type: str
ansible_net_hostname:
  description: The configured hostname of the device
  returned: always
  type: string
ansible_net_image:
  description: The image file the device is running
  returned: always
  type: string

# hardware
ansible_net_filesystems:
  description: All file system names available on the device
  returned: when hardware is configured
  type: list
ansible_net_memfree_mb:
  description: The available free memory on the remote device in Mb
  returned: when hardware is configured
  type: int
ansible_net_memtotal_mb:
  description: The total memory on the remote device in Mb
  returned: when hardware is configured
  type: int

# config
ansible_net_config:
  description: The current active config from the device
  returned: when config is configured
  type: str

# interfaces
ansible_net_all_ipv4_addresses:
  description: All IPv4 addresses configured on the device
  returned: when interfaces is configured
  type: list
ansible_net_all_ipv6_addresses:
  description: All IPv6 addresses configured on the device
  returned: when interfaces is configured
  type: list
ansible_net_interfaces:
  description: A hash of all interfaces running on the system
  returned: when interfaces is configured
  type: dict
ansible_net_neighbors:
  description: The list of LLDP neighbors from the remote device
  returned: when interfaces is configured
  type: dict


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOS_SYSTEM    (/usr/lib/python2.7/site-packages/ansible/modules/network/ios/ios_system.py)

  This module provides declarative management of node system attributes on Cisco IOS devices.  It provides an option to
  configure host system parameters or remove those parameters from the device active configuration.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- domain_name
        Configure the IP domain name on the remote device to the provided value. Value should be in the dotted name form
        and will be appended to the `hostname' to create a fully-qualified domain name.
        [Default: (null)]
- domain_search
        Provides the list of domain suffixes to append to the hostname for the purpose of doing name resolution. This
        argument accepts a list of names and will be reconciled with the current active configuration on the running
        node.
        [Default: (null)]
- hostname
        Configure the device hostname parameter. This option takes an ASCII string value.
        [Default: (null)]
- lookup_enabled
        Administrative control for enabling or disabling DNS lookups.  When this argument is set to True, lookups are
        performed and when it is set to False, lookups are not performed.
        [Default: (null)]
- lookup_source
        Provides one or more source interfaces to use for performing DNS lookups.  The interface provided in
        `lookup_source' must be a valid interface configured on the device.
        [Default: (null)]
- name_servers
        List of DNS name servers by IP address to use to perform name resolution lookups.  This argument accepts either a
        list of DNS servers See examples.
        [Default: (null)]
- provider
        A dict object containing connection details.
        [Default: None]
- state
        State of the configuration values in the device's current active configuration.  When set to `present', the
        values should be configured in the device active configuration and when set to `absent' the values should not be
        in the device active configuration
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: configure hostname and domain name
  ios_system:
    hostname: ios01
    domain_name: test.example.com
    domain-search:
      - ansible.com
      - redhat.com
      - cisco.com

- name: remove configuration
  ios_system:
    state: absent

- name: configure DNS lookup sources
  ios_system:
    lookup_source: MgmtEth0/0/CPU0/0
    lookup_enabled: yes

- name: configure name servers
  ios_system:
    name_servers:
      - 8.8.8.8
      - 8.8.4.4

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - hostname ios01
    - ip domain name test.example.com


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOS_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/ios/_ios_template.py)

  Manages Cisco IOS network device configurations over SSH.  This module allows implementers to work with the device
  running-config.  It provides a way to push a set of commands onto a network device by evaluating the current running-
  config and only pushing configuration commands that are not already configured.  The config source can be a set of
  commands or a template.

DEPRECATED: 
Deprecated in 2.2. Use M(ios_config) instead.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- backup
        When this argument is configured true, the module will backup the running-config from the node prior to making
        any changes. The backup file will be written to backup_{{ hostname }} in the root of the playbook directory.
        (Choices: true, false)[Default: False]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task.  The `config' argument allows the implementer to pass in the
        configuration to use as the base config for comparison.
        [Default: None]
- force
        The force argument instructs the module not to consider the current device running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        (Choices: true, false)[Default: False]
= include_defaults
        The module, by default, will collect the current device running-config to use as a base for comparison to the
        commands in `src'.  Setting this value to true will cause the command issued to add any necessary flags to
        collect all defaults as well as the device configuration.  If the destination device does not support such a
        flag, this argument is silently ignored.
        (Choices: true, false)
- provider
        A dict object containing connection details.
        [Default: None]
= src
        The path to the config source.  The source can be either a file with config or a template that will be merged
        during runtime.  By default the task will first search for the source file in role or playbook root folder in
        templates unless a full path to the file is given.

EXAMPLES:
- name: push a configuration onto the device
  ios_template:
    src: config.j2

- name: forceable push a configuration onto the device
  ios_template:
    src: config.j2
    force: yes

- name: provide the base configuration for comparison
  ios_template:
    src: candidate_config.txt
    config: current_config.txt

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> IOS_VRF    (/usr/lib/python2.7/site-packages/ansible/modules/network/ios/ios_vrf.py)

  This module provides declarative management of VRF definitions on Cisco IOS devices.  It allows playbooks to manage
  individual or the entire VRF collection.  It also supports purging VRF definitions from the configuration that are not
  explicitly defined.

Options (= is mandatory):

- auth_pass
        Specifies the password to use if required to enter privileged mode on the remote device.  If `authorize' is
        false, then this argument does nothing. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_AUTH_PASS' will be used instead.
        [Default: none]
- authorize
        Instructs the module to enter privileged mode on the remote device before sending any commands.  If not
        specified, the device will attempt to execute all commands in non-privileged mode. If the value is not specified
        in the task, the value of environment variable `ANSIBLE_NET_AUTHORIZE' will be used instead.
        (Choices: yes, no)[Default: False]
- description
        Provides a short description of the VRF definition in the current active configuration.  The VRF definition value
        accepts alphanumeric characters used to provide additional information about the VRF.
        [Default: (null)]
- interfaces
        Identifies the set of interfaces that should be configured in the VRF.  Interfaces must be routed interfaces in
        order to be placed into a VRF.
        [Default: (null)]
- name
        The name of the VRF definition to be managed on the remote IOS device.  The VRF definition name is an ASCII
        string name used to uniquely identify the VRF.  This argument is mutually exclusive with the `vrfs' argument
        [Default: (null)]
- provider
        A dict object containing connection details.
        [Default: None]
- purge
        Instructs the module to consider the VRF definition absolute.  It will remove any previously configured VRFs on
        the device.
        [Default: False]
- rd
        The router-distinguisher value uniquely identifies the VRF to routing processes on the remote IOS system.  The RD
        value takes the form of `A:B' where `A' and `B' are both numeric values.
        [Default: (null)]
- state
        Configures the state of the VRF definition as it relates to the device operational configuration.  When set to
        `present', the VRF should be configured in the device active configuration and when set to `absent' the VRF
        should not be in the device active configuration
        (Choices: present, absent)[Default: present]
- vrfs
        The set of VRF definition objects to be configured on the remote IOS device.  Ths list entries can either be the
        VRF name or a hash of VRF definitions and attributes.  This argument is mutually exclusive with the `name'
        argument.
        [Default: (null)]
EXAMPLES:
- name: configure a vrf named management
  ios_vrf:
    name: management
    description: oob mgmt vrf
    interfaces:
      - Management1

- name: remove a vrf named test
  ios_vrf:
    name: test
    state: absent

- name: configure set of VRFs and purge any others
  ios_vrf:
    vrfs:
      - red
      - blue
      - green
    purge: yes

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - vrf definition ansible
    - description management vrf
    - rd: 1:100
start:
  description: The time the job started
  returned: always
  type: str
  sample: "2016-11-16 10:38:15.126146"
end:
  description: The time the job ended
  returned: always
  type: str
  sample: "2016-11-16 10:38:25.595612"
delta:
  description: The time elapsed to perform all operations
  returned: always
  type: str
  sample: "0:00:10.469466"


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOSXR_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/iosxr/iosxr_command.py)

  Sends arbitrary commands to an IOS XR node and returns the results read from the device. This module includes an
  argument that will cause the module to wait for a specific condition before returning or timing out if the condition is
  not met. This module does not support running commands in configuration mode. Please use [iosxr_config] to configure
  iosxr devices.

Options (= is mandatory):

= commands
        List of commands to send to the remote iosxr device over the configured provider. The resulting output from the
        command is returned. If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of retries has expired.

- interval
        Configures the interval in seconds to wait between retries of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the wait_for must be satisfied.
        If the value is set to `any' then only one of the values must be satisfied.
        (Choices: any, all)[Default: all]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should by tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditions.
        [Default: 10]
- wait_for
        List of conditions to evaluate against the output of the command. The task will wait for each condition to be
        true before moving forward. If the conditional is not true within the configured number of retries, the task
        fails. See examples.
        [Default: None]
EXAMPLES:
tasks:
  - name: run show version on remote devices
    iosxr_command:
      commands: show version

  - name: run show version and check to see if output contains iosxr
    iosxr_command:
      commands: show version
      wait_for: result[0] contains IOS-XR

  - name: run multiple commands on remote nodes
    iosxr_command:
      commands:
        - show version
        - show interfaces

  - name: run multiple commands and evaluate the output
    iosxr_command:
      commands:
        - show version
        - show interfaces
      wait_for:
        - result[0] contains IOS-XR
        - result[1] contains Loopback0

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']
stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]
failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOSXR_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/iosxr/iosxr_config.py)

  Cisco IOS XR configurations use a simple block indent file syntax for segmenting configuration into sections.  This
  module provides an implementation for working with IOS XR configuration sections in a deterministic way.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- backup
        This argument will cause the module to create a full backup of the current `running-config' from the remote
        device before any changes are made.  The backup file is written to the `backup' folder in the playbook root
        directory.  If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- comment
        Allows a commit description to be specified to be included when the configuration is committed.  If the
        configuration is not changed or committed, this argument is ignored.
        [Default: configured by iosxr_config]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuration to use as the base config for comparison.
        [Default: None]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        Note this argument should be considered deprecated.  To achieve the equivalent, set the `match=none' which is
        idempotent.  This argument will be removed in a future release.
        (Choices: yes, no)[Default: False]
- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  If match is set to `exact', command lines must be an equal match.  Finally, if
        match is set to `none', the module will not attempt to compare the source configuration with the running
        configuration on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If the
        parents argument is omitted, the commands are checked against the set of top level or global commands.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct.
        (Choices: line, block, config)[Default: line]
- src
        Specifies the source path to the file that contains the configuration or configuration template to load.  The
        path to the source file can either be the full path on the Ansible control host or a relative path from the
        playbook or role root directory.  This argument is mutually exclusive with `lines'.
        [Default: None]
EXAMPLES:
- name: configure top level configuration
  iosxr_config:
    lines: hostname {{ inventory_hostname }}

- name: configure interface settings
  iosxr_config:
    lines:
      - description test interface
      - ip address 172.31.1.1 255.255.255.0
    parents: interface GigabitEthernet0/0/0/0

- name: load a config from disk and replace the current config
  iosxr_config:
    src: config.cfg
    backup: yes

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: Only when lines is specified.
  type: list
  sample: ['...', '...']
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/iosxr01.2016-07-16@22:28:34


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOSXR_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/iosxr/iosxr_facts.py)

  Collects a base set of device facts from a remote device that is running IOS XR.  This module prepends all of the base
  network fact keys with `ansible_net_<fact>'.  The facts module will always collect a base set of facts from the device
  and can enable or disable collection of additional facts.

Options (= is mandatory):

- gather_subset
        When supplied, this argument will restrict the facts collected to a given subset.  Possible values for this
        argument include all, hardware, config, and interfaces.  Can specify a list of values to include a larger subset.
        Values can also be used with an initial `[!]' to specify that a specific subset should not be collected.
        [Default: !config]
- provider
        A dict object containing connection details.
        [Default: None]
EXAMPLES:
# Collect all facts from the device
- iosxr_facts:
    gather_subset: all

# Collect only the config and default facts
- iosxr_facts:
    gather_subset:
      - config

# Do not collect hardware facts
- iosxr_facts:
    gather_subset:
      - "!hardware"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the device
  returned: always
  type: list

# default
ansible_net_version:
  description: The operating system version running on the remote device
  returned: always
  type: str
ansible_net_hostname:
  description: The configured hostname of the device
  returned: always
  type: string
ansible_net_image:
  description: The image file the device is running
  returned: always
  type: string

# hardware
ansible_net_filesystems:
  description: All file system names available on the device
  returned: when hardware is configured
  type: list
ansible_net_memfree_mb:
  description: The available free memory on the remote device in Mb
  returned: when hardware is configured
  type: int
ansible_net_memtotal_mb:
  description: The total memory on the remote device in Mb
  returned: when hardware is configured
  type: int

# config
ansible_net_config:
  description: The current active config from the device
  returned: when config is configured
  type: str

# interfaces
ansible_net_all_ipv4_addresses:
  description: All IPv4 addresses configured on the device
  returned: when interfaces is configured
  type: list
ansible_net_all_ipv6_addresses:
  description: All IPv6 addresses configured on the device
  returned: when interfaces is configured
  type: list
ansible_net_interfaces:
  description: A hash of all interfaces running on the system
  returned: when interfaces is configured
  type: dict
ansible_net_neighbors:
  description: The list of LLDP neighbors from the remote device
  returned: when interfaces is configured
  type: dict


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOSXR_SYSTEM    (/usr/lib/python2.7/site-packages/ansible/modules/network/iosxr/iosxr_system.py)

  This module provides declarative management of node system attributes on Cisco IOS XR devices.  It provides an option
  to configure host system parameters or remove those parameters from the device active configuration.

Options (= is mandatory):

- domain_name
        Configure the IP domain name on the remote device to the provided value. Value should be in the dotted name form
        and will be appended to the `hostname' to create a fully-qualified domain name.
        [Default: (null)]
- domain_search
        Provides the list of domain suffixes to append to the hostname for the purpose of doing name resolution. This
        argument accepts a list of names and will be reconciled with the current active configuration on the running
        node.
        [Default: (null)]
- hostname
        Configure the device hostname parameter. This option takes an ASCII string value.
        [Default: (null)]
- lookup_enabled
        Provides administrative control for enabling or disabling DNS lookups.  When this argument is set to True,
        lookups are performed and when it is set to False, lookups are not performed.
        [Default: (null)]
- lookup_source
        The `lookup_source' argument provides one or more source interfaces to use for performing DNS lookups.  The
        interface provided in `lookup_source' must be a valid interface configured on the device.
        [Default: (null)]
- name_servers
        The `name_serves' argument accepts a list of DNS name servers by way of either FQDN or IP address to use to
        perform name resolution lookups.  This argument accepts wither a list of DNS servers See examples.
        [Default: (null)]
- provider
        A dict object containing connection details.
        [Default: None]
- state
        State of the configuration values in the device's current active configuration.  When set to `present', the
        values should be configured in the device active configuration and when set to `absent' the values should not be
        in the device active configuration
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: configure hostname and domain-name
  iosxr_system:
    hostname: iosxr01
    domain_name: test.example.com
    domain-search:
      - ansible.com
      - redhat.com
      - cisco.com
- name: remove configuration
  iosxr_system:
    state: absent
- name: configure DNS lookup sources
  iosxr_system:
    lookup_source: MgmtEth0/0/CPU0/0
    lookup_enabled: yes
- name: configure name servers
  iosxr_system:
    name_servers:
      - 8.8.8.8
      - 8.8.4.4

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - hostname iosxr01
    - ip domain-name test.example.com


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> IOSXR_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/iosxr/_iosxr_template.py)

  Manages network device configurations over SSH.  This module allows implementers to work with the device running-
  config.  It provides a way to push a set of commands onto a network device by evaluating the current running-config and
  only pushing configuration commands that are not already configured.  The config source can be a set of commands or a
  template.

DEPRECATED: 
Deprecated in 2.2. Use M(iosxr_config) instead.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- backup
        When this argument is configured true, the module will backup the running-config from the node prior to making
        any changes. The backup file will be written to backup_{{ hostname }} in the root of the playbook directory.
        (Choices: true, false)[Default: False]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task.  The `config' argument allows the implementer to pass in the
        configuration to use as the base config for comparison.
        [Default: None]
- force
        The force argument instructs the module not to consider the current device running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        (Choices: true, false)[Default: False]
- provider
        A dict object containing connection details.
        [Default: None]
- src
        The path to the config source.  The source can be either a file with config or a template that will be merged
        during runtime.  By default the task will first search for the source file in role or playbook root folder in
        templates unless a full path to the file is given.
        [Default: None]
EXAMPLES:

- name: push a configuration onto the device
  iosxr_template:
    src: config.j2

- name: forceable push a configuration onto the device
  iosxr_template:
    src: config.j2
    force: yes

- name: provide the base configuration for comparison
  iosxr_template:
    src: candidate_config.txt
    config: current_config.txt

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['...', '...']


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> IPA_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_group.py)

  Add, modify and delete group within IPA server

Options (= is mandatory):

= cn
        Canonical name.
        Can not be changed as it is the unique identifier.

- external
        Allow adding external non-IPA members from trusted domains.
        [Default: (null)]
- gidnumber
        GID (use this option to set it manually).
        [Default: (null)]
- group
        List of group names assigned to this group.
        If an empty list is passed all groups will be removed from this group.
        If option is omitted assigned groups will not be checked or changed.
        Groups that are already assigned but not passed will be removed.
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- nonposix
        Create as a non-POSIX group.
        [Default: (null)]
- state
        State to ensure
        (Choices: present, absent)[Default: present]
- user
        List of user names assigned to this group.
        If an empty list is passed all users will be removed from this group.
        If option is omitted assigned users will not be checked or changed.
        Users that are already assigned but not passed will be removed.
        [Default: (null)]
- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
EXAMPLES:
# Ensure group is present
- ipa_group:
    name: oinstall
    gidnumber: 54321
    state: present
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure that groups sysops and appops are assigned to ops but no other group
- ipa_group:
    name: ops
    group:
    - sysops
    - appops
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure that users linus and larry are assign to the group, but no other user
- ipa_group:
    name: sysops
    user:
    - linus
    - larry
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure group is absent
- ipa_group:
    name: sysops
    state: absent
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
group:
  description: Group as returned by IPA API
  returned: always
  type: dict


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPA_HBACRULE    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_hbacrule.py)

  Add, modify or delete an IPA HBAC rule using IPA API.

Options (= is mandatory):

= cn
        Canonical name.
        Can not be changed as it is the unique identifier.

- description
        Description
        [Default: (null)]
- host
        List of host names to assign.
        If an empty list is passed all hosts will be removed from the rule.
        If option is omitted hosts will not be checked or changed.
        [Default: (null)]
- hostcategory
        Host category
        (Choices: all)[Default: (null)]
- hostgroup
        List of hostgroup names to assign.
        If an empty list is passed all hostgroups will be removed. from the rule
        If option is omitted hostgroups will not be checked or changed.
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- service
        List of service names to assign.
        If an empty list is passed all services will be removed from the rule.
        If option is omitted services will not be checked or changed.
        [Default: (null)]
- servicecategory
        Service category
        (Choices: all)[Default: (null)]
- servicegroup
        List of service group names to assign.
        If an empty list is passed all assigned service groups will be removed from the rule.
        If option is omitted service groups will not be checked or changed.
        [Default: (null)]
- sourcehost
        List of source host names to assign.
        If an empty list if passed all assigned source hosts will be removed from the rule.
        If option is omitted source hosts will not be checked or changed.
        [Default: (null)]
- sourcehostcategory
        Source host category
        (Choices: all)[Default: (null)]
- sourcehostgroup
        List of source host group names to assign.
        If an empty list if passed all assigned source host groups will be removed from the rule.
        If option is omitted source host groups will not be checked or changed.
        [Default: (null)]
- state
        State to ensure
        (Choices: present, absent, enabled, disabled)[Default: present]
- user
        List of user names to assign.
        If an empty list if passed all assigned users will be removed from the rule.
        If option is omitted users will not be checked or changed.
        [Default: (null)]
- usercategory
        User category
        (Choices: all)[Default: (null)]
- usergroup
        List of user group names to assign.
        If an empty list if passed all assigned user groups will be removed from the rule.
        If option is omitted user groups will not be checked or changed.
        [Default: (null)]
- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
EXAMPLES:
# Ensure rule to allow all users to access any host from any host
- ipa_hbacrule:
    name: allow_all
    description: Allow all users to access any host from any host
    hostcategory: all
    servicecategory: all
    usercategory: all
    state: present
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure rule with certain limitations
- ipa_hbacrule:
    name: allow_all_developers_access_to_db
    description: Allow all developers to access any database from any host
    hostgroup:
    - db-server
    usergroup:
    - developers
    state: present
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure rule is absent
- ipa_hbacrule:
    name: rule_to_be_deleted
    state: absent
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
hbacrule:
  description: HBAC rule as returned by IPA API.
  returned: always
  type: dict


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPA_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_host.py)

  Add, modify and delete an IPA host using IPA API

Options (= is mandatory):

- description
        A description of this host.
        [Default: (null)]
- force
        Force host name even if not in DNS.
        [Default: (null)]
= fqdn
        Full qualified domain name.
        Can not be changed as it is the unique identifier.

- ip_address
        Add the host to DNS with this IP address.
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- mac_address
        List of Hardware MAC address(es) off this host.
        If option is omitted MAC addresses will not be checked or changed.
        If an empty list is passed all assigned MAC addresses will be removed.
        MAC addresses that are already assigned but not passed will be removed.
        [Default: (null)]
- ns_hardware_platform
        Host hardware platform (e.g. "Lenovo T61")
        [Default: (null)]
- ns_host_location
        Host location (e.g. "Lab 2")
        [Default: (null)]
- ns_os_version
        Host operating system and version (e.g. "Fedora 9")
        [Default: (null)]
- state
        State to ensure
        (Choices: present, absent, disabled)[Default: present]
- user_certificate
        List of Base-64 encoded server certificates.
        If option is omitted certificates will not be checked or changed.
        If an emtpy list is passed all assigned certificates will be removed.
        Certificates already assigned but not passed will be removed.
        [Default: (null)]
- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
EXAMPLES:
# Ensure host is present
- ipa_host:
    name: host01.example.com
    description: Example host
    ip_address: 192.168.0.123
    ns_host_location: Lab
    ns_os_version: CentOS 7
    ns_hardware_platform: Lenovo T61
    mac_address:
    - "08:00:27:E3:B1:2D"
    - "52:54:00:BD:97:1E"
    state: present
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure host is disabled
- ipa_host:
    name: host01.example.com
    state: disabled
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure that all user certificates are removed
- ipa_host:
    name: host01.example.com
    user_certificate: []
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure host is absent
- ipa_host:
    name: host01.example.com
    state: absent
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
host:
  description: Host as returned by IPA API.
  returned: always
  type: dict
host_diff:
  description: List of options that differ and would be changed
  returned: if check mode and a difference is found
  type: list


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPA_HOSTGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_hostgroup.py)

  Add, modify and delete an IPA host-group using IPA API

Options (= is mandatory):

= cn
        Name of host-group.
        Can not be changed as it is the unique identifier.

- description
        Description
        [Default: (null)]
- host
        List of hosts that belong to the host-group.
        If an empty list is passed all hosts will be removed from the group.
        If option is omitted hosts will not be checked or changed.
        If option is passed all assigned hosts that are not passed will be unassigned from the group.
        [Default: (null)]
- hostgroup
        List of host-groups than belong to that host-group.
        If an empty list is passed all host-groups will be removed from the group.
        If option is omitted host-groups will not be checked or changed.
        If option is passed all assigned hostgroups that are not passed will be unassigned from the group.
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- state
        State to ensure.
        (Choices: present, absent)[Default: present]
- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
EXAMPLES:
# Ensure host-group databases is present
- ipa_hostgroup:
    name: databases
    state: present
    host:
    - db.example.com
    hostgroup:
    - mysql-server
    - oracle-server
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure host-group databases is absent
- ipa_hostgroup:
    name: databases
    state: absent
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
hostgroup:
  description: Hostgroup as returned by IPA API.
  returned: always
  type: dict


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPA_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_role.py)

  Add, modify and delete a role within FreeIPA server using FreeIPA API

Options (= is mandatory):

= cn
        Role name.
        Can not be changed as it is the unique identifier.

- description
        A description of this role-group.
        [Default: (null)]
- group
        List of group names assign to this role.
        If an empty list is passed all assigned groups will be unassigned from the role.
        If option is omitted groups will not be checked or changed.
        If option is passed all assigned groups that are not passed will be unassigned from the role.
        [Default: (null)]
- host
        List of host names to assign.
        If an empty list is passed all assigned hosts will be unassigned from the role.
        If option is omitted hosts will not be checked or changed.
        If option is passed all assigned hosts that are not passed will be unassigned from the role.
        [Default: (null)]
- hostgroup
        List of host group names to assign.
        If an empty list is passed all assigned host groups will be removed from the role.
        If option is omitted host groups will not be checked or changed.
        If option is passed all assigned hostgroups that are not passed will be unassigned from the role.
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- service
        List of service names to assign.
        If an empty list is passed all assigned services will be removed from the role.
        If option is omitted services will not be checked or changed.
        If option is passed all assigned services that are not passed will be removed from the role.
        [Default: (null)]
- state
        State to ensure
        (Choices: present, absent)[Default: present]
- user
        List of user names to assign.
        If an empty list is passed all assigned users will be removed from the role.
        If option is omitted users will not be checked or changed.
        [Default: (null)]
- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
EXAMPLES:
# Ensure role is present
- ipa_role:
    name: dba
    description: Database Administrators
    state: present
    user:
    - pinky
    - brain
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure role with certain details
- ipa_role:
    name: another-role
    description: Just another role
    group:
    - editors
    host:
    - host01.example.com
    hostgroup:
    - hostgroup01
    service:
    - service01

# Ensure role is absent
- ipa_role:
    name: dba
    state: absent
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
role:
  description: Role as returned by IPA API.
  returned: always
  type: dict


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPA_SUDOCMD    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_sudocmd.py)

  Add, modify or delete sudo command within FreeIPA server using FreeIPA API.

Options (= is mandatory):

- description
        A description of this command.
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- state
        State to ensure
        (Choices: present, absent)[Default: present]
= sudocmd
        Sudo Command.

- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
EXAMPLES:
# Ensure sudo command exists
- ipa_sudocmd:
    name: su
    description: Allow to run su via sudo
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure sudo command does not exist
- ipa_sudocmd:
    name: su
    state: absent
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
sudocmd:
  description: Sudo command as return from IPA API
  returned: always
  type: dict


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPA_SUDOCMDGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_sudocmdgroup.py)

  Add, modify or delete sudo command group within IPA server using IPA API.

Options (= is mandatory):

= cn
        Sudo Command Group.

- description
        Group description.
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- state
        State to ensure
        (Choices: present, absent)[Default: present]
- sudocmd
        List of sudo commands to assign to the group.
        If an empty list is passed all assigned commands will be removed from the group.
        If option is omitted sudo commands will not be checked or changed.
        [Default: (null)]
- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
EXAMPLES:
- name: Ensure sudo command group exists
  ipa_sudocmdgroup:
    name: group01
    description: Group of important commands
    sudocmd:
    - su
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

- name: Ensure sudo command group does not exists
  ipa_sudocmdgroup:
    name: group01
    state: absent
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
sudocmdgroup:
  description: Sudo command group as returned by IPA API
  returned: always
  type: dict


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPA_SUDORULE    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_sudorule.py)

  Add, modify or delete sudo rule within IPA server using IPA API.

Options (= is mandatory):

- cmd
        List of commands assigned to the rule.
        If an empty list is passed all commands will be removed from the rule.
        If option is omitted commands will not be checked or changed.
        [Default: (null)]
- cmdcategory
        Command category the rule applies to.
        (Choices: all)[Default: (null)]
= cn
        Canonical name.
        Can not be changed as it is the unique identifier.

- host
        List of hosts assigned to the rule.
        If an empty list is passed all hosts will be removed from the rule.
        If option is omitted hosts will not be checked or changed.
        Option `hostcategory' must be omitted to assign hosts.
        [Default: (null)]
- hostcategory
        Host category the rule applies to.
        If 'all' is passed one must omit `host' and `hostgroup'.
        Option `host' and `hostgroup' must be omitted to assign 'all'.
        (Choices: all)[Default: (null)]
- hostgroup
        List of host groups assigned to the rule.
        If an empty list is passed all host groups will be removed from the rule.
        If option is omitted host groups will not be checked or changed.
        Option `hostcategory' must be omitted to assign host groups.
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- state
        State to ensure
        (Choices: present, absent, enabled, disabled)[Default: present]
- user
        List of users assigned to the rule.
        If an empty list is passed all users will be removed from the rule.
        If option is omitted users will not be checked or changed.
        [Default: (null)]
- usercategory
        User category the rule applies to.
        (Choices: all)[Default: (null)]
- usergroup
        List of user groups assigned to the rule.
        If an empty list is passed all user groups will be removed from the rule.
        If option is omitted user groups will not be checked or changed.
        [Default: (null)]
- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
EXAMPLES:
# Ensure sudo rule is present thats allows all every body to execute any command on any host without beeing asked for a password.
- ipa_sudorule:
    name: sudo_all_nopasswd
    cmdcategory: all
    description: Allow to run every command with sudo without password
    hostcategory: all
    sudoopt:
    - '!authenticate'
    usercategory: all
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret
# Ensure user group developers can run every command on host group db-server as well as on host db01.example.com.
- ipa_sudorule:
    name: sudo_dev_dbserver
    description: Allow developers to run every command with sudo on all database server
    cmdcategory: all
    host:
    - db01.example.com
    hostgroup:
    - db-server
    sudoopt:
    - '!authenticate'
    usergroup:
    - developers
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
sudorule:
  description: Sudorule as returned by IPA
  returned: always
  type: dict


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPA_USER    (/usr/lib/python2.7/site-packages/ansible/modules/identity/ipa/ipa_user.py)

  Add, modify and delete user within IPA server

Options (= is mandatory):

- displayname
        Display name
        [Default: (null)]
- givenname
        First name
        [Default: (null)]
- ipa_host
        IP or hostname of IPA server
        [Default: ipa.example.com]
= ipa_pass
        Password of administrative user

- ipa_port
        Port of IPA server
        [Default: 443]
- ipa_prot
        Protocol used by IPA server
        (Choices: http, https)[Default: https]
- ipa_user
        Administrative account used on IPA server
        [Default: admin]
- loginshell
        Login shell
        [Default: (null)]
- mail
        List of mail addresses assigned to the user.
        If an empty list is passed all assigned email addresses will be deleted.
        If None is passed email addresses will not be checked or changed.
        [Default: (null)]
- password
        Password
        [Default: (null)]
- sn
        Surname
        [Default: (null)]
- sshpubkey
        List of public SSH key.
        If an empty list is passed all assigned public keys will be deleted.
        If None is passed SSH public keys will not be checked or changed.
        [Default: (null)]
- state
        State to ensure
        (Choices: present, absent, enabled, disabled)[Default: present]
- telephonenumber
        List of telephone numbers assigned to the user.
        If an empty list is passed all assigned telephone numbers will be deleted.
        If None is passed telephone numbers will not be checked or changed.
        [Default: (null)]
- title
        Title
        [Default: (null)]
= uid
        uid of the user

- validate_certs
        This only applies if `ipa_prot' is `https'.
        If set to `no', the SSL certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates.
        [Default: True]
Requirements:  base64, hashlib

EXAMPLES:
# Ensure pinky is present
- ipa_user:
    name: pinky
    state: present
    givenname: Pinky
    sn: Acme
    mail:
    - pinky@acme.com
    telephonenumber:
    - '+555123456'
    sshpubkeyfp:
    - ssh-rsa ....
    - ssh-dsa ....
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

# Ensure brain is absent
- ipa_user:
    name: brain
    state: absent
    ipa_host: ipa.example.com
    ipa_user: admin
    ipa_pass: topsecret

RETURN VALUES:
user:
  description: User as returned by IPA API
  returned: always
  type: dict


MAINTAINERS: Thomas Krahn (@Nosmoht)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPADM_ADDR    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/ipadm_addr.py)

  Create/delete static/dynamic IP addresses on network interfaces on Solaris/illumos systems. Up/down static/dynamic IP
  addresses on network interfaces on Solaris/illumos systems. Manage IPv6 link-local addresses on network interfaces on
  Solaris/illumos systems.

Options (= is mandatory):

- address
        Specifiies an IP address to configure in CIDR notation.
        [Default: (null)]
= addrobj
        Specifies an unique IP address on the system.

- addrtype
        Specifiies a type of IP address to configure.
        (Choices: static, dhcp, addrconf)[Default: static]
- state
        Create/delete/enable/disable an IP address on the network interface.
        (Choices: absent, present, up, down, enabled, disabled, refreshed)[Default: present]
- temporary
        Specifies that the configured IP address is temporary. Temporary IP addresses do not persist across reboots.
        [Default: False]
- wait
        Specifies the time in seconds we wait for obtaining address via DHCP.
        [Default: 60]
EXAMPLES:
name: Configure IP address 10.0.0.1 on e1000g0
ipadm_addr: addr=10.0.0.1/32 addrobj=e1000g0/v4 state=present

name: Delete addrobj
ipadm_addr: addrobj=e1000g0/v4 state=absent

name: Configure link-local IPv6 address
ipadm_addr: addtype=addrconf addrobj=vnic0/v6

name: Configure address via DHCP and wait 180 seconds for address obtaining
ipadm_addr: addrobj=vnic0/dhcp addrtype=dhcp wait=180

RETURN VALUES:
addrobj:
    description: address object name
    returned: always
    type: string
    sample: bge0/v4
state:
    description: state of the target
    returned: always
    type: string
    sample: present
temporary:
    description: specifies if operation will persist across reboots
    returned: always
    type: boolean
    sample: True
addrtype:
    description: address type
    returned: always
    type: string
    sample: static
address:
    description: IP address
    returned: only if addrtype is 'static'
    type: string
    sample: 1.3.3.7/32
wait:
    description: time we wait for DHCP
    returned: only if addrtype is 'dhcp'
    type: string
    sample: 10


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPADM_ADDRPROP    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/ipadm_addrprop.py)

  Modify IP address properties on Solaris/illumos systems.

Options (= is mandatory):

= addrobj
        Specifies the address object we want to manage.

= property
        Specifies the name of the address property we want to manage.

- state
        Set or reset the property value.
        (Choices: present, absent, reset)[Default: present]
- temporary
        Specifies that the address property value is temporary. Temporary values do not persist across reboots.
        [Default: False]
- value
        Specifies the value we want to set for the address property.
        [Default: (null)]
EXAMPLES:
name: Mark address on addrobj as deprecated
ipadm_addrprop: property=deprecated value=on addrobj=e1000g0/v6

name: Set network prefix length for addrobj
ipadm_addrprop: addrobj=bge0/v4 name=prefixlen value=26

RETURN VALUES:
property:
    description: property name
    returned: always
    type: string
    sample: deprecated
addrobj:
    description: address object name
    returned: always
    type: string
    sample: bge0/v4
state:
    description: state of the target
    returned: always
    type: string
    sample: present
temporary:
    description: specifies if operation will persist across reboots
    returned: always
    type: boolean
    sample: True
value:
    description: property value
    returned: when value is provided
    type: string
    sample: 26


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPADM_IF    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/ipadm_if.py)

  Create, delete, enable or disable IP interfaces on Solaris/illumos systems.

Options (= is mandatory):

= name
        IP interface name.

- state
        Create or delete Solaris/illumos IP interfaces.
        (Choices: present, absent, enabled, disabled)[Default: present]
- temporary
        Specifies that the IP interface is temporary. Temporary IP interfaces do not persist across reboots.
        (Choices: true, false)[Default: False]
EXAMPLES:
# Create vnic0 interface
- ipadm_if:
    name: vnic0
    state: enabled

# Disable vnic0 interface
- ipadm_if:
    name: vnic0
    state: disabled

RETURN VALUES:
name:
    description: IP interface name
    returned: always
    type: string
    sample: "vnic0"
state:
    description: state of the target
    returned: always
    type: string
    sample: "present"
temporary:
    description: persistence of a IP interface
    returned: always
    type: boolean
    sample: "True"


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPADM_IFPROP    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/ipadm_ifprop.py)

  Modify IP interface properties on Solaris/illumos systems.

Options (= is mandatory):

= interface
        Specifies the IP interface we want to manage.

= property
        Specifies the name of the property we want to manage.

= protocol
        Specifies the procotol for which we want to manage properties.

- state
        Set or reset the property value.
        (Choices: present, absent, reset)[Default: present]
- temporary
        Specifies that the property value is temporary. Temporary property values do not persist across reboots.
        [Default: False]
- value
        Specifies the value we want to set for the property.
        [Default: (null)]
EXAMPLES:
name: Allow forwarding of IPv4 packets on network interface e1000g0
ipadm_ifprop: protocol=ipv4 property=forwarding value=on interface=e1000g0

name: Temporarily reset IPv4 forwarding property on network interface e1000g0
ipadm_ifprop: protocol=ipv4 interface=e1000g0  temporary=true property=forwarding state=reset

name: Configure IPv6 metric on network interface e1000g0
ipadm_ifprop: protocol=ipv6 nic=e1000g0 name=metric value=100

name: Set IPv6 MTU on network interface bge0
ipadm_ifprop: interface=bge0 name=mtu value=1280 protocol=ipv6

RETURN VALUES:
protocol:
    description: property's protocol
    returned: always
    type: str
    sample: ipv4
property:
    description: property's name
    returned: always
    type: str
    sample: mtu
interface:
    description: interface name we want to set property on
    returned: always
    type: str
    sample: e1000g0
state:
    description: state of the target
    returned: always
    type: string
    sample: present
value:
    description: property's value
    returned: when value is provided
    type: str
    sample: 1280


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPADM_PROP    (/usr/lib/python2.7/site-packages/ansible/modules/network/illumos/ipadm_prop.py)

  Modify protocol properties on Solaris/illumos systems.

Options (= is mandatory):

= property
        Specifies the name of property we want to manage.

= protocol
        Specifies the procotol for which we want to manage properties.

- state
        Set or reset the property value.
        (Choices: present, absent, reset)[Default: present]
- temporary
        Specifies that the property value is temporary. Temporary property values do not persist across reboots.
        (Choices: true, false)[Default: False]
- value
        Specifies the value we want to set for the property.
        [Default: (null)]
EXAMPLES:
# Set TCP receive buffer size
ipadm_prop: protocol=tcp property=recv_buf value=65536

# Reset UDP send buffer size to the default value
ipadm_prop: protocol=udp property=send_buf state=reset

RETURN VALUES:
protocol:
    description: property's protocol
    returned: always
    type: string
    sample: "TCP"
property:
    description: name of the property
    returned: always
    type: string
    sample: "recv_maxbuf"
state:
    description: state of the target
    returned: always
    type: string
    sample: "present"
temporary:
    description: property's persistence
    returned: always
    type: boolean
    sample: "True"
value:
    description: value of the property
    returned: always
    type: int/string (depends on property)
    sample: "'1024' or 'never'"


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPIFY_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/ipify_facts.py)

  If behind NAT and need to know the public IP of your internet gateway.

Options (= is mandatory):

- api_url
        URL of the ipify.org API service.
        `?format=json' will be appended per default.
        [Default: https://api.ipify.org]
- timeout
        HTTP connection timeout in seconds.
        [Default: 10]
Notes:
  * Visit https://www.ipify.org to get more information.
EXAMPLES:
# Gather IP facts from ipify.org
- name: get my public IP
  ipify_facts:

# Gather IP facts from your own ipify service endpoint with a custom timeout
- name: get my public IP
  ipify_facts:
    api_url: http://api.example.com/ipify
    timeout: 20

RETURN VALUES:
---
ipify_public_ip:
  description: Public IP of the internet gateway.
  returned: success
  type: string
  sample: 1.2.3.4


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPINFOIO_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/ipinfoio_facts.py)

  Gather IP geolocation facts of a host's IP address using ipinfo.io API

Options (= is mandatory):

- http_agent
        Set http user agent
        [Default: ansible-ipinfoio-module/0.0.1]
- timeout
        HTTP connection timeout in seconds
        [Default: 10]
Notes:
  * Check http://ipinfo.io/ for more information
EXAMPLES:
# Retrieve geolocation data of a host's IP address
- name: get IP geolocation data
  ipinfoio_facts:

RETURN VALUES:
ansible_facts:
  description: "Dictionary of ip geolocation facts for a host's IP address"
  returned: changed
  type: complex
  contains:
    ip:
      description: "Public IP address of a host"
      type: string
      sample: "8.8.8.8"
    hostname:
      description: Domain name
      type: string
      sample: "google-public-dns-a.google.com"
    country:
      description: ISO 3166-1 alpha-2 country code
      type: string
      sample: "US"
    region:
      description: State or province name
      type: string
      sample: "California"
    city:
      description: City name
      type: string
      sample: "Mountain View"
    loc:
      description: Latitude and Longitude of the location
      type: string
      sample: "37.3860,-122.0838"
    org:
      description: "organization's name"
      type: string
      sample: "AS3356 Level 3 Communications, Inc."
    postal:
      description: Postal code
      type: string
      sample: "94035"


MAINTAINERS: Aleksei Kostiuk (@akostyuk)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPMI_BOOT    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/ipmi/ipmi_boot.py)

  Use this module to manage order of boot devices

Options (= is mandatory):

= bootdev
        Set boot device to use on next reboot
        (Choices: network -- Request network boot, hd -- Boot from hard drive, safe -- Boot from hard drive, requesting
        'safe mode', optical -- boot from CD/DVD/BD drive, setup -- Boot into setup utility, default -- remove any IPMI
        directed boot device request)
= name
        Hostname or ip address of the BMC.

= password
        Password to connect to the BMC.
        [Default: None]
- persistent
        If set, ask that system firmware uses this device beyond next boot. Be aware many systems do not honor this.
        [Default: False]
- port
        Remote RMCP port.
        [Default: 623]
- state
        Whether to ensure that boot devices is desired.
        (Choices: present -- Request system turn on, absent -- Request system turn on)[Default: present]
- uefiboot
        If set, request UEFI boot explicitly. Strictly speaking, the spec suggests that if not set, the system should
        BIOS boot and offers no "don't care" option. In practice, this flag not being set does not preclude UEFI boot on
        any system I've encountered.
        [Default: False]
= user
        Username to use to connect to the BMC.

Requirements:  python >= 2.6, pyghmi

EXAMPLES:
# Ensure bootdevice is HD.
- ipmi_boot:
    name: test.testdomain.com
    user: admin
    password: password
    bootdev: hd

# Ensure bootdevice is not Network
- ipmi_boot:
    name: test.testdomain.com
    user: admin
    password: password
    bootdev: network
    state: absent

RETURN VALUES:
bootdev:
    description: The boot device name which will be used beyond next boot.
    returned: success
    type: string
    sample: default
persistent:
    description: If True, system firmware will use this device beyond next boot.
    returned: success
    type: bool
    sample: false
uefimode:
    description: If True, system firmware will use UEFI boot explicitly beyond next boot.
    returned: success
    type: bool
    sample: false


MAINTAINERS: Bulat Gaifullin (gaifullinbf@gmail.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPMI_POWER    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/ipmi/ipmi_power.py)

  Use this module for power management

Options (= is mandatory):

= name
        Hostname or ip address of the BMC.

= password
        Password to connect to the BMC.
        [Default: None]
- port
        Remote RMCP port.
        [Default: 623]
= state
        Whether to ensure that the machine in desired state.
        (Choices: on -- Request system turn on, off -- Request system turn off without waiting for OS to shutdown,
        shutdown -- Have system request OS proper shutdown, reset -- Request system reset without waiting for OS, boot --
        If system is off, then 'on', else 'reset')
- timeout
        Maximum number of seconds before interrupt request.
        [Default: 300]
= user
        Username to use to connect to the BMC.

Requirements:  python >= 2.6, pyghmi

EXAMPLES:
# Ensure machine is powered on.
- ipmi_power:
    name: test.testdomain.com
    user: admin
    password: password
    state: on

RETURN VALUES:
powerstate:
    description: The current power state of the machine.
    returned: success
    type: string
    sample: on


MAINTAINERS: Bulat Gaifullin (gaifullinbf@gmail.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> IPTABLES    (/usr/lib/python2.7/site-packages/ansible/modules/system/iptables.py)

  Iptables is used to set up, maintain, and inspect the tables of IP packet filter rules in the Linux kernel. This module
  does not handle the saving and/or loading of rules, but rather only manipulates the current rules that are present in
  memory. This is the same as the behaviour of the "iptables" and "ip6tables" command which this module uses internally.

Options (= is mandatory):

- action
        Whether the rule should be appended at the bottom or inserted at the top. If the rule already exists the chain
        won't be modified.
        (Choices: append, insert)[Default: append]
- chain
        Chain to operate on. This option can either be the name of a user defined chain or any of the builtin chains:
        'INPUT', 'FORWARD', 'OUTPUT', 'PREROUTING', 'POSTROUTING', 'SECMARK', 'CONNSECMARK'.
        [Default: (null)]
- comment
        This specifies a comment that will be added to the rule
        [Default: None]
- ctstate
        ctstate is a list of the connection states to match in the conntrack module. Possible states are: 'INVALID',
        'NEW', 'ESTABLISHED', 'RELATED', 'UNTRACKED', 'SNAT', 'DNAT'
        [Default: []]
- destination
        Destination specification. Address can be either a network name, a hostname, a network IP address (with /mask),
        or a plain IP address. Hostnames will be resolved once only, before the rule is submitted to the kernel. Please
        note that specifying any name to be resolved with a remote query such as DNS is a really bad idea. The mask can
        be either a network mask or a plain number, specifying the number of 1's at the left side of the network mask.
        Thus, a mask of 24 is equivalent to 255.255.255.0. A "!" argument before the address specification inverts the
        sense of the address.
        [Default: None]
- destination_port
        Destination port or port range specification. This can either be a service name or a port number. An inclusive
        range can also be specified, using the format first:last. If the first port is omitted, '0' is assumed; if the
        last is omitted, '65535' is assumed. If the first port is greater than the second one they will be swapped.
        [Default: None]
- flush
        Flushes the specified table and chain of all rules. If no chain is specified then the entire table is purged.
        Ignores all other parameters.
        [Default: (null)]
- fragment
        This means that the rule only refers to second and further fragments of fragmented packets. Since there is no way
        to tell the source or destination ports of such a packet (or ICMP type), such a packet will not match any rules
        which specify them. When the "!" argument precedes fragment argument, the rule will only match head fragments, or
        unfragmented packets.
        [Default: None]
- goto
        This specifies that the processing should continue in a user specified chain. Unlike the jump argument return
        will not continue processing in this chain but instead in the chain that called us via jump.
        [Default: None]
- icmp_type
        This allows specification of the ICMP type, which can be a numeric ICMP type, type/code pair, or one of the ICMP
        type names shown by the command 'iptables -p icmp -h'
        [Default: (null)]
- in_interface
        Name of an interface via which a packet was received (only for packets entering the INPUT, FORWARD and PREROUTING
        chains). When the "!" argument is used before the interface name, the sense is inverted. If the interface name
        ends in a "+", then any interface which begins with this name will match. If this option is omitted, any
        interface name will match.
        [Default: None]
- ip_version
        Which version of the IP protocol this rule should apply to.
        (Choices: ipv4, ipv6)[Default: ipv4]
- jump
        This specifies the target of the rule; i.e., what to do if the packet matches it. The target can be a user-
        defined chain (other than the one this rule is in), one of the special builtin targets which decide the fate of
        the packet immediately, or an extension (see EXTENSIONS below).  If this option is omitted in a rule (and the
        goto paramater is not used), then matching the rule will have no effect on the packet's fate, but the counters on
        the rule will be incremented.
        [Default: None]
- limit
        Specifies the maximum average number of matches to allow per second. The number can specify units explicitly,
        using `/second', `/minute', `/hour' or `/day', or parts of them (so `5/second' is the same as `5/s').
        [Default: None]
- limit_burst
        Specifies the maximum burst before the above limit kicks in.
        [Default: None]
- match
        Specifies a match to use, that is, an extension module that tests for a specific property. The set of matches
        make up the condition under which a target is invoked. Matches are evaluated first to last if specified as an
        array and work in short-circuit fashion, i.e. if one extension yields false, evaluation will stop.
        [Default: []]
- out_interface
        Name of an interface via which a packet is going to be sent (for packets entering the FORWARD, OUTPUT and
        POSTROUTING chains). When the "!" argument is used before the interface name, the sense is inverted. If the
        interface name ends in a "+", then any interface which begins with this name will match. If this option is
        omitted, any interface name will match.
        [Default: None]
- policy
        Set the policy for the chain to the given target. Valid targets are ACCEPT, DROP, QUEUE, RETURN. Only built in
        chains can have policies. This parameter requires the chain parameter. Ignores all other parameters.
        [Default: (null)]
- protocol
        The protocol of the rule or of the packet to check. The specified protocol can be one of tcp, udp, udplite, icmp,
        esp, ah, sctp or the special keyword "all", or it can be a numeric value, representing one of these protocols or
        a different one. A protocol name from /etc/protocols is also allowed. A "!" argument before the protocol inverts
        the test.  The number zero is equivalent to all. "all" will match with all protocols and is taken as default when
        this option is omitted.
        [Default: None]
- reject_with
        Specifies the error packet type to return while rejecting.
        [Default: (null)]
- set_counters
        This enables the administrator to initialize the packet and byte counters of a rule (during INSERT, APPEND,
        REPLACE operations).
        [Default: None]
- set_dscp_mark
        This allows specifying a DSCP mark to be added to packets. It takes either an integer or hex value. Mutually
        exclusive with `set_dscp_mark_class'.
        [Default: None]
- set_dscp_mark_class
        This allows specifying a predefined DiffServ class which will be translated to the corresponding DSCP mark.
        Mutually exclusive with `set_dscp_mark'.
        [Default: None]
- source
        Source specification. Address can be either a network name, a hostname, a network IP address (with /mask), or a
        plain IP address. Hostnames will be resolved once only, before the rule is submitted to the kernel. Please note
        that specifying any name to be resolved with a remote query such as DNS is a really bad idea. The mask can be
        either a network mask or a plain number, specifying the number of 1's at the left side of the network mask. Thus,
        a mask of 24 is equivalent to 255.255.255.0. A "!" argument before the address specification inverts the sense of
        the address.
        [Default: None]
- source_port
        Source port or port range specification. This can either be a service name or a port number. An inclusive range
        can also be specified, using the format first:last. If the first port is omitted, '0' is assumed; if the last is
        omitted, '65535' is assumed. If the first port is greater than the second one they will be swapped.
        [Default: None]
- state
        Whether the rule should be absent or present.
        (Choices: present, absent)[Default: present]
- table
        This option specifies the packet matching table which the command should operate on. If the kernel is configured
        with automatic module loading, an attempt will be made to load the appropriate module for that table if it is not
        already there.
        (Choices: filter, nat, mangle, raw, security)[Default: filter]
- to_destination
        This specifies a destination address to use with DNAT: without this, the destination address is never altered.
        [Default: None]
- to_ports
        This specifies a destination port or range of ports to use: without this, the destination port is never altered.
        This is only valid if the rule also specifies one of the following protocols: tcp, udp, dccp or sctp.
        [Default: None]
- to_source
        This specifies a source address to use with SNAT: without this, the source address is never altered.
        [Default: None]
- uid_owner
        Specifies the UID or username to use in match by owner rule.
        [Default: (null)]
Notes:
  * This module just deals with individual rules. If you need advanced chaining of rules the recommended way is to
        template the iptables restore file.
EXAMPLES:
# Block specific IP
- iptables:
    chain: INPUT
    source: 8.8.8.8
    jump: DROP
  become: yes

# Forward port 80 to 8600
- iptables:
    table: nat
    chain: PREROUTING
    in_interface: eth0
    protocol: tcp
    match: tcp
    destination_port: 80
    jump: REDIRECT
    to_ports: 8600
    comment: Redirect web traffic to port 8600
  become: yes

# Allow related and established connections
- iptables:
    chain: INPUT
    ctstate: ESTABLISHED,RELATED
    jump: ACCEPT
  become: yes

# Tag all outbound tcp packets with DSCP mark 8
- iptables:
    chain: OUTPUT
    jump: DSCP
    table: mangle
    set_dscp_mark: 8
    protocol: tcp

# Tag all outbound tcp packets with DSCP DiffServ class CS1
- iptables:
    chain: OUTPUT
    jump: DSCP
    table: mangle
    set_dscp_mark_class: CS1
    protocol: tcp


MAINTAINERS: Linus Unnebäck (@LinusU) <linus@folkdatorn.se>

METADATA:
	Status: ['preview']
	Supported_by: core
> IRC    (/usr/lib/python2.7/site-packages/ansible/modules/notification/irc.py)

  Send a message to an IRC channel. This is a very simplistic implementation.

Options (= is mandatory):

= channel
        Channel name.  One of nick_to or channel needs to be set.  When both are set, the message will be sent to both of
        them.

- color
        Text color for the message. ("none" is a valid option in 1.6 or later, in 1.6 and prior, the default color is
        black, not "none"). Added 11 more colors in version 2.0.
        (Choices: none, white, black, blue, green, red, brown, purple, orange, yellow, light_green, teal, light_cyan,
        light_blue, pink, gray, light_gray)[Default: none]
- key
        Channel key
        [Default: (null)]
= msg
        The message body.
        [Default: None]
- nick
        Nickname to send the message from. May be shortened, depending on server's NICKLEN setting.
        [Default: ansible]
- nick_to
        A list of nicknames to send the message to. One of nick_to or channel needs to be set.  When both are defined,
        the message will be sent to both of them.
        [Default: None]
- part
        Designates whether user should part from channel after sending message or not. Useful for when using a faux bot
        and not wanting join/parts between messages.
        [Default: True]
- passwd
        Server password
        [Default: (null)]
- port
        IRC server port number
        [Default: 6667]
- server
        IRC server name/address
        [Default: localhost]
- style
        Text style for the message. Note italic does not work on some clients
        (Choices: bold, underline, reverse, italic)[Default: None]
- timeout
        Timeout to use while waiting for successful registration and join messages, this is to prevent an endless loop
        [Default: 30]
- topic
        Set the channel topic
        [Default: None]
- use_ssl
        Designates whether TLS/SSL should be used when connecting to the IRC server
        [Default: False]
Requirements:  socket

EXAMPLES:
- irc:
    server: irc.example.net
    channel: #t1
    msg: Hello world

- local_action:
    module: irc
    port: 6669
    server: irc.example.net
    channel: #t1
    msg: 'All finished at {{ ansible_date_time.iso8601 }}'
    color: red
    nick: ansibleIRC

- local_action:
    module: irc
    port: 6669
    server: irc.example.net
    channel: #t1
    nick_to:
      - nick1
      - nick2
    msg: 'All finished at {{ ansible_date_time.iso8601 }}'
    color: red
    nick: ansibleIRC


MAINTAINERS: "Jan-Piet Mens (@jpmens)", "Matt Martz (@sivel)"

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> ISO_EXTRACT    (/usr/lib/python2.7/site-packages/ansible/modules/files/iso_extract.py)

  This module mounts an iso image in a temporary directory and extracts files from there to a given destination.

Options (= is mandatory):

= dest
        The destination directory to extract files to.

= files
        A list of files to extract from the image.
        Extracting directories does not work.

= image
        The ISO image to extract files from.

Notes:
  * Only the file hash (content) is taken into account for extracting files from the ISO image.
EXAMPLES:
- name: Extract kernel and ramdisk from a LiveCD
  iso_extract:
    image: /tmp/rear-test.iso
    dest: /tmp/virt-rear/
    files:
    - isolinux/kernel
    - isolinux/initrd.cgz

RETURN VALUES:
#


MAINTAINERS: Jeroen Hoekx (@jhoekx), Matt Robinson (@ribbons)

METADATA:
	Status: ['preview']
	Supported_by: core
> JABBER    (/usr/lib/python2.7/site-packages/ansible/modules/notification/jabber.py)

  Send a message to jabber

Options (= is mandatory):

- encoding
        message encoding
        [Default: (null)]
- host
        host to connect, overrides user info
        [Default: (null)]
= msg
        The message body.
        [Default: None]
= password
        password for user to connect

- port
        port to connect to, overrides default
        [Default: 5222]
= to
        user ID or name of the room, when using room use a slash to indicate your nick.

= user
        User as which to connect

Requirements:  python xmpp (xmpppy)

EXAMPLES:
# send a message to a user
- jabber:
    user: mybot@example.net
    password: secret
    to: friend@example.net
    msg: Ansible task finished

# send a message to a room
- jabber:
    user: mybot@example.net
    password: secret
    to: mychaps@conference.example.net/ansiblebot
    msg: Ansible task finished

# send a message, specifying the host and port
- jabber:
    user: mybot@example.net
    host: talk.example.net
    port: 5223
    password: secret
    to: mychaps@example.net
    msg: Ansible task finished


MAINTAINERS: Brian Coca (@bcoca)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> JAVA_CERT    (/usr/lib/python2.7/site-packages/ansible/modules/system/java_cert.py)

  This is a wrapper module around keytool. Which can be used to import/remove certificates from a given java keystore.

Options (= is mandatory):

- cert_alias
        Imported certificate alias.
        [Default: (null)]
- cert_path
        Local path to load certificate from. One of cert_url or cert_path is required to load certificate.
        [Default: (null)]
- cert_port
        Port to connect to URL. This will be used to create server URL:PORT
        [Default: 443]
- cert_url
        Basic URL to fetch SSL certificate from. One of cert_url or cert_path is required to load certificate.
        [Default: (null)]
- executable
        Path to keytool binary if not used we search in PATH for it.
        [Default: keytool]
- keystore_create
        Create keystore if it doesn't exist
        [Default: (null)]
= keystore_pass
        Keystore password.

- keystore_path
        Path to keystore.
        [Default: (null)]
- state
        Defines action which can be either certificate import or removal.
        (Choices: present, absent)[Default: present]
EXAMPLES:
# Import SSL certificate from google.com to a given cacerts keystore
java_cert:
  cert_url: google.com
  cert_port: 443
  keystore_path: /usr/lib/jvm/jre7/lib/security/cacerts
  keystore_pass: changeit
  state: present

# Remove certificate with given alias from a keystore
java_cert:
  cert_url: google.com
  keystore_path: /usr/lib/jvm/jre7/lib/security/cacerts
  keystore_pass: changeit
  executable: /usr/lib/jvm/jre7/bin/keytool
  state: absent

# Import SSL certificate from google.com to a keystore,
# create it if it doesn't exist
java_cert:
  cert_url: google.com
  keystore_path: /tmp/cacerts
  keystore_pass: changeit
  keystore_create: yes
  state: present

RETURN VALUES:
msg:
  description: Output from stdout of keytool command after execution of given command.
  returned: success
  type: string
  sample: "Module require existing keystore at keystore_path '/tmp/test/cacerts'"

rc:
  description: Keytool command execution return value
  returned: success
  type: int
  sample: "0"

cmd:
  description: Executed command to get action done
  returned: success
  type: string
  sample: "keytool -importcert -noprompt -keystore"


MAINTAINERS: Adam Hamsik @haad

METADATA:
	Status: ['preview']
	Supported_by: community
> JBOSS    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/jboss.py)

  Deploy applications to JBoss standalone using the filesystem

Options (= is mandatory):

- deploy_path
        The location in the filesystem where the deployment scanner listens
        [Default: /var/lib/jbossas/standalone/deployments]
= deployment
        The name of the deployment

- src
        The remote path of the application ear or war to deploy
        [Default: (null)]
- state
        Whether the application should be deployed or undeployed
        (Choices: present, absent)[Default: present]
Notes:
  * The JBoss standalone deployment-scanner has to be enabled in standalone.xml
  * Ensure no identically named application is deployed through the JBoss CLI
EXAMPLES:
# Deploy a hello world application
- jboss:
    src: /tmp/hello-1.0-SNAPSHOT.war
    deployment: hello.war
    state: present

# Update the hello world application
- jboss:
    src: /tmp/hello-1.1-SNAPSHOT.war
    deployment: hello.war
    state: present

# Undeploy the hello world application
- jboss:
    deployment: hello.war
    state: absent


MAINTAINERS: Jeroen Hoekx (@jhoekx)

METADATA:
	Status: ['preview']
	Supported_by: community
> JENKINS_JOB    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/jenkins_job.py)

  Manage Jenkins jobs by using Jenkins REST API.

Options (= is mandatory):

- config
        config in XML format.
        Required if job does not yet exist.
        Mututally exclusive with `enabled'.
        Considered if `state=present'.
        [Default: (null)]
- enabled
        Whether the job should be enabled or disabled.
        Mututally exclusive with `config'.
        Considered if `state=present'.
        [Default: (null)]
= name
        Name of the Jenkins job.

- password
        Password to authenticate with the Jenkins server.
        [Default: (null)]
- state
        Attribute that specifies if the job has to be created or deleted.
        (Choices: present, absent)[Default: present]
- token
        API token used to authenticate alternatively to password.
        [Default: (null)]
- url
        Url where the Jenkins server is accessible.
        [Default: http://localhost:8080]
- user
        User to authenticate with the Jenkins server.
        [Default: (null)]
Requirements:  python-jenkins >= 0.4.12, lxml >= 3.3.3

EXAMPLES:
# Create a jenkins job using basic authentication
- jenkins_job:
    config: "{{ lookup('file', 'templates/test.xml') }}"
    name: test
    password: admin
    url: http://localhost:8080
    user: admin

# Create a jenkins job using the token
- jenkins_job:
    config: "{{ lookup('template', 'templates/test.xml.j2') }}"
    name: test
    token: asdfasfasfasdfasdfadfasfasdfasdfc
    url: http://localhost:8080
    user: admin

# Delete a jenkins job using basic authentication
- jenkins_job:
    name: test
    password: admin
    state: absent
    url: http://localhost:8080
    user: admin

# Delete a jenkins job using the token
- jenkins_job:
    name: test
    token: asdfasfasfasdfasdfadfasfasdfasdfc
    state: absent
    url: http://localhost:8080
    user: admin

# Disable a jenkins job using basic authentication
- jenkins_job:
    name: test
    password: admin
    enabled: False
    url: http://localhost:8080
    user: admin

# Disable a jenkins job using the token
- jenkins_job:
    name: test
    token: asdfasfasfasdfasdfadfasfasdfasdfc
    enabled: False
    url: http://localhost:8080
    user: admin

RETURN VALUES:
---
name:
  description: Name of the jenkins job.
  returned: success
  type: string
  sample: test-job
state:
  description: State of the jenkins job.
  returned: success
  type: string
  sample: present
enabled:
  description: Whether the jenkins job is enabled or not.
  returned: success
  type: bool
  sample: true
user:
  description: User used for authentication.
  returned: success
  type: string
  sample: admin
url:
  description: Url to connect to the Jenkins server.
  returned: success
  type: string
  sample: https://jenkins.mydomain.com


MAINTAINERS: Sergio Millan Rodriguez (@sermilrod)

METADATA:
	Status: ['preview']
	Supported_by: community
> JENKINS_PLUGIN    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/jenkins_plugin.py)

  Ansible module which helps to manage Jenkins plugins.

Options (= is mandatory):

- group
        Name of the Jenkins group on the OS.
        [Default: jenkins]
- jenkins_home
        Home directory of the Jenkins user.
        [Default: /var/lib/jenkins]
- mode
        File mode applied on versioned plugins.
        [Default: 0664]
= name
        Plugin name.

- owner
        Name of the Jenkins user on the OS.
        [Default: jenkins]
- params
        Option used to allow the user to overwrite any of the other options. To remove an option, set the value of the
        option to `null'.
        [Default: None]
- state
        Desired plugin state.
        If the `latest' is set, the check for new version will be performed every time. This is suitable to keep the
        plugin up-to-date.
        (Choices: absent, present, pinned, unpinned, enabled, disabled, latest)[Default: present]
- timeout
        Server connection timeout in secs.
        [Default: 30]
- updates_expiration
        Number of seconds after which a new copy of the `update-center.json' file is downloaded. This is used to avoid
        the need to download the plugin to calculate its checksum when `latest' is specified.
        Set it to `0' if no cache file should be used. In that case, the plugin file will always be downloaded to
        calculate its checksum when `latest' is specified.
        [Default: 86400]
- updates_url
        URL of the Update Centre.
        Used as the base URL to download the plugins and the `update-center.json' JSON file.
        [Default: https://updates.jenkins-ci.org]
- url
        URL of the Jenkins server.
        [Default: http://localhost:8080]
- version
        Plugin version number.
        If this option is specified, all plugin dependencies must be installed manually.
        It might take longer to verify that the correct version is installed. This is especially true if a specific
        version number is specified.
        Quote the version to prevent the value to be interpreted as float. For example if `1.20' would be unquoted, it
        would become `1.2'.
        [Default: None]
- with_dependencies
        Defines whether to install plugin dependencies.
        This option takes effect only if the `version' is not defined.
        (Choices: yes, no)[Default: yes]
Notes:
  * Plugin installation should be run under root or the same user which owns the plugin files on the disk. Only if
        the plugin is not installed yet and no version is specified, the API installation is performed which
        requires only the Web UI credentials.
  * It's necessary to notify the handler or call the `service' module to restart the Jenkins service after a new
        plugin was installed.
  * Pinning works only if the plugin is installed and Jenkis service was successfully restarted after the plugin
        installation.
  * It is not possible to run the module remotely by changing the `url' parameter to point to the Jenkins server.
        The module must be used on the host where Jenkins runs as it needs direct access to the plugin files.
EXAMPLES:
- name: Install plugin
  jenkins_plugin:
    name: build-pipeline-plugin

- name: Install plugin without its dependencies
  jenkins_plugin:
    name: build-pipeline-plugin
    with_dependencies: no

- name: Make sure the plugin is always up-to-date
  jenkins_plugin:
    name: token-macro
    state: latest

- name: Install specific version of the plugin
  jenkins_plugin:
    name: token-macro
    version: "1.15"

- name: Pin the plugin
  jenkins_plugin:
    name: token-macro
    state: pinned

- name: Unpin the plugin
  jenkins_plugin:
    name: token-macro
    state: unpinned

- name: Enable the plugin
  jenkins_plugin:
    name: token-macro
    state: enabled

- name: Disable the plugin
  jenkins_plugin:
    name: token-macro
    state: disabled

- name: Uninstall plugin
  jenkins_plugin:
    name: build-pipeline-plugin
    state: absent

#
# Example of how to use the params
#
# Define a variable and specify all default parameters you want to use across
# all jenkins_plugin calls:
#
# my_jenkins_params:
#   url_username: admin
#   url_password: p4ssw0rd
#   url: http://localhost:8888
#
- name: Install plugin
  jenkins_plugin:
    name: build-pipeline-plugin
    params: "{{ my_jenkins_params }}"

#
# Example of a Play which handles Jenkins restarts during the state changes
#
- name: Jenkins Master play
  hosts: jenkins-master
  vars:
    my_jenkins_plugins:
      token-macro:
        enabled: yes
      build-pipeline-plugin:
        version: "1.4.9"
        pinned: no
        enabled: yes
  tasks:
    - name: Install plugins without a specific version
      jenkins_plugin:
        name: "{{ item.key }}"
      register: my_jenkins_plugin_unversioned
      when: >
        'version' not in item.value
      with_dict: "{{ my_jenkins_plugins }}"

    - name: Install plugins with a specific version
      jenkins_plugin:
        name: "{{ item.key }}"
        version: "{{ item.value['version'] }}"
      register: my_jenkins_plugin_versioned
      when: >
        'version' in item.value
      with_dict: "{{ my_jenkins_plugins }}"

    - name: Initiate the fact
      set_fact:
        jenkins_restart_required: no

    - name: Check if restart is required by any of the versioned plugins
      set_fact:
        jenkins_restart_required: yes
      when: item.changed
      with_items: "{{ my_jenkins_plugin_versioned.results }}"

    - name: Check if restart is required by any of the unversioned plugins
      set_fact:
        jenkins_restart_required: yes
      when: item.changed
      with_items: "{{ my_jenkins_plugin_unversioned.results }}"

    - name: Restart Jenkins if required
      service:
        name: jenkins
        state: restarted
      when: jenkins_restart_required

    - name: Wait for Jenkins to start up
      uri:
        url: http://localhost:8080
        status_code: 200
        timeout: 5
      register: jenkins_service_status
      # Keep trying for 5 mins in 5 sec intervals
      retries: 60
      delay: 5
      until: >
         'status' in jenkins_service_status and
         jenkins_service_status['status'] == 200
      when: jenkins_restart_required

    - name: Reset the fact
      set_fact:
        jenkins_restart_required: no
      when: jenkins_restart_required

    - name: Plugin pinning
      jenkins_plugin:
        name: "{{ item.key }}"
        state: "{{ 'pinned' if item.value['pinned'] else 'unpinned'}}"
      when: >
        'pinned' in item.value
      with_dict: "{{ my_jenkins_plugins }}"

    - name: Plugin enabling
      jenkins_plugin:
        name: "{{ item.key }}"
        state: "{{ 'enabled' if item.value['enabled'] else 'disabled'}}"
      when: >
        'enabled' in item.value
      with_dict: "{{ my_jenkins_plugins }}"

RETURN VALUES:
plugin:
    description: plugin name
    returned: success
    type: string
    sample: build-pipeline-plugin
state:
    description: state of the target, after execution
    returned: success
    type: string
    sample: "present"


MAINTAINERS: Jiri Tyr (@jtyr)

METADATA:
	Status: ['preview']
	Supported_by: community
> JENKINS_SCRIPT    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/jenkins_script.py)

  The `jenkins_script' module takes a script plus a dict of values to use within the script and returns the result of the
  script being run.

Options (= is mandatory):

- args
        A dict of key-value pairs used in formatting the script.
        [Default: None]
- password
        The password to connect to the jenkins server with.
        [Default: None]
= script
        The groovy script to be executed. This gets passed as a string Template if args is defined.
        [Default: None]
- url
        The jenkins server to execute the script against. The default is a local jenkins instance that is not being
        proxied through a webserver.
        [Default: http://localhost:8080]
- user
        The username to connect to the jenkins server with.
        [Default: None]
- validate_certs
        If set to `no', the SSL certificates will not be validated. This should only set to `no' used on personally
        controlled sites using self-signed certificates as it avoids verifying the source site.
        [Default: True]
Notes:
  * Since the script can do anything this does not report on changes. Knowing the script is being run it's
        important to set changed_when for the ansible output to be clear on any alterations made.
EXAMPLES:
- name: Obtaining a list of plugins
  jenkins_script:
    script: 'println(Jenkins.instance.pluginManager.plugins)'
    user: admin
    password: admin

- name: Setting master using a variable to hold a more complicate script
  vars:
    setmaster_mode: |
        import jenkins.model.*
        instance = Jenkins.getInstance()
        instance.setMode(${jenkins_mode})
        instance.save()

- name: use the variable as the script
  jenkins_script:
    script: "{{ setmaster_mode }}"
    args:
      jenkins_mode: Node.Mode.EXCLUSIVE

- name: interacting with an untrusted HTTPS connection
  jenkins_script:
    script: "println(Jenkins.instance.pluginManager.plugins)"
    user: admin
    password: admin
    url: https://localhost
    validate_certs: no

RETURN VALUES:
output:
    description: Result of script
    returned: success
    type: string
    sample: 'Result: true'


MAINTAINERS: James Hogarth

METADATA:
	Status: ['preview']
	Supported_by: community
> JIRA    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/jira.py)

  Create and modify issues in a JIRA instance.

Options (= is mandatory):

- assignee
        Sets the assignee on create or transition operations. Note not all transitions will allow this.
        [Default: (null)]
- comment
        The comment text to add.
        [Default: (null)]
- description
        The issue description, where appropriate.
        [Default: (null)]
- fields
        This is a free-form data structure that can contain arbitrary data. This is passed directly to the JIRA REST API
        (possibly after merging with other required data, as when passed to create). See examples for more information,
        and the JIRA REST API for the structure required for various fields.
        [Default: (null)]
- inwardissue
        Set issue from which link will be created.
        [Default: (null)]
- issue
        An existing issue key to operate on.
        [Default: (null)]
- issuetype
        The issue type, for issue creation.
        [Default: (null)]
- linktype
        Set type of link, when action 'link' selected.
        [Default: (null)]
= operation
        The operation to perform.
        (Choices: create, comment, edit, fetch, transition)
- outwardissue
        Set issue to which link will be created.
        [Default: (null)]
= password
        The password to log-in with.

- project
        The project for this operation. Required for issue creation.
        [Default: (null)]
- status
        The desired status; only relevant for the transition operation.
        [Default: (null)]
- summary
        The issue summary, where appropriate.
        [Default: (null)]
- timeout
        Set timeout, in seconds, on requests to JIRA API.
        [Default: 10]
= uri
        Base URI for the JIRA instance.

= username
        The username to log-in with.

Notes:
  * Currently this only works with basic-auth.
EXAMPLES:
# Create a new issue and add a comment to it:
- name: Create an issue
  jira:
    uri: '{{ server }}'
    username: '{{ user }}'
    password: '{{ pass }}'
    project: ANS
    operation: create
    summary: Example Issue
    description: Created using Ansible
    issuetype: Task
  register: issue

- name: Comment on issue
  jira:
    uri: '{{ server }}'
    username: '{{ user }}'
    password: '{{ pass }}'
    issue: '{{ issue.meta.key }}'
    operation: comment
    comment: A comment added by Ansible

# Assign an existing issue using edit
- name: Assign an issue using free-form fields
  jira:
    uri: '{{ server }}'
    username: '{{ user }}'
    password: '{{ pass }}'
    issue: '{{ issue.meta.key}}'
    operation: edit
    assignee: ssmith

# Create an issue with an existing assignee
- name: Create an assigned issue
  jira:
    uri: '{{ server }}'
    username: '{{ user }}'
    password: '{{ pass }}'
    project: ANS
    operation: create
    summary: Assigned issue
    description: Created and assigned using Ansible
    issuetype: Task
    assignee: ssmith

# Edit an issue
- name: Set the labels on an issue using free-form fields
  jira:
    uri: '{{ server }}'
    username: '{{ user }}'
    password: '{{ pass }}'
    issue: '{{ issue.meta.key }}'
    operation: edit
  args:
    fields:
        labels:
          - autocreated
          - ansible

# Retrieve metadata for an issue and use it to create an account
- name: Get an issue
  jira:
    uri: '{{ server }}'
    username: '{{ user }}'
    password: '{{ pass }}'
    project: ANS
    operation: fetch
    issue: ANS-63
  register: issue

- name: Create a unix account for the reporter
  become: true
  user:
    name: '{{ issue.meta.fields.creator.name }}'
    comment: '{{ issue.meta.fields.creator.displayName }}'

- name: Create link from HSP-1 to MKY-1
  jira:
    uri: '{{ server }}'
    username: '{{ user }}'
    password: '{{ pass }}'
    operation: link
    linktype: Relate
    inwardissue: HSP-1
    outwardissue: MKY-1

# Transition an issue by target status
- name: Close the issue
  jira:
    uri: '{{ server }}'
    username: '{{ user }}'
    password: '{{ pass }}'
    issue: '{{ issue.meta.key }}'
    operation: transition
    status: Done


MAINTAINERS: Steve Smith (@tarka)

METADATA:
	Status: ['preview']
	Supported_by: community
> JUNOS_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/junos/junos_command.py)

  Sends an arbitrary set of commands to an JUNOS node and returns the results read from the device.  This module includes
  an argument that will cause the module to wait for a specific condition before returning or timing out if the condition
  is not met.

Options (= is mandatory):

- commands
        The commands to send to the remote junos device over the configured provider.  The resulting output from the
        command is returned.  If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of `retries' has been exceeded.
        [Default: None]
- display
        Encoding scheme to use when serializing output from the device. This handles how to properly understand the
        output and apply the conditionals path to the result set. For `rpcs' argument default display is `xml' and for
        `commands' argument default display is `text'.
        (Choices: text, json, xml)[Default: depends on input argument `rpcs' or `commands']
- interval
        Configures the interval in seconds to wait between retries of the command.  If the command does not pass the
        specified conditional, the interval indicates how to long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the `wait_for' must be
        satisfied.  If the value is set to `any' then only one of the values must be satisfied.
        (Choices: any, all)[Default: all]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should be tried before it is considered failed.  The command is run on
        the target device every retry and evaluated against the `wait_for' conditionals.
        [Default: 10]
- rpcs
        The `rpcs' argument accepts a list of RPCs to be executed over a netconf session and the results from the RPC
        execution is return to the playbook via the modules results dictionary.
        [Default: None]
- wait_for
        Specifies what to evaluate from the output of the command and what conditionals to apply.  This argument will
        cause the task to wait for a particular conditional to be true before moving forward.   If the conditional is not
        true by the configured retries, the task fails.  See examples.
        [Default: None]
EXAMPLES:
- name: run show version on remote devices
  junos_command:
    commands: show version

- name: run show version and check to see if output contains Juniper
  junos_command:
    commands: show version
    wait_for: result[0] contains Juniper

- name: run multiple commands on remote nodes
  junos_command:
    commands:
      - show version
      - show interfaces

- name: run multiple commands and evaluate the output
  junos_command:
    commands:
      - show version
      - show interfaces
    wait_for:
      - result[0] contains Juniper
      - result[1] contains Loopback0

- name: run commands and specify the output format
  junos_command:
    commands: show version
    display: json

- name: run rpc on the remote device
  junos_command:
    rpcs: get-software-information


RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']
stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]
failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> JUNOS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/junos/junos_config.py)

  This module provides an implementation for working with the active configuration running on Juniper JUNOS devices.  It
  provides a set of arguments for loading configuration, performing rollback operations and zeroing the active
  configuration on the device.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- backup
        This argument will cause the module to create a full backup of the current `running-config' from the remote
        device before any changes are made.  The backup file is written to the `backup' folder in the playbook root
        directory.  If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- comment
        The `comment' argument specifies a text string to be used when committing the configuration.  If the `confirm'
        argument is set to False, this argument is silently ignored.
        [Default: configured by junos_config]
- confirm
        The `confirm' argument will configure a time out value for the commit to be confirmed before it is automatically
        rolled back.  If the `confirm' argument is set to False, this argument is silently ignored.  If the value for
        this argument is set to 0, the commit is confirmed immediately.
        [Default: 0]
- lines
        This argument takes a list of `set' or `delete' configuration lines to push into the remote device.  Each line
        must start with either `set' or `delete'.  This argument is mutually exclusive with the `src' argument.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        The `replace' argument will instruct the remote device to replace the current configuration hierarchy with the
        one specified in the corresponding hierarchy of the source configuration loaded from this module.
        Note this argument should be considered deprecated.  To achieve the equivalent, set the `update' argument to
        `replace'. This argument will be removed in a future release. The `replace' and `update' argument is mutually
        exclusive.
        (Choices: yes, no)[Default: False]
- rollback
        The `rollback' argument instructs the module to rollback the current configuration to the identifier specified in
        the argument.  If the specified rollback identifier does not exist on the remote device, the module will fail.
        To rollback to the most recent commit, set the `rollback' argument to 0.
        [Default: None]
- src
        The `src' argument provides a path to the configuration file to load into the remote system.  The path can either
        be a full system path to the configuration file if the value starts with / or relative to the root of the
        implemented role or playbook. This argument is mutually exclusive with the `lines' argument.
        [Default: None]
- src_format
        The `src_format' argument specifies the format of the configuration found int `src'.  If the `src_format'
        argument is not provided, the module will attempt to determine the format of the configuration file specified in
        `src'.
        (Choices: xml, set, text, json)[Default: None]
- update
        This argument will decide how to load the configuration data particulary when the candidate configuration and
        loaded configuration contain conflicting statements. Following are accepted values. `merge' combines the data in
        the loaded configuration with the candidate configuration. If statements in the loaded configuration conflict
        with statements in the candidate configuration, the loaded statements replace the candidate ones. `override'
        discards the entire candidate configuration and replaces it with the loaded configuration. `replace' substitutes
        each hierarchy level in the loaded configuration for the corresponding level.
        (Choices: merge, override, replace)[Default: merge]
- zeroize
        The `zeroize' argument is used to completely sanitize the remote device configuration back to initial defaults.
        This argument will effectively remove all current configuration statements on the remote device.
        [Default: None]
Notes:
  * This module requires the netconf system service be enabled on the remote device being managed.
Requirements:  junos-eznc

EXAMPLES:
- name: load configure file into device
  junos_config:
    src: srx.cfg
    comment: update config
    provider: "{{ netconf }}"

- name: rollback the configuration to id 10
  junos_config:
    rollback: 10
    provider: "{{ netconf }}"

- name: zero out the current configuration
  junos_config:
    zeroize: yes
    provider: "{{ netconf }}"

- name: confirm a previous commit
  junos_config:
    provider: "{{ netconf }}"

RETURN VALUES:
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/config.2016-07-16@22:28:34


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> JUNOS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/junos/junos_facts.py)

  Collects fact information from a remote device running the Junos operating system.  By default, the module will collect
  basic fact information from the device to be included with the hostvars. Additional fact information can be collected
  based on the configured set of arguments.

Options (= is mandatory):

- config_format
        The `config_format' argument specifies the format of the configuration when serializing output from the device.
        This argument is applicable only when `config' value is present in `gather_subset'.
        (Choices: xml, set, text, json)[Default: text]
- gather_subset
        When supplied, this argument will restrict the facts collected to a given subset.  Possible values for this
        argument include all, hardware, config, and interfaces.  Can specify a list of values to include a larger subset.
        Values can also be used with an initial `[!]' to specify that a specific subset should not be collected.
        [Default: !config]
- provider
        A dict object containing connection details.
        [Default: None]
EXAMPLES:
- name: collect default set of facts
  junos_facts:

- name: collect default set of facts and configuration
  junos_facts:
    gather_subset: config

RETURN VALUES:
ansible_facts:
  description: Returns the facts collect from the device
  returned: always
  type: dict


MAINTAINERS: Nathaniel Case (@qalthos)

METADATA:
	Status: ['preview']
	Supported_by: core
> JUNOS_NETCONF    (/usr/lib/python2.7/site-packages/ansible/modules/network/junos/junos_netconf.py)

  This module provides an abstraction that enables and configures the netconf system service running on Junos devices.
  This module can be used to easily enable the Netconf API. Netconf provides a programmatic interface for working with
  configuration and state resources as defined in RFC 6242.

Options (= is mandatory):

- netconf_port
        This argument specifies the port the netconf service should listen on for SSH connections.  The default port as
        defined in RFC 6242 is 830.
        [Default: 830]
- provider
        A dict object containing connection details.
        [Default: None]
- state
        Specifies the state of the `junos_netconf' resource on the remote device.  If the `state' argument is set to
        `present' the netconf service will be configured.  If the `state' argument is set to `absent' the netconf service
        will be removed from the configuration.
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: enable netconf service on port 830
  junos_netconf:
    listens_on: 830
    state: present

- name: disable netconf service
  junos_netconf:
    state: absent

RETURN VALUES:
commands:
  description: Returns the command sent to the remote device
  returned: when changed is True
  type: str
  sample: 'set system services netconf ssh port 830'


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> JUNOS_PACKAGE    (/usr/lib/python2.7/site-packages/ansible/modules/network/junos/junos_package.py)

  This module can install new and updated packages on remote devices running Junos.  The module will compare the
  specified package with the one running on the remote device and install the specified version if there is a mismatch

Options (= is mandatory):

= force
        The `force' argument instructs the module to bypass the package version check and install the packaged identified
        in `src' on the remote device.
        (Choices: true, false)[Default: False]
- no_copy
        The `no_copy' argument is responsible for instructing the remote device on where to install the package from.
        When enabled, the package is transferred to the remote device prior to installing.
        (Choices: true, false)[Default: False]
- provider
        A dict object containing connection details.
        [Default: None]
= reboot
        In order for a package to take effect, the remote device must be restarted.  When enabled, this argument will
        instruct the module to reboot the device once the updated package has been installed. If disabled or the remote
        package does not need to be changed, the device will not be started.
        (Choices: true, false)[Default: True]
= src
        The `src' argument specifies the path to the source package to be installed on the remote device in the advent of
        a version mismatch. The `src' argument can be either a localized path or a full path to the package file to
        install.
        [Default: None]
- version
        The `version' argument can be used to explicitly specify the version of the package that should be installed on
        the remote device.  If the `version' argument is not specified, then the version is extracts from the `src'
        filename.
        [Default: None]
Notes:
  * This module requires the netconf system service be enabled on the remote device being managed
Requirements:  junos-eznc

EXAMPLES:
# the required set of connection arguments have been purposely left off
# the examples for brevity

- name: install local package on remote device
  junos_package:
    src: junos-vsrx-12.1X46-D10.2-domestic.tgz

- name: install local package on remote device without rebooting
  junos_package:
    src: junos-vsrx-12.1X46-D10.2-domestic.tgz
    reboot: no


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> JUNOS_RPC    (/usr/lib/python2.7/site-packages/ansible/modules/network/junos/junos_rpc.py)

  Sends a request to the remote device running JUNOS to execute the specified RPC using the NetConf transport.  The reply
  is then returned to the playbook in the c(xml) key.  If an alternate output format is requested, the reply is
  transformed to the requested output.

Options (= is mandatory):

- args
        The `args' argument provides a set of arguments for the RPC call and are encoded in the request message.  This
        argument accepts a set of key=value arguments.
        [Default: None]
- output
        The `output' argument specifies the desired output of the return data.  This argument accepts one of `xml',
        `text', or `json'.  For `json', the JUNOS device must be running a version of software that supports native JSON
        output.
        [Default: xml]
- provider
        A dict object containing connection details.
        [Default: None]
= rpc
        The `rpc' argument specifies the RPC call to send to the remote devices to be executed.  The RPC Reply message is
        parsed and the contents are returned to the playbook.

EXAMPLES:
- name: collect interface information using rpc
  junos_rpc:
    rpc: get-interface-information
    args:
      interface: em0
      media: True

- name: get system information
  junos_rpc:
    rpc: get-system-information

RETURN VALUES:
xml:
  description: The xml return string from the rpc request.
  returned: always
  type: string
output:
  description: The rpc rely converted to the output format.
  returned: always
  type: string
output_lines:
  description: The text output split into lines for readability.
  returned: always
  type: list


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> JUNOS_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/junos/_junos_template.py)

  This module will load a candidate configuration from a template file onto a remote device running Junos.  The module
  will return the differences in configuration if the diff option is specified on the Ansible command line

DEPRECATED: 
Deprecated in 2.2. Use M(junos_config) instead.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- action
        The `action' argument specifies how the module will apply changes.
        (Choices: merge, overwrite, replace)[Default: merge]
- backup
        When this argument is configured true, the module will backup the configuration from the node prior to making any
        changes. The backup file will be written to backup_{{ hostname }} in the root of the playbook directory.
        (Choices: true, false)[Default: False]
- comment
        The `comment' argument specifies a text string to be used when committing the configuration.  If the `confirm'
        argument is set to False, this argument is silently ignored.
        [Default: configured by junos_template]
- config_format
        The `format' argument specifies the format of the configuration template specified in `src'.  If the format
        argument is not specified, the module will attempt to infer the configuration format based of file extension.
        Files that end in `xml' will set the format to xml.  Files that end in `set' will set the format to set and all
        other files will default the format to text.
        (Choices: text, xml, set)[Default: None]
- confirm
        The `confirm' argument will configure a time out value for the commit to be confirmed before it is automatically
        rolled back.  If the `confirm' argument is set to False, this argument is silently ignored.  If the value for
        this argument is set to 0, the commit is confirmed immediately.
        [Default: 0]
- provider
        A dict object containing connection details.
        [Default: None]
= src
        The path to the config source.  The source can be either a file with config or a template that will be merged
        during runtime.  By default the task will search for the source file in role or playbook root folder in templates
        directory.
        [Default: None]
Notes:
  * This module requires the netconf system service be enabled on the remote device being managed
Requirements:  junos-eznc

EXAMPLES:
- junos_template:
    src: config.j2
    comment: update system config

- name: replace config hierarchy
  junos_template:
    src: config.j2
    action: replace

- name: overwrite the config
  junos_template:
    src: config.j2
    action: overwrite


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> JUNOS_USER    (/usr/lib/python2.7/site-packages/ansible/modules/network/junos/junos_user.py)

  This module manages locally configured user accounts on remote network devices running the JUNOS operating system.  It
  provides a set of arguments for creating, removing and updating locally defined accounts

Options (= is mandatory):

- full_name
        The `full_name' argument provides the full name of the user account to be created on the remote device.  This
        argument accepts any text string value.
        [Default: None]
- name
        The `name' argument defines the username of the user to be created on the system.  This argument must follow
        appropriate usernaming conventions for the target device running JUNOS.  This argument is mutually exclusive with
        the `users' argument.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- purge
        The `purge' argument instructs the module to consider the users definition absolute.  It will remove any
        previously configured users on the device with the exception of the current defined set of users.
        [Default: False]
- role
        The `role' argument defines the role of the user account on the remote system.  User accounts can have more than
        one role configured.
        (Choices: operator, read-only, super-user, unauthorized)[Default: read-only]
- sshkey
        The `sshkey' argument defines the public SSH key to be configured for the user account on the remote system.
        This argument must be a valid SSH key
        [Default: None]
- state
        The `state' argument configures the state of the user definitions as it relates to the device operational
        configuration.  When set to `present', the user should be configured in the device active configuration and when
        set to `absent' the user should not be in the device active configuration
        (Choices: present, absent)[Default: present]
- users
        The `users' argument defines a list of users to be configured on the remote device.  The list of users will be
        compared against the current users and only changes will be added or removed from the device configuration.  This
        argument is mutually exclusive with the name argument.
        [Default: None]
EXAMPLES:
- name: create new user account
  junos_user:
    name: ansible
    role: super-user
    sshkey: "{{ lookup('file', '~/.ssh/ansible.pub') }}"
    state: present

- name: remove a user account
  junos_user:
    name: ansible
    state: absent

- name: remove all user accounts except ansible
  junos_user:
    name: ansible
    purge: yes

RETURN VALUES:


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> KATELLO    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/foreman/katello.py)

  Allows the management of Katello resources inside your Foreman server

Options (= is mandatory):

= entity
        The Foreman resource that the action will be performed on (e.g. organization, host)

= params
        Parameters associated to the entity resource to set or edit in dictionary format (e.g. name, description)

= password
        Password for user accessing Foreman server

= server_url
        URL of Foreman server

= username
        Username on Foreman server

Requirements:  nailgun >= 0.28.0, python >= 2.6, datetime

EXAMPLES:
---
# Simple Example:

- name: "Create Product"
  local_action:
      module: katello
      username: "admin"
      password: "admin"
      server_url: "https://fakeserver.com"
      entity: "product"
      params:
        name: "Centos 7"

# Abstraction Example:
# katello.yml
---
- name: "{{ name }}"
  local_action:
      module: katello
      username: "admin"
      password: "admin"
      server_url: "https://fakeserver.com"
      entity: "{{ entity }}"
      params: "{{ params }}"

# tasks.yml
---
- include: katello.yml
  vars:
    name: "Create Dev Environment"
    entity: "lifecycle_environment"
    params:
      name: "Dev"
      prior: "Library"
      organization: "Default Organization"

- include: katello.yml
  vars:
    name: "Create Centos Product"
    entity: "product"
    params:
      name: "Centos 7"
      organization: "Default Organization"

- include: katello.yml
  vars:
    name: "Create 7.2 Repository"
    entity: "repository"
    params:
      name: "Centos 7.2"
      product: "Centos 7"
      organization: "Default Organization"
      content_type: "yum"
      url: "http://mirror.centos.org/centos/7/os/x86_64/"

- include: katello.yml
  vars:
      name: "Create Centos 7 View"
      entity: "content_view"
      params:
        name: "Centos 7 View"
        organization: "Default Organization"
        repositories:
          - name: "Centos 7.2"
            product: "Centos 7"

- include: katello.yml
  vars:
      name: "Enable RHEL Product"
      entity: "repository_set"
      params:
        name: "Red Hat Enterprise Linux 7 Server (RPMs)"
        product: "Red Hat Enterprise Linux Server"
        organization: "Default Organization"
        basearch: "x86_64"
        releasever: "7"

RETURN VALUES:
 

MAINTAINERS: Eric D Helms (@ehelms)

METADATA:
	Status: ['preview']
	Supported_by: community
> KERNEL_BLACKLIST    (/usr/lib/python2.7/site-packages/ansible/modules/system/kernel_blacklist.py)

  Add or remove kernel modules from blacklist.

Options (= is mandatory):

- blacklist_file
        If specified, use this blacklist file instead of `/etc/modprobe.d/blacklist-ansible.conf'.
        [Default: None]
= name
        Name of kernel module to black- or whitelist.

- state
        Whether the module should be present in the blacklist or absent.
        (Choices: present, absent)[Default: present]
EXAMPLES:
# Blacklist the nouveau driver module
- kernel_blacklist:
    name: nouveau
    state: present


MAINTAINERS: Matthias Vogelgesang (@matze)

METADATA:
	Status: ['preview']
	Supported_by: community
> KEYSTONE_USER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_keystone_user.py)

  Manage users,tenants, roles from OpenStack.

DEPRECATED: 
Deprecated in 2.0. Use M(os_user) instead.

Options (= is mandatory):

- email
        An email address for the user
        [Default: None]
- endpoint
        The keystone url for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
- login_password
        Password of login user
        [Default: yes]
- login_tenant_name
        The tenant login_user belongs to
        [Default: None]
- login_user
        login username to authenticate to keystone
        [Default: admin]
- password
        The password to be assigned to the user
        [Default: None]
- role
        The name of the role to be assigned or created
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant
        The tenant name that has be added/removed
        [Default: None]
- tenant_description
        A description for the tenant
        [Default: None]
- token
        The token to be uses in case the password is not specified
        [Default: None]
- user
        The name of the user that has to added/removed from OpenStack
        [Default: None]
Requirements:  python >= 2.6, python-keystoneclient

EXAMPLES:
- name: Create a tenant
  keystone_user:
    tenant: demo
    tenant_description: "Default Tenant"

- name: Create a user
  keystone_user:
    user: john
    tenant: demo
    password: secrete

- name: Apply the admin role to the john user in the demo tenant
  keystone_user:
    role: admin
    user: john
    tenant: demo


MAINTAINERS: Ansible Core Team (deprecated)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> KIBANA_PLUGIN    (/usr/lib/python2.7/site-packages/ansible/modules/database/misc/kibana_plugin.py)

  Manages Kibana plugins.

Options (= is mandatory):

- force
        Delete and re-install the plugin. Can be useful for plugins update
        (Choices: yes, no)[Default: False]
= name
        Name of the plugin to install

- plugin_bin
        Location of the plugin binary
        [Default: /opt/kibana/bin/kibana]
- plugin_dir
        Your configured plugin directory specified in Kibana
        [Default: /opt/kibana/installedPlugins/]
- state
        Desired state of a plugin.
        (Choices: present, absent)[Default: present]
- timeout
        Timeout setting: 30s, 1m, 1h...
        [Default: 1m]
- url
        Set exact URL to download the plugin from. For local file, prefix its absolute path with file://
        [Default: None]
- version
        Version of the plugin to be installed. If plugin exists with previous version, it will NOT be updated if `force'
        is not set to yes
        [Default: None]
EXAMPLES:
- name: Install Elasticsearch head plugin
  kibana_plugin:
    state: present
    name: elasticsearch/marvel

- name: Install specific version of a plugin
  kibana_plugin:
    state: present
    name: elasticsearch/marvel
    version: '2.3.3'

- name: Uninstall Elasticsearch head plugin
  kibana_plugin:
    state: absent
    name: elasticsearch/marvel

RETURN VALUES:
cmd:
    description: the launched command during plugin mangement (install / remove)
    returned: success
    type: string
name:
    description: the plugin name to install or remove
    returned: success
    type: string
url:
    description: the url from where the plugin is installed from
    returned: success
    type: string
timeout:
    description: the timout for plugin download
    returned: success
    type: string
stdout:
    description: the command stdout
    returned: success
    type: string
stderr:
    description: the command stderr
    returned: success
    type: string
state:
    description: the state for the managed plugin
    returned: success
    type: string


MAINTAINERS: Thierno IB. BARRY (@barryib)

METADATA:
	Status: ['preview']
	Supported_by: community
> KINESIS_STREAM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/kinesis_stream.py)

  Create or Delete a Kinesis Stream. Update the retention period of a Kinesis Stream. Update Tags on a Kinesis Stream.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= name
        The name of the Kinesis Stream you are managing.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- retention_period
        The default retention period is 24 hours and can not be less than 24 hours.
        The retention period can be modified during any point in time.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- shards
        The number of shards you want to have with this stream. This can not be modified after being created.
        This is required when state == present
        [Default: None]
- state
        Create or Delete the Kinesis Stream.
        (Choices: present, absent)[Default: present]
- tags
        A dictionary of resource tags of the form: { tag1: value1, tag2: value2 }.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- wait
        Wait for operation to complete before returning.
        [Default: True]
- wait_timeout
        How many seconds to wait for an operation to complete before timing out.
        [Default: 300]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Basic creation example:
- name: Set up Kinesis Stream with 10 shards and wait for the stream to become ACTIVE
  kinesis_stream:
    name: test-stream
    shards: 10
    wait: yes
    wait_timeout: 600
  register: test_stream

# Basic creation example with tags:
- name: Set up Kinesis Stream with 10 shards, tag the environment, and wait for the stream to become ACTIVE
  kinesis_stream:
    name: test-stream
    shards: 10
    tags:
      Env: development
    wait: yes
    wait_timeout: 600
  register: test_stream

# Basic creation example with tags and increase the retention period from the default 24 hours to 48 hours:
- name: Set up Kinesis Stream with 10 shards, tag the environment, increase the retention period and wait for the stream to become ACTIVE
  kinesis_stream:
    name: test-stream
    retention_period: 48
    shards: 10
    tags:
      Env: development
    wait: yes
    wait_timeout: 600
  register: test_stream

# Basic delete example:
- name: Delete Kinesis Stream test-stream and wait for it to finish deleting.
  kinesis_stream:
    name: test-stream
    state: absent
    wait: yes
    wait_timeout: 600
  register: test_stream

RETURN VALUES:
stream_name:
  description: The name of the Kinesis Stream.
  returned: when state == present.
  type: string
  sample: "test-stream"
stream_arn:
  description: The amazon resource identifier
  returned: when state == present.
  type: string
  sample: "arn:aws:kinesis:east-side:123456789:stream/test-stream"
stream_status:
  description: The current state of the Kinesis Stream.
  returned: when state == present.
  type: string
  sample: "ACTIVE"
retention_period_hours:
  description: Number of hours messages will be kept for a Kinesis Stream.
  returned: when state == present.
  type: int
  sample: 24
tags:
  description: Dictionary containing all the tags associated with the Kinesis stream.
  returned: when state == present.
  type: dict
  sample: {
      "Name": "Splunk",
      "Env": "development"
  }


MAINTAINERS: Allen Sanabria (@linuxdynasty)

METADATA:
	Status: ['preview']
	Supported_by: community
> KNOWN_HOSTS    (/usr/lib/python2.7/site-packages/ansible/modules/system/known_hosts.py)

  The `known_hosts' module lets you add or remove a host keys from the `known_hosts' file. Starting at Ansible 2.2,
  multiple entries per host are allowed, but only one for each key type supported by ssh. This is useful if you're going
  to want to use the [git] module over ssh, for example. If you have a very large number of host keys to manage, you will
  find the [template] module more useful.

Options (= is mandatory):

- hash_host
        Hash the hostname in the known_hosts file
        [Default: False]
- key
        The SSH public host key, as a string (required if state=present, optional when state=absent, in which case all
        keys for the host are removed). The key must be in the right format for ssh (see sshd(1), section
        "SSH_KNOWN_HOSTS FILE FORMAT")
        [Default: None]
= name
        The host to add or remove (must match a host specified in key)
        [Default: None]
- path
        The known_hosts file to edit
        [Default: (homedir)+/.ssh/known_hosts]
- state
        `present' to add the host key, `absent' to remove it.
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: tell the host about our servers it might want to ssh to
  known_hosts:
    path: /etc/ssh/ssh_known_hosts
    name: foo.com.invalid
    key: "{{ lookup('file', 'pubkeys/foo.com.invalid') }}"


MAINTAINERS: Matthew Vernon (@mcv21)

METADATA:
	Status: ['preview']
	Supported_by: community
> KUBERNETES    (/usr/lib/python2.7/site-packages/ansible/modules/clustering/kubernetes.py)

  This module can manage Kubernetes resources on an existing cluster using the Kubernetes server API. Users can specify
  in-line API data, or specify an existing Kubernetes YAML file. Currently, this module, Only supports HTTP Basic Auth
  Only supports 'strategic merge' for update, http://goo.gl/fCPYxT SSL certs are not working, use 'validate_certs=off' to
  disable

Options (= is mandatory):

= api_endpoint
        The IPv4 API endpoint of the Kubernetes cluster.
        [Default: None]
- certificate_authority_data
        Certificate Authority data for Kubernetes server. Should be in either standard PEM format or base64 encoded PEM
        data. Note that certificate verification is broken until ansible supports a version of 'match_hostname' that can
        match the IP address against the CA data.
        [Default: None]
- file_reference
        Specify full path to a Kubernets YAML file to send to API `endpoint'. This option is mutually exclusive with
        `'inline_data''.
        [Default: None]
= inline_data
        The Kubernetes YAML data to send to the API `endpoint'. This option is mutually exclusive with
        `'file_reference''.
        [Default: None]
- insecure
        Reverts the connection to using HTTP instead of HTTPS. This option should only be used when execuing the
        ['kubernetes'] module local to the Kubernetes cluster using the insecure local port (locahost:8080 by default).
        [Default: (null)]
= state
        The desired action to take on the Kubernetes data.
        (Choices: present, absent, update, replace)[Default: present]
- url_password
        The HTTP Basic Auth password for the API `endpoint'. This should be set unless using the `'insecure'' option.
        [Default: None]
- url_username
        The HTTP Basic Auth username for the API `endpoint'. This should be set unless using the `'insecure'' option.
        [Default: admin]
- validate_certs
        Enable/disable certificate validation. Note that this is set to `false' until Ansible can support IP address
        based certificate hostname matching (exists in >= python3.5.0).
        [Default: False]
EXAMPLES:
# Create a new namespace with in-line YAML.
- name: Create a kubernetes namespace
  kubernetes:
    api_endpoint: 123.45.67.89
    url_username: admin
    url_password: redacted
    inline_data:
      kind: Namespace
      apiVersion: v1
      metadata:
        name: ansible-test
        labels:
          label_env: production
          label_ver: latest
        annotations:
          a1: value1
          a2: value2
    state: present

# Create a new namespace from a YAML file.
- name: Create a kubernetes namespace
  kubernetes:
    api_endpoint: 123.45.67.89
    url_username: admin
    url_password: redacted
    file_reference: /path/to/create_namespace.yaml
    state: present

# Do the same thing, but using the insecure localhost port
- name: Create a kubernetes namespace
  kubernetes:
    api_endpoint: 123.45.67.89
    insecure: true
    file_reference: /path/to/create_namespace.yaml
    state: present


RETURN VALUES:
# Example response from creating a Kubernetes Namespace.
api_response:
    description: Raw response from Kubernetes API, content varies with API.
    returned: success
    type: dictionary
    contains:
        apiVersion: "v1"
        kind: "Namespace"
        metadata:
            creationTimestamp: "2016-01-04T21:16:32Z"
            name: "test-namespace"
            resourceVersion: "509635"
            selfLink: "/api/v1/namespaces/test-namespace"
            uid: "6dbd394e-b328-11e5-9a02-42010af0013a"
        spec:
            finalizers:
                - kubernetes
        status:
            phase: "Active"


MAINTAINERS: Eric Johnson (@erjohnso) <erjohnso@google.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> LAMBDA    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/lambda.py)

  Allows for the management of Lambda functions.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- dead_letter_arn
        The parent object that contains the target Amazon Resource Name (ARN) of an Amazon SQS queue or Amazon SNS topic.
        [Default: None]
- description
        A short, user-defined function description. Lambda does not use this value. Assign a meaningful description as
        you see fit.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- environment_variables
        A dictionary of environment variables the Lambda function is given.
        [Default: None]
- handler
        The function within your code that Lambda calls to begin execution
        [Default: None]
- memory_size
        The amount of memory, in MB, your Lambda function is given
        [Default: 128]
= name
        The name you want to assign to the function you are uploading. Cannot be changed.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- role
        The Amazon Resource Name (ARN) of the IAM role that Lambda assumes when it executes your function to access any
        other Amazon Web Services (AWS) resources. You may use the bare ARN if the role belongs to the same AWS account.
        [Default: None]
= runtime
        The runtime environment for the Lambda function you are uploading. Required when creating a function. Use
        parameters as described in boto3 docs. Current example runtime environments are nodejs, nodejs4.3, java8 or
        python2.7

- s3_bucket
        Amazon S3 bucket name where the .zip file containing your deployment package is stored
        [Default: None]
- s3_key
        The Amazon S3 object (the deployment package) key name you want to upload
        [Default: None]
- s3_object_version
        The Amazon S3 object (the deployment package) version you want to upload.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or delete Lambda function
        (Choices: present, absent)[Default: present]
- timeout
        The function execution time at which Lambda should terminate the function.
        [Default: 3]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_security_group_ids
        List of VPC security group IDs to associate with the Lambda function. Required when vpc_subnet_ids is used.
        [Default: None]
- vpc_subnet_ids
        List of subnet IDs to run Lambda function in. Use this option if you need to access resources in your VPC. Leave
        empty if you don't want to run the function in a VPC.
        [Default: None]
- zip_file
        A .zip file containing your deployment package
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
# Create Lambda functions
tasks:
- name: looped creation
  lambda:
    name: '{{ item.name }}'
    state: present
    zip_file: '{{ item.zip_file }}'
    runtime: 'python2.7'
    role: 'arn:aws:iam::987654321012:role/lambda_basic_execution'
    handler: 'hello_python.my_handler'
    vpc_subnet_ids:
    - subnet-123abcde
    - subnet-edcba321
    vpc_security_group_ids:
    - sg-123abcde
    - sg-edcba321
    environment_variables: '{{ item.env_vars }}'
  with_items:
    - name: HelloWorld
      zip_file: hello-code.zip
      env_vars:
        key1: "first"
        key2: "second"
    - name: ByeBye
      zip_file: bye-code.zip
      env_vars:
        key1: "1"
        key2: "2"

# Basic Lambda function deletion
tasks:
- name: Delete Lambda functions HelloWorld and ByeBye
  lambda:
    name: '{{ item }}'
    state: absent
  with_items:
    - HelloWorld
    - ByeBye

RETURN VALUES:
output:
  description: the data returned by get_function in boto3
  returned: success
  type: dict
  sample:
    'code':
      {
        'location': 'an S3 URL',
        'repository_type': 'S3',
      }
    'configuration':
      {
        'function_name': 'string',
        'function_arn': 'string',
        'runtime': 'nodejs',
        'role': 'string',
        'handler': 'string',
        'code_size': 123,
        'description': 'string',
        'timeout': 123,
        'memory_size': 123,
        'last_modified': 'string',
        'code_sha256': 'string',
        'version': 'string',
      }


MAINTAINERS: Steyn Huizinga (@steynovich)

METADATA:
	Status: ['preview']
	Supported_by: community
> LAMBDA_ALIAS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/lambda_alias.py)

  This module allows the management of AWS Lambda functions aliases via the Ansible framework.  It is idempotent and
  supports "Check" mode.    Use module [lambda] to manage the lambda function itself and [lambda_event] to manage event
  source mappings.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- description
        A short, user-defined function alias description.
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= function_name
        The name of the function alias.

= name
        Name of the function alias.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Describes the desired state.
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- version
        Version associated with the Lambda function alias. A value of 0 (or omitted parameter) sets the alias to the
        $LATEST version.
        [Default: (null)]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
---
# Simple example to create a lambda function and publish a version
- hosts: localhost
  gather_facts: no
  vars:
    state: present
    project_folder: /path/to/deployment/package
    deployment_package: lambda.zip
    account: 123456789012
    production_version: 5
  tasks:
  - name: AWS Lambda Function
    lambda:
      state: "{{ state | default('present') }}"
      name: myLambdaFunction
      publish: True
      description: lambda function description
      code_s3_bucket: package-bucket
      code_s3_key: "lambda/{{ deployment_package }}"
      local_path: "{{ project_folder }}/{{ deployment_package }}"
      runtime: python2.7
      timeout: 5
      handler: lambda.handler
      memory_size: 128
      role: "arn:aws:iam::{{ account }}:role/API2LambdaExecRole"

  - name: show results
    debug:
      var: lambda_facts

# The following will set the Dev alias to the latest version ($LATEST) since version is omitted (or = 0)
  - name: "alias 'Dev' for function {{ lambda_facts.FunctionName }} "
    lambda_alias:
      state: "{{ state | default('present') }}"
      function_name: "{{ lambda_facts.FunctionName }}"
      name: Dev
      description: Development is $LATEST version

# The QA alias will only be created when a new version is published (i.e. not = '$LATEST')
  - name: "alias 'QA' for function {{ lambda_facts.FunctionName }} "
    lambda_alias:
      state: "{{ state | default('present') }}"
      function_name: "{{ lambda_facts.FunctionName }}"
      name: QA
      version: "{{ lambda_facts.Version }}"
      description: "QA is version {{ lambda_facts.Version }}"
    when: lambda_facts.Version != "$LATEST"

# The Prod alias will have a fixed version based on a variable
  - name: "alias 'Prod' for function {{ lambda_facts.FunctionName }} "
    lambda_alias:
      state: "{{ state | default('present') }}"
      function_name: "{{ lambda_facts.FunctionName }}"
      name: Prod
      version: "{{ production_version }}"
      description: "Production is version {{ production_version }}"

RETURN VALUES:
---
alias_arn:
    description: Full ARN of the function, including the alias
    returned: success
    type: string
    sample: arn:aws:lambda:us-west-2:123456789012:function:myFunction:dev
description:
    description: A short description of the alias
    returned: success
    type: string
    sample: The development stage for my hot new app
function_version:
    description: The qualifier that the alias refers to
    returned: success
    type: string
    sample: $LATEST
name:
    description: The name of the alias assigned
    returned: success
    type: string
    sample: dev


MAINTAINERS: Pierre Jodouin (@pjodouin), Ryan Scott Brown (@ryansb)

METADATA:
	Status: ['preview']
	Supported_by: community
> LAMBDA_EVENT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/lambda_event.py)

  This module allows the management of AWS Lambda function event source mappings such as DynamoDB and Kinesis stream
  events via the Ansible framework. These event source mappings are relevant only in the AWS Lambda pull model, where AWS
  Lambda invokes the function. It is idempotent and supports "Check" mode.  Use module [lambda] to manage the lambda
  function itself and [lambda_alias] to manage function aliases.

Options (= is mandatory):

= alias
        Name of the function alias. Mutually exclusive with `version'.

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- event_source
        Source of the event that triggers the lambda function.
        (Choices: stream)[Default: stream]
= lambda_function_arn
        The name or ARN of the lambda function.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= source_params
        Sub-parameters required for event source.
        `== stream event source =='
        `source_arn' The Amazon Resource Name (ARN) of the Kinesis or DynamoDB stream that is the event source.
        `enabled' Indicates whether AWS Lambda should begin polling the event source. Default is True.
        `batch_size' The largest number of records that AWS Lambda will retrieve from your event source at the time of
        invoking your function. Default is 100.
        `starting_position' The position in the stream where AWS Lambda should start reading. Choices are TRIM_HORIZON or
        LATEST.

= state
        Describes the desired state.
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- version
        Version of the Lambda function. Mutually exclusive with `alias'.
        [Default: (null)]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
---
# Example that creates a lambda event notification for a DynamoDB stream
- hosts: localhost
  gather_facts: no
  vars:
    state: present
  tasks:
  - name: DynamoDB stream event mapping
    lambda_event:
      state: "{{ state | default('present') }}"
      event_source: stream
      function_name: "{{ function_name }}"
      alias: Dev
      source_params:
        source_arn: arn:aws:dynamodb:us-east-1:123456789012:table/tableName/stream/2016-03-19T19:51:37.457
        enabled: True
        batch_size: 100
        starting_position: TRIM_HORIZON

  - name: Show source event
    debug:
      var: lambda_stream_events

RETURN VALUES:
---
lambda_stream_events:
    description: list of dictionaries returned by the API describing stream event mappings
    returned: success
    type: list


MAINTAINERS: Pierre Jodouin (@pjodouin), Ryan Brown (@ryansb)

METADATA:
	Status: ['preview']
	Supported_by: community
> LAMBDA_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/lambda_facts.py)

  Gathers various details related to Lambda functions, including aliases, versions and event source mappings. Use module
  [lambda] to manage the lambda function itself, [lambda_alias] to manage function aliases and [lambda_event] to manage
  lambda event source mappings.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- event_source_arn
        For query type 'mappings', this is the Amazon Resource Name (ARN) of the Amazon Kinesis or DynamoDB stream.
        [Default: None]
- function_name
        The name of the lambda function for which facts are requested.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
= query
        Specifies the resource type for which to gather facts.  Leave blank to retrieve all facts.
        (Choices: aliases, all, config, mappings, policy, versions)[Default: all]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, python >= 2.6

EXAMPLES:
---
# Simple example of listing all info for a function
- name: List all for a specific function
  lambda_facts:
    query: all
    function_name: myFunction
  register: my_function_details
# List all versions of a function
- name: List function versions
  lambda_facts:
    query: versions
    function_name: myFunction
  register: my_function_versions
# List all lambda function versions
- name: List all function
  lambda_facts:
    query: all
    max_items: 20
- name: show Lambda facts
  debug:
    var: lambda_facts

RETURN VALUES:
---
lambda_facts:
    description: lambda facts
    returned: success
    type: dict
lambda_facts.function:
    description: lambda function list
    returned: success
    type: dict
lambda_facts.function.TheName:
    description: lambda function information, including event, mapping, and version information
    returned: success
    type: dict


MAINTAINERS: Pierre Jodouin (@pjodouin)

METADATA:
	Status: ['preview']
	Supported_by: community
> LAYMAN    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/layman.py)

  Uses Layman to manage an additional repositories for the Portage package manager on Gentoo Linux. Please note that
  Layman must be installed on a managed node prior using this module.

Options (= is mandatory):

- list_url
        An URL of the alternative overlays list that defines the overlay to install. This list will be fetched and saved
        under `${overlay_defs}'/${name}.xml), where `overlay_defs' is readed from the Layman's configuration.
        [Default: (null)]
= name
        The overlay id to install, synchronize, or uninstall. Use 'ALL' to sync all of the installed overlays (can be
        used only when `state=updated').

- state
        Whether to install (`present'), sync (`updated'), or uninstall (`absent') the overlay.
        (Choices: present, absent, updated)[Default: present]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be set to `no' when no other option exists.
        Prior to 1.9.3 the code defaulted to `no'.
        (Choices: yes, no)[Default: yes]
Requirements:  python >= 2.6, layman python module

EXAMPLES:
# Install the overlay 'mozilla' which is on the central overlays list.
- layman:
    name: mozilla

# Install the overlay 'cvut' from the specified alternative list.
- layman:
    name: cvut
    list_url: 'http://raw.github.com/cvut/gentoo-overlay/master/overlay.xml'

# Update (sync) the overlay 'cvut', or install if not installed yet.
- layman:
    name: cvut
    list_url: 'http://raw.github.com/cvut/gentoo-overlay/master/overlay.xml'
    state: updated

# Update (sync) all of the installed overlays.
- layman:
    name: ALL
    state: updated

# Uninstall the overlay 'cvut'.
- layman:
    name: cvut
    state: absent


MAINTAINERS: Jakub Jirutka (@jirutka)

METADATA:
	Status: ['preview']
	Supported_by: community
> LDAP_ATTR    (/usr/lib/python2.7/site-packages/ansible/modules/network/ldap_attr.py)

  Add or remove LDAP attribute values.

Options (= is mandatory):

- bind_dn
        A DN to bind with. If this is omitted, we'll try a SASL bind with the EXTERNAL mechanism. If this is blank, we'll
        use an anonymous bind.
        [Default: None]
- bind_pw
        The password to use with `bind_dn'.
        [Default: None]
= dn
        The DN of the entry to modify.

= name
        The name of the attribute to modify.

- server_uri
        A URI to the LDAP server. The default value lets the underlying LDAP client library look for a UNIX domain socket
        in its default location.
        [Default: ldapi:///]
- start_tls
        If true, we'll use the START_TLS LDAP extension.
        (Choices: yes, no)[Default: no]
- state
        The state of the attribute values. If `present', all given values will be added if they're missing. If `absent',
        all given values will be removed if present. If `exact', the set of values will be forced to exactly those
        provided and no others. If `state=exact' and `value' is empty, all values for this attribute will be removed.
        (Choices: present, absent, exact)[Default: present]
= values
        The value(s) to add or remove. This can be a string or a list of strings. The complex argument format is required
        in order to pass a list of strings (see examples).

Notes:
  * This only deals with attributes on existing entries. To add or remove whole entries, see [ldap_entry].
  * The default authentication settings will attempt to use a SASL EXTERNAL bind over a UNIX domain socket. This
        works well with the default Ubuntu install for example, which includes a cn=peercred,cn=external,cn=auth
        ACL rule allowing root to modify the server configuration. If you need to use a simple bind to access your
        server, pass the credentials in `bind_dn' and `bind_pw'.
  * For `state=present' and `state=absent', all value comparisons are performed on the server for maximum accuracy.
        For `state=exact', values have to be compared in Python, which obviously ignores LDAP matching rules. This
        should work out in most cases, but it is theoretically possible to see spurious changes when target and
        actual values are semantically identical but lexically distinct.
Requirements:  python-ldap

EXAMPLES:
- name: Configure directory number 1 for example.com
  ldap_attr:
    dn: olcDatabase={1}hdb,cn=config
    name: olcSuffix
    values: dc=example,dc=com
    state: exact

# The complex argument format is required here to pass a list of ACL strings.
- name: Set up the ACL
  ldap_attr:
    dn: olcDatabase={1}hdb,cn=config
    name: olcAccess
    values:
      - >-
        {0}to attrs=userPassword,shadowLastChange
        by self write
        by anonymous auth
        by dn="cn=admin,dc=example,dc=com" write
        by * none'
      - >-
        {1}to dn.base="dc=example,dc=com"
        by dn="cn=admin,dc=example,dc=com" write
        by * read
    state: exact

- name: Declare some indexes
  ldap_attr:
    dn: olcDatabase={1}hdb,cn=config
    name: olcDbIndex
    values: "{{ item }}"
  with_items:
    - objectClass eq
    - uid eq

- name: Set up a root user, which we can use later to bootstrap the directory
  ldap_attr:
    dn: olcDatabase={1}hdb,cn=config
    name: "{{ item.key }}"
    values: "{{ item.value }}"
    state: exact
  with_dict:
    olcRootDN: cn=root,dc=example,dc=com
    olcRootPW: "{SSHA}tabyipcHzhwESzRaGA7oQ/SDoBZQOGND"

- name: Get rid of an unneeded attribute
  ldap_attr:
    dn: uid=jdoe,ou=people,dc=example,dc=com
    name: shadowExpire
    values: ""
    state: exact
    server_uri: ldap://localhost/
    bind_dn: cn=admin,dc=example,dc=com
    bind_pw: password

#
# The same as in the previous example but with the authentication details
# stored in the ldap_auth variable:
#
# ldap_auth:
#   server_uri: ldap://localhost/
#   bind_dn: cn=admin,dc=example,dc=com
#   bind_pw: password
- name: Get rid of an unneeded attribute
  ldap_attr:
    dn: uid=jdoe,ou=people,dc=example,dc=com
    name: shadowExpire
    values: ""
    state: exact
    params: "{{ ldap_auth }}"

RETURN VALUES:
modlist:
  description: list of modified parameters
  returned: success
  type: list
  sample: '[[2, "olcRootDN", ["cn=root,dc=example,dc=com"]]]'


MAINTAINERS: Jiri Tyr (@jtyr)

METADATA:
	Status: ['preview']
	Supported_by: community
> LDAP_ENTRY    (/usr/lib/python2.7/site-packages/ansible/modules/network/ldap_entry.py)

  Add or remove LDAP entries. This module only asserts the existence or non-existence of an LDAP entry, not its
  attributes. To assert the attribute values of an entry, see [ldap_attr].

Options (= is mandatory):

- attributes
        If `state=present', attributes necessary to create an entry. Existing entries are never modified. To assert
        specific attribute values on an existing entry, use [ldap_attr] module instead.
        [Default: None]
- bind_dn
        A DN to bind with. If this is omitted, we'll try a SASL bind with the EXTERNAL mechanism. If this is blank, we'll
        use an anonymous bind.
        [Default: None]
- bind_pw
        The password to use with `bind_dn'.
        [Default: None]
= dn
        The DN of the entry to add or remove.

- objectClass
        If `state=present', value or list of values to use when creating the entry. It can either be a string or an
        actual list of strings.
        [Default: None]
- params
        List of options which allows to overwrite any of the task or the `attributes' options. To remove an option, set
        the value of the option to `null'.
        [Default: None]
- server_uri
        A URI to the LDAP server. The default value lets the underlying LDAP client library look for a UNIX domain socket
        in its default location.
        [Default: ldapi:///]
- start_tls
        If true, we'll use the START_TLS LDAP extension.
        (Choices: yes, no)[Default: no]
- state
        The target state of the entry.
        (Choices: present, absent)[Default: present]
Notes:
  * The default authentication settings will attempt to use a SASL EXTERNAL bind over a UNIX domain socket. This
        works well with the default Ubuntu install for example, which includes a cn=peercred,cn=external,cn=auth
        ACL rule allowing root to modify the server configuration. If you need to use a simple bind to access your
        server, pass the credentials in `bind_dn' and `bind_pw'.
Requirements:  python-ldap

EXAMPLES:
- name: Make sure we have a parent entry for users
  ldap_entry:
    dn: ou=users,dc=example,dc=com
    objectClass: organizationalUnit

- name: Make sure we have an admin user
  ldap_entry:
    dn: cn=admin,dc=example,dc=com
    objectClass:
      - simpleSecurityObject
      - organizationalRole
    attributes:
      description: An LDAP administrator
      userPassword: "{SSHA}tabyipcHzhwESzRaGA7oQ/SDoBZQOGND"

- name: Get rid of an old entry
  ldap_entry:
    dn: ou=stuff,dc=example,dc=com
    state: absent
    server_uri: ldap://localhost/
    bind_dn: cn=admin,dc=example,dc=com
    bind_pw: password

#
# The same as in the previous example but with the authentication details
# stored in the ldap_auth variable:
#
# ldap_auth:
#   server_uri: ldap://localhost/
#   bind_dn: cn=admin,dc=example,dc=com
#   bind_pw: password
- name: Get rid of an old entry
  ldap_entry:
    dn: ou=stuff,dc=example,dc=com
    state: absent
    params: "{{ ldap_auth }}"

RETURN VALUES:
# Default return values


MAINTAINERS: Jiri Tyr (@jtyr)

METADATA:
	Status: ['preview']
	Supported_by: community
> LETSENCRYPT    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/letsencrypt.py)

  Create and renew SSL certificates with Let's Encrypt. Let’s Encrypt is a free, automated, and open certificate
  authority (CA), run for the public’s benefit. For details see https://letsencrypt.org. The current implementation
  supports the http-01, tls-sni-02 and dns-01 challenges. To use this module, it has to be executed at least twice.
  Either as two different tasks in the same run or during multiple runs. Between these two tasks you have to fulfill the
  required steps for the chosen challenge by whatever means necessary. For http-01 that means creating the necessary
  challenge file on the destination webserver. For dns-01 the necessary dns record has to be created. tls-sni-02 requires
  you to create a SSL certificate with the appropriate subjectAlternativeNames. It is `not' the responsibility of this
  module to perform these steps. For details on how to fulfill these challenges, you might have to read through
  https://tools.ietf.org/html/draft-ietf-acme-acme-02#section-7 Although the defaults are chosen so that the module can
  be used with the Let's Encrypt CA, the module can be used with any service using the ACME protocol.

Options (= is mandatory):

- account_email
        The email address associated with this account.
        It will be used for certificate expiration warnings.
        [Default: None]
= account_key
        File containing the the Let's Encrypt account RSA key.
        Can be created with `openssl rsa ...'.

- acme_directory
        The ACME directory to use. This is the entry point URL to access CA server API.
        For safety reasons the default is set to the Let's Encrypt staging server. This will create technically correct,
        but untrusted certificates.
        [Default: https://acme-staging.api.letsencrypt.org/directory]
- agreement
        URI to a terms of service document you agree to when using the ACME service at `acme_directory'.
        [Default: https://letsencrypt.org/documents/LE-SA-v1.1.1-August-1-2016.pdf]
- challenge
        The challenge to be performed.
        (Choices: http-01, dns-01, tls-sni-02)[Default: http-01]
= csr
        File containing the CSR for the new certificate.
        Can be created with `openssl csr ...'.
        The CSR may contain multiple Subject Alternate Names, but each one will lead to an individual challenge that must
        be fulfilled for the CSR to be signed.

- data
        The data to validate ongoing challenges.
        The value that must be used here will be provided by a previous use of this module.
        [Default: None]
= dest
        The destination file for the certificate.

- remaining_days
        The number of days the certificate must have left being valid. If `cert_days < remaining_days', then it will be
        renewed. If the certificate is not renewed, module return values will not include `challenge_data'.
        [Default: 10]
Requirements:  python >= 2.6, openssl

EXAMPLES:
- letsencrypt:
    account_key: /etc/pki/cert/private/account.key
    csr: /etc/pki/cert/csr/sample.com.csr
    dest: /etc/httpd/ssl/sample.com.crt
  register: sample_com_challenge

# perform the necessary steps to fulfill the challenge
# for example:
#
# - copy:
#     dest: /var/www/html/{{ sample_com_challenge['challenge_data']['sample.com']['http-01']['resource'] }}
#     content: "{{ sample_com_challenge['challenge_data']['sample.com']['http-01']['resource_value'] }}"
#     when: sample_com_challenge|changed

- letsencrypt:
    account_key: /etc/pki/cert/private/account.key
    csr: /etc/pki/cert/csr/sample.com.csr
    dest: /etc/httpd/ssl/sample.com.crt
    data: "{{ sample_com_challenge }}"

RETURN VALUES:
cert_days:
  description: the number of days the certificate remains valid.
  returned: success
challenge_data:
  description: per domain / challenge type challenge data
  returned: changed
  type: dictionary
  contains:
    resource:
      description: the challenge resource that must be created for validation
      returned: changed
      type: string
      sample: .well-known/acme-challenge/evaGxfADs6pSRb2LAv9IZf17Dt3juxGJ-PCt92wr-oA
    resource_value:
      description: the value the resource has to produce for the validation
      returned: changed
      type: string
      sample: IlirfxKKXA...17Dt3juxGJ-PCt92wr-oA
authorizations:
  description: ACME authorization data.
  returned: changed
  type: list
  contains:
      authorization:
        description: ACME authorization object. See https://tools.ietf.org/html/draft-ietf-acme-acme-02#section-6.1.2
        returned: success
        type: dict


MAINTAINERS: Michael Gruener (@mgruener)

METADATA:
	Status: ['preview']
	Supported_by: community
> LIBRATO_ANNOTATION    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/librato_annotation.py)

  Create an annotation event on the given annotation stream :name. If the annotation stream does not exist, it will be
  created automatically

Options (= is mandatory):

= api_key
        Librato account api key

- description
        The description contains extra meta-data about a particular annotation
        The description should contain specifics on the individual annotation e.g. Deployed 9b562b2 shipped new feature
        foo!
        [Default: (null)]
- end_time
        The unix timestamp indicating the the time at which the event referenced by this annotation ended
        For events that have a duration, this is a useful way to annotate the duration of the event
        [Default: (null)]
= links
        See examples

- name
        The annotation stream name
        If the annotation stream does not exist, it will be created automatically
        [Default: (null)]
- source
        A string which describes the originating source of an annotation when that annotation is tracked across multiple
        members of a population
        [Default: (null)]
- start_time
        The unix timestamp indicating the the time at which the event referenced by this annotation started
        [Default: (null)]
= title
        The title of an annotation is a string and may contain spaces
        The title should be a short, high-level summary of the annotation e.g. v45 Deployment

= user
        Librato account username

EXAMPLES:
# Create a simple annotation event with a source
- librato_annotation:
    user: user@example.com
    api_key: XXXXXXXXXXXXXXXXX
    title: App Config Change
    source: foo.bar
    description: This is a detailed description of the config change

# Create an annotation that includes a link
- librato_annotation:
    user: user@example.com
    api_key: XXXXXXXXXXXXXXXXXX
    name: code.deploy
    title: app code deploy
    description: this is a detailed description of a deployment
    links:
      - rel: example
        href: http://www.example.com/deploy

# Create an annotation with a start_time and end_time
- librato_annotation:
    user: user@example.com
    api_key: XXXXXXXXXXXXXXXXXX
    name: maintenance
    title: Maintenance window
    description: This is a detailed description of maintenance
    start_time: 1395940006
    end_time: 1395954406


MAINTAINERS: Seth Edwards (@sedward)

METADATA:
	Status: ['preview']
	Supported_by: community
> LINEINFILE    (/usr/lib/python2.7/site-packages/ansible/modules/files/lineinfile.py)

  This module will search a file for a line, and ensure that it is present or absent. This is primarily useful when you
  want to change a single line in a file only. See the [replace] module if you want to change multiple, similar lines or
  check [blockinfile] if you want to insert/update/remove a block of lines in a file. For other cases, see the [copy] or
  [template] modules.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- backrefs
        Used with `state=present'. If set, line can contain backreferences (both positional and named) that will get
        populated if the `regexp' matches. This flag changes the operation of the module slightly; `insertbefore' and
        `insertafter' will be ignored, and if the `regexp' doesn't match anywhere in the file, the file will be left
        unchanged. If the `regexp' does match, the last matching line will be replaced by the expanded line parameter.
        (Choices: yes, no)[Default: no]
- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- create
        Used with `state=present'. If specified, the file will be created if it does not already exist. By default it
        will fail if the file is missing.
        (Choices: yes, no)[Default: no]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- insertafter
        Used with `state=present'. If specified, the line will be inserted after the last match of specified regular
        expression. A special value is available; `EOF' for inserting the line at the end of the file. If specified
        regular expression has no matches, EOF will be used instead. May not be used with `backrefs'.
        (Choices: EOF, *regex*)[Default: EOF]
- insertbefore
        Used with `state=present'. If specified, the line will be inserted before the last match of specified regular
        expression. A value is available; `BOF' for inserting the line at the beginning of the file. If specified regular
        expression has no matches, the line will be inserted at the end of the file.  May not be used with `backrefs'.
        (Choices: BOF, *regex*)[Default: (null)]
- line
        Required for `state=present'. The line to insert/replace into the file. If `backrefs' is set, may contain
        backreferences that will get expanded with the `regexp' capture groups if the regexp matches.
        [Default: (null)]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- others
        All arguments accepted by the [file] module also work here.
        [Default: (null)]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
= path
        The file to modify.
        Before 2.3 this option was only usable as `dest', `destfile' and `name'.

- regexp
        The regular expression to look for in every line of the file. For `state=present', the pattern to replace if
        found; only the last line found will be replaced. For `state=absent', the pattern of the line to remove.  Uses
        Python regular expressions; see http://docs.python.org/2/library/re.html.
        [Default: (null)]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- state
        Whether the line should be there or not.
        (Choices: present, absent)[Default: present]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- validate
        The validation command to run before copying into place. The path to the file to validate is passed in via '%s'
        which must be present as in the example below. The command is passed securely so shell features like expansion
        and pipes won't work.
        [Default: None]
Notes:
  * As of Ansible 2.3, the `dest' option has been changed to `path' as default, but `dest' still works as well.
EXAMPLES:
# Before 2.3, option 'dest', 'destfile' or 'name' was used instead of 'path'
- lineinfile:
    path: /etc/selinux/config
    regexp: '^SELINUX='
    line: 'SELINUX=enforcing'

- lineinfile:
    path: /etc/sudoers
    state: absent
    regexp: '^%wheel'

- lineinfile:
    path: /etc/hosts
    regexp: '^127\.0\.0\.1'
    line: '127.0.0.1 localhost'
    owner: root
    group: root
    mode: 0644

- lineinfile:
    path: /etc/httpd/conf/httpd.conf
    regexp: '^Listen '
    insertafter: '^#Listen '
    line: 'Listen 8080'

- lineinfile:
    path: /etc/services
    regexp: '^# port for http'
    insertbefore: '^www.*80/tcp'
    line: '# port for http by default'

# Add a line to a file if it does not exist, without passing regexp
- lineinfile:
    path: /tmp/testfile
    line: '192.168.1.99 foo.lab.net foo'

# Fully quoted because of the ': ' on the line. See the Gotchas in the YAML docs.
- lineinfile:
    path: /etc/sudoers
    state: present
    regexp: '^%wheel\s'
    line: '%wheel ALL=(ALL) NOPASSWD: ALL'

# Yaml requires escaping backslashes in double quotes but not in single quotes
- lineinfile:
    path: /opt/jboss-as/bin/standalone.conf
    regexp: '^(.*)Xms(\\d+)m(.*)$'
    line: '\1Xms${xms}m\3'
    backrefs: yes

# Validate the sudoers file before saving
- lineinfile:
    path: /etc/sudoers
    state: present
    regexp: '^%ADMIN ALL='
    line: '%ADMIN ALL=(ALL) NOPASSWD: ALL'
    validate: 'visudo -cf %s'


MAINTAINERS: Daniel Hokka Zakrissoni (@dhozac), Ahti Kitsik (@ahtik)

METADATA:
	Status: ['preview']
	Supported_by: core
> LINODE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/linode/linode.py)

  creates / deletes a Linode Public Cloud instance and optionally waits for it to be 'running'.

Options (= is mandatory):

- additional_disks
        List of dictionaries for creating additional disks that are added to the Linode configuration settings.
        Dictionary takes Size, Label, Type. Size is in MB.
        [Default: None]
- alert_bwin_enabled
        Set status of bandwidth in alerts.
        (Choices: True, False)[Default: True]
- alert_bwin_threshold
        Set threshold in MB of bandwidth in alerts.
        [Default: None]
- alert_bwout_enabled
        Set status of bandwidth out alerts.
        (Choices: True, False)[Default: True]
- alert_bwout_threshold
        Set threshold in MB of bandwidth out alerts.
        [Default: None]
- alert_bwquota_enabled
        Set status of bandwidth quota alerts as percentage of network tranfer quota.
        (Choices: True, False)[Default: True]
- alert_bwquota_threshold
        Set threshold in MB of bandwidth quota alerts.
        [Default: None]
- alert_cpu_enabled
        Set status of receiving CPU usage alerts.
        (Choices: True, False)[Default: True]
- alert_cpu_threshold
        Set percentage threshold for receiving CPU usage alerts. Each CPU core adds 100% to total.
        [Default: None]
- alert_diskio_enabled
        Set status of receiving disk IO alerts.
        (Choices: True, False)[Default: True]
- alert_diskio_threshold
        Set threshold for average IO ops/sec over 2 hour period.
        [Default: None]
- api_key
        Linode API key
        [Default: None]
- backupweeklyday
        Integer value for what day of the week to store weekly backups.
        [Default: None]
- datacenter
        datacenter to create an instance in (Linode Datacenter)
        [Default: None]
- displaygroup
        Add the instance to a Display Group in Linode Manager
        [Default: None]
- distribution
        distribution to use for the instance (Linode Distribution)
        [Default: None]
- linode_id
        Unique ID of a linode server
        [Default: None]
- name
        Name to give the instance (alphanumeric, dashes, underscore)
        To keep sanity on the Linode Web Console, name is prepended with LinodeID_
        [Default: None]
- password
        root password to apply to a new server (auto generated if missing)
        [Default: None]
- payment_term
        payment term to use for the instance (payment term in months)
        (Choices: 1, 12, 24)[Default: 1]
- plan
        plan to use for the instance (Linode plan)
        [Default: None]
- private_ip
        Add private IPv4 address when Linode is created.
        (Choices: yes, no)[Default: no]
- ssh_pub_key
        SSH public key applied to root user
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, active, started, absent, deleted, stopped, restarted)[Default: present]
- swap
        swap size in MB
        [Default: 512]
- wait
        wait for the instance to be in state 'running' before returning
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
- watchdog
        Set status of Lassie watchdog.
        (Choices: True, False)[Default: True]
Notes:
  * LINODE_API_KEY env variable can be used instead
Requirements:  python >= 2.6, linode-python, pycurl

EXAMPLES:
# Create a server with a private IP Address
- local_action:
     module: linode
     api_key: 'longStringFromLinodeApi'
     name: linode-test1
     plan: 1
     datacenter: 2
     distribution: 99
     password: 'superSecureRootPassword'
     private_ip: yes
     ssh_pub_key: 'ssh-rsa qwerty'
     swap: 768
     wait: yes
     wait_timeout: 600
     state: present

# Fully configure new server
- local_action:
     module: linode
     api_key: 'longStringFromLinodeApi'
     name: linode-test1
     plan: 4
     datacenter: 2
     distribution: 99
     password: 'superSecureRootPassword'
     private_ip: yes
     ssh_pub_key: 'ssh-rsa qwerty'
     swap: 768
     wait: yes
     wait_timeout: 600
     state: present
     alert_bwquota_enabled: True
     alert_bwquota_threshold: 80
     alert_bwin_enabled: True
     alert_bwin_threshold: 10
     alert_cpu_enabled: True
     alert_cpu_threshold: 210
     alert_diskio_enabled: True
     alert_bwout_enabled: True
     alert_bwout_threshold: 10
     alert_diskio_enabled: True
     alert_diskio_threshold: 10000
     backupweeklyday: 1
     backupwindow: 2
     displaygroup: 'test'
     additional_disks:
      - {Label: 'disk1', Size: 2500, Type: 'raw'}
      - {Label: 'newdisk', Size: 2000}
     watchdog: True

# Ensure a running server (create if missing)
- local_action:
     module: linode
     api_key: 'longStringFromLinodeApi'
     name: linode-test1
     linode_id: 12345678
     plan: 1
     datacenter: 2
     distribution: 99
     password: 'superSecureRootPassword'
     ssh_pub_key: 'ssh-rsa qwerty'
     swap: 768
     wait: yes
     wait_timeout: 600
     state: present

# Delete a server
- local_action:
     module: linode
     api_key: 'longStringFromLinodeApi'
     name: linode-test1
     linode_id: 12345678
     state: absent

# Stop a server
- local_action:
     module: linode
     api_key: 'longStringFromLinodeApi'
     name: linode-test1
     linode_id: 12345678
     state: stopped

# Reboot a server
- local_action:
     module: linode
     api_key: 'longStringFromLinodeApi'
     name: linode-test1
     linode_id: 12345678
     state: restarted


MAINTAINERS: Vincent Viallet (@zbal)

METADATA:
	Status: ['preview']
	Supported_by: community
> LLDP    (/usr/lib/python2.7/site-packages/ansible/modules/network/lldp.py)

  Reads data out of lldpctl

Notes:
  * Requires lldpd running and lldp enabled on switches
Requirements:  lldpctl

EXAMPLES:
# Retrieve switch/port information
 - name: Gather information from lldp
   lldp:

 - name: Print each switch/port
   debug:
    msg: "{{ lldp[item]['chassis']['name'] }} / {{ lldp[item]['port']['ifalias'] }}"
   with_items: "{{ lldp.keys() }}"

# TASK: [Print each switch/port] ***********************************************************
# ok: [10.13.0.22] => (item=eth2) => {"item": "eth2", "msg": "switch1.example.com / Gi0/24"}
# ok: [10.13.0.22] => (item=eth1) => {"item": "eth1", "msg": "switch2.example.com / Gi0/3"}
# ok: [10.13.0.22] => (item=eth0) => {"item": "eth0", "msg": "switch3.example.com / Gi0/3"}



MAINTAINERS: Andy Hill (@andyhky)

METADATA:
	Status: ['preview']
	Supported_by: community
> LOCALE_GEN    (/usr/lib/python2.7/site-packages/ansible/modules/system/locale_gen.py)

  Manages locales by editing /etc/locale.gen and invoking locale-gen.

Options (= is mandatory):

= name
        Name and encoding of the locale, such as "en_GB.UTF-8".
        [Default: None]
- state
        Whether the locale shall be present.
        (Choices: present, absent)[Default: present]
EXAMPLES:
# Ensure a locale exists.
- locale_gen:
    name: de_CH.UTF-8
    state: present


MAINTAINERS: Augustus Kling (@AugustusKling)

METADATA:
	Status: ['preview']
	Supported_by: community
> LOGENTRIES    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/logentries.py)

  Sends logs to LogEntries in realtime

Options (= is mandatory):

- logtype
        type of the log
        [Default: (null)]
- name
        name of the log
        [Default: (null)]
= path
        path to a log file

- state
        following state of the log
        (Choices: present, absent)[Default: present]
Notes:
  * Requires the LogEntries agent which can be installed following the instructions at logentries.com
EXAMPLES:
# Track nginx logs
- logentries:
    path: /var/log/nginx/access.log
    state: present
    name: nginx-access-log

# Stop tracking nginx logs
- logentries:
    path: /var/log/nginx/error.log
    state: absent


MAINTAINERS: Ivan Vanderbyl (@ivanvanderbyl)

METADATA:
	Status: ['preview']
	Supported_by: community
> LOGICMONITOR    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/logicmonitor.py)

  LogicMonitor is a hosted, full-stack, infrastructure monitoring platform. This module manages hosts, host groups, and
  collectors within your LogicMonitor account.

Options (= is mandatory):

= action
        The action you wish to perform on target.
        Add: Add an object to your LogicMonitor account.
        Remove: Remove an object from your LogicMonitor account.
        Update: Update properties, description, or groups (target=host) for an object in your LogicMonitor account.
        SDT: Schedule downtime for an object in your LogicMonitor account.
        (Choices: add, remove, update, sdt)[Default: None]
- alertenable
        A boolean flag to turn alerting on or off for an object.
        Optional for managing all hosts (action=add or action=update).
        (Choices: True, False)[Default: True]
- collector
        The fully qualified domain name of a collector in your LogicMonitor account.
        This is required for the creation of a LogicMonitor host (target=host action=add).
        This is required for updating, removing or scheduling downtime for hosts if 'displayname' isn't specified
        (target=host action=update action=remove action=sdt).
        [Default: None]
= company
        The LogicMonitor account company name. If you would log in to your account at "superheroes.logicmonitor.com" you
        would use "superheroes."
        [Default: None]
- description
        The long text description of the object in your LogicMonitor account.
        Optional for managing hosts and host groups (target=host or target=hostgroup; action=add or action=update).
        [Default: ]
- displayname
        The display name of a host in your LogicMonitor account or the desired display name of a device to manage.
        Optional for managing hosts (target=host).
        [Default: hostname -f]
- duration
        The duration (minutes) of the Scheduled Down Time (SDT).
        Optional for putting an object into SDT (action=sdt).
        [Default: 30]
- fullpath
        The fullpath of the host group object you would like to manage.
        Recommend running on a single Ansible host.
        Required for management of LogicMonitor host groups (target=hostgroup).
        [Default: None]
- groups
        A list of groups that the host should be a member of.
        Optional for managing hosts (target=host; action=add or action=update).
        [Default: []]
- hostname
        The hostname of a host in your LogicMonitor account, or the desired hostname of a device to manage.
        Optional for managing hosts (target=host).
        [Default: hostname -f]
- id
        ID of the datasource to target.
        Required for management of LogicMonitor datasources (target=datasource).
        [Default: None]
= password
        The password of the specified LogicMonitor user
        [Default: None]
- properties
        A dictionary of properties to set on the LogicMonitor host or host group.
        Optional for managing hosts and host groups (target=host or target=hostgroup; action=add or action=update).
        This parameter will add or update existing properties in your LogicMonitor account.
        [Default: {}]
- starttime
        The time that the Scheduled Down Time (SDT) should begin.
        Optional for managing SDT (action=sdt).
        Y-m-d H:M
        [Default: Now]
= target
        The type of LogicMonitor object you wish to manage.
        Collector: Perform actions on a LogicMonitor collector.
        NOTE You should use Ansible service modules such as [service] or [supervisorctl] for managing the Collector
        'logicmonitor-agent' and 'logicmonitor-watchdog' services. Specifically, you'll probably want to start these
        services after a Collector add and stop these services before a Collector remove.
        Host: Perform actions on a host device.
        Hostgroup: Perform actions on a LogicMonitor host group.
        NOTE Host and Hostgroup tasks should always be performed via delegate_to: localhost. There are no benefits to
        running these tasks on the remote host and doing so will typically cause problems.
        (Choices: collector, host, datsource, hostgroup)[Default: None]
= user
        A LogicMonitor user name. The module will authenticate and perform actions on behalf of this user.
        [Default: None]
Notes:
  * You must have an existing LogicMonitor account for this module to function.
Requirements:  An existing LogicMonitor account, Linux

EXAMPLES:
# example of adding a new LogicMonitor collector to these devices
---
- hosts: collectors
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Deploy/verify LogicMonitor collectors
    become: yes
    logicmonitor:
      target: collector
      action: add
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'

#example of adding a list of hosts into monitoring
---
- hosts: hosts
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Deploy LogicMonitor Host
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: host
      action: add
      collector: mycompany-Collector
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      groups: /servers/production,/datacenter1
      properties:
        snmp.community: secret
        dc: 1
        type: prod
    delegate_to: localhost

#example of putting a datasource in SDT
---
- hosts: localhost
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: SDT a datasource
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: datasource
      action: sdt
      id: 123
      duration: 3000
      starttime: '2017-03-04 05:06'
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'

#example of creating a hostgroup
---
- hosts: localhost
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Create a host group
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: hostgroup
      action: add
      fullpath: /servers/development
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      properties:
        snmp.community: commstring
        type: dev

#example of putting a list of hosts into SDT
---
- hosts: hosts
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: SDT hosts
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: host
      action: sdt
      duration: 3000
      starttime: '2016-11-10 09:08'
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      collector: mycompany-Collector
    delegate_to: localhost

#example of putting a host group in SDT
---
- hosts: localhost
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: SDT a host group
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: hostgroup
      action: sdt
      fullpath: /servers/development
      duration: 3000
      starttime: '2017-03-04 05:06'
      company=: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'

#example of updating a list of hosts
---
- hosts: hosts
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Update a list of hosts
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: host
      action: update
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      collector: mycompany-Collector
      groups: /servers/production,/datacenter5
      properties:
        snmp.community: commstring
        dc: 5
    delegate_to: localhost

#example of updating a hostgroup
---
- hosts: hosts
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Update a host group
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: hostgroup
      action: update
      fullpath: /servers/development
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      properties:
        snmp.community: hg
        type: dev
        status: test
    delegate_to: localhost

#example of removing a list of hosts from monitoring
---
- hosts: hosts
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Remove LogicMonitor hosts
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: host
      action: remove
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      collector: mycompany-Collector
    delegate_to: localhost

#example of removing a host group
---
- hosts: hosts
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Remove LogicMonitor development servers hostgroup
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: hostgroup
      action: remove
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      fullpath: /servers/development
    delegate_to: localhost
  - name: Remove LogicMonitor servers hostgroup
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: hostgroup
      action: remove
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      fullpath: /servers
    delegate_to: localhost
  - name: Remove LogicMonitor datacenter1 hostgroup
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: hostgroup
      action: remove
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      fullpath: /datacenter1
    delegate_to: localhost
  - name: Remove LogicMonitor datacenter5 hostgroup
    # All tasks except for target=collector should use delegate_to: localhost
    logicmonitor:
      target: hostgroup
      action: remove
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      fullpath: /datacenter5
    delegate_to: localhost

### example of removing a new LogicMonitor collector to these devices
---
- hosts: collectors
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Remove LogicMonitor collectors
    become: yes
    logicmonitor:
      target: collector
      action: remove
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'

#complete example
---
- hosts: localhost
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Create a host group
    logicmonitor:
      target: hostgroup
      action: add
      fullpath: /servers/production/database
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      properties:
        snmp.community: commstring
  - name: SDT a host group
    logicmonitor:
      target: hostgroup
      action: sdt
      fullpath: /servers/production/web
      duration: 3000
      starttime: '2012-03-04 05:06'
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'

- hosts: collectors
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: Deploy/verify LogicMonitor collectors
    logicmonitor:
      target: collector
      action: add
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
  - name: Place LogicMonitor collectors into 30 minute Scheduled downtime
    logicmonitor:
      target: collector
      action: sdt
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
  - name: Deploy LogicMonitor Host
    logicmonitor:
      target: host
      action: add
      collector: agent1.ethandev.com
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      properties:
        snmp.community: commstring
        dc: 1
      groups: /servers/production/collectors, /datacenter1
    delegate_to: localhost

- hosts: database-servers
  remote_user: '{{ username }}'
  vars:
    company: mycompany
    user: myusername
    password: mypassword
  tasks:
  - name: deploy logicmonitor hosts
    logicmonitor:
      target: host
      action: add
      collector: monitoring.dev.com
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
      properties:
        snmp.community: commstring
        type: db
        dc: 1
      groups: /servers/production/database, /datacenter1
    delegate_to: localhost
  - name: schedule 5 hour downtime for 2012-11-10 09:08
    logicmonitor:
      target: host
      action: sdt
      duration: 3000
      starttime: '2012-11-10 09:08'
      company: '{{ company }}'
      user: '{{ user }}'
      password: '{{ password }}'
    delegate_to: localhost

RETURN VALUES:
---
success:
    description: flag indicating that execution was successful
    returned: success
    type: boolean
    sample: True
...


MAINTAINERS: Ethan Culler-Mayeno (@ethanculler), Jeff Wozniak (@woz5999)

METADATA:
	Status: ['preview']
	Supported_by: community
> LOGICMONITOR_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/logicmonitor_facts.py)

  LogicMonitor is a hosted, full-stack, infrastructure monitoring platform. This module collects facts about hosts and
  host groups within your LogicMonitor account.

Options (= is mandatory):

- collector
        The fully qualified domain name of a collector in your LogicMonitor account.
        This is optional for querying a LogicMonitor host when a displayname is specified.
        This is required for querying a LogicMonitor host when a displayname is not specified.
        [Default: None]
= company
        The LogicMonitor account company name. If you would log in to your account at "superheroes.logicmonitor.com" you
        would use "superheroes".
        [Default: None]
- displayname
        The display name of a host in your LogicMonitor account or the desired display name of a device to add into
        monitoring.
        [Default: hostname -f]
- fullpath
        The fullpath of the hostgroup object you would like to manage.
        Recommend running on a single ansible host.
        Required for management of LogicMonitor host groups (target=hostgroup).
        [Default: None]
- hostname
        The hostname of a host in your LogicMonitor account, or the desired hostname of a device to add into monitoring.
        Required for managing hosts (target=host).
        [Default: hostname -f]
= password
        The password for the chosen LogicMonitor User.
        If an md5 hash is used, the digest flag must be set to true.
        [Default: None]
= target
        The LogicMonitor object you wish to manage.
        (Choices: host, hostgroup)[Default: None]
= user
        A LogicMonitor user name. The module will authenticate and perform actions on behalf of this user.
        [Default: None]
Notes:
  * You must have an existing LogicMonitor account for this module to function.
Requirements:  An existing LogicMonitor account, Linux

EXAMPLES:
# Always run those modules on localhost using delegate_to:localhost, or localaction

- name: query a list of hosts
  logicmonitor_facts:
    target: host
    company: yourcompany
    user: Luigi
    password: ImaLuigi,number1!
  delegate_to: localhost

- name: query a host group
  logicmonitor_facts:
    target: hostgroup
    fullpath: /servers/production
    company: yourcompany
    user: mario
    password: itsame.Mario!
  delegate_to: localhost

RETURN VALUES:
---
    ansible_facts:
        description: LogicMonitor properties set for the specified object
        returned: success
        type: list of dicts containing name/value pairs
        example: >
            {
                "name": "dc",
                "value": "1"
            },
            {
                "name": "type",
                "value": "prod"
            },
            {
                "name": "system.categories",
                "value": ""
            },
            {
                "name": "snmp.community",
                "value": "********"
            }
...


MAINTAINERS: Ethan Culler-Mayeno (@ethanculler), Jeff Wozniak (@woz5999)

METADATA:
	Status: ['preview']
	Supported_by: community
> LOGSTASH_PLUGIN    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/logstash_plugin.py)

  Manages Logstash plugins.

Options (= is mandatory):

= name
        Install plugin with that name.

- plugin_bin
        Specify logstash-plugin to use for plugin management.
        [Default: /usr/share/logstash/bin/logstash-plugin]
- proxy_host
        Proxy host to use during plugin installation.
        [Default: None]
- proxy_port
        Proxy port to use during plugin installation.
        [Default: None]
- state
        Apply plugin state.
        (Choices: present, absent)[Default: present]
- version
        Specify plugin Version of the plugin to install. If plugin exists with previous version, it will NOT be updated.
        [Default: None]
EXAMPLES:
- name: Install Logstash beats input plugin
  logstash_plugin:
    state: present
    name: logstash-input-beats

- name: Install specific version of a plugin
  logstash_plugin:
    state: present
    name: logstash-input-syslog
    version: '3.2.0'

- name: Uninstall Logstash plugin
  logstash_plugin:
    state: absent
    name: logstash-filter-multiline


MAINTAINERS: Loic Blot (@nerzhul)

METADATA:
	Status: ['preview']
	Supported_by: community
> LVG    (/usr/lib/python2.7/site-packages/ansible/modules/system/lvg.py)

  This module creates, removes or resizes volume groups.

Options (= is mandatory):

- force
        If yes, allows to remove volume group with logical volumes.
        (Choices: yes, no)[Default: no]
- pesize
        The size of the physical extent in megabytes. Must be a power of 2.
        [Default: 4]
- pvs
        List of comma-separated devices to use as physical devices in this volume group. Required when creating or
        resizing volume group.
        The module will take care of running pvcreate if needed.
        [Default: (null)]
- state
        Control if the volume group exists.
        (Choices: present, absent)[Default: present]
= vg
        The name of the volume group.

- vg_options
        Additional options to pass to `vgcreate' when creating the volume group.
        [Default: None]
Notes:
  * module does not modify PE size for already present volume group
EXAMPLES:
# Create a volume group on top of /dev/sda1 with physical extent size = 32MB.
- lvg:
    vg: vg.services
    pvs: /dev/sda1
    pesize: 32

# Create or resize a volume group on top of /dev/sdb1 and /dev/sdc5.
# If, for example, we already have VG vg.services on top of /dev/sdb1,
# this VG will be extended by /dev/sdc5.  Or if vg.services was created on
# top of /dev/sda5, we first extend it with /dev/sdb1 and /dev/sdc5,
# and then reduce by /dev/sda5.
- lvg:
    vg: vg.services
    pvs: /dev/sdb1,/dev/sdc5

# Remove a volume group with name vg.services.
- lvg:
    vg: vg.services
    state: absent


MAINTAINERS: Alexander Bulimov (@abulimov)

METADATA:
	Status: ['preview']
	Supported_by: community
> LVOL    (/usr/lib/python2.7/site-packages/ansible/modules/system/lvol.py)

  This module creates, removes or resizes logical volumes.

Options (= is mandatory):

- active
        Whether the volume is activate and visible to the host.
        (Choices: yes, no)[Default: yes]
- force
        Shrink or remove operations of volumes requires this switch. Ensures that that filesystems get never
        corrupted/destroyed by mistake.
        (Choices: yes, no)[Default: no]
= lv
        The name of the logical volume.

- opts
        Free-form options to be passed to the lvcreate command
        [Default: (null)]
- pvs
        Comma separated list of physical volumes e.g. /dev/sda,/dev/sdb
        [Default: (null)]
- shrink
        shrink if current size is higher than size requested
        [Default: True]
- size
        The size of the logical volume, according to lvcreate(8) --size, by default in megabytes or optionally with one
        of [bBsSkKmMgGtTpPeE] units; or according to lvcreate(8) --extents as a percentage of [VG|PVS|FREE]; Float values
        must begin with a digit. Resizing using percentage values was not supported prior to 2.1.
        [Default: (null)]
- snapshot
        The name of the snapshot volume
        [Default: (null)]
- state
        Control if the logical volume exists. If `present' and the volume does not already exist then the `size' option
        is required.
        (Choices: present, absent)[Default: present]
= vg
        The volume group this logical volume is part of.

Notes:
  * Filesystems on top of the volume are not resized.
EXAMPLES:
# Create a logical volume of 512m.
- lvol:
    vg: firefly
    lv: test
    size: 512

# Create a logical volume of 512m with disks /dev/sda and /dev/sdb
- lvol:
    vg: firefly
    lv: test
    size: 512
    pvs: /dev/sda,/dev/sdb

# Create cache pool logical volume
- lvol:
    vg: firefly
    lv: lvcache
    size: 512m
    opts: --type cache-pool

# Create a logical volume of 512g.
- lvol:
    vg: firefly
    lv: test
    size: 512g

# Create a logical volume the size of all remaining space in the volume group
- lvol:
    vg: firefly
    lv: test
    size: 100%FREE

# Create a logical volume with special options
- lvol:
    vg: firefly
    lv: test
    size: 512g
    opts: -r 16

# Extend the logical volume to 1024m.
- lvol:
    vg: firefly
    lv: test
    size: 1024

# Extend the logical volume to consume all remaining space in the volume group
- lvol:
    vg: firefly
    lv: test
    size: +100%FREE

# Extend the logical volume to take all remaining space of the PVs
- lvol:
    vg: firefly
    lv: test
    size: 100%PVS

# Resize the logical volume to % of VG
- lvol:
    vg: firefly
    lv: test
    size: 80%VG
    force: yes

# Reduce the logical volume to 512m
- lvol:
    vg: firefly
    lv: test
    size: 512
    force: yes

# Set the logical volume to 512m and do not try to shrink if size is lower than current one
- lvol:
    vg: firefly
    lv: test
    size: 512
    shrink: no

# Remove the logical volume.
- lvol:
    vg: firefly
    lv: test
    state: absent
    force: yes

# Create a snapshot volume of the test logical volume.
- lvol:
    vg: firefly
    lv: test
    snapshot: snap1
    size: 100m

# Deactivate a logical volume
- lvol:
    vg: firefly
    lv: test
    active: false

# Create a deactivated logical volume
- lvol:
    vg: firefly
    lv: test
    size: 512g
    active: false


MAINTAINERS: Jeroen Hoekx (@jhoekx), Alexander Bulimov (@abulimov)

METADATA:
	Status: ['preview']
	Supported_by: community
> LXC_CONTAINER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/lxc/lxc_container.py)

  Management of LXC containers

Options (= is mandatory):

- archive
        Create an archive of a container. This will create a tarball of the running container.
        (Choices: True, False)[Default: False]
- archive_compression
        Type of compression to use when creating an archive of a running container.
        (Choices: gzip, bzip2, none)[Default: gzip]
- archive_path
        Path the save the archived container. If the path does not exist the archive method will attempt to create it.
        [Default: None]
- backing_store
        Backend storage type for the container.
        (Choices: dir, lvm, loop, btrfs, overlayfs, zfs)[Default: dir]
- clone_name
        Name of the new cloned server. This is only used when state is clone.
        [Default: False]
- clone_snapshot
        Create a snapshot a container when cloning. This is not supported by all container storage backends. Enabling
        this may fail if the backing store does not support snapshots.
        (Choices: True, False)[Default: False]
- config
        Path to the LXC configuration file.
        [Default: None]
- container_command
        Run a command within a container.
        [Default: (null)]
- container_config
        list of 'key=value' options to use when configuring a container.
        [Default: (null)]
- container_log
        Enable a container log for host actions to the container.
        (Choices: True, False)[Default: False]
- container_log_level
        Set the log level for a container where *container_log* was set.
        (Choices: INFO, ERROR, DEBUG)[Default: INFO]
- directory
        Place rootfs directory under DIR.
        [Default: (null)]
- fs_size
        File system Size.
        [Default: 5G]
- fs_type
        Create fstype TYPE.
        [Default: ext4]
- lv_name
        Name of the logical volume, defaults to the container name.
        [Default: $CONTAINER_NAME]
- lxc_path
        Place container under PATH
        [Default: (null)]
= name
        Name of a container.

- state
        Define the state of a container. If you clone a container using `clone_name` the newly cloned container created
        in a stopped state. The running container will be stopped while the clone operation is happening and upon
        completion of the clone the original container state will be restored.
        (Choices: started, stopped, restarted, absent, frozen)[Default: started]
- template
        Name of the template to use within an LXC create.
        [Default: ubuntu]
- template_options
        Template options when building the container.
        [Default: (null)]
- thinpool
        Use LVM thin pool called TP.
        [Default: (null)]
- vg_name
        If Backend store is lvm, specify the name of the volume group.
        [Default: lxc]
- zfs_root
        Create zfs under given zfsroot.
        [Default: (null)]
Notes:
  * Containers must have a unique name. If you attempt to create a container with a name that already exists in the
        users namespace the module will simply return as "unchanged".
  * The "container_command" can be used with any state except "absent". If used with state "stopped" the container
        will be "started", the command executed, and then the container "stopped" again. Likewise if the state is
        "stopped" and the container does not exist it will be first created, "started", the command executed, and
        then "stopped". If you use a "|" in the variable you can use common script formatting within the variable
        iteself The "container_command" option will always execute as BASH. When using "container_command" a log
        file is created in the /tmp/ directory which contains both stdout and stderr of any command executed.
  * If "archive" is **true** the system will attempt to create a compressed tarball of the running container. The
        "archive" option supports LVM backed containers and will create a snapshot of the running container when
        creating the archive.
  * If your distro does not have a package for "python2-lxc", which is a requirement for this module, it can be
        installed from source at "https://github.com/lxc/python2-lxc" or installed via pip using the package name
        lxc-python2.
Requirements:  lxc >= 1.0 # OS package, python >= 2.6 # OS Package, lxc-python2 >= 0.1 # PIP Package from
        https://github.com/lxc/python2-lxc

EXAMPLES:
- name: Create a started container
  lxc_container:
    name: test-container-started
    container_log: true
    template: ubuntu
    state: started
    template_options: --release trusty

- name: Create a stopped container
  lxc_container:
    name: test-container-stopped
    container_log: true
    template: ubuntu
    state: stopped
    template_options: --release trusty

- name: Create a frozen container
  lxc_container:
    name: test-container-frozen
    container_log: true
    template: ubuntu
    state: frozen
    template_options: --release trusty
    container_command: |
      echo 'hello world.' | tee /opt/started-frozen

# Create filesystem container, configure it, and archive it, and start it.
- name: Create filesystem container
  lxc_container:
    name: test-container-config
    backing_store: dir
    container_log: true
    template: ubuntu
    state: started
    archive: true
    archive_compression: none
    container_config:
      - "lxc.aa_profile=unconfined"
      - "lxc.cgroup.devices.allow=a *:* rmw"
    template_options: --release trusty

# Create an lvm container, run a complex command in it, add additional
# configuration to it, create an archive of it, and finally leave the container
# in a frozen state. The container archive will be compressed using bzip2
- name: Create a frozen lvm container
  lxc_container:
    name: test-container-lvm
    container_log: true
    template: ubuntu
    state: frozen
    backing_store: lvm
    template_options: --release trusty
    container_command: |
      apt-get update
      apt-get install -y vim lxc-dev
      echo 'hello world.' | tee /opt/started
      if [[ -f "/opt/started" ]]; then
          echo 'hello world.' | tee /opt/found-started
      fi
    container_config:
      - "lxc.aa_profile=unconfined"
      - "lxc.cgroup.devices.allow=a *:* rmw"
    archive: true
    archive_compression: bzip2
  register: lvm_container_info

- name: Debug info on container "test-container-lvm"
  debug:
    var: lvm_container_info

- name: Run a command in a container and ensure its in a "stopped" state.
  lxc_container:
    name: test-container-started
    state: stopped
    container_command: |
      echo 'hello world.' | tee /opt/stopped

- name: Run a command in a container and ensure its it in a "frozen" state.
  lxc_container:
    name: test-container-stopped
    state: frozen
    container_command: |
      echo 'hello world.' | tee /opt/frozen

- name: Start a container
  lxc_container:
    name: test-container-stopped
    state: started

- name: Run a command in a container and then restart it
  lxc_container:
    name: test-container-started
    state: restarted
    container_command: |
      echo 'hello world.' | tee /opt/restarted

- name: Run a complex command within a "running" container
  lxc_container:
    name: test-container-started
    container_command: |
      apt-get update
      apt-get install -y curl wget vim apache2
      echo 'hello world.' | tee /opt/started
      if [[ -f "/opt/started" ]]; then
          echo 'hello world.' | tee /opt/found-started
      fi

# Create an archive of an existing container, save the archive to a defined
# path and then destroy it.
- name: Archive container
  lxc_container:
    name: test-container-started
    state: absent
    archive: true
    archive_path: /opt/archives

# Create a container using overlayfs, create an archive of it, create a
# snapshot clone of the container and and finally leave the container
# in a frozen state. The container archive will be compressed using gzip.
- name: Create an overlayfs container archive and clone it
  lxc_container:
    name: test-container-overlayfs
    container_log: true
    template: ubuntu
    state: started
    backing_store: overlayfs
    template_options: --release trusty
    clone_snapshot: true
    clone_name: test-container-overlayfs-clone-snapshot
    archive: true
    archive_compression: gzip
  register: clone_container_info

- name: debug info on container "test-container"
  debug:
    var: clone_container_info

- name: Clone a container using snapshot
  lxc_container:
    name: test-container-overlayfs-clone-snapshot
    backing_store: overlayfs
    clone_name: test-container-overlayfs-clone-snapshot2
    clone_snapshot: true

- name: Create a new container and clone it
  lxc_container:
    name: test-container-new-archive
    backing_store: dir
    clone_name: test-container-new-archive-clone

- name: Archive and clone a container then destroy it
  lxc_container:
    name: test-container-new-archive
    state: absent
    clone_name: test-container-new-archive-destroyed-clone
    archive: true
    archive_compression: gzip

- name: Start a cloned container.
  lxc_container:
    name: test-container-new-archive-destroyed-clone
    state: started

- name: Destroy a container
  lxc_container:
    name: '{{ item }}'
    state: absent
  with_items:
    - test-container-stopped
    - test-container-started
    - test-container-frozen
    - test-container-lvm
    - test-container-config
    - test-container-overlayfs
    - test-container-overlayfs-clone
    - test-container-overlayfs-clone-snapshot
    - test-container-overlayfs-clone-snapshot2
    - test-container-new-archive
    - test-container-new-archive-clone
    - test-container-new-archive-destroyed-clone

RETURN VALUES:
lxc_container:
    description: container information
    returned: success
    type: list
    contains:
        name:
            description: name of the lxc container
            returned: success
            type: string
            sample: test_host
        init_pid:
            description: pid of the lxc init process
            returned: success
            type: int
            sample: 19786
        interfaces:
            description: list of the container's network interfaces
            returned: success
            type: list
            sample: [ "eth0", "lo" ]
        ips:
            description: list of ips
            returned: success
            type: list
            sample: [ "10.0.3.3" ]
        state:
            description: resulting state of the container
            returned: success
            type: string
            sample: "running"
        archive:
            description: resulting state of the container
            returned: success, when archive is true
            type: string
            sample: "/tmp/test-container-config.tar"
        clone:
            description: if the container was cloned
            returned: success, when clone_name is specified
            type: boolean
            sample: True


MAINTAINERS: Kevin Carter (@cloudnull)

METADATA:
	Status: ['preview']
	Supported_by: community
> LXD_CONTAINER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/lxd/lxd_container.py)

  Management of LXD containers

Options (= is mandatory):

- architecture
        The architecture for the container (e.g. "x86_64" or "i686"). See https://github.com/lxc/lxd/blob/master/doc
        /rest-api.md#post-1
        [Default: (null)]
- cert_file
        The client certificate file path.
        [Default: "{}/.config/lxc/client.crt" .format(os.environ["HOME"])]
- config
        The config for the container (e.g. {"limits.cpu": "2"}). See https://github.com/lxc/lxd/blob/master/doc/rest-
        api.md#post-1
        If the container already exists and its "config" value in metadata obtained from GET /1.0/containers/<name>
        https://github.com/lxc/lxd/blob/master/doc/rest-api.md#10containersname are different, they this module tries to
        apply the configurations.
        The key starts with 'volatile.' are ignored for this comparison.
        Not all config values are supported to apply the existing container. Maybe you need to delete and recreate a
        container.
        [Default: (null)]
- devices
        The devices for the container (e.g. { "rootfs": { "path": "/dev/kvm", "type": "unix-char" }). See
        https://github.com/lxc/lxd/blob/master/doc/rest-api.md#post-1
        [Default: (null)]
- ephemeral
        Whether or not the container is ephemeral (e.g. true or false). See https://github.com/lxc/lxd/blob/master/doc
        /rest-api.md#post-1
        [Default: (null)]
- force_stop
        If this is true, the `lxd_container' forces to stop the container when it stops or restarts the container.
        [Default: False]
- key_file
        The client certificate key file path.
        [Default: "{}/.config/lxc/client.key" .format(os.environ["HOME"])]
= name
        Name of a container.

- source
        The source for the container (e.g. { "type": "image", "mode": "pull", "server":
        "https://images.linuxcontainers.org", "protocol": "lxd", "alias": "ubuntu/xenial/amd64" }). See
        https://github.com/lxc/lxd/blob/master/doc/rest-api.md#post-1
        [Default: (null)]
- state
        Define the state of a container.
        (Choices: started, stopped, restarted, absent, frozen)[Default: started]
- timeout
        A timeout for changing the state of the container.
        This is also used as a timeout for waiting until IPv4 addresses are set to the all network interfaces in the
        container after starting or restarting.
        [Default: 30]
- trust_password
        The client trusted password.
        You need to set this password on the LXD server before running this module using the following command. lxc
        config set core.trust_password <some random password> See https://www.stgraber.org/2016/04/18/lxd-api-direct-
        interaction/
        If trust_password is set, this module send a request for authentication before sending any requests.
        [Default: (null)]
- url
        The unix domain socket path or the https URL for the LXD server.
        [Default: unix:/var/lib/lxd/unix.socket]
- wait_for_ipv4_addresses
        If this is true, the `lxd_container' waits until IPv4 addresses are set to the all network interfaces in the
        container after starting or restarting.
        [Default: False]
Notes:
  * Containers must have a unique name. If you attempt to create a container with a name that already existed in
        the users namespace the module will simply return as "unchanged".
  * There are two ways to can run commands in containers, using the command module or using the ansible lxd
        connection plugin bundled in Ansible >= 2.1, the later requires python to be installed in the container
        which can be done with the command module.
  * You can copy a file from the host to the container with the Ansible [copy] and [template] module and the `lxd`
        connection plugin. See the example below.
  * You can copy a file in the creatd container to the localhost with `command=lxc file pull
        container_name/dir/filename filename`. See the first example below.
EXAMPLES:
# An example for creating a Ubuntu container and install python
- hosts: localhost
  connection: local
  tasks:
    - name: Create a started container
      lxd_container:
        name: mycontainer
        state: started
        source:
          type: image
          mode: pull
          server: https://images.linuxcontainers.org
          protocol: lxd
          alias: ubuntu/xenial/amd64
        profiles: ["default"]
        wait_for_ipv4_addresses: true
        timeout: 600

    - name: check python is installed in container
      delegate_to: mycontainer
      raw: dpkg -s python
      register: python_install_check
      failed_when: python_install_check.rc not in [0, 1]
      changed_when: false

    - name: install python in container
      delegate_to: mycontainer
      raw: apt-get install -y python
      when: python_install_check.rc == 1

# An example for deleting a container
- hosts: localhost
  connection: local
  tasks:
    - name: Delete a container
      lxd_container:
        name: mycontainer
        state: absent

# An example for restarting a container
- hosts: localhost
  connection: local
  tasks:
    - name: Restart a container
      lxd_container:
        name: mycontainer
        state: restarted

# An example for restarting a container using https to connect to the LXD server
- hosts: localhost
  connection: local
  tasks:
    - name: Restart a container
      lxd_container:
        url: https://127.0.0.1:8443
        # These cert_file and key_file values are equal to the default values.
        #cert_file: "{{ lookup('env', 'HOME') }}/.config/lxc/client.crt"
        #key_file: "{{ lookup('env', 'HOME') }}/.config/lxc/client.key"
        trust_password: mypassword
        name: mycontainer
        state: restarted

# Note your container must be in the inventory for the below example.
#
# [containers]
# mycontainer ansible_connection=lxd
#
- hosts:
    - mycontainer
  tasks:
    - name: copy /etc/hosts in the created container to localhost with name "mycontainer-hosts"
      fetch:
        src: /etc/hosts
        dest: /tmp/mycontainer-hosts
        flat: true

RETURN VALUES:
addresses:
  description: Mapping from the network device name to a list of IPv4 addresses in the container
  returned: when state is started or restarted
  type: object
  sample: {"eth0": ["10.155.92.191"]}
old_state:
  description: The old state of the container
  returned: when state is started or restarted
  type: string
  sample: "stopped"
logs:
  description: The logs of requests and responses.
  returned: when ansible-playbook is invoked with -vvvv.
  type: list
  sample: "(too long to be placed here)"
actions:
  description: List of actions performed for the container.
  returned: success
  type: list
  sample: '["create", "start"]'


MAINTAINERS: Hiroaki Nakamura (@hnakamur)

METADATA:
	Status: ['preview']
	Supported_by: community
> LXD_PROFILE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/lxd/lxd_profile.py)

  Management of LXD profiles

Options (= is mandatory):

- cert_file
        The client certificate file path.
        [Default: "{}/.config/lxc/client.crt" .format(os.environ["HOME"])]
- config
        The config for the container (e.g. {"limits.memory": "4GB"}). See https://github.com/lxc/lxd/blob/master/doc
        /rest-api.md#patch-3
        If the profile already exists and its "config" value in metadata obtained from GET /1.0/profiles/<name>
        https://github.com/lxc/lxd/blob/master/doc/rest-api.md#get-19 are different, they this module tries to apply the
        configurations.
        Not all config values are supported to apply the existing profile. Maybe you need to delete and recreate a
        profile.
        [Default: (null)]
- devices
        The devices for the profile (e.g. {"rootfs": {"path": "/dev/kvm", "type": "unix-char"}). See
        https://github.com/lxc/lxd/blob/master/doc/rest-api.md#patch-3
        [Default: (null)]
- key_file
        The client certificate key file path.
        [Default: "{}/.config/lxc/client.key" .format(os.environ["HOME"])]
= name
        Name of a profile.

- new_name
        A new name of a profile.
        If this parameter is specified a profile will be renamed to this name. See
        https://github.com/lxc/lxd/blob/master/doc/rest-api.md#post-11
        [Default: (null)]
- state
        Define the state of a profile.
        (Choices: present, absent)[Default: present]
- trust_password
        The client trusted password.
        You need to set this password on the LXD server before running this module using the following command. lxc
        config set core.trust_password <some random password> See https://www.stgraber.org/2016/04/18/lxd-api-direct-
        interaction/
        If trust_password is set, this module send a request for authentication before sending any requests.
        [Default: (null)]
- url
        The unix domain socket path or the https URL for the LXD server.
        [Default: unix:/var/lib/lxd/unix.socket]
Notes:
  * Profiles must have a unique name. If you attempt to create a profile with a name that already existed in the
        users namespace the module will simply return as "unchanged".
EXAMPLES:
# An example for creating a profile
- hosts: localhost
  connection: local
  tasks:
    - name: Create a profile
      lxd_profile:
        name: macvlan
        state: present
        config: {}
        description: my macvlan profile
        devices:
          eth0:
            nictype: macvlan
            parent: br0
            type: nic

# An example for creating a profile via http connection
- hosts: localhost
  connection: local
  tasks:
  - name: create macvlan profile
    lxd_profile:
      url: https://127.0.0.1:8443
      # These cert_file and key_file values are equal to the default values.
      #cert_file: "{{ lookup('env', 'HOME') }}/.config/lxc/client.crt"
      #key_file: "{{ lookup('env', 'HOME') }}/.config/lxc/client.key"
      trust_password: mypassword
      name: macvlan
      state: present
      config: {}
      description: my macvlan profile
      devices:
        eth0:
          nictype: macvlan
          parent: br0
          type: nic

# An example for deleting a profile
- hosts: localhost
  connection: local
  tasks:
    - name: Delete a profile
      lxd_profile:
        name: macvlan
        state: absent

# An example for renaming a profile
- hosts: localhost
  connection: local
  tasks:
    - name: Rename a profile
      lxd_profile:
        name: macvlan
        new_name: macvlan2
        state: present

RETURN VALUES:
old_state:
  description: The old state of the profile
  returned: success
  type: string
  sample: "absent"
logs:
  description: The logs of requests and responses.
  returned: when ansible-playbook is invoked with -vvvv.
  type: list
  sample: "(too long to be placed here)"
actions:
  description: List of actions performed for the profile.
  returned: success
  type: list
  sample: '["create"]'


MAINTAINERS: Hiroaki Nakamura (@hnakamur)

METADATA:
	Status: ['preview']
	Supported_by: community
> MACPORTS    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/macports.py)

  Manages MacPorts packages

Options (= is mandatory):

= name
        name of package to install/remove

- state
        state of the package
        (Choices: present, absent, active, inactive)[Default: present]
- update_cache
        update the package db first
        (Choices: yes, no)[Default: no]
EXAMPLES:
- macports:
    name: foo
    state: present

- macports:
    name: foo
    state: present
    update_cache: yes

- macports:
    name: foo
    state: absent

- macports:
    name: foo
    state: active

- macports:
    name: foo
    state: inactive


MAINTAINERS: Jimmy Tang (@jcftang)

METADATA:
	Status: ['preview']
	Supported_by: community
> MAIL    (/usr/lib/python2.7/site-packages/ansible/modules/notification/mail.py)

  This module is useful for sending emails from playbooks. One may wonder why automate sending emails?  In complex
  environments there are from time to time processes that cannot be automated, either because you lack the authority to
  make it so, or because not everyone agrees to a common approach. If you cannot automate a specific step, but the step
  is non-blocking, sending out an email to the responsible party to make him perform his part of the bargain is an
  elegant way to put the responsibility in someone else's lap. Of course sending out a mail can be equally useful as a
  way to notify one or more people in a team that a specific action has been (successfully) taken.

Options (= is mandatory):

- attach
        A space-separated list of pathnames of files to attach to the message. Attached files will have their content-
        type set to `application/octet-stream'.
        [Default: None]
- bcc
        The email-address(es) the mail is being 'blind' copied to. This is a comma-separated list, which may contain
        address and phrase portions.
        [Default: (null)]
- body
        The body of the email being sent.
        [Default: $subject]
- cc
        The email-address(es) the mail is being copied to. This is a comma-separated list, which may contain address and
        phrase portions.
        [Default: (null)]
- charset
        The character set of email being sent
        [Default: us-ascii]
- from
        The email-address the mail is sent from. May contain address and phrase.
        [Default: root]
- headers
        A vertical-bar-separated list of headers which should be added to the message. Each individual header is
        specified as `header=value' (see example below).
        [Default: None]
- host
        The mail server
        [Default: localhost]
- password
        If SMTP requires password
        [Default: None]
- port
        The mail server port.  This must be a valid integer between 1 and 65534
        [Default: 25]
- secure
        If `always', the connection will only send email if the connection is Encrypted. If the server doesn't accept the
        encrypted connection it will fail.
        If `try', the connection will attempt to setup a secure SSL/TLS session, before trying to send.
        If `never', the connection will not attempt to setup a secure SSL/TLS session, before sending
        If `starttls', the connection will try to upgrade to a secure SSL/TLS connection, before sending. If it is unable
        to do so it will fail.
        (Choices: always, never, try, starttls)[Default: try]
= subject
        The subject of the email being sent.

- subtype
        The minor mime type, can be either text or html. The major type is always text.
        [Default: plain]
- timeout
        Sets the Timeout in seconds for connection attempts
        [Default: 20]
- to
        The email-address(es) the mail is being sent to. This is a comma-separated list, which may contain address and
        phrase portions.
        [Default: root]
- username
        If SMTP requires username
        [Default: None]
EXAMPLES:
# Example playbook sending mail to root
- mail:
    subject: 'System {{ ansible_hostname }} has been successfully provisioned.'
  delegate_to: localhost

# Sending an e-mail using Gmail SMTP servers
- mail:
    host: smtp.gmail.com
    port: 587
    username: username@gmail.com
    password: mysecret
    to: John Smith <john.smith@example.com>
    subject: Ansible-report
    body: 'System {{ ansible_hostname }} has been successfully provisioned.'
  delegate_to: localhost

# Send e-mail to a bunch of users, attaching files
- mail:
    host: 127.0.0.1
    port: 2025
    subject: Ansible-report
    body: Hello, this is an e-mail. I hope you like it ;-)
    from: jane@example.net (Jane Jolie)
    to: John Doe <j.d@example.org>, Suzie Something <sue@example.com>
    cc: Charlie Root <root@localhost>
    attach: /etc/group /tmp/pavatar2.png
    headers: 'Reply-To=john@example.com|X-Special="Something or other"'
    charset: utf8
  delegate_to: localhost

# Sending an e-mail using the remote machine, not the Ansible controller node
- mail:
    host: localhost
    port: 25
    to: John Smith <john.smith@example.com>
    subject: Ansible-report
    body: 'System {{ ansible_hostname }} has been successfully provisioned.'

# Sending an e-mail using Legacy SSL to the remote machine
- mail:
    host: localhost
    port: 25
    to: John Smith <john.smith@example.com>
    subject: Ansible-report
    body: 'System {{ ansible_hostname }} has been successfully provisioned.'
    secure: always

 # Sending an e-mail using StartTLS to the remote machine
- mail:
    host: localhost
    port: 25
    to: John Smith <john.smith@example.com>
    subject: Ansible-report
    body: 'System {{ ansible_hostname }} has been successfully provisioned.'
    secure: starttls



MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> MAKE    (/usr/lib/python2.7/site-packages/ansible/modules/system/make.py)

  Run targets in a Makefile.

Options (= is mandatory):

= chdir
        cd into this directory before running make

- params
        Any extra parameters to pass to make
        [Default: none]
- target
        The target to run
        [Default: none]
Requirements:  make

EXAMPLES:
# Build the default target
- make:
    chdir: /home/ubuntu/cool-project

# Run `install` target as root
- make:
    chdir: /home/ubuntu/cool-project
    target: install
  become: yes

# Pass in extra arguments to build
- make:
    chdir: /home/ubuntu/cool-project
    target: all
    params:
      NUM_THREADS: 4
      BACKEND: lapack

RETURN VALUES:
 

MAINTAINERS: Linus Unnebäck (@LinusU) <linus@folkdatorn.se>

METADATA:
	Status: ['preview']
	Supported_by: community
> MATTERMOST    (/usr/lib/python2.7/site-packages/ansible/modules/notification/mattermost.py)

  Sends notifications to http://your.mattermost.url via the Incoming WebHook integration.

Options (= is mandatory):

= api_key
        Mattermost webhook api key. Log into your mattermost site, go to Menu -> Integration -> Incomming Webhook -> Add
        Incomming Webhook. This will give you full URL. api_key is the last part.
        http://mattermost.example.com/hooks/`API_KEY'

- channel
        Channel to send the message to. If absent, the message goes to the channel selected for the `api_key'.
        [Default: (null)]
- icon_url
        Url for the message sender's icon.
        [Default: https://www.ansible.com/favicon.ico]
= text
        Text to send. Note that the module does not handle escaping characters.

= url
        Mattermost url (i.e. http://mattermost.yourcompany.com).

- username
        This is the sender of the message (Username Override need to be enabled by mattermost admin, see mattermost doc.
        [Default: Ansible]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: True]
EXAMPLES:
- name: Send notification message via Mattermost
  mattermost:
    url: http://mattermost.example.com
    api_key: my_api_key
    text: '{{ inventory_hostname }} completed'

- name: Send notification message via Mattermost all options
  mattermost:
    url: http://mattermost.example.com
    api_key: my_api_key
    text: '{{ inventory_hostname }} completed'
    channel: notifications
    username: 'Ansible on {{ inventory_hostname }}'
    icon_url: http://www.example.com/some-image-file.png

RETURN VALUES:
payload:
    description: Mattermost payload
    returned: success
    type: string
webhook_url:
    description: URL the webhook is sent to
    returned: success
    type: string


MAINTAINERS: Benjamin Jolivot (@bjolivot)

METADATA:
	Status: ['preview']
	Supported_by: community
> MAVEN_ARTIFACT    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/maven_artifact.py)

  Downloads an artifact from a maven repository given the maven coordinates provided to the module. Can retrieve
  snapshots or release versions of the artifact and will resolve the latest available version if one is not available.

Options (= is mandatory):

= artifact_id
        The maven artifactId coordinate

- classifier
        The maven classifier coordinate
        [Default: None]
= dest
        The path where the artifact should be written to
        [Default: False]
- extension
        The maven type/extension coordinate
        [Default: jar]
= group_id
        The Maven groupId coordinate

- password
        The password to authenticate with to the Maven Repository. Use AWS secret access key of the repository is hosted
        on S3
        [Default: None]
- repository_url
        The URL of the Maven Repository to download from.
        Use s3://... if the repository is hosted on Amazon S3, added in version 2.2.
        [Default: http://repo1.maven.org/maven2]
= state
        The desired state of the artifact
        (Choices: present, absent)[Default: present]
- timeout
        Specifies a timeout in seconds for the connection attempt
        [Default: 10]
- username
        The username to authenticate as to the Maven Repository. Use AWS secret key of the repository is hosted on S3
        [Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be set to `no' when no other option exists.
        (Choices: yes, no)[Default: yes]
- version
        The maven version coordinate
        [Default: latest]
Requirements:  python >= 2.6, lxml, boto if using a S3 repository (s3://...)

EXAMPLES:
# Download the latest version of the JUnit framework artifact from Maven Central
- maven_artifact:
    group_id: junit
    artifact_id: junit
    dest: /tmp/junit-latest.jar

# Download JUnit 4.11 from Maven Central
- maven_artifact:
    group_id: junit
    artifact_id: junit
    version: 4.11
    dest: /tmp/junit-4.11.jar

# Download an artifact from a private repository requiring authentication
- maven_artifact:
    group_id: com.company
    artifact_id: library-name
    repository_url: 'https://repo.company.com/maven'
    username: user
    password: pass
    dest: /tmp/library-name-latest.jar

# Download a WAR File to the Tomcat webapps directory to be deployed
- maven_artifact:
    group_id: com.company
    artifact_id: web-app
    extension: war
    repository_url: 'https://repo.company.com/maven'
    dest: /var/lib/tomcat7/webapps/web-app.war


MAINTAINERS: Chris Schmidt (@chrisisbeef)

METADATA:
	Status: ['preview']
	Supported_by: community
> META    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/helper/meta.py)

  Meta tasks are a special kind of task which can influence Ansible internal execution or state. Prior to Ansible 2.0,
  the only meta option available was `flush_handlers`. As of 2.2, there are five meta tasks which can be used. Meta tasks
  can be used anywhere within your playbook.

Options (= is mandatory):

= free_form
        This module takes a free form command, as a string. There's not an actual option named "free form".  See the
        examples!
        `flush_handlers' makes Ansible run any handler tasks which have thus far been notified. Ansible inserts these
        tasks internally at certain points to implicitly trigger handler runs (after pre/post tasks, the final role
        execution, and the main tasks section of your plays).
        `refresh_inventory' (added in 2.0) forces the reload of the inventory, which in the case of dynamic inventory
        scripts means they will be re-executed. This is mainly useful when additional hosts are created and users wish to
        use them instead of using the `add_host` module.
        `noop' (added in 2.0) This literally does 'nothing'. It is mainly used internally and not recommended for general
        use.
        `clear_facts' (added in 2.1) causes the gathered facts for the hosts specified in the play's list of hosts to be
        cleared, including the fact cache.
        `clear_host_errors' (added in 2.1) clears the failed state (if any) from hosts specified in the play's list of
        hosts.
        `end_play' (added in 2.2) causes the play to end without failing the host.
        `reset_connection' (added in 2.3) interrupts a persistent connection (i.e. ssh + control persist)
        (Choices: noop, flush_handlers, refresh_inventory, clear_facts, clear_host_errors, end_play)[Default: None]
Notes:
  * meta is not really a module nor action_plugin as such it cannot be overwritten.
EXAMPLES:
- template:
    src: new.j2
    dest: /etc/config.txt
  notify: myhandler
- name: force all notified handlers to run at this point, not waiting for normal sync points
  meta: flush_handlers

- name: reload inventory, useful with dynamic inventories when play makes changes to the existing hosts
  cloud_guest:            # this is fake module
    name: newhost
    state: present
- name: Refresh inventory to ensure new instaces exist in inventory
  meta: refresh_inventory

- name: Clear gathered facts from all currently targeted hosts
  meta: clear_facts

- name: bring host back to play after failure
  copy:
    src: file
    dest: /etc/file
  remote_user: imightnothavepermission

- meta: clear_host_errors

- user: name={{ansible_user}} groups=input
- name: reset ssh connection to allow user changes to affect 'current login user'
  meta: reset_connection


MAINTAINERS: Ansible Core Team

METADATA:
	Status: ['preview']
	Supported_by: core
> MODPROBE    (/usr/lib/python2.7/site-packages/ansible/modules/system/modprobe.py)

  Add or remove kernel modules.

Options (= is mandatory):

= name
        Name of kernel module to manage.

- params
        Modules parameters.
        [Default: ]
- state
        Whether the module should be present or absent.
        (Choices: present, absent)[Default: present]
EXAMPLES:
# Add the 802.1q module
- modprobe:
    name: 8021q
    state: present

# Add the dummy module
- modprobe:
    name: dummy
    state: present
    params: 'numdummies=2'


MAINTAINERS: Julien Dauphant, Matt Jeffery, David Stygstra (@stygstra)

METADATA:
	Status: ['preview']
	Supported_by: community
> MONGODB_PARAMETER    (/usr/lib/python2.7/site-packages/ansible/modules/database/mongodb/mongodb_parameter.py)

  Change an administrative parameter on a MongoDB server.

Options (= is mandatory):

= database
        The name of the database to add/remove the user from

- login_database
        The database where login credentials are stored
        [Default: None]
- login_host
        The host running the database
        [Default: localhost]
- login_password
        The password used to authenticate with
        [Default: None]
- login_port
        The port to connect to
        [Default: 27017]
- login_user
        The username used to authenticate with
        [Default: None]
= param
        MongoDB administrative parameter to modify

- param_type
        Define the parameter value (str, int)
        [Default: str]
- replica_set
        Replica set to connect to (automatically connects to primary for writes)
        [Default: None]
- ssl
        Whether to use an SSL connection when connecting to the database
        [Default: False]
= value
        MongoDB administrative parameter value to set

Notes:
  * Requires the pymongo Python package on the remote host, version 2.4.2+. This can be installed using pip or the
        OS package manager. @see http://api.mongodb.org/python/current/installation.html
Requirements:  pymongo

EXAMPLES:
# Set MongoDB syncdelay to 60 (this is an int)
- mongodb_parameter:
    param: syncdelay
    value: 60
    param_type: int

RETURN VALUES:
before:
    description: value before modification
    returned: success
    type: string
after:
    description: value after modification
    returned: success
    type: string


MAINTAINERS: Loic Blot (@nerzhul)

METADATA:
	Status: ['preview']
	Supported_by: community
> MONGODB_USER    (/usr/lib/python2.7/site-packages/ansible/modules/database/mongodb/mongodb_user.py)

  Adds or removes a user from a MongoDB database.

Options (= is mandatory):

= database
        The name of the database to add/remove the user from

- login_database
        The database where login credentials are stored
        [Default: None]
- login_host
        The host running the database
        [Default: localhost]
- login_password
        The password used to authenticate with
        [Default: None]
- login_port
        The port to connect to
        [Default: 27017]
- login_user
        The username used to authenticate with
        [Default: None]
= name
        The name of the user to add or remove
        [Default: None]
- password
        The password to use for the user
        [Default: None]
- replica_set
        Replica set to connect to (automatically connects to primary for writes)
        [Default: None]
- roles
        The database user roles valid values could either be one or more of the following strings: 'read', 'readWrite',
        'dbAdmin', 'userAdmin', 'clusterAdmin', 'readAnyDatabase', 'readWriteAnyDatabase', 'userAdminAnyDatabase',
        'dbAdminAnyDatabase'
        Or the following dictionary '{ db: DATABASE_NAME, role: ROLE_NAME }'.
        This param requires pymongo 2.5+. If it is a string, mongodb 2.4+ is also required. If it is a dictionary, mongo
        2.6+  is required.
        [Default: readWrite]
- ssl
        Whether to use an SSL connection when connecting to the database
        [Default: False]
- ssl_cert_reqs
        Specifies whether a certificate is required from the other side of the connection, and whether it will be
        validated if provided.
        (Choices: CERT_REQUIRED, CERT_OPTIONAL, CERT_NONE)[Default: CERT_REQUIRED]
- state
        The database user state
        (Choices: present, absent)[Default: present]
- update_password
        `always' will update passwords if they differ.  `on_create' will only set the password for newly created users.
        (Choices: always, on_create)[Default: always]
Notes:
  * Requires the pymongo Python package on the remote host, version 2.4.2+. This can be installed using pip or the
        OS package manager. @see http://api.mongodb.org/python/current/installation.html
Requirements:  pymongo

EXAMPLES:
# Create 'burgers' database user with name 'bob' and password '12345'.
- mongodb_user:
    database: burgers
    name: bob
    password: 12345
    state: present

# Create a database user via SSL (MongoDB must be compiled with the SSL option and configured properly)
- mongodb_user:
    database: burgers
    name: bob
    password: 12345
    state: present
    ssl: True

# Delete 'burgers' database user with name 'bob'.
- mongodb_user:
    database: burgers
    name: bob
    state: absent

# Define more users with various specific roles (if not defined, no roles is assigned, and the user will be added via pre mongo 2.2 style)
- mongodb_user:
    database: burgers
    name: ben
    password: 12345
    roles: read
    state: present
- mongodb_user:
    database: burgers
    name: jim
    password: 12345
    roles: readWrite,dbAdmin,userAdmin
    state: present
- mongodb_user:
    database: burgers
    name: joe
    password: 12345
    roles: readWriteAnyDatabase
    state: present

# add a user to database in a replica set, the primary server is automatically discovered and written to
- mongodb_user:
    database: burgers
    name: bob
    replica_set: belcher
    password: 12345
    roles: readWriteAnyDatabase
    state: present

# add a user 'oplog_reader' with read only access to the 'local' database on the replica_set 'belcher'. This is useful for oplog access (MONGO_OPLOG_URL).
# please notice the credentials must be added to the 'admin' database because the 'local' database is not syncronized and can't receive user credentials
# To login with such user, the connection string should be MONGO_OPLOG_URL="mongodb://oplog_reader:oplog_reader_password@server1,server2/local?authSource=admin"
# This syntax requires mongodb 2.6+ and pymongo 2.5+
- mongodb_user:
    login_user: root
    login_password: root_password
    database: admin
    user: oplog_reader
    password: oplog_reader_password
    state: present
    replica_set: belcher
    roles:
      - db: local
        role: read


RETURN VALUES:
user:
    description: The name of the user to add or remove.
    returned: success
    type: string


MAINTAINERS: Elliott Foster (@elliotttf)

METADATA:
	Status: ['preview']
	Supported_by: community
> MONIT    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/monit.py)

  Manage the state of a program monitored via `Monit'

Options (= is mandatory):

= name
        The name of the `monit' program/process to manage
        [Default: None]
= state
        The state of service
        (Choices: present, started, stopped, restarted, monitored, unmonitored, reloaded)[Default: None]
- timeout
        If there are pending actions for the service monitored by monit, then Ansible will check for up to this many
        seconds to verify the the requested action has been performed. Ansible will sleep for five seconds between each
        check.
        [Default: 300]
EXAMPLES:
# Manage the state of program "httpd" to be in "started" state.
- monit:
    name: httpd
    state: started


MAINTAINERS: Darryl Stoflet (@dstoflet)

METADATA:
	Status: ['preview']
	Supported_by: community
> MOUNT    (/usr/lib/python2.7/site-packages/ansible/modules/system/mount.py)

  This module controls active and configured mount points in `/etc/fstab'.

Options (= is mandatory):

- boot
        Determines if the filesystem should be mounted on boot.
        Only applies to Solaris systems.
        (Choices: yes, no)[Default: True]
- dump
        Dump (see fstab(5)). Note that if set to `null' and `state' set to `present', it will cease to work and duplicate
        entries will be made with subsequent runs.
        Has no effect on Solaris systems.
        [Default: 0]
- fstab
        File to use instead of `/etc/fstab'. You shouldn't use this option unless you really know what you are doing.
        This might be useful if you need to configure mountpoints in a chroot environment.  OpenBSD does not allow
        specifying alternate fstab files with mount so do not use this on OpenBSD with any state that operates on the
        live filesystem.
        [Default: /etc/fstab (/etc/vfstab on Solaris)]
- fstype
        Filesystem type. Required when `state' is `present' or `mounted'.
        [Default: None]
- opts
        Mount options (see fstab(5), or vfstab(4) on Solaris).
        [Default: None]
- passno
        Passno (see fstab(5)). Note that if set to `null' and `state' set to `present', it will cease to work and
        duplicate entries will be made with subsequent runs.
        Deprecated on Solaris systems.
        [Default: 0]
= path
        Path to the mount point (e.g. `/mnt/files').
        Before 2.3 this option was only usable as `dest', `destfile' and `name'.

- src
        Device to be mounted on `path'. Required when `state' set to `present' or `mounted'.
        [Default: None]
= state
        If `mounted' or `unmounted', the device will be actively mounted or unmounted as needed and appropriately
        configured in `fstab'.
        `absent' and `present' only deal with `fstab' but will not affect current mounting.
        If specifying `mounted' and the mount point is not present, the mount point will be created.
        Similarly, specifying `absent' will remove the mount point directory.
        (Choices: present, absent, mounted, unmounted)
Notes:
  * As of Ansible 2.3, the `name' option has been changed to `path' as default, but `name' still works as well.
EXAMPLES:
# Before 2.3, option 'name' was used instead of 'path'
- name: Mount DVD read-only
  mount:
    path: /mnt/dvd
    src: /dev/sr0
    fstype: iso9660
    opts: ro
    state: present

- name: Mount up device by label
  mount:
    path: /srv/disk
    src: LABEL=SOME_LABEL
    fstype: ext4
    state: present

- name: Mount up device by UUID
  mount:
    path: /home
    src: UUID=b3e48f45-f933-4c8e-a700-22a159ec9077
    fstype: xfs
    opts: noatime
    state: present


MAINTAINERS: Ansible Core Team, Seth Vidal

METADATA:
	Status: ['preview']
	Supported_by: core
> MQTT    (/usr/lib/python2.7/site-packages/ansible/modules/notification/mqtt.py)

  Publish a message on an MQTT topic.

Options (= is mandatory):

- ca_certs
        The path to the Certificate Authority certificate files that are to be treated as trusted by this client. If this
        is the only option given then the client will operate in a similar manner to a web browser. That is to say it
        will require the broker to have a certificate signed by the Certificate Authorities in ca_certs and will
        communicate using TLS v1, but will not attempt any form of authentication. This provides basic network encryption
        but may not be sufficient depending on how the broker is configured.
        [Default: None]
- certfile
        The path pointing to the PEM encoded client certificate. If this is not None it will be used as client
        information for TLS based authentication. Support for this feature is broker dependent.
        [Default: None]
- client_id
        MQTT client identifier
        [Default: hostname + pid]
- keyfile
        The path pointing to the PEM encoded client private key. If this is not None it will be used as client
        information for TLS based authentication. Support for this feature is broker dependent.
        [Default: None]
- password
        Password for `username' to authenticate against the broker.
        [Default: (null)]
= payload
        Payload. The special string `"None"' may be used to send a NULL (i.e. empty) payload which is useful to simply
        notify with the `topic' or to clear previously retained messages.
        [Default: None]
- port
        MQTT broker port number
        [Default: 1883]
- qos
        QoS (Quality of Service)
        (Choices: 0, 1, 2)[Default: 0]
- retain
        Setting this flag causes the broker to retain (i.e. keep) the message so that applications that subsequently
        subscribe to the topic can received the last retained message immediately.
        [Default: False]
- server
        MQTT broker address/name
        [Default: localhost]
= topic
        MQTT topic name
        [Default: None]
- username
        Username to authenticate against the broker.
        [Default: (null)]
Notes:
  * This module requires a connection to an MQTT broker such as Mosquitto http://mosquitto.org and the `Paho'
        `mqtt' Python client (https://pypi.python.org/pypi/paho-mqtt).
Requirements:  mosquitto

EXAMPLES:
- mqtt:
    topic: 'service/ansible/{{ ansible_hostname }}'
    payload: 'Hello at {{ ansible_date_time.iso8601 }}'
    qos: 0
    retain: False
    client_id: ans001
  delegate_to: localhost


MAINTAINERS: Jan-Piet Mens (@jpmens)

METADATA:
	Status: ['preview']
	Supported_by: community
> MSSQL_DB    (/usr/lib/python2.7/site-packages/ansible/modules/database/mssql/mssql_db.py)

  Add or remove MSSQL databases from a remote host.

Options (= is mandatory):

- autocommit
        Automatically commit the change only if the import succeed. Sometimes it is necessary to use autocommit=true,
        since some content can't be changed within a transaction.
        (Choices: false, true)[Default: False]
- login_host
        Host running the database
        [Default: (null)]
- login_password
        The password used to authenticate with
        [Default: None]
- login_port
        Port of the MSSQL server. Requires login_host be defined as other then localhost if login_port is used
        [Default: 1433]
- login_user
        The username used to authenticate with
        [Default: None]
= name
        name of the database to add or remove
        [Default: None]
- state
        The database state
        (Choices: present, absent, import)[Default: present]
- target
        Location, on the remote host, of the dump file to read from or write to. Uncompressed SQL files (`.sql') files
        are supported.
        [Default: (null)]
Notes:
  * Requires the pymssql Python package on the remote host. For Ubuntu, this is as easy as pip install pymssql (See
        [pip].)
Requirements:  python >= 2.7, pymssql

EXAMPLES:
# Create a new database with name 'jackdata'
- mssql_db:
    name: jackdata
    state: present

# Copy database dump file to remote host and restore it to database 'my_db'
- copy:
    src: dump.sql
    dest: /tmp

- mssql_db:
    name: my_db
    state: import
    target: /tmp/dump.sql

RETURN VALUES:
#


MAINTAINERS: Vedit Firat Arig

METADATA:
	Status: ['preview']
	Supported_by: community
> MYSQL_DB    (/usr/lib/python2.7/site-packages/ansible/modules/database/mysql/mysql_db.py)

  Add or remove MySQL databases from a remote host.

Options (= is mandatory):

- collation
        Collation mode (sorting). This only applies to new table/databases and does not update existing ones, this is a
        limitation of MySQL.
        [Default: None]
- config_file
        Specify a config file from which user and password are to be read.
        [Default: ~/.my.cnf]
- connect_timeout
        The connection timeout when connecting to the MySQL server.
        [Default: 30]
- encoding
        Encoding mode to use, examples include `utf8' or `latin1_swedish_ci'
        [Default: None]
- login_host
        Host running the database.
        [Default: localhost]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_port
        Port of the MySQL server. Requires `login_host' be defined as other then localhost if login_port is used.
        [Default: 3306]
- login_unix_socket
        The path to a Unix domain socket for local connections.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: None]
= name
        name of the database to add or remove
        name=all May only be provided if `state' is `dump' or `import'.
        if name=all Works like --all-databases option for mysqldump (Added in 2.0)
        [Default: None]
- quick
        Option used for dumping large tables
        [Default: True]
- single_transaction
        Execute the dump in a single transaction
        [Default: False]
- ssl_ca
        The path to a Certificate Authority (CA) certificate. This option, if used, must specify the same certificate as
        used by the server.
        [Default: None]
- ssl_cert
        The path to a client public key certificate.
        [Default: None]
- ssl_key
        The path to the client private key.
        [Default: None]
- state
        The database state
        (Choices: present, absent, dump, import)[Default: present]
- target
        Location, on the remote host, of the dump file to read from or write to. Uncompressed SQL files (`.sql') as well
        as bzip2 (`.bz2'), gzip (`.gz') and xz (Added in 2.0) compressed files are supported.
        [Default: (null)]
Notes:
  * Requires the python-mysqldb package on the remote host, as well as mysql and mysqldump binaries.
  * Requires the MySQLdb Python package on the remote host. For Ubuntu, this is as easy as apt-get install python-
        mysqldb. (See [apt].) For CentOS/Fedora, this is as easy as yum install MySQL-python. (See [yum].)
  * Both `login_password' and `login_user' are required when you are passing credentials. If none are present, the
        module will attempt to read the credentials from `~/.my.cnf', and finally fall back to using the MySQL
        default login of 'root' with no password.
Requirements:  MySQLdb, mysql (command line binary), mysqldump (command line binary)

EXAMPLES:
- name: Create a new database with name 'bobdata'
  mysql_db:
    name: bobdata
    state: present

# Copy database dump file to remote host and restore it to database 'my_db'
- name: Copy database dump file
  copy:
    src: dump.sql.bz2
    dest: /tmp
- name: Restore database
  mysql_db:
    name: my_db
    state: import
    target: /tmp/dump.sql.bz2

- name: Dump all databases to hostname.sql
  mysql_db:
    state: dump
    name: all
    target: /tmp/{{ inventory_hostname }}.sql

- name: Import file.sql similar to mysql -u <username> -p <password> < hostname.sql
  mysql_db:
    state: import
    name: all
    target: /tmp/{{ inventory_hostname }}.sql


MAINTAINERS: Ansible Core Team

METADATA:
	Status: ['preview']
	Supported_by: community
> MYSQL_REPLICATION    (/usr/lib/python2.7/site-packages/ansible/modules/database/mysql/mysql_replication.py)

  Manages MySQL server replication, slave, master status get and change master host.

Options (= is mandatory):

- config_file
        Specify a config file from which user and password are to be read.
        [Default: ~/.my.cnf]
- connect_timeout
        The connection timeout when connecting to the MySQL server.
        [Default: 30]
- login_host
        Host running the database.
        [Default: localhost]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_port
        Port of the MySQL server. Requires `login_host' be defined as other then localhost if login_port is used.
        [Default: 3306]
- login_unix_socket
        The path to a Unix domain socket for local connections.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: None]
- master_auto_position
        does the host uses GTID based replication or not
        [Default: None]
- master_connect_retry
        same as mysql variable
        [Default: (null)]
- master_host
        same as mysql variable
        [Default: (null)]
- master_log_file
        same as mysql variable
        [Default: (null)]
- master_log_pos
        same as mysql variable
        [Default: (null)]
- master_password
        same as mysql variable
        [Default: (null)]
- master_port
        same as mysql variable
        [Default: (null)]
- master_ssl
        same as mysql variable
        (Choices: 0, 1)[Default: (null)]
- master_ssl_ca
        same as mysql variable
        [Default: (null)]
- master_ssl_capath
        same as mysql variable
        [Default: (null)]
- master_ssl_cert
        same as mysql variable
        [Default: (null)]
- master_ssl_cipher
        same as mysql variable
        [Default: (null)]
- master_ssl_key
        same as mysql variable
        [Default: (null)]
- master_user
        same as mysql variable
        [Default: (null)]
- mode
        module operating mode. Could be getslave (SHOW SLAVE STATUS), getmaster (SHOW MASTER STATUS), changemaster
        (CHANGE MASTER TO), startslave (START SLAVE), stopslave (STOP SLAVE), resetslave (RESET SLAVE), resetslaveall
        (RESET SLAVE ALL)
        (Choices: getslave, getmaster, changemaster, stopslave, startslave, resetslave, resetslaveall)[Default: getslave]
- relay_log_file
        same as mysql variable
        [Default: (null)]
- relay_log_pos
        same as mysql variable
        [Default: (null)]
- ssl_ca
        The path to a Certificate Authority (CA) certificate. This option, if used, must specify the same certificate as
        used by the server.
        [Default: None]
- ssl_cert
        The path to a client public key certificate.
        [Default: None]
- ssl_key
        The path to the client private key.
        [Default: None]
Notes:
  * Requires the MySQLdb Python package on the remote host. For Ubuntu, this is as easy as apt-get install python-
        mysqldb. (See [apt].) For CentOS/Fedora, this is as easy as yum install MySQL-python. (See [yum].)
  * Both `login_password' and `login_user' are required when you are passing credentials. If none are present, the
        module will attempt to read the credentials from `~/.my.cnf', and finally fall back to using the MySQL
        default login of 'root' with no password.
Requirements:  MySQLdb

EXAMPLES:
# Stop mysql slave thread
- mysql_replication:
    mode: stopslave

# Get master binlog file name and binlog position
- mysql_replication:
    mode: getmaster

# Change master to master server 192.0.2.1 and use binary log 'mysql-bin.000009' with position 4578
- mysql_replication:
    mode: changemaster
    master_host: 192.0.2.1
    master_log_file: mysql-bin.000009
    master_log_pos: 4578

# Check slave status using port 3308
- mysql_replication:
    mode: getslave
    login_host: ansible.example.com
    login_port: 3308


MAINTAINERS: Balazs Pocze (@banyek)

METADATA:
	Status: ['preview']
	Supported_by: community
> MYSQL_USER    (/usr/lib/python2.7/site-packages/ansible/modules/database/mysql/mysql_user.py)

  Adds or removes a user from a MySQL database.

Options (= is mandatory):

- append_privs
        Append the privileges defined by priv to the existing ones for this user instead of overwriting existing ones.
        (Choices: yes, no)[Default: no]
- check_implicit_admin
        Check if mysql allows login as root/nopassword before trying supplied credentials.
        (Choices: yes, no)[Default: no]
- config_file
        Specify a config file from which user and password are to be read.
        [Default: ~/.my.cnf]
- connect_timeout
        The connection timeout when connecting to the MySQL server.
        [Default: 30]
- encrypted
        Indicate that the 'password' field is a `mysql_native_password` hash
        (Choices: yes, no)[Default: no]
- host
        the 'host' part of the MySQL username
        [Default: localhost]
- host_all
        override the host option, making ansible apply changes to all hostnames for a given user.  This option cannot be
        used when creating users
        (Choices: yes, no)[Default: no]
- login_host
        Host running the database.
        [Default: localhost]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_port
        Port of the MySQL server. Requires `login_host' be defined as other then localhost if login_port is used.
        [Default: 3306]
- login_unix_socket
        The path to a Unix domain socket for local connections.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: None]
= name
        name of the user (role) to add or remove

- password
        set the user's password.
        [Default: None]
- priv
        MySQL privileges string in the format: `db.table:priv1,priv2'.
        Multiple privileges can be specified by separating each one using a forward slash: `db.table:priv/db.table:priv'.
        The format is based on MySQL `GRANT' statement.
        Database and table names can be quoted, MySQL-style.
        If column privileges are used, the `priv1,priv2' part must be exactly as returned by a `SHOW GRANT' statement. If
        not followed, the module will always report changes. It includes grouping columns by permission
        (`SELECT(col1,col2') instead of `SELECT(col1',SELECT(col2))).
        [Default: None]
- sql_log_bin
        Whether binary logging should be enabled or disabled for the connection.
        (Choices: yes, no)[Default: yes]
- ssl_ca
        The path to a Certificate Authority (CA) certificate. This option, if used, must specify the same certificate as
        used by the server.
        [Default: None]
- ssl_cert
        The path to a client public key certificate.
        [Default: None]
- ssl_key
        The path to the client private key.
        [Default: None]
- state
        Whether the user should exist.  When `absent', removes the user.
        (Choices: present, absent)[Default: present]
- update_password
        `always' will update passwords if they differ.  `on_create' will only set the password for newly created users.
        (Choices: always, on_create)[Default: always]
Notes:
  * MySQL server installs with default login_user of 'root' and no password. To secure this user as part of an
        idempotent playbook, you must create at least two tasks: the first must change the root user's password,
        without providing any login_user/login_password details. The second must drop a ~/.my.cnf file containing
        the new root credentials. Subsequent runs of the playbook will then succeed by reading the new credentials
        from the file.
  * Currently, there is only support for the `mysql_native_password` encrypted password hash module.
  * Requires the MySQLdb Python package on the remote host. For Ubuntu, this is as easy as apt-get install python-
        mysqldb. (See [apt].) For CentOS/Fedora, this is as easy as yum install MySQL-python. (See [yum].)
  * Both `login_password' and `login_user' are required when you are passing credentials. If none are present, the
        module will attempt to read the credentials from `~/.my.cnf', and finally fall back to using the MySQL
        default login of 'root' with no password.
Requirements:  MySQLdb

EXAMPLES:
# Removes anonymous user account for localhost
- mysql_user:
    name: ''
    host: localhost
    state: absent

# Removes all anonymous user accounts
- mysql_user:
    name: ''
    host_all: yes
    state: absent

# Create database user with name 'bob' and password '12345' with all database privileges
- mysql_user:
    name: bob
    password: 12345
    priv: '*.*:ALL'
    state: present

# Create database user with name 'bob' and previously hashed mysql native password '*EE0D72C1085C46C5278932678FBE2C6A782821B4' with all database privileges
- mysql_user:
    name: bob
    password: '*EE0D72C1085C46C5278932678FBE2C6A782821B4'
    encrypted: yes
    priv: '*.*:ALL'
    state: present

# Creates database user 'bob' and password '12345' with all database privileges and 'WITH GRANT OPTION'
- mysql_user:
    name: bob
    password: 12345
    priv: '*.*:ALL,GRANT'
    state: present

# Modify user Bob to require SSL connections. Note that REQUIRESSL is a special privilege that should only apply to *.* by itself.
- mysql_user:
    name: bob
    append_privs: true
    priv: '*.*:REQUIRESSL'
    state: present

# Ensure no user named 'sally'@'localhost' exists, also passing in the auth credentials.
- mysql_user:
    login_user: root
    login_password: 123456
    name: sally
    state: absent

# Ensure no user named 'sally' exists at all
- mysql_user:
    name: sally
    host_all: yes
    state: absent

# Specify grants composed of more than one word
- mysql_user:
    name: replication
    password: 12345
    priv: "*.*:REPLICATION CLIENT"
    state: present

# Revoke all privileges for user 'bob' and password '12345'
- mysql_user:
    name: bob
    password: 12345
    priv: "*.*:USAGE"
    state: present

# Example privileges string format
# mydb.*:INSERT,UPDATE/anotherdb.*:SELECT/yetanotherdb.*:ALL

# Example using login_unix_socket to connect to server
- mysql_user:
    name: root
    password: abc123
    login_unix_socket: /var/run/mysqld/mysqld.sock

# Example of skipping binary logging while adding user 'bob'
- mysql_user:
    name: bob
    password: 12345
    priv: "*.*:USAGE"
    state: present
    sql_log_bin: no

# Example .my.cnf file for setting the root password
# [client]
# user=root
# password=n<_665{vS43y


MAINTAINERS: Jonathan Mainguy (@Jmainguy)

METADATA:
	Status: ['preview']
	Supported_by: community
> MYSQL_VARIABLES    (/usr/lib/python2.7/site-packages/ansible/modules/database/mysql/mysql_variables.py)

  Query / Set MySQL variables

Options (= is mandatory):

- config_file
        Specify a config file from which user and password are to be read.
        [Default: ~/.my.cnf]
- connect_timeout
        The connection timeout when connecting to the MySQL server.
        [Default: 30]
- login_host
        Host running the database.
        [Default: localhost]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_port
        Port of the MySQL server. Requires `login_host' be defined as other then localhost if login_port is used.
        [Default: 3306]
- login_unix_socket
        The path to a Unix domain socket for local connections.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: None]
- ssl_ca
        The path to a Certificate Authority (CA) certificate. This option, if used, must specify the same certificate as
        used by the server.
        [Default: None]
- ssl_cert
        The path to a client public key certificate.
        [Default: None]
- ssl_key
        The path to the client private key.
        [Default: None]
- value
        If set, then sets variable value to this
        [Default: (null)]
= variable
        Variable name to operate

Notes:
  * Requires the MySQLdb Python package on the remote host. For Ubuntu, this is as easy as apt-get install python-
        mysqldb. (See [apt].) For CentOS/Fedora, this is as easy as yum install MySQL-python. (See [yum].)
  * Both `login_password' and `login_user' are required when you are passing credentials. If none are present, the
        module will attempt to read the credentials from `~/.my.cnf', and finally fall back to using the MySQL
        default login of 'root' with no password.
Requirements:  MySQLdb

EXAMPLES:
# Check for sync_binlog setting
- mysql_variables:
    variable: sync_binlog

# Set read_only variable to 1
- mysql_variables:
    variable: read_only
    value: 1


MAINTAINERS: Balazs Pocze (@banyek)

METADATA:
	Status: ['preview']
	Supported_by: community
> NA_CDOT_AGGREGATE    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/na_cdot_aggregate.py)

  Create or destroy aggregates on NetApp cDOT.

Options (= is mandatory):

- disk_count
        Number of disks to place into the aggregate, including parity disks.
        The disks in this newly-created aggregate come from the spare disk pool.
        The smallest disks in this pool join the aggregate first, unless the `disk-size' argument is provided.
        Either `disk-count' or `disks' must be supplied. Range [0..2^31-1].
        Required when `state=present'.
        [Default: (null)]
= hostname
        The hostname or IP address of the ONTAP instance.

= name
        The name of the aggregate to manage.

= password
        Password for the specified user.

= state
        Whether the specified aggregate should exist or not.
        (Choices: present, absent)
= username
        This can be a Cluster-scoped or SVM-scoped account, depending on whether a Cluster-level or SVM-level API is
        required. For more information, please read the documentation https://goo.gl/BRu78Z.

Notes:
  * The modules prefixed with `netapp\_cdot' are built to support the ONTAP storage platform.
Requirements:  A physical or virtual clustered Data ONTAP system. The modules were developed with Clustered Data ONTAP
        8.3, Ansible 2.2, netapp-lib (2015.9.25). Install using 'pip install netapp-lib'

EXAMPLES:
- name: Manage Aggregates
  na_cdot_aggregate:
    state: present
    name: ansibleAggr
    disk_count: 1
    hostname: "{{ netapp_hostname }}"
    username: "{{ netapp_username }}"
    password: "{{ netapp_password }}"

- name: Manage Aggregates
  na_cdot_aggregate:
    state: present
    name: ansibleAggr
    hostname: "{{ netapp_hostname }}"
    username: "{{ netapp_username }}"
    password: "{{ netapp_password }}"

RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> NA_CDOT_LICENSE    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/na_cdot_license.py)

  Add or remove licenses on NetApp ONTAP.

Options (= is mandatory):

= hostname
        The hostname or IP address of the ONTAP instance.

- licenses
        List of licenses to add or remove.
        Please note that trying to remove a non-existent license will throw an error.
        [Default: (null)]
= password
        Password for the specified user.

- remove_expired
        Remove licenses that have expired in the cluster.
        (Choices: true, false)[Default: (null)]
- remove_unused
        Remove licenses that have no controller affiliation in the cluster.
        (Choices: true, false)[Default: (null)]
- serial_number
        Serial number of the node associated with the license.
        This parameter is used primarily when removing license for a specific service.
        If this parameter is not provided, the cluster serial number is used by default.
        [Default: None]
= username
        This can be a Cluster-scoped or SVM-scoped account, depending on whether a Cluster-level or SVM-level API is
        required. For more information, please read the documentation https://goo.gl/BRu78Z.

Notes:
  * The modules prefixed with `netapp\_cdot' are built to support the ONTAP storage platform.
Requirements:  A physical or virtual clustered Data ONTAP system. The modules were developed with Clustered Data ONTAP
        8.3, Ansible 2.2, netapp-lib (2015.9.25). Install using 'pip install netapp-lib'

EXAMPLES:
- name: Add licenses
  na_cdot_license:
    hostname: "{{ netapp_hostname }}"
    username: "{{ netapp_username }}"
    password: "{{ netapp_password }}"
    serial_number: #################
    licenses:
      nfs: #################
      cifs: #################
      iscsi: #################
      fcp: #################
      snaprestore: #################
      flexclone: #################

- name: Remove licenses
  na_cdot_license:
    hostname: "{{ netapp_hostname }}"
    username: "{{ netapp_username }}"
    password: "{{ netapp_password }}"
    remove_unused: false
    remove_expired: true
    serial_number: #################
    licenses:
      nfs: remove

RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> NA_CDOT_LUN    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/na_cdot_lun.py)

  Create, destroy, resize luns on NetApp cDOT.

Options (= is mandatory):

- flexvol_name
        The name of the FlexVol the lun should exist on.
        Required when `state=present'.
        [Default: (null)]
- force_remove
        If "true", override checks that prevent a LUN from being destroyed if it is online and mapped.
        If "false", destroying an online and mapped LUN will fail.
        [Default: False]
- force_remove_fenced
        If "true", override checks that prevent a LUN from being destroyed while it is fenced.
        If "false", attempting to destroy a fenced LUN will fail.
        The default if not specified is "false". This field is available in Data ONTAP 8.2 and later.
        [Default: False]
- force_resize
        Forcibly reduce the size. This is required for reducing the size of the LUN to avoid accidentally reducing the
        LUN size.
        [Default: False]
= hostname
        The hostname or IP address of the ONTAP instance.

= name
        The name of the lun to manage.

= password
        Password for the specified user.

- size
        The size of the lun in `size_unit'.
        Required when `state=present'.
        [Default: (null)]
- size_unit
        The unit used to interpret the size parameter.
        (Choices: bytes, b, kb, mb, gb, tb, pb, eb, zb, yb)[Default: gb]
= state
        Whether the specified lun should exist or not.
        (Choices: present, absent)
= username
        This can be a Cluster-scoped or SVM-scoped account, depending on whether a Cluster-level or SVM-level API is
        required. For more information, please read the documentation https://goo.gl/BRu78Z.

= vserver
        The name of the vserver to use.

Notes:
  * The modules prefixed with `netapp\_cdot' are built to support the ONTAP storage platform.
Requirements:  A physical or virtual clustered Data ONTAP system. The modules were developed with Clustered Data ONTAP
        8.3, Ansible 2.2, netapp-lib (2015.9.25). Install using 'pip install netapp-lib'

EXAMPLES:
- name: Create LUN
  na_cdot_lun:
    state: present
    name: ansibleLUN
    flexvol_name: ansibleVolume
    vserver: ansibleVServer
    size: 5
    size_unit: mb
    hostname: "{{ netapp_hostname }}"
    username: "{{ netapp_username }}"
    password: "{{ netapp_password }}"

- name: Resize Lun
  na_cdot_lun:
    state: present
    name: ansibleLUN
    force_resize: True
    flexvol_name: ansibleVolume
    vserver: ansibleVServer
    size: 5
    size_unit: gb
    hostname: "{{ netapp_hostname }}"
    username: "{{ netapp_username }}"
    password: "{{ netapp_password }}"

RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> NA_CDOT_QTREE    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/na_cdot_qtree.py)

  Create or destroy Qtrees.

Options (= is mandatory):

- flexvol_name
        The name of the FlexVol the Qtree should exist on. Required when `state=present'.
        [Default: (null)]
= hostname
        The hostname or IP address of the ONTAP instance.

= name
        The name of the Qtree to manage.

= password
        Password for the specified user.

= state
        Whether the specified Qtree should exist or not.
        (Choices: present, absent)
= username
        This can be a Cluster-scoped or SVM-scoped account, depending on whether a Cluster-level or SVM-level API is
        required. For more information, please read the documentation https://goo.gl/BRu78Z.

= vserver
        The name of the vserver to use.

Notes:
  * The modules prefixed with `netapp\_cdot' are built to support the ONTAP storage platform.
Requirements:  A physical or virtual clustered Data ONTAP system. The modules were developed with Clustered Data ONTAP
        8.3, Ansible 2.2, netapp-lib (2015.9.25). Install using 'pip install netapp-lib'

EXAMPLES:
- name: Create QTree
  na_cdot_qtree:
    state: present
    name: ansibleQTree
    flexvol_name: ansibleVolume
    vserver: ansibleVServer
    hostname: "{{ netapp_hostname }}"
    username: "{{ netapp_username }}"
    password: "{{ netapp_password }}"

- name: Rename QTree
  na_cdot_qtree:
    state: present
    name: ansibleQTree
    flexvol_name: ansibleVolume
    vserver: ansibleVServer
    hostname: "{{ netapp_hostname }}"
    username: "{{ netapp_username }}"
    password: "{{ netapp_password }}"

RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> NA_CDOT_SVM    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/na_cdot_svm.py)

  Create or destroy svm on NetApp cDOT

Options (= is mandatory):

= hostname
        The hostname or IP address of the ONTAP instance.

= name
        The name of the SVM to manage.

= password
        Password for the specified user.

- root_volume
        Root volume of the SVM. Required when `state=present'.
        [Default: (null)]
- root_volume_aggregate
        The aggregate on which the root volume will be created.
        Required when `state=present'.
        [Default: (null)]
- root_volume_security_style
        Security Style of the root volume.
        When specified as part of the vserver-create, this field represents the security style for the Vserver root
        volume.
        When specified as part of vserver-get-iter call, this will return the list of matching Vservers.
        Possible values are 'unix', 'ntfs', 'mixed'.
        The 'unified' security style, which applies only to Infinite Volumes, cannot be applied to a Vserver's root
        volume.
        Valid options are "unix" for NFS, "ntfs" for CIFS, "mixed" for Mixed, "unified" for Unified.
        Required when `state=present'
        (Choices: unix, ntfs, mixed, unified)[Default: (null)]
= state
        Whether the specified SVM should exist or not.
        (Choices: present, absent)
= username
        This can be a Cluster-scoped or SVM-scoped account, depending on whether a Cluster-level or SVM-level API is
        required. For more information, please read the documentation https://goo.gl/BRu78Z.

Notes:
  * The modules prefixed with `netapp\_cdot' are built to support the ONTAP storage platform.
Requirements:  A physical or virtual clustered Data ONTAP system. The modules were developed with Clustered Data ONTAP
        8.3, Ansible 2.2, netapp-lib (2015.9.25). Install using 'pip install netapp-lib'

EXAMPLES:

    - name: Create SVM
      na_cdot_svm:
        state: present
        name: ansibleVServer
        root_volume: vol1
        root_volume_aggregate: aggr1
        root_volume_security_style: mixed
        hostname: "{{ netapp_hostname }}"
        username: "{{ netapp_username }}"
        password: "{{ netapp_password }}"


RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> NA_CDOT_USER    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/na_cdot_user.py)

  Create or destroy users.

Options (= is mandatory):

= application
        Applications to grant access to.
        (Choices: console, http, ontapi, rsh, snmp, sp, ssh, telnet)
= authentication_method
        Authentication method for the application.
        Not all authentication methods are valid for an application.
        Valid authentication methods for each application are as denoted in `authentication_choices_description'.
        password for console application
        password, domain, nsswitch, cert for http application.
        password, domain, nsswitch, cert for ontapi application.
        community for snmp application (when creating SNMPv1 and SNMPv2 users).
        usm and community for snmp application (when creating SNMPv3 users).
        password for sp application.
        password for rsh application.
        password for telnet application.
        password, publickey, domain, nsswitch for ssh application.
        (Choices: community, password, publickey, domain, nsswitch, usm)
= hostname
        The hostname or IP address of the ONTAP instance.

= name
        The name of the user to manage.

= password
        Password for the specified user.

- role_name
        The name of the role. Required when `state=present'
        [Default: (null)]
- set_password
        Password for the user account.
        It is ignored for creating snmp users, but is required for creating non-snmp users.
        For an existing user, this value will be used as the new password.
        [Default: None]
= state
        Whether the specified user should exist or not.
        (Choices: present, absent)
= username
        This can be a Cluster-scoped or SVM-scoped account, depending on whether a Cluster-level or SVM-level API is
        required. For more information, please read the documentation https://goo.gl/BRu78Z.

= vserver
        The name of the vserver to use.

Notes:
  * The modules prefixed with `netapp\_cdot' are built to support the ONTAP storage platform.
Requirements:  A physical or virtual clustered Data ONTAP system. The modules were developed with Clustered Data ONTAP
        8.3, Ansible 2.2, netapp-lib (2015.9.25). Install using 'pip install netapp-lib'

EXAMPLES:

    - name: Create User
      na_cdot_user:
        state: present
        name: SampleUser
        application: ssh
        authentication_method: password
        set_password: apn1242183u1298u41
        role_name: vsadmin
        vserver: ansibleVServer
        hostname: "{{ netapp_hostname }}"
        username: "{{ netapp_username }}"
        password: "{{ netapp_password }}"


RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> NA_CDOT_USER_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/na_cdot_user_role.py)

  Create or destroy user roles

Options (= is mandatory):

- access_level
        The name of the role to manage.
        (Choices: none, readonly, all)[Default: all]
= command_directory_name
        The command or command directory to which the role has an access.

= hostname
        The hostname or IP address of the ONTAP instance.

= name
        The name of the role to manage.

= password
        Password for the specified user.

= state
        Whether the specified user should exist or not.
        (Choices: present, absent)
= username
        This can be a Cluster-scoped or SVM-scoped account, depending on whether a Cluster-level or SVM-level API is
        required. For more information, please read the documentation https://goo.gl/BRu78Z.

= vserver
        The name of the vserver to use.

Notes:
  * The modules prefixed with `netapp\_cdot' are built to support the ONTAP storage platform.
Requirements:  A physical or virtual clustered Data ONTAP system. The modules were developed with Clustered Data ONTAP
        8.3, Ansible 2.2, netapp-lib (2015.9.25). Install using 'pip install netapp-lib'

EXAMPLES:

    - name: Create User Role
      na_cdot_user_role:
        state: present
        name: ansibleRole
        command_directory_name: DEFAULT
        access_level: none
        vserver: ansibleVServer
        hostname: "{{ netapp_hostname }}"
        username: "{{ netapp_username }}"
        password: "{{ netapp_password }}"


RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> NA_CDOT_VOLUME    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/na_cdot_volume.py)

  Create or destroy volumes on NetApp cDOT

Options (= is mandatory):

- aggregate_name
        The name of the aggregate the flexvol should exist on. Required when `state=present'.
        [Default: (null)]
= hostname
        The hostname or IP address of the ONTAP instance.

- infinite
        Set True if the volume is an Infinite Volume.
        (Choices: True, False)[Default: False]
= name
        The name of the lun to manage.

- online
        Whether the specified volume is online, or not.
        (Choices: True, False)[Default: True]
= password
        Password for the specified user.

- size
        The size of the volume in (size_unit). Required when `state=present'.
        [Default: (null)]
- size_unit
        The unit used to interpret the size parameter.
        (Choices: bytes, b, kb, mb, gb, tb, pb, eb, zb, yb)[Default: gb]
= state
        Whether the specified volume should exist or not.
        (Choices: present, absent)
= username
        This can be a Cluster-scoped or SVM-scoped account, depending on whether a Cluster-level or SVM-level API is
        required. For more information, please read the documentation https://goo.gl/BRu78Z.

= vserver
        Name of the vserver to use.
        [Default: None]
Notes:
  * The modules prefixed with `netapp\_cdot' are built to support the ONTAP storage platform.
Requirements:  A physical or virtual clustered Data ONTAP system. The modules were developed with Clustered Data ONTAP
        8.3, Ansible 2.2, netapp-lib (2015.9.25). Install using 'pip install netapp-lib'

EXAMPLES:

    - name: Create FlexVol
      na_cdot_volume:
        state: present
        name: ansibleVolume
        infinite: False
        aggregate_name: aggr1
        size: 20
        size_unit: mb
        vserver: ansibleVServer
        hostname: "{{ netapp_hostname }}"
        username: "{{ netapp_username }}"
        password: "{{ netapp_password }}"

    - name: Make FlexVol offline
      na_cdot_volume:
        state: present
        name: ansibleVolume
        infinite: False
        online: False
        vserver: ansibleVServer
        hostname: "{{ netapp_hostname }}"
        username: "{{ netapp_username }}"
        password: "{{ netapp_password }}"


RETURN VALUES:




MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> NAGIOS    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/nagios.py)

  The `nagios' module has two basic functions: scheduling downtime and toggling alerts for services or hosts. All actions
  require the `host' parameter to be given explicitly. In playbooks you can use the `{{inventory_hostname}}' variable to
  refer to the host the playbook is currently running on. You can specify multiple services at once by separating them
  with commas, .e.g., `services=httpd,nfs,puppet'. When specifying what service to handle there is a special service
  value, `host', which will handle alerts/downtime for the `host itself', e.g., `service=host'. This keyword may not be
  given with other services at the same time. `Setting alerts/downtime for a host does not affect alerts/downtime for any
  of the services running on it.' To schedule downtime for all services on particular host use keyword "all", e.g.,
  `service=all'. When using the `nagios' module you will need to specify your Nagios server using the `delegate_to'
  parameter.

Options (= is mandatory):

= action
        Action to take.
        servicegroup options were added in 2.0.
        delete_downtime options were added in 2.2.
        (Choices: downtime, delete_downtime, enable_alerts, disable_alerts, silence, unsilence, silence_nagios,
        unsilence_nagios, command, servicegroup_service_downtime, servicegroup_host_downtime)
- author
        Author to leave downtime comments as. Only usable with the `downtime' action.
        [Default: Ansible]
- cmdfile
        Path to the nagios `command file' (FIFO pipe). Only required if auto-detection fails.
        [Default: auto-detected]
= command
        The raw command to send to nagios, which should not include the submitted time header or the line-feed *Required*
        option when using the `command' action.

- comment
        Comment for `downtime' action.
        [Default: Scheduling downtime]
- host
        Host to operate on in Nagios.
        [Default: None]
- minutes
        Minutes to schedule downtime for.
        Only usable with the `downtime' action.
        [Default: 30]
- servicegroup
        The Servicegroup we want to set downtimes/alerts for. *Required* option when using the
        `servicegroup_service_downtime' amd `servicegroup_host_downtime'.
        [Default: (null)]
= services
        What to manage downtime/alerts for. Separate multiple services with commas. `service' is an alias for `services'.
        *Required* option when using the `downtime', `enable_alerts', and `disable_alerts' actions.

EXAMPLES:
# set 30 minutes of apache downtime
- nagios:
    action: downtime
    minutes: 30
    service: httpd
    host: '{{ inventory_hostname }}'

# schedule an hour of HOST downtime
- nagios:
    action: downtime
    minutes: 60
    service: host
    host: '{{ inventory_hostname }}'

# schedule an hour of HOST downtime, with a comment describing the reason
- nagios:
    action: downtime
    minutes: 60
    service: host
    host: '{{ inventory_hostname }}'
    comment: Rebuilding machine

# schedule downtime for ALL services on HOST
- nagios:
    action: downtime
    minutes: 45
    service: all
    host: '{{ inventory_hostname }}'

# schedule downtime for a few services
- nagios:
    action: downtime
    services: frob,foobar,qeuz
    host: '{{ inventory_hostname }}'

# set 30 minutes downtime for all services in servicegroup foo
- nagios:
    action: servicegroup_service_downtime
    minutes: 30
    servicegroup: foo
    host: '{{ inventory_hostname }}'

# set 30 minutes downtime for all host in servicegroup foo
- nagios:
    action: servicegroup_host_downtime
    minutes: 30
    servicegroup: foo
    host: '{{ inventory_hostname }}'

# delete all downtime for a given host
- nagios:
    action: delete_downtime
    host: '{{ inventory_hostname }}'
    service: all

# delete all downtime for HOST with a particular comment
- nagios:
    action: delete_downtime
    host: '{{ inventory_hostname }}'
    service: host
    comment: Planned maintenance

# enable SMART disk alerts
- nagios:
    action: enable_alerts
    service: smart
    host: '{{ inventory_hostname }}'

# "two services at once: disable httpd and nfs alerts"
- nagios:
    action: disable_alerts
    service: httpd,nfs
    host: '{{ inventory_hostname }}'

# disable HOST alerts
- nagios:
    action: disable_alerts
    service: host
    host: '{{ inventory_hostname }}'

# silence ALL alerts
- nagios:
    action: silence
    host: '{{ inventory_hostname }}'

# unsilence all alerts
- nagios:
    action: unsilence
    host: '{{ inventory_hostname }}'

# SHUT UP NAGIOS
- nagios:
    action: silence_nagios

# ANNOY ME NAGIOS
- nagios:
    action: unsilence_nagios

# command something
- nagios:
    action: command
    command: DISABLE_FAILURE_PREDICTION


MAINTAINERS: Tim Bielawa (@tbielawa)

METADATA:
	Status: ['preview']
	Supported_by: community
> NCLU    (/usr/lib/python2.7/site-packages/ansible/modules/network/cumulus/nclu.py)

  Interface to the Network Command Line Utility, developed to make it easier to configure operating systems running
  ifupdown2 and Quagga, such as Cumulus Linux. Command documentation is available at
  https://docs.cumulusnetworks.com/display/DOCS/Network+Command+Line+Utility

Options (= is mandatory):

- abort
        Boolean. When true, perform a 'net abort' before the block. This cleans out any uncommitted changes in the
        buffer. Mutually exclusive with `atomic'.
        [Default: False]
- atomic
        When true, equivalent to both `commit' and `abort' being true. Mutually exclusive with `commit' and `atomic'.
        [Default: False]
- commands
        A list of strings containing the net commands to run. Mutually exclusive with `template'.
        [Default: (null)]
- commit
        When true, performs a 'net commit' at the end of the block. Mutually exclusive with `atomic'.
        [Default: False]
- description
        Commit description that will be recorded to the commit log if `commit' or `atomic' are true.
        [Default: Ansible-originated commit]
- template
        A single, multi-line string with jinja2 formatting. This string will be broken by lines, and each line will be
        run through net. Mutually exclusive with `commands'.
        [Default: (null)]
EXAMPLES:

- name: Add two interfaces without committing any changes
  nclu:
    commands:
        - add int swp1
        - add int swp2

- name: Add 48 interfaces and commit the change.
  nclu:
    template: |
        {% for iface in range(1,49) %}
        add int swp{{iface}}
        {% endfor %}
    commit: true
    description: "Ansible - add swps1-48"

- name: Atomically add an interface
  nclu:
    commands:
        - add int swp1
    atomic: true
    description: "Ansible - add swp1"

RETURN VALUES:
changed:
    description: whether the interface was changed
    returned: changed
    type: bool
    sample: True
msg:
    description: human-readable report of success or failure
    returned: always
    type: string
    sample: "interface bond0 config updated"


MAINTAINERS: Cumulus Networks

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_AMG    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_amg.py)

  Allows for the creation, removal and updating of Asynchronous Mirror Groups for NetApp E-series storage arrays

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- interfaceType
        The intended protocol to use if both Fibre and iSCSI are available.
        (Choices: iscsi, fibre)[Default: None]
- manualSync
        Setting this to true will cause other synchronization values to be ignored
        [Default: False]
= name
        The name of the async array you wish to target, or create.
        If `state' is present and the name isn't found, it will attempt to create.

- recoveryWarnThresholdMinutes
        Recovery point warning threshold (minutes). The user will be warned when the age of the last good failures point
        exceeds this value
        [Default: 20]
- repoUtilizationWarnThreshold
        Recovery point warning threshold
        [Default: 80]
= secondaryArrayId
        The ID of the secondary array to be used in mirroing process

= ssid
        The ID of the array to manage. This value must be unique for each array.

= state
        A `state' of present will either create or update the async mirror group.
        A `state' of absent will remove the async mirror group.

- syncIntervalMinutes
        The synchronization interval in minutes
        [Default: 10]
- syncWarnThresholdMinutes
        The threshold (in minutes) for notifying the user that periodic synchronization has taken too long to complete.
        [Default: 10]
- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: AMG removal
      na_eseries_amg:
        state: absent
        ssid: "{{ ssid }}"
        secondaryArrayId: "{{amg_secondaryArrayId}}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        new_name: "{{amg_array_name}}"
        name: "{{amg_name}}"
      when: amg_create

    - name: AMG create
      netapp_e_amg:
        state: present
        ssid: "{{ ssid }}"
        secondaryArrayId: "{{amg_secondaryArrayId}}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        new_name: "{{amg_array_name}}"
        name: "{{amg_name}}"
      when: amg_create

RETURN VALUES:
msg:
    description: Successful removal
    returned: success
    type: string
    sample: "Async mirror group removed."

msg:
    description: Successful creation
    returned: success
    type: string
    sample: '{"changed": true, "connectionType": "fc", "groupRef": "3700000060080E5000299C24000006E857AC7EEC", "groupState": "optimal", "id": "3700000060080E5000299C24000006E857AC7EEC", "label": "amg_made_by_ansible", "localRole": "primary", "mirrorChannelRemoteTarget": "9000000060080E5000299C24005B06E557AC7EEC", "orphanGroup": false, "recoveryPointAgeAlertThresholdMinutes": 20, "remoteRole": "secondary", "remoteTarget": {"nodeName": {"ioInterfaceType": "fc", "iscsiNodeName": null, "remoteNodeWWN": "20040080E5299F1C"}, "remoteRef": "9000000060080E5000299C24005B06E557AC7EEC", "scsiinitiatorTargetBaseProperties": {"ioInterfaceType": "fc", "iscsiinitiatorTargetBaseParameters": null}}, "remoteTargetId": "ansible2", "remoteTargetName": "Ansible2", "remoteTargetWwn": "60080E5000299F880000000056A25D56", "repositoryUtilizationWarnThreshold": 80, "roleChangeProgress": "none", "syncActivity": "idle", "syncCompletionTimeAlertThresholdMinutes": 10, "syncIntervalMinutes": 10, "worldWideName": "60080E5000299C24000006E857AC7EEC"}'


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_AMG_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_amg_role.py)

  Update a storage array to become the primary or secondary instance in an asynchronous mirror group

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- force
        Whether to force the role reversal regardless of the online-state of the primary
        [Default: False]
- noSync
        Whether to avoid synchronization prior to role reversal
        (Choices: True, False)[Default: False]
= role
        Whether the array should be the primary or secondary array for the AMG
        (Choices: primary, secondary)
= ssid
        The ID of the primary storage array for the async mirror action

- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: Update the role of a storage array
      netapp_e_amg_role:
        name: updating amg role
        role: primary
        ssid: "{{ ssid }}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"

RETURN VALUES:
msg:
    description: Failure message
    returned: failure
    type: string
    sample: "No Async Mirror Group with the name."


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_AMG_SYNC    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_amg_sync.py)

  Allows for the initialization, suspension and resumption of an asynchronous mirror group's synchronization for NetApp
  E-series storage arrays.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- delete_recovery_point
        Indicates whether the failures point can be deleted on the secondary if necessary to achieve the synchronization.
        If true, and if the amount of unsynchronized data exceeds the CoW repository capacity on the secondary for any
        member volume, the last failures point will be deleted and synchronization will continue.
        If false, the synchronization will be suspended if the amount of unsynchronized data exceeds the CoW Repository
        capacity on the secondary and the failures point will be preserved.
        NOTE: This only has impact for newly launched syncs.
        (Choices: True, False)[Default: False]
= name
        The name of the async mirror group you wish to target

- ssid
        The ID of the storage array containing the AMG you wish to target
        [Default: (null)]
= state
        The synchronization action you'd like to take.
        If `running' then it will begin syncing if there is no active sync or will resume a suspended sync. If there is
        already a sync in progress, it will return with an OK status.
        If `suspended' it will suspend any ongoing sync action, but return OK if there is no active sync or if the sync
        is already suspended
        (Choices: running, suspended)
- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: start AMG async
      netapp_e_amg_sync:
        name: "{{ amg_sync_name }}"
        state: running
        ssid: "{{ ssid }}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"

RETURN VALUES:
json:
    description: The object attributes of the AMG.
    returned: success
    type: string
    example:
        {
            "changed": false,
            "connectionType": "fc",
            "groupRef": "3700000060080E5000299C24000006EF57ACAC70",
            "groupState": "optimal",
            "id": "3700000060080E5000299C24000006EF57ACAC70",
            "label": "made_with_ansible",
            "localRole": "primary",
            "mirrorChannelRemoteTarget": "9000000060080E5000299C24005B06E557AC7EEC",
            "orphanGroup": false,
            "recoveryPointAgeAlertThresholdMinutes": 20,
            "remoteRole": "secondary",
            "remoteTarget": {
                "nodeName": {
                    "ioInterfaceType": "fc",
                    "iscsiNodeName": null,
                    "remoteNodeWWN": "20040080E5299F1C"
                },
                "remoteRef": "9000000060080E5000299C24005B06E557AC7EEC",
                "scsiinitiatorTargetBaseProperties": {
                    "ioInterfaceType": "fc",
                    "iscsiinitiatorTargetBaseParameters": null
                }
            },
            "remoteTargetId": "ansible2",
            "remoteTargetName": "Ansible2",
            "remoteTargetWwn": "60080E5000299F880000000056A25D56",
            "repositoryUtilizationWarnThreshold": 80,
            "roleChangeProgress": "none",
            "syncActivity": "idle",
            "syncCompletionTimeAlertThresholdMinutes": 10,
            "syncIntervalMinutes": 10,
            "worldWideName": "60080E5000299C24000006EF57ACAC70"
    }


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_AUTH    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_auth.py)

  Sets or updates the password for a storage array.  When the password is updated on the storage array, it must be
  updated on the SANtricity Web Services proxy. Note, all storage arrays do not have a Monitor or RO role.

Options (= is mandatory):

- api_password
        The password used to authenticate against the API
        This can optionally be set via an environment variable, API_PASSWORD
        [Default: (null)]
- api_url
        The full API url.
        Example: http://ENDPOINT:8080/devmgr/v2
        This can optionally be set via an environment variable, API_URL
        [Default: (null)]
- api_username
        The username used to authenticate against the API
        This can optionally be set via an environment variable, API_USERNAME
        [Default: (null)]
- current_password
        The current admin password. This is not required if the password hasn't been set before.
        [Default: (null)]
- name
        The name of the storage array. Note that if more than one storage array with this name is detected, the task will
        fail and you'll have to use the ID instead.
        [Default: (null)]
= new_password
        The password you would like to set. Cannot be more than 30 characters.

- set_admin
        Boolean value on whether to update the admin password. If set to false then the RO account is updated.
        [Default: False]
- ssid
        the identifier of the storage array in the Web Services Proxy.
        [Default: (null)]
- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
- name: Test module
  netapp_e_auth:
    name: trex
    current_password: OldPasswd
    new_password: NewPasswd
    set_admin: yes
    api_url: '{{ netapp_api_url }}'
    api_username: '{{ netapp_api_username }}'
    api_password: '{{ netapp_api_password }}'

RETURN VALUES:
msg:
    description: Success message
    returned: success
    type: string
    sample: "Password Updated Successfully"


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_facts.py)

  Return various information about NetApp E-Series storage arrays (eg, configuration, disks)

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= ssid
        The ID of the array to manage. This value must be unique for each array.

- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
---
    - name: Get array facts
      netapp_e_facts:
        array_id: "{{ netapp_array_id }}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"

RETURN VALUES:
msg: Gathered facts for <StorageArrayId>.


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_FLASHCACHE    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_flashcache.py)

  Create or remove SSD caches on a NetApp E-Series storage array.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- cache_size_min
        The minimum size (in size_units) of the ssd cache. The cache will be expanded if this exceeds the current size of
        the cache.
        [Default: (null)]
- disk_count
        The minimum number of disks to use for building the cache. The cache will be expanded if this number exceeds the
        number of disks already in place
        [Default: (null)]
- io_type
        The type of workload to optimize the cache for.
        (Choices: filesystem, database, media)[Default: filesystem]
= name
        The name of the SSD cache to manage

- size_unit
        The unit to be applied to size arguments
        (Choices: bytes, b, kb, mb, gb, tb, pb, eb, zb, yb)[Default: gb]
= ssid
        The ID of the array to manage (as configured on the web services proxy).

= state
        Whether the specified SSD cache should exist or not.
        (Choices: present, absent)[Default: present]
- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: Flash Cache
      netapp_e_flashcache:
        ssid: "{{ ssid }}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"
        name: SSDCacheBuiltByAnsible

RETURN VALUES:
msg:
    description: Success message
    returned: success
    type: string
    sample: json for newly created flash cache


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_host.py)

  Create, update, remove hosts on NetApp E-series storage arrays

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API, for example
        `https://prod-1.wahoo.acme.com/devmgr/v2'.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- group
        the group you want the host to be a member of
        [Default: (null)]
= host_type_index
        The index that maps to host type you wish to create. It is recommended to use the [netapp_e_facts] module to
        gather this information. Alternatively you can use the WSP portal to retrieve the information.

= name
        If the host doesnt yet exist, the label to assign at creation time.
        If the hosts already exists, this is what is used to identify the host to apply any desired changes

- ports
        a list of of dictionaries of host ports you wish to associate with the newly created host
        [Default: (null)]
= ssid
        the id of the storage array you wish to act against

- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: Set Host Info
      netapp_e_host:
        ssid: "{{ ssid }}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        name: "{{ host_name }}"
        host_type_index: "{{ host_type_index }}"

RETURN VALUES:
msg:
    description: Success message
    returned: success
    type: string
    sample: The host has been created.


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_HOSTGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_hostgroup.py)

  Create, update or destroy host groups on a NetApp E-Series storage array.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- hosts:
        a list of host names/labels to add to the group
        [Default: (null)]
- id
        The id number of the host group to manage. Either this or `name' must be supplied.
        [Default: (null)]
- name
        The name of the host group to manage. Either this or `id_num' must be supplied.
        [Default: (null)]
- new_name
        specify this when you need to update the name of a host group
        [Default: (null)]
= ssid
        The ID of the array to manage (as configured on the web services proxy).

= state
        Whether the specified host group should exist or not.
        (Choices: present, absent)
- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: Configure Hostgroup
      netapp_e_hostgroup:
        ssid: "{{ ssid }}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"
        state: present

RETURN VALUES:
clusterRef:
    description: The unique identification value for this object. Other objects may use this reference value to refer to the cluster.
    returned: always except when state is absent
    type: string
    sample: "3233343536373839303132333100000000000000"
confirmLUNMappingCreation:
    description: If true, indicates that creation of LUN-to-volume mappings should require careful confirmation from the end-user, since such a mapping will alter the volume access rights of other clusters, in addition to this one.
    returned: always
    type: boolean
    sample: false
hosts:
    description: A list of the hosts that are part of the host group after all operations.
    returned: always except when state is absent
    type: list
    sample: ["HostA","HostB"]
id:
    description: The id number of the hostgroup
    returned: always except when state is absent
    type: string
    sample: "3233343536373839303132333100000000000000"
isSAControlled:
    description:  If true, indicates that I/O accesses from this cluster are subject to the storage array's default LUN-to-volume mappings. If false, indicates that I/O accesses from the cluster are subject to cluster-specific LUN-to-volume mappings.
    returned: always except when state is absent
    type: boolean
    sample: false
label:
    description: The user-assigned, descriptive label string for the cluster.
    returned: always
    type: string
    sample: "MyHostGroup"
name:
    description: same as label
    returned: always except when state is absent
    type: string
    sample: "MyHostGroup"
protectionInformationCapableAccessMethod:
    description: This field is true if the host has a PI capable access method.
    returned: always except when state is absent
    type: boolean
    sample: true


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_LUN_MAPPING    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_lun_mapping.py)

  Allows for the creation and removal of volume to host mappings for NetApp E-series storage arrays.

Options (= is mandatory):

- api_password
        The password used to authenticate against the API. This can optionally be set via an environment variable,
        API_PASSWORD
        [Default: (null)]
- api_url
        The full API url. Example: http://ENDPOINT:8080/devmgr/v2
        This can optionally be set via an environment variable, API_URL
        [Default: (null)]
- api_username
        The username used to authenticate against the API. This can optionally be set via an environment variable,
        API_USERNAME
        [Default: (null)]
- lun
        The LUN number you wish to give the mapping
        If the supplied `volume_name' is associated with a different LUN, it will be updated to what is supplied here.
        [Default: 0]
- ssid
        The storage system array identifier.
        [Default: (null)]
= state
        Present will ensure the mapping exists, absent will remove the mapping.
        All parameters `lun', `target', `target_type' and `volume_name' must still be supplied.
        (Choices: present, absent)
- target
        The name of host or hostgroup you wish to assign to the mapping
        If omitted, the default hostgroup is used.
        If the supplied `volume_name' is associated with a different target, it will be updated to what is supplied here.
        [Default: (null)]
- target_type
        Whether the target is a host or group.
        Required if supplying an explicit target.
        (Choices: host, group)[Default: (null)]
- validate_certs
        Should https certificates be validated?
        [Default: True]
= volume_name
        The name of the volume you wish to include in the mapping.

EXAMPLES:
---
    - name: Lun Mapping Example
      netapp_e_lun_mapping:
        state: present
        ssid: 1
        lun: 12
        target: Wilson
        volume_name: Colby1
        target_type: group
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"

RETURN VALUES:
msg: Mapping exists.
msg: Mapping removed.


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_SNAPSHOT_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_snapshot_group.py)

  Create, update, delete snapshot groups for NetApp E-series storage arrays

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= base_volume_name
        The name of the base volume or thin volume to use as the base for the new snapshot group.
        If a snapshot group with an identical `name' already exists but with a different base volume an error will be
        returned.

- delete_limit
        The automatic deletion indicator.
        If non-zero, the oldest snapshot image will be automatically deleted when creating a new snapshot image to keep
        the total number of snapshot images limited to the number specified.
        This value is overridden by the consistency group setting if this snapshot group is associated with a consistency
        group.
        [Default: 30]
- full_policy
        The behavior on when the data repository becomes full.
        This value is overridden by consistency group setting if this snapshot group is associated with a consistency
        group
        (Choices: purgepit, unknown, failbasewrites, __UNDEFINED)[Default: purgepit]
= name
        The name to give the snapshot group

- repo_pct
        The size of the repository in relation to the size of the base volume
        [Default: 20]
- rollback_priority
        The importance of the rollback operation.
        This value is overridden by consistency group setting if this snapshot group is associated with a consistency
        group
        (Choices: highest, high, medium, low, lowest, __UNDEFINED)[Default: medium]
= state
        Whether to ensure the group is present or absent.
        (Choices: present, absent)
= storage_pool_name
        The name of the storage pool on which to allocate the repository volume.

- validate_certs
        Should https certificates be validated?
        [Default: True]
- warning_threshold
        The repository utilization warning threshold, as a percentage of the repository volume capacity.
        [Default: 80]
EXAMPLES:
    - name: Configure Snapshot group
      netapp_e_snapshot_group:
        ssid: "{{ ssid }}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"
        base_volume_name: SSGroup_test
        name=: OOSS_Group
        repo_pct: 20
        warning_threshold: 85
        delete_limit: 30
        full_policy: purgepit
        storage_pool_name: Disk_Pool_1
        rollback_priority: medium

RETURN VALUES:
msg:
    description: Success message
    returned: success
    type: string
    sample: json facts for newly created snapshot group.


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_SNAPSHOT_IMAGES    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_snapshot_images.py)

  Create and delete snapshots images on snapshot groups for NetApp E-series storage arrays. Only the oldest snapshot
  image can be deleted so consistency is preserved. Related: Snapshot volumes are created from snapshot images.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= snapshot_group
        The name of the snapshot group in which you want to create a snapshot image.

= state
        Whether a new snapshot image should be created or oldest be deleted.
        (Choices: create, remove)
- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: Create Snapshot
      netapp_e_snapshot_images:
        ssid: "{{ ssid }}"
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ validate_certs }}"
        snapshot_group: "3300000060080E5000299C24000005B656D9F394"
        state: 'create'

RETURN VALUES:
---
    changed: true
    msg: "Created snapshot image"
    image_id: "3400000060080E5000299B640063074057BC5C5E "


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_SNAPSHOT_VOLUME    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_snapshot_volume.py)

  Create, update, remove snapshot volumes for NetApp E/EF-Series storage arrays.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- full_threshold
        The repository utilization warning threshold percentage
        [Default: 85]
= name
        The name you wish to give the snapshot volume

- repo_percentage
        The size of the view in relation to the size of the base volume
        [Default: 20]
= snapshot_image_id
        The identifier of the snapshot image used to create the new snapshot volume.
        Note: You'll likely want to use the [netapp_e_facts] module to find the ID of the image you want.

= ssid
        storage array ID

= state
        Whether to create or remove the snapshot volume
        (Choices: absent, present)
= storage_pool_name
        Name of the storage pool on which to allocate the repository volume.

- validate_certs
        Should https certificates be validated?
        [Default: True]
= view_mode
        The snapshot volume access mode
        (Choices: modeUnknown, readWrite, readOnly, __UNDEFINED)
Notes:
  * Only `full_threshold' is supported for update operations. If the snapshot volume already exists and the
        threshold matches, then an `ok' status will be returned, no other changes can be made to a pre-existing
        snapshot volume.
EXAMPLES:
    - name: Snapshot volume
      netapp_e_snapshot_volume:
        ssid: "{{ ssid }}"
        api_url: "{{ netapp_api_url }}/"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        state: present
        storage_pool_name: "{{ snapshot_volume_storage_pool_name }}"
        snapshot_image_id: "{{ snapshot_volume_image_id }}"
        name: "{{ snapshot_volume_name }}"

RETURN VALUES:
msg:
    description: Success message
    returned: success
    type: string
    sample: Json facts for the volume that was created.


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_STORAGE_SYSTEM    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_storage_system.py)

  Manage the arrays accessible via a NetApp Web Services Proxy for NetApp E-series storage arrays.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- array_password
        The management password of the array to manage, if set.
        [Default: (null)]
- array_wwn
        The WWN of the array to manage. Only necessary if in-band managing multiple arrays on the same agent host.
        Mutually exclusive of controller_addresses parameter.
        [Default: (null)]
= controller_addresses
        The list addresses for the out-of-band management adapter or the agent host. Mutually exclusive of array_wwn
        parameter.

- enable_trace
        Enable trace logging for SYMbol calls to the storage system.
        [Default: False]
- meta_tags
        Optional meta tags to associate to this storage system
        [Default: None]
= ssid
        The ID of the array to manage. This value must be unique for each array.

= state
        Whether the specified array should be configured on the Web Services Proxy or not.
        (Choices: present, absent)
- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
---
    - name:  Presence of storage system
      netapp_e_storage_system:
        ssid: "{{ item.key }}"
        state: present
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"
        controller_addresses:
          - "{{ item.value.address1 }}"
          - "{{ item.value.address2 }}"
      with_dict: "{{ storage_systems }}"
      when: check_storage_system

RETURN VALUES:
msg: Storage system removed.
msg: Storage system added.


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_STORAGEPOOL    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_storagepool.py)

  Create or remove disk groups and disk pools for NetApp E-series storage arrays.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- criteria_drive_count
        The number of disks to use for building the storage pool. The pool will be expanded if this number exceeds the
        number of disks already in place
        [Default: (null)]
- criteria_drive_interface_type
        The interface type to use when selecting drives for the storage pool (no value means all interface types will be
        considered)
        (Choices: sas, sas4k, fibre, fibre520b, scsi, sata, pata)[Default: (null)]
- criteria_drive_min_size
        The minimum individual drive size (in size_unit) to consider when choosing drives for the storage pool.
        [Default: (null)]
- criteria_drive_require_fde
        Whether full disk encryption ability is required for drives to be added to the storage pool
        [Default: (null)]
- criteria_drive_type
        The type of disk (hdd or ssd) to use when searching for candidates to use.
        (Choices: hdd, ssd)[Default: (null)]
- criteria_min_usable_capacity
        The minimum size of the storage pool (in size_unit). The pool will be expanded if this value exceeds itscurrent
        size.
        [Default: (null)]
- criteria_size_unit
        The unit used to interpret size parameters
        (Choices: bytes, b, kb, mb, gb, tb, pb, eb, zb, yb)[Default: gb]
- erase_secured_drives
        Whether to erase secured disks before adding to storage pool
        (Choices: true, false)[Default: (null)]
= name
        The name of the storage pool to manage

= raid_level
        Only required when the requested state is 'present'.  The RAID level of the storage pool to be created.
        (Choices: raidAll, raid0, raid1, raid3, raid5, raid6, raidDiskPool)
- remove_volumes
        Prior to removing a storage pool, delete all volumes in the pool.
        [Default: False]
- reserve_drive_count
        Set the number of drives reserved by the storage pool for reconstruction operations. Only valide on raid disk
        pools.
        [Default: (null)]
- secure_pool
        Whether to convert to a secure storage pool. Will only work if all drives in the pool are security capable.
        (Choices: true, false)[Default: (null)]
= ssid
        The ID of the array to manage (as configured on the web services proxy).

= state
        Whether the specified storage pool should exist or not.
        Note that removing a storage pool currently requires the removal of all defined volumes first.
        (Choices: present, absent)
- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: No disk groups
      netapp_e_storagepool:
        ssid: "{{ ssid }}"
        name: "{{ item }}"
        state: absent
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"

RETURN VALUES:
msg:
    description: Success message
    returned: success
    type: string
    sample: Json facts for the pool that was created.


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_VOLUME    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_volume.py)

  Create or remove volumes (standard and thin) for NetApp E/EF-series storage arrays.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- data_assurance_enabled
        If data assurance should be enabled for the volume
        [Default: False]
= name
        The name of the volume to manage

- segment_size_kb
        The segment size of the new volume
        [Default: 512]
= size
        Required only when state = 'present'.  The size of the volume in (size_unit).

- size_unit
        The unit used to interpret the size parameter
        (Choices: bytes, b, kb, mb, gb, tb, pb, eb, zb, yb)[Default: gb]
- ssd_cache_enabled
        Whether an existing SSD cache should be enabled on the volume (fails if no SSD cache defined)
        (Choices: yes, no, true, false)[Default: None (ignores existing SSD cache setting)]
= ssid
        The ID of the array to manage (as configured on the web services proxy).

= state
        Whether the specified volume should exist or not.
        (Choices: present, absent)
= storage_pool_name
        Required only when requested state is 'present'.  The name of the storage pool the volume should exist on.

- thin_provision
        Whether the volume should be thin provisioned.  Thin volumes can only be created on disk pools (raidDiskPool).
        (Choices: yes, no, true, false)[Default: False]
- thin_volume_max_repo_size
        Maximum size that the thin volume repository volume will automatically expand to
        [Default: same as size (in size_unit)]
= thin_volume_repo_size
        Initial size of the thin volume repository volume (in size_unit)

- validate_certs
        Should https certificates be validated?
        [Default: True]
EXAMPLES:
    - name: No thin volume
      netapp_e_volume:
        ssid: "{{ ssid }}"
        name: NewThinVolumeByAnsible
        state: absent
        log_path: /tmp/volume.log
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"
      when: check_volume


    - name: No fat volume
      netapp_e_volume:
        ssid: "{{ ssid }}"
        name: NewVolumeByAnsible
        state: absent
        log_path: /tmp/volume.log
        api_url: "{{ netapp_api_url }}"
        api_username: "{{ netapp_api_username }}"
        api_password: "{{ netapp_api_password }}"
        validate_certs: "{{ netapp_api_validate_certs }}"
      when: check_volume

RETURN VALUES:
---
msg: "Standard volume [workload_vol_1] has been created."
msg: "Thin volume [workload_thin_vol] has been created."
msg: "Volume [workload_vol_1] has been expanded."
msg: "Volume [workload_vol_1] has been deleted."
msg: "Volume [workload_vol_1] did not exist."
msg: "Volume [workload_vol_1] already exists."


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETAPP_E_VOLUME_COPY    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/netapp_e_volume_copy.py)

  Create and delete snapshots images on volume groups for NetApp E-series storage arrays.

Options (= is mandatory):

= api_password
        The password to authenticate with the SANtricity WebServices Proxy or embedded REST API.

= api_url
        The url to the SANtricity WebServices Proxy or embedded REST API, for example
        `https://prod-1.wahoo.acme.com/devmgr/v2'.

= api_username
        The username to authenticate with the SANtricity WebServices Proxy or embedded REST API.

- create_copy_pair_if_does_not_exist
        Defines if a copy pair will be created if it does not exist.
        If set to True destination_volume_id and source_volume_id are required.
        (Choices: True, False)[Default: True]
- destination_volume_id
        The the id of the volume copy destination.
        If used, must be paired with source_volume_id
        Mutually exclusive with volume_copy_pair_id, and search_volume_id
        [Default: (null)]
- search_volume_id
        Searches for all valid potential target and source volumes that could be used in a copy_pair
        Mutually exclusive with volume_copy_pair_id, destination_volume_id and source_volume_id
        [Default: (null)]
- source_volume_id
        The the id of the volume copy source.
        If used, must be paired with destination_volume_id
        Mutually exclusive with volume_copy_pair_id, and search_volume_id
        [Default: (null)]
- start_stop_copy
        starts a re-copy or stops a copy in progress
        Note: If you stop the initial file copy before it it done the copy pair will be destroyed
        Requires volume_copy_pair_id
        [Default: (null)]
= state
        Whether the specified volume copy pair should exist or not.
        (Choices: present, absent)
- validate_certs
        Should https certificates be validated?
        [Default: True]
- volume_copy_pair_id
        The the id of a given volume copy pair
        Mutually exclusive with destination_volume_id, source_volume_id, and search_volume_id
        Can use to delete or check presence of volume pairs
        Must specify this or (destination_volume_id and source_volume_id)
        [Default: (null)]
EXAMPLES:
---
msg:
    description: Success message
    returned: success
    type: string
    sample: Json facts for the volume copy that was created.

RETURN VALUES:
msg:
    description: Success message
    returned: success
    type: string
    sample: Created Volume Copy Pair with ID


MAINTAINERS: Kevin Hulquest (@hulquest)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETCONF_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/netconf/netconf_config.py)

  Netconf is a network management protocol developed and standardized by the IETF. It is documented in RFC 6241. This
  module allows the user to send a configuration XML file to a netconf device, and detects if there was a configuration
  change.

Options (= is mandatory):

= host
        the hostname or ip address of the netconf device

- hostkey_verify
        if true, the ssh host key of the device must match a ssh key present on the host
        if false, the ssh host key of the device is not checked
        [Default: True]
= password
        password of the user to authenticate with

- port
        the netconf port
        [Default: 830]
= username
        the username to authenticate with

= xml
        the XML content to send to the device

Notes:
  * This module supports devices with and without the the candidate and confirmed-commit capabilities. It always
        use the safer feature.
Requirements:  python >= 2.6, ncclient

EXAMPLES:
- name: set ntp server in the device
  netconf_config:
    host: 10.0.0.1
    username: admin
    password: admin
    xml: |
        <config xmlns:xc="urn:ietf:params:xml:ns:netconf:base:1.0">
            <system xmlns="urn:ietf:params:xml:ns:yang:ietf-system">
                <ntp>
                    <enabled>true</enabled>
                    <server>
                        <name>ntp1</name>
                        <udp><address>127.0.0.1</address></udp>
                    </server>
                </ntp>
            </system>
        </config>

- name: wipe ntp configuration
  netconf_config:
    host: 10.0.0.1
    username: admin
    password: admin
    xml: |
        <config xmlns:xc="urn:ietf:params:xml:ns:netconf:base:1.0">
            <system xmlns="urn:ietf:params:xml:ns:yang:ietf-system">
                <ntp>
                    <enabled>false</enabled>
                    <server operation="remove">
                        <name>ntp1</name>
                    </server>
                </ntp>
            </system>
        </config>


RETURN VALUES:
server_capabilities:
    description: list of capabilities of the server
    returned: success
    type: list
    sample: ['urn:ietf:params:netconf:base:1.1','urn:ietf:params:netconf:capability:confirmed-commit:1.0','urn:ietf:params:netconf:capability:candidate:1.0']



MAINTAINERS: Leandro Lisboa Penz (@lpenz)

METADATA:
	Status: ['preview']
	Supported_by: community
> NETSCALER    (/usr/lib/python2.7/site-packages/ansible/modules/network/citrix/netscaler.py)

  Manages Citrix NetScaler server and service entities.

Options (= is mandatory):

- action
        the action you want to perform on the entity
        (Choices: enable, disable)[Default: disable]
= name
        name of the entity
        [Default: hostname]
= nsc_host
        hostname or ip of your netscaler
        [Default: None]
- nsc_protocol
        protocol used to access netscaler
        [Default: https]
= password
        password
        [Default: None]
- type
        type of the entity
        (Choices: server, service)[Default: server]
= user
        username
        [Default: None]
- validate_certs
        If `no', SSL certificates for the target url will not be validated. This should only be used on personally
        controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
# Disable the server
- netscaler:
    nsc_host: nsc.example.com
    user: apiuser
    password: apipass

# Enable the server
- netscaler:
    nsc_host: nsc.example.com
    user: apiuser
    password: apipass
    action: enable

# Disable the service local:8080
- netscaler:
    nsc_host: nsc.example.com
    user: apiuser
    password: apipass
    name: 'local:8080'
    type: service
    action: disable


MAINTAINERS: Nandor Sivok (@dominis)

METADATA:
	Status: ['preview']
	Supported_by: community
> NEWRELIC_DEPLOYMENT    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/newrelic_deployment.py)

  Notify newrelic about app deployments (see https://docs.newrelic.com/docs/apm/new-relic-apm/maintenance/deployment-
  notifications#api)

Options (= is mandatory):

- app_name
        (one of app_name or application_id are required) The value of app_name in the newrelic.yml file used by the
        application
        [Default: (null)]
- application_id
        (one of app_name or application_id are required) The application id, found in the URL when viewing the
        application in RPM
        [Default: (null)]
- appname
        Name of the application
        [Default: (null)]
- changelog
        A list of changes for this deployment
        [Default: (null)]
- description
        Text annotation for the deployment - notes for you
        [Default: (null)]
- environment
        The environment for this deployment
        [Default: (null)]
- revision
        A revision number (e.g., git commit SHA)
        [Default: (null)]
= token
        API token, to place in the x-api-key header.

- user
        The name of the user/process that triggered this deployment
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- newrelic_deployment:
    token: AAAAAA
    app_name: myapp
    user: ansible deployment
    revision: '1.0'


MAINTAINERS: Matt Coddington (@mcodd)

METADATA:
	Status: ['preview']
	Supported_by: community
> NEXMO    (/usr/lib/python2.7/site-packages/ansible/modules/notification/nexmo.py)

  Send a SMS message via nexmo

Options (= is mandatory):

= api_key
        Nexmo API Key

= api_secret
        Nexmo API Secret

= dest
        Phone number(s) to send SMS message to

= msg
        Message to text to send. Messages longer than 160 characters will be split into multiple messages

= src
        Nexmo Number to send from

- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- name: Send notification message via Nexmo
  nexmo:
    api_key: 640c8a53
    api_secret: 0ce239a6
    src: 12345678901
    dest:
      - 10987654321
      - 16789012345
    msg: '{{ inventory_hostname }} completed'
  delegate_to: localhost


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> NGINX_STATUS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/nginx_status_facts.py)

  Gathers facts from nginx from an URL having `stub_status' enabled.

Options (= is mandatory):

- timeout
        HTTP connection timeout in seconds.
        [Default: 10]
= url
        URL of the nginx status.

Notes:
  * See http://nginx.org/en/docs/http/ngx_http_stub_status_module.html for more information.
EXAMPLES:
# Gather status facts from nginx on localhost
- name: get current http stats
  nginx_status_facts:
    url: http://localhost/nginx_status

# Gather status facts from nginx on localhost with a custom timeout of 20 seconds
- name: get current http stats
  nginx_status_facts:
    url: http://localhost/nginx_status
    timeout: 20

RETURN VALUES:
---
nginx_status_facts.active_connections:
  description: Active connections.
  returned: success
  type: int
  sample: 2340
nginx_status_facts.accepts:
  description: The total number of accepted client connections.
  returned: success
  type: int
  sample: 81769947
nginx_status_facts.handled:
  description: The total number of handled connections. Generally, the parameter value is the same as accepts unless some resource limits have been reached.
  returned: success
  type: int
  sample: 81769947
nginx_status_facts.requests:
  description: The total number of client requests.
  returned: success
  type: int
  sample: 144332345
nginx_status_facts.reading:
  description: The current number of connections where nginx is reading the request header.
  returned: success
  type: int
  sample: 0
nginx_status_facts.writing:
  description: The current number of connections where nginx is writing the response back to the client.
  returned: success
  type: int
  sample: 241
nginx_status_facts.waiting:
  description: The current number of idle client connections waiting for a request.
  returned: success
  type: int
  sample: 2092
nginx_status_facts.data:
  description: HTTP response as is.
  returned: success
  type: string
  sample: "Active connections: 2340 
server accepts handled requests
 81769947 81769947 144332345 
Reading: 0 Writing: 241 Waiting: 2092 
"


MAINTAINERS: René Moser (@resmo)

METADATA:
	Status: ['preview']
	Supported_by: community
> NMCLI    (/usr/lib/python2.7/site-packages/ansible/modules/network/nmcli.py)

  Manage the network devices. Create, modify, and manage, ethernet, teams, bonds, vlans etc.

Options (= is mandatory):

- ageingtime
        This is only used with bridge - [ageing-time <0-1000000>] the Ethernet MAC address aging time, in seconds
        [Default: 300]
- arp_interval
        This is only used with bond - ARP interval
        [Default: None]
- arp_ip_target
        This is only used with bond - ARP IP target
        [Default: None]
- autoconnect
        Whether the connection should start on boot.
        Whether the connection profile can be automatically activated
        (Choices: yes, no)[Default: yes]
= conn_name
        Where conn_name will be the name used to call the connection. when not provided a default name is generated:
        <type>[-<ifname>][-<num>]

- dns4
        A list of upto 3 dns servers, ipv4 format e.g. To add two IPv4 DNS server addresses: ["192.0.2.53",
        "198.51.100.53"]
        [Default: None]
- dns6
        A list of upto 3 dns servers, ipv6 format e.g. To add two IPv6 DNS server addresses: ["2001:4860:4860::8888
        2001:4860:4860::8844"]
        [Default: (null)]
- downdelay
        This is only used with bond - downdelay
        [Default: None]
- egress
        This is only used with VLAN - VLAN egress priority mapping
        [Default: None]
- flags
        This is only used with VLAN - flags
        [Default: None]
- forwarddelay
        This is only used with bridge - [forward-delay <2-30>] STP forwarding delay, in seconds
        [Default: 15]
- gw4
        The IPv4 gateway for this interface using this format ie: "192.0.2.1"
        [Default: (null)]
- gw6
        The IPv6 gateway for this interface using this format ie: "2001:db8::1"
        [Default: None]
- hairpin
        This is only used with 'bridge-slave' - 'hairpin mode' for the slave, which allows frames to be sent back out
        through the slave the frame was received on.
        [Default: True]
- hellotime
        This is only used with bridge - [hello-time <1-10>] STP hello time, in seconds
        [Default: 2]
- ifname
        Where IFNAME will be the what we call the interface name.
        interface to bind the connection to. The connection will only be applicable to this interface name.
        A special value of "*" can be used for interface-independent connections.
        The ifname argument is mandatory for all connection types except bond, team, bridge and vlan.
        [Default: conn_name]
- ingress
        This is only used with VLAN - VLAN ingress priority mapping
        [Default: None]
- ip4
        The IPv4 address to this interface using this format ie: "192.0.2.24/24"
        [Default: None]
- ip6
        The IPv6 address to this interface using this format ie: "abbe::cafe"
        [Default: None]
- mac
        This is only used with bridge - MAC address of the bridge (note: this requires a recent kernel feature,
        originally introduced in 3.15 upstream kernel)
        [Default: None]
- master
        master <master (ifname, or connection UUID or conn_name) of bridge, team, bond master connection profile.
        [Default: None]
- maxage
        This is only used with bridge - [max-age <6-42>] STP maximum message age, in seconds
        [Default: 20]
- miimon
        This is only used with bond - miimon
        [Default: 100]
- mode
        This is the type of device or network connection that you wish to create for a bond, team or bridge.
        (Choices: balance-rr, active-backup, balance-xor, broadcast, 802.3ad, balance-tlb, balance-alb)[Default: balence-
        rr]
- mtu
        The connection MTU, e.g. 9000. This can't be applied when creating the interface and is done once the interface
        has been created.
        Can be used when modifying Team, VLAN, Ethernet (Future plans to implement wifi, pppoe, infiniband)
        [Default: 1500]
- path_cost
        This is only used with 'bridge-slave' - [<1-65535>] - STP port cost for destinations via this slave
        [Default: 100]
- primary
        This is only used with bond and is the primary interface name (for "active-backup" mode), this is the usually the
        'ifname'
        [Default: None]
- priority
        This is only used with 'bridge' - sets STP priority
        [Default: 128]
- slavepriority
        This is only used with 'bridge-slave' - [<0-63>] - STP priority of this slave
        [Default: 32]
= state
        Whether the device should exist or not, taking action if the state is different from what is stated.
        (Choices: present, absent)
- stp
        This is only used with bridge and controls whether Spanning Tree Protocol (STP) is enabled for this bridge
        [Default: None]
- type
        This is the type of device or network connection that you wish to create.
        (Choices: ethernet, team, team-slave, bond, bond-slave, bridge, vlan)[Default: (null)]
- updelay
        This is only used with bond - updelay
        [Default: None]
- vlandev
        This is only used with VLAN - parent device this VLAN is on, can use ifname
        [Default: None]
- vlanid
        This is only used with VLAN - VLAN ID in range <0-4095>
        [Default: None]
Requirements:  nmcli, dbus

EXAMPLES:
# These examples are using the following inventory:
#
# ## Directory layout:
#
# |_/inventory/cloud-hosts
# |           /group_vars/openstack-stage.yml
# |           /host_vars/controller-01.openstack.host.com
# |           /host_vars/controller-02.openstack.host.com
# |_/playbook/library/nmcli.py
# |          /playbook-add.yml
# |          /playbook-del.yml
# ```
#
# ## inventory examples
# ### groups_vars
# ```yml
# ---
# #devops_os_define_network
# storage_gw: "192.0.2.254"
# external_gw: "198.51.100.254"
# tenant_gw: "203.0.113.254"
#
# #Team vars
# nmcli_team:
#   - conn_name: tenant
#     ip4: '{{ tenant_ip }}'
#     gw4: '{{ tenant_gw }}'
#   - conn_name: external
#     ip4: '{{ external_ip }}'
#     gw4: '{{ external_gw }}'
#   - conn_name: storage
#     ip4: '{{ storage_ip }}'
#     gw4: '{{ storage_gw }}'
# nmcli_team_slave:
#   - conn_name: em1
#     ifname: em1
#     master: tenant
#   - conn_name: em2
#     ifname: em2
#     master: tenant
#   - conn_name: p2p1
#     ifname: p2p1
#     master: storage
#   - conn_name: p2p2
#     ifname: p2p2
#     master: external
#
# #bond vars
# nmcli_bond:
#   - conn_name: tenant
#     ip4: '{{ tenant_ip }}'
#     gw4: ''
#     mode: balance-rr
#   - conn_name: external
#     ip4: '{{ external_ip }}'
#     gw4: ''
#     mode: balance-rr
#   - conn_name: storage
#     ip4: '{{ storage_ip }}'
#     gw4: '{{ storage_gw }}'
#     mode: balance-rr
# nmcli_bond_slave:
#   - conn_name: em1
#     ifname: em1
#     master: tenant
#   - conn_name: em2
#     ifname: em2
#     master: tenant
#   - conn_name: p2p1
#     ifname: p2p1
#     master: storage
#   - conn_name: p2p2
#     ifname: p2p2
#     master: external
#
# #ethernet vars
# nmcli_ethernet:
#   - conn_name: em1
#     ifname: em1
#     ip4: '{{ tenant_ip }}'
#     gw4: '{{ tenant_gw }}'
#   - conn_name: em2
#     ifname: em2
#     ip4: '{{ tenant_ip1 }}'
#     gw4: '{{ tenant_gw }}'
#   - conn_name: p2p1
#     ifname: p2p1
#     ip4: '{{ storage_ip }}'
#     gw4: '{{ storage_gw }}'
#   - conn_name: p2p2
#     ifname: p2p2
#     ip4: '{{ external_ip }}'
#     gw4: '{{ external_gw }}'
# ```
#
# ### host_vars
# ```yml
# ---
# storage_ip: "192.0.2.91/23"
# external_ip: "198.51.100.23/21"
# tenant_ip: "203.0.113.77/23"
# ```



## playbook-add.yml example

---
- hosts: openstack-stage
  remote_user: root
  tasks:

  - name: install needed network manager libs
    yum:
      name: '{{ item }}'
      state: installed
    with_items:
      - NetworkManager-glib
      - libnm-qt-devel.x86_64
      - nm-connection-editor.x86_64
      - libsemanage-python
      - policycoreutils-python

##### Working with all cloud nodes - Teaming
  - name: try nmcli add team - conn_name only & ip4 gw4
    nmcli:
      type: team
      conn_name: '{{ item.conn_name }}'
      ip4: '{{ item.ip4 }}'
      gw4: '{{ item.gw4 }}'
      state: present
    with_items:
      - '{{ nmcli_team }}'

  - name: try nmcli add teams-slave
    nmcli:
      type: team-slave
      conn_name: '{{ item.conn_name }}'
      ifname: '{{ item.ifname }}'
      master: '{{ item.master }}'
      state: present
    with_items:
      - '{{ nmcli_team_slave }}'

###### Working with all cloud nodes - Bonding
  - name: try nmcli add bond - conn_name only & ip4 gw4 mode
    nmcli:
      type: bond
      conn_name: '{{ item.conn_name }}'
      ip4: '{{ item.ip4 }}'
      gw4: '{{ item.gw4 }}'
      mode: '{{ item.mode }}'
      state: present
    with_items:
      - '{{ nmcli_bond }}'

  - name: try nmcli add bond-slave
    nmcli:
      type: bond-slave
      conn_name: '{{ item.conn_name }}'
      ifname: '{{ item.ifname }}'
      master: '{{ item.master }}'
      state: present
    with_items:
      - '{{ nmcli_bond_slave }}'

##### Working with all cloud nodes - Ethernet
  - name: nmcli add Ethernet - conn_name only & ip4 gw4
    nmcli:
      type: ethernet
      conn_name: '{{ item.conn_name }}'
      ip4: '{{ item.ip4 }}'
      gw4: '{{ item.gw4 }}'
      state: present
    with_items:
      - '{{ nmcli_ethernet }}'

## playbook-del.yml example
- hosts: openstack-stage
  remote_user: root
  tasks:

  - name: try nmcli del team - multiple
    nmcli:
      conn_name: '{{ item.conn_name }}'
      state: absent
    with_items:
      - conn_name: em1
      - conn_name: em2
      - conn_name: p1p1
      - conn_name: p1p2
      - conn_name: p2p1
      - conn_name: p2p2
      - conn_name: tenant
      - conn_name: storage
      - conn_name: external
      - conn_name: team-em1
      - conn_name: team-em2
      - conn_name: team-p1p1
      - conn_name: team-p1p2
      - conn_name: team-p2p1
      - conn_name: team-p2p2

# To add an Ethernet connection with static IP configuration, issue a command as follows
- nmcli:
    conn_name: my-eth1
    ifname: eth1
    type: ethernet
    ip4: 192.0.2.100/24
    gw4: 192.0.2.1
    state: present

# To add an Team connection with static IP configuration, issue a command as follows
- nmcli:
    conn_name: my-team1
    ifname: my-team1
    type: team
    ip4: 192.0.2.100/24
    gw4: 192.0.2.1
    state: present
    autoconnect: yes

# Optionally, at the same time specify IPv6 addresses for the device as follows:
- nmcli:
    conn_name: my-eth1
    ifname: eth1
    type: ethernet
    ip4: 192.0.2.100/24
    gw4: 192.0.2.1
    ip6: '2001:db8::cafe'
    gw6: '2001:db8::1'
    state: present

# To add two IPv4 DNS server addresses:
- nmcli:
    conn_name: my-eth1
    dns4:
      - 192.0.2.53
      - 198.51.100.53
    state: present

# To make a profile usable for all compatible Ethernet interfaces, issue a command as follows
- nmcli:
    ctype: ethernet
    name: my-eth1
    ifname: '*'
    state: present

# To change the property of a setting e.g. MTU, issue a command as follows:
- nmcli:
    conn_name: my-eth1
    mtu: 9000
    type: ethernet
    state: present

# Exit Status's:
#     - nmcli exits with status 0 if it succeeds, a value greater than 0 is
#     returned if an error occurs.
#     - 0 Success - indicates the operation succeeded
#     - 1 Unknown or unspecified error
#     - 2 Invalid user input, wrong nmcli invocation
#     - 3 Timeout expired (see --wait option)
#     - 4 Connection activation failed
#     - 5 Connection deactivation failed
#     - 6 Disconnecting device failed
#     - 7 Connection deletion failed
#     - 8 NetworkManager is not running
#     - 9 nmcli and NetworkManager versions mismatch
#     - 10 Connection, device, or access point does not exist.


MAINTAINERS: Chris Long (@alcamie101)

METADATA:
	Status: ['preview']
	Supported_by: community
> NOVA_COMPUTE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_nova_compute.py)

  Create or Remove virtual machines from Openstack.

DEPRECATED: 
Deprecated in 2.0. Use M(os_server) instead.

Options (= is mandatory):

- auth_url
        The keystone url for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
- auto_floating_ip
        Should a floating ip be auto created and assigned
        [Default: no]
- availability_zone
        Name of the availability zone
        [Default: None]
- config_drive
        Whether to boot the server with config drive enabled
        [Default: no]
- flavor_id
        The id of the flavor in which the new VM has to be created. Mutually exclusive with flavor_ram
        [Default: 1]
- flavor_include
        Text to use to filter flavor names, for the case, such as Rackspace, where there are multiple flavors that have
        the same ram count. flavor_include is a positive match filter - it must exist in the flavor name.
        [Default: (null)]
- flavor_ram
        The minimum amount of ram in MB that the flavor in which the new VM has to be created must have. Mutually
        exclusive with flavor_id
        [Default: 1]
- floating_ip_pools
        list of floating IP pools from which to choose a floating IP
        [Default: None]
- floating_ips
        list of valid floating IPs that pre-exist to assign to this node
        [Default: None]
- image_exclude
        Text to use to filter image names, for the case, such as HP, where there are multiple image names matching the
        common identifying portions. image_exclude is a negative match filter - it is text that may not exist in the
        image name. Defaults to "(deprecated)"
        [Default: (null)]
= image_id
        The id of the base image to boot. Mutually exclusive with image_name
        [Default: None]
= image_name
        The name of the base image to boot. Mutually exclusive with image_id
        [Default: None]
- key_name
        The key pair name to be used when creating a VM
        [Default: None]
= login_password
        Password of login user
        [Default: yes]
= login_tenant_name
        The tenant name of the login user
        [Default: yes]
= login_username
        login username to authenticate to keystone
        [Default: admin]
- meta
        A list of key value pairs that should be provided as a metadata to the new VM
        [Default: None]
= name
        Name that has to be given to the instance
        [Default: None]
- nics
        A list of network id's to which the VM's interface should be attached
        [Default: None]
- region_name
        Name of the region
        [Default: None]
- scheduler_hints
        Arbitrary key/value pairs to the scheduler for custom use
        [Default: None]
- security_groups
        The name of the security group to which the VM should be added
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- user_data
        Opaque blob of data which is made available to the instance
        [Default: None]
- wait
        If the module should wait for the VM to be created.
        [Default: yes]
- wait_for
        The amount of time the module should wait for the VM to get into active state
        [Default: 180]
Requirements:  python >= 2.6, python-novaclient

EXAMPLES:
# Creates a new VM and attaches to a network and passes metadata to the instance
- nova_compute:
       state: present
       login_username: admin
       login_password: admin
       login_tenant_name: admin
       name: vm1
       image_id: 4f905f38-e52a-43d2-b6ec-754a13ffb529
       key_name: ansible_key
       wait_for: 200
       flavor_id: 4
       nics:
         - net-id: 34605f38-e52a-25d2-b6ec-754a13ffb723
       meta:
         hostname: test1
         group: uge_master

# Creates a new VM in HP Cloud AE1 region availability zone az2 and automatically assigns a floating IP
- name: launch a nova instance
  hosts: localhost
  tasks:
  - name: launch an instance
    nova_compute:
      state: present
      login_username: username
      login_password: Equality7-2521
      login_tenant_name: username-project1
      name: vm1
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
      region_name: region-b.geo-1
      availability_zone: az2
      image_id: 9302692b-b787-4b52-a3a6-daebb79cb498
      key_name: test
      wait_for: 200
      flavor_id: 101
      security_groups: default
      auto_floating_ip: yes

# Creates a new VM in HP Cloud AE1 region availability zone az2 and assigns a pre-known floating IP
- name: launch a nova instance
  hosts: localhost
  tasks:
  - name: launch an instance
    nova_compute:
      state: present
      login_username: username
      login_password: Equality7-2521
      login_tenant_name: username-project1
      name: vm1
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
      region_name: region-b.geo-1
      availability_zone: az2
      image_id: 9302692b-b787-4b52-a3a6-daebb79cb498
      key_name: test
      wait_for: 200
      flavor_id: 101
      floating_ips:
        - 12.34.56.79

# Creates a new VM with 4G of RAM on Ubuntu Trusty, ignoring deprecated images
- name: launch a nova instance
  hosts: localhost
  tasks:
  - name: launch an instance
    nova_compute:
      name: vm1
      state: present
      login_username: username
      login_password: Equality7-2521
      login_tenant_name: username-project1
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
      region_name: region-b.geo-1
      image_name: Ubuntu Server 14.04
      image_exclude: deprecated
      flavor_ram: 4096

# Creates a new VM with 4G of RAM on Ubuntu Trusty on a Rackspace Performance node in DFW
- name: launch a nova instance
  hosts: localhost
  tasks:
  - name: launch an instance
    nova_compute:
      name: vm1
      state: present
      login_username: username
      login_password: Equality7-2521
      login_tenant_name: username-project1
      auth_url: https://identity.api.rackspacecloud.com/v2.0/
      region_name: DFW
      image_name: Ubuntu 14.04 LTS (Trusty Tahr) (PVHVM)
      flavor_ram: 4096
      flavor_include: Performance


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> NOVA_KEYPAIR    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_nova_keypair.py)

  Add or Remove key pair from nova .

DEPRECATED: 
Deprecated in 2.0. Use M(os_keypair) instead.

Options (= is mandatory):

- auth_url
        The keystone url for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
= login_password
        Password of login user
        [Default: yes]
= login_tenant_name
        The tenant name of the login user
        [Default: yes]
= login_username
        login username to authenticate to keystone
        [Default: admin]
= name
        Name that has to be given to the key pair
        [Default: None]
- public_key
        The public key that would be uploaded to nova and injected to vm's upon creation
        [Default: None]
- region_name
        Name of the region
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
Requirements:  python >= 2.6, python-novaclient

EXAMPLES:
- name: Create a key pair with the running users public key
  nova_keypair:
    state: present
    login_username: admin
    login_password: admin
    login_tenant_name: admin
    name: ansible_key
    public_key: "{{ lookup('file','~/.ssh/id_rsa.pub') }}"

- name: Create a new key pair and the private key returned after the run.
  nova_keypair:
    state: present
    login_username: admin
    login_password: admin
    login_tenant_name: admin
    name: ansible_key


MAINTAINERS: Benno Joy (@bennojoy), Michael DeHaan

METADATA:
	Status: ['deprecated']
	Supported_by: community
> NPM    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/npm.py)

  Manage node.js packages with Node Package Manager (npm)

Options (= is mandatory):

- executable
        The executable location for npm.
        This is useful if you are using a version manager, such as nvm
        [Default: (null)]
- global
        Install the node.js library globally
        (Choices: yes, no)[Default: False]
- ignore_scripts
        Use the --ignore-scripts flag when installing.
        (Choices: yes, no)[Default: False]
- name
        The name of a node.js library to install
        [Default: (null)]
- path
        The base path where to install the node.js libraries
        [Default: (null)]
- production
        Install dependencies in production mode, excluding devDependencies
        (Choices: yes, no)[Default: False]
- registry
        The registry to install modules from.
        [Default: (null)]
- state
        The state of the node.js library
        (Choices: present, absent, latest)[Default: present]
- version
        The version to be installed
        [Default: (null)]
EXAMPLES:
- name: Install "coffee-script" node.js package.
  npm:
    name: coffee-script
    path: /app/location

- name: Install "coffee-script" node.js package on version 1.6.1.
  npm:
    name: coffee-script
    version: '1.6.1'
    path: /app/location

- name: Install "coffee-script" node.js package globally.
  npm:
    name: coffee-script
    global: yes

- name: Remove the globally package "coffee-script".
  npm:
    name: coffee-script
    global: yes
    state: absent

- name: Install "coffee-script" node.js package from custom registry.
  npm:
    name: coffee-script
    registry: 'http://registry.mysite.com'

- name: Install packages based on package.json.
  npm:
    path: /app/location

- name: Update packages based on package.json to their latest version.
  npm:
    path: /app/location
    state: latest

- name: Install packages based on package.json using the npm installed with nvm v0.10.1.
  npm:
    path: /app/location
    executable: /opt/nvm/v0.10.1/bin/npm
    state: present


MAINTAINERS: Chris Hoffman (@chrishoffman)

METADATA:
	Status: ['preview']
	Supported_by: community
> NSUPDATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nsupdate.py)

  Create, update and remove DNS records using DDNS updates DDNS works well with both bind and Microsoft DNS (see
  https://technet.microsoft.com/en-us/library/cc961412.aspx)

Options (= is mandatory):

- key_algorithm
        Specify key algorithm used by `key_secret'.
        (Choices: HMAC-MD5.SIG-ALG.REG.INT, hmac-md5, hmac-sha1, hmac-sha224, hmac-sha256, hamc-sha384, hmac-
        sha512)[Default: hmac-md5]
- key_name
        Use TSIG key name to authenticate against DNS `server'
        [Default: (null)]
- key_secret
        Use TSIG key secret, associated with `key_name', to authenticate against `server'
        [Default: (null)]
= record
        Sets the DNS record to modify.

= server
        Apply DNS modification on this server.

- state
        Manage DNS record.
        (Choices: present, absent)[Default: present]
- ttl
        Sets the record TTL.
        [Default: 3600]
- type
        Sets the record type.
        [Default: A]
- value
        Sets the record value.
        [Default: None]
= zone
        DNS record will be modified on this `zone'.

Requirements:  dnspython

EXAMPLES:
- name: Add or modify ansible.example.org A to 192.168.1.1"
  nsupdate:
    key_name: "nsupdate"
    key_secret: "+bFQtBCta7j2vWkjPkAFtgA=="
    server: "10.1.1.1"
    zone: "example.org"
    record: "ansible"
    value: "192.168.1.1"

- name: Remove puppet.example.org CNAME
  nsupdate:
    key_name: "nsupdate"
    key_secret: "+bFQtBCta7j2vWkjPkAFtgA=="
    server: "10.1.1.1"
    zone: "example.org"
    record: "puppet"
    type: "CNAME"
    state: absent

RETURN VALUES:
changed:
    description: If module has modified record
    returned: success
    type: string
record:
    description: DNS record
    returned: success
    type: string
    sample: 'ansible'
ttl:
    description: DNS record TTL
    returned: success
    type: int
    sample: 86400
type:
    description: DNS record type
    returned: success
    type: string
    sample: 'CNAME'
value:
    description: DNS record value
    returned: success
    type: string
    sample: '192.168.1.1'
zone:
    description: DNS record zone
    returned: success
    type: string
    sample: 'example.org.'
dns_rc:
    description: dnspython return code
    returned: always
    type: int
    sample: 4
dns_rc_str:
    description: dnspython return code (string representation)
    returned: always
    type: string
    sample: 'REFUSED'


MAINTAINERS: Loic Blot (@nerzhul)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_AAA_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_aaa_server.py)

  Manages AAA server global configuration

Options (= is mandatory):

- deadtime
        Duration for which a non-reachable AAA server is skipped, in minutes. Range is 1-1440. Device default is 0.
        [Default: None]
- directed_request
        Enables direct authentication requests to AAA server. Device default is disabled.
        (Choices: enabled, disabled)[Default: None]
- encrypt_type
        The state of encryption applied to the entered global key. O clear text, 7 encrypted. Type-6 encryption is not
        supported.
        (Choices: 0, 7)[Default: None]
- global_key
        Global AAA shared secret.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- server_timeout
        Global AAA server timeout period, in seconds. Range is 1-60. Device default is 5.
        [Default: None]
= server_type
        The server type is either radius or tacacs.
        (Choices: radius, tacacs)
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Manage the state of the resource.
        (Choices: present, default)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * The server_type parameter is always required.
  * If encrypt_type is not supplied, the global AAA server key will be stored as encrypted (type 7).
  * Changes to the global AAA server key with encrypt_type=0 are not idempotent.
  * If global AAA server key is not found, it's shown as "unknown"
  * state=default will set the supplied parameters to their default values. The parameters that you want to default
        must also be set to default. If global_key=default, the global key will be removed.
EXAMPLES:
# Radius Server Basic settings
  - name: "Radius Server Basic settings"
    nxos_aaa_server:
        server_type: radius
        server_timeout: 9
        deadtime: 20
        directed_request: enabled
        host:  inventory_hostname }}
        username:  un }}
        password:  pwd }}

# Tacacs Server Basic settings
  - name: "Tacacs Server Basic settings"
    nxos_aaa_server:
        server_type: tacacs
        server_timeout: 8
        deadtime: 19
        directed_request: disabled
        host:  inventory_hostname }}
        username:  un }}
        password:  pwd }}

# Setting Global Key
  - name: "AAA Server Global Key"
    nxos_aaa_server:
        server_type: radius
        global_key: test_key
        host:  inventory_hostname }}
        username:  un }}
        password:  pwd }}

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"deadtime": "22", "directed_request": "enabled",
            "server_type": "radius", "server_timeout": "11"}
existing:
    description:
        - k/v pairs of existing aaa server
    returned: always
    type: dict
    sample: {"deadtime": "0", "directed_request": "disabled",
            "global_key": "unknown", "server_timeout": "5"}
end_state:
    description: k/v pairs of aaa params after module execution
    returned: always
    type: dict
    sample: {"deadtime": "22", "directed_request": "enabled",
            "global_key": "unknown", "server_timeout": "11"}
state:
    description: state as sent in from the playbook
    returned: always
    type: string
    sample: "present"
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["radius-server deadtime 22", "radius-server timeout 11",
             "radius-server directed-request"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_AAA_SERVER_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_aaa_server_host.py)

  Manages AAA server host-specific configuration.

Options (= is mandatory):

- acct_port
        Alternate UDP port for RADIUS accounting.
        [Default: None]
= address
        Address or name of the radius or tacacs host.

- auth_port
        Alternate UDP port for RADIUS authentication.
        [Default: None]
- encrypt_type
        The state of encryption applied to the entered key. O for clear text, 7 for encrypted. Type-6 encryption is not
        supported.
        (Choices: 0, 7)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- host_timeout
        Timeout period for specified host, in seconds. Range is 1-60.
        [Default: None]
- key
        Shared secret for the specified host.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
= server_type
        The server type is either radius or tacacs.
        (Choices: radius, tacacs)
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- tacacs_port
        Alternate TCP port TACACS Server.
        [Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * Changes to the AAA server host key (shared secret) are not idempotent.
  * If `state=absent' removes the whole host configuration.
EXAMPLES:
# Radius Server Host Basic settings
  - name: "Radius Server Host Basic settings"
    nxos_aaa_server_host:
        state: present
        server_type: radius
        address: 1.2.3.4
        acct_port: 2084
        host_timeout: 10
        host: "{{ inventory_hostname }}"
        username: "{{ un }}"
        password: "{{ pwd }}"

# Radius Server Host Key Configuration
  - name: "Radius Server Host Key Configuration"
    nxos_aaa_server_host:
        state: present
        server_type: radius
        address: 1.2.3.4
        key: hello
        encrypt_type: 7
        host:  inventory_hostname }}
        username: "{{ un }}"
        password: "{{ pwd }}"

# TACACS Server Host Configuration
  - name: "Tacacs Server Host Configuration"
    nxos_aaa_server_host:
        state: present
        server_type: tacacs
        tacacs_port: 89
        host_timeout: 10
        address: 5.6.7.8
        host:  inventory_hostname }}
        username:  un }}
        password:  pwd }}

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"address": "1.2.3.4", "auth_port": "2084",
            "host_timeout": "10", "server_type": "radius"}
existing:
    description:
        - k/v pairs of existing configuration
    returned: always
    type: dict
    sample: {}
end_state:
    description: k/v pairs of configuration after module execution
    returned: always
    type: dict
    sample: {"address": "1.2.3.4", "auth_port": "2084",
            "host_timeout": "10", "server_type": "radius"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["radius-server host 1.2.3.4 auth-port 2084 timeout 10"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_ACL    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_acl.py)

  Manages access list entries for ACLs.

Options (= is mandatory):

- ack
        Match on the ACK bit.
        (Choices: enable)[Default: None]
- action
        Action of the ACE.
        (Choices: permit, deny, remark)[Default: None]
- dest
        Destination ip and mask using IP/MASK notation and supports the keyword 'any'.
        [Default: None]
- dest_port1
        Port/protocol and also first (lower) port when using range operand.
        [Default: None]
- dest_port2
        Second (end) port when using range operand.
        [Default: None]
- dest_port_op
        Destination port operands such as eq, neq, gt, lt, range.
        (Choices: any, eq, gt, lt, neq, range)[Default: None]
- dscp
        Match packets with given dscp value.
        (Choices: af11, af12, af13, af21, af22, af23, af31, af32, af33, af41, af42, af43, cs1, cs2, cs3, cs4, cs5, cs6,
        cs7, default, ef)[Default: None]
- established
        Match established connections.
        (Choices: enable)[Default: None]
- fin
        Match on the FIN bit.
        (Choices: enable)[Default: None]
- fragments
        Check non-initial fragments.
        (Choices: enable)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- log
        Log matches against this entry.
        (Choices: enable)[Default: None]
= name
        Case sensitive name of the access list (ACL).

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- precedence
        Match packets with given precedence.
        (Choices: critical, flash, flash-override, immediate, internet, network, priority, routine)[Default: None]
- proto
        Port number or protocol (as supported by the switch).
        [Default: None]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- psh
        Match on the PSH bit.
        (Choices: enable)[Default: None]
- remark
        If action is set to remark, this is the description.
        [Default: None]
- rst
        Match on the RST bit.
        (Choices: enable)[Default: None]
- seq
        Sequence number of the entry (ACE).
        [Default: None]
- src
        Source ip and mask using IP/MASK notation and supports keyword 'any'.
        [Default: None]
- src_port1
        Port/protocol and also first (lower) port when using range operand.
        [Default: None]
- src_port2
        Second (end) port when using range operand.
        [Default: None]
- src_port_op
        Source port operands such as eq, neq, gt, lt, range.
        (Choices: any, eq, gt, lt, neq, range)[Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Specify desired state of the resource.
        (Choices: present, absent, delete_acl)[Default: present]
- syn
        Match on the SYN bit.
        (Choices: enable)[Default: None]
- time-range
        Name of time-range to apply.
        [Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- urg
        Match on the URG bit.
        (Choices: enable)[Default: None]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * `state=absent' removes the ACE if it exists.
  * `state=delete_acl' deleted the ACL if it exists.
  * For idempotency, use port numbers for the src/dest port params like `src_port1' and names for the well defined
        protocols for the `proto' param.
  * Although this module is idempotent in that if the ace as presented in the task is identical to the one on the
        switch, no changes will be made. If there is any difference, what is in Ansible will be pushed (configured
        options will be overridden).  This is to improve security, but at the same time remember an ACE is removed,
        then re-added, so if there is a change, the new ACE will be exactly what parameters you are sending to the
        module.
EXAMPLES:

# configure ACL ANSIBLE
- nxos_acl:
    name: ANSIBLE
    seq: 10
    action: permit
    proto: tcp
    src: 1.1.1.1/24
    dest: any
    state: present
    provider: "{{ nxos_provider }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module.
    returned: always
    type: dict
    sample: {"action": "permit", "dest": "any", "name": "ANSIBLE",
            "proto": "tcp", "seq": "10", "src": "1.1.1.1/24"}
existing:
    description: k/v pairs of existing ACL entries.
    returned: always
    type: dict
    sample: {}
end_state:
    description: k/v pairs of ACL entries after module execution.
    returned: always
    type: dict
    sample: {"action": "permit", "dest": "any", "name": "ANSIBLE",
            "proto": "tcp", "seq": "10", "src": "1.1.1.1/24"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["ip access-list ANSIBLE", "10 permit tcp 1.1.1.1/24 any"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_ACL_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_acl_interface.py)

  Manages applying ACLs to interfaces.

Options (= is mandatory):

= direction
        Direction ACL to be applied in on the interface.
        (Choices: ingress, egress)
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Full name of interface, e.g. `Ethernet1/1'.

= name
        Case sensitive name of the access list (ACL).

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Specify desired state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
- name: apply egress acl to ethernet1/41
  nxos_acl_interface:
    name: ANSIBLE
    interface: ethernet1/41
    direction: egress
    state: present
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"direction": "egress", "interface": "ethernet1/41",
            "name": "ANSIBLE"}
existing:
    description: k/v pairs of existing ACL applied to the interface
    returned: always
    type: dict
    sample: {}
end_state:
    description: k/v pairs of interface ACL after module execution
    returned: always
    type: dict
    sample: {"direction": "egress", "interface": "ethernet1/41",
            "name": "ANSIBLE"}
acl_applied_to:
    description: list of interfaces the ACL is applied to
    returned: always
    type: list
    sample: [{"acl_type": "Router ACL", "direction": "egress",
            "interface": "Ethernet1/41", "name": "ANSIBLE"}]
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface ethernet1/41", "ip access-group ANSIBLE out"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_BGP    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_bgp.py)

  Manages BGP configurations on NX-OS switches.

Options (= is mandatory):

= asn
        BGP autonomous system number. Valid values are String, Integer in ASPLAIN or ASDOT notation.

- bestpath_always_compare_med
        Enable/Disable MED comparison on paths from different autonomous systems.
        (Choices: true, false)[Default: None]
- bestpath_aspath_multipath_relax
        Enable/Disable load sharing across the providers with different (but equal-length) AS paths.
        (Choices: true, false)[Default: None]
- bestpath_compare_routerid
        Enable/Disable comparison of router IDs for identical eBGP paths.
        (Choices: true, false)[Default: None]
- bestpath_cost_community_ignore
        Enable/Disable Ignores the cost community for BGP best-path calculations.
        (Choices: true, false)[Default: None]
- bestpath_med_confed
        Enable/Disable enforcement of bestpath to do a MED comparison only between paths originated within a
        confederation.
        (Choices: true, false)[Default: None]
- bestpath_med_missing_as_worst
        Enable/Disable assigns the value of infinity to received routes that do not carry the MED attribute, making these
        routes the least desirable.
        (Choices: true, false)[Default: None]
- bestpath_med_non_deterministic
        Enable/Disable deterministic selection of the best MED pat from among the paths from the same autonomous system.
        (Choices: true, false)[Default: None]
- cluster_id
        Route Reflector Cluster-ID.
        [Default: None]
- confederation_id
        Routing domain confederation AS.
        [Default: None]
- confederation_peers
        AS confederation parameters.
        [Default: None]
- disable_policy_batching
        Enable/Disable the batching evaluation of prefix advertisement to all peers.
        (Choices: true, false)[Default: None]
- disable_policy_batching_ipv4_prefix_list
        Enable/Disable the batching evaluation of prefix advertisements to all peers with prefix list.
        [Default: None]
- disable_policy_batching_ipv6_prefix_list
        Enable/Disable the batching evaluation of prefix advertisements to all peers with prefix list.
        [Default: (null)]
- enforce_first_as
        Enable/Disable enforces the neighbor autonomous system to be the first AS number listed in the AS path attribute
        for eBGP. On NX-OS, this property is only supported in the global BGP context.
        (Choices: true, false)[Default: None]
- event_history_cli
        Enable/Disable cli event history buffer.
        (Choices: size_small, size_medium, size_large, size_disable, default)[Default: None]
- event_history_detail
        Enable/Disable detail event history buffer.
        (Choices: size_small, size_medium, size_large, size_disable, default)[Default: None]
- event_history_events
        Enable/Disable event history buffer.
        (Choices: size_small, size_medium, size_large, size_disable, default)[Default: None]
- event_history_periodic
        Enable/Disable periodic event history buffer.
        (Choices: size_small, size_medium, size_large, size_disable, default)[Default: (null)]
- fast_external_fallover
        Enable/Disable immediately reset the session if the link to a directly connected BGP peer goes down.  Only
        supported in the global BGP context.
        (Choices: true, false)[Default: None]
- flush_routes
        Enable/Disable flush routes in RIB upon controlled restart. On NX-OS, this property is only supported in the
        global BGP context.
        (Choices: true, false)[Default: None]
- graceful_restart
        Enable/Disable graceful restart.
        (Choices: true, false)[Default: None]
- graceful_restart_helper
        Enable/Disable graceful restart helper mode.
        (Choices: true, false)[Default: None]
- graceful_restart_timers_restart
        Set maximum time for a restart sent to the BGP peer.
        (Choices: true, false)[Default: None]
- graceful_restart_timers_stalepath_time
        Set maximum time that BGP keeps the stale routes from the restarting BGP peer.
        (Choices: true, false)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- isolate
        Enable/Disable isolate this router from BGP perspective.
        (Choices: true, false)[Default: None]
- local_as
        Local AS number to be used within a VRF instance.
        [Default: None]
- log_neighbor_changes
        Enable/Disable message logging for neighbor up/down event.
        (Choices: true, false)[Default: None]
- maxas_limit
        Specify Maximum number of AS numbers allowed in the AS-path attribute. Valid values are between 1 and 512.
        [Default: None]
- neighbor_down_fib_accelerate
        Enable/Disable handle BGP neighbor down event, due to various reasons.
        (Choices: true, false)[Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- reconnect_interval
        The BGP reconnection interval for dropped sessions. Valid values are between 1 and 60.
        [Default: None]
- router_id
        Router Identifier (ID) of the BGP router VRF instance.
        [Default: None]
- shutdown
        Administratively shutdown the BGP protocol.
        (Choices: true, false)[Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- suppress_fib_pending
        Enable/Disable advertise only routes programmed in hardware to peers.
        (Choices: true, false)[Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
- timer_bestpath_limit
        Specify timeout for the first best path after a restart, in seconds.
        [Default: None]
- timer_bestpath_limit_always
        Enable/Disable update-delay-always option.
        (Choices: true, false)[Default: None]
- timer_bgp_hold
        Set BGP hold timer.
        [Default: None]
- timer_bgp_keepalive
        Set BGP keepalive timer.
        [Default: None]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vrf
        Name of the VRF. The name 'default' is a valid VRF representing the global BGP.
        [Default: None]
Notes:
  * `state=absent' removes the whole BGP ASN configuration when `vrf=default' or the whole VRF instance within the
        BGP process when using a different VRF.
  * Default when supported restores params default value.
  * Configuring global parmas is only permitted if `vrf=default'.
EXAMPLES:
- name: Configure a simple ASN
  nxos_bgp:
      asn: 65535
      vrf: test
      router_id: 1.1.1.1
      state: present
      username: "{{ un }}"
      password: "{{ pwd }}"
      host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"asn": "65535", "router_id": "1.1.1.1", "vrf": "test"}
existing:
    description: k/v pairs of existing BGP configuration
    returned: verbose mode
    type: dict
    sample: {"asn": "65535", "bestpath_always_compare_med": false,
            "bestpath_aspath_multipath_relax": false,
            "bestpath_compare_neighborid": false,
            "bestpath_compare_routerid": false,
            "bestpath_cost_community_ignore": false,
            "bestpath_med_confed": false,
            "bestpath_med_missing_as_worst": false,
            "bestpath_med_non_deterministic": false, "cluster_id": "",
            "confederation_id": "", "confederation_peers": "",
            "graceful_restart": true, "graceful_restart_helper": false,
            "graceful_restart_timers_restart": "120",
            "graceful_restart_timers_stalepath_time": "300", "local_as": "",
            "log_neighbor_changes": false, "maxas_limit": "",
            "neighbor_down_fib_accelerate": false, "reconnect_interval": "60",
            "router_id": "11.11.11.11", "suppress_fib_pending": false,
            "timer_bestpath_limit": "", "timer_bgp_hold": "180",
            "timer_bgp_keepalive": "60", "vrf": "test"}
end_state:
    description: k/v pairs of BGP configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"asn": "65535", "bestpath_always_compare_med": false,
            "bestpath_aspath_multipath_relax": false,
            "bestpath_compare_neighborid": false,
            "bestpath_compare_routerid": false,
            "bestpath_cost_community_ignore": false,
            "bestpath_med_confed": false,
            "bestpath_med_missing_as_worst": false,
            "bestpath_med_non_deterministic": false, "cluster_id": "",
            "confederation_id": "", "confederation_peers": "",
            "graceful_restart": true, "graceful_restart_helper": false,
            "graceful_restart_timers_restart": "120",
            "graceful_restart_timers_stalepath_time": "300", "local_as": "",
            "log_neighbor_changes": false, "maxas_limit": "",
            "neighbor_down_fib_accelerate": false, "reconnect_interval": "60",
            "router_id": "1.1.1.1",  "suppress_fib_pending": false,
            "timer_bestpath_limit": "", "timer_bgp_hold": "180",
            "timer_bgp_keepalive": "60", "vrf": "test"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router bgp 65535", "vrf test", "router-id 1.1.1.1"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_BGP_AF    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_bgp_af.py)

  Manages BGP Address-family configurations on NX-OS switches.

Options (= is mandatory):

- additional_paths_install
        Install a backup path into the forwarding table and provide prefix independent convergence (PIC) in case of a PE-
        CE link failure.
        (Choices: true, false)[Default: None]
- additional_paths_receive
        Enables the receive capability of additional paths for all of the neighbors under this address family for which
        the capability has not been disabled.
        (Choices: true, false)[Default: None]
- additional_paths_selection
        Configures the capability of selecting additional paths for a prefix. Valid values are a string defining the name
        of the route-map.
        [Default: None]
- additional_paths_send
        Enables the send capability of additional paths for all of the neighbors under this address family for which the
        capability has not been disabled.
        (Choices: true, false)[Default: None]
- advertise_l2vpn_evpn
        Advertise evpn routes.
        (Choices: true, false)[Default: None]
= afi
        Address Family Identifier.
        (Choices: ipv4, ipv6, vpnv4, vpnv6, l2vpn)
= asn
        BGP autonomous system number. Valid values are String, Integer in ASPLAIN or ASDOT notation.

- client_to_client
        Configure client-to-client route reflection.
        (Choices: true, false)[Default: None]
- dampen_igp_metric
        Specify dampen value for IGP metric-related changes, in seconds. Valid values are integer and keyword 'default'.
        [Default: None]
- dampening_half_time
        Specify decay half-life in minutes for route-flap dampening. Valid values are integer and keyword 'default'.
        [Default: None]
- dampening_max_suppress_time
        Specify max suppress time for route-flap dampening stable route. Valid values are integer and keyword 'default'.
        [Default: None]
- dampening_reuse_time
        Specify route reuse time for route-flap dampening. Valid values are integer and keyword 'default'.
        [Default: (null)]
- dampening_routemap
        Specify route-map for route-flap dampening. Valid values are a string defining the name of the route-map.
        [Default: None]
- dampening_state
        Enable/disable route-flap dampening.
        (Choices: true, false)[Default: None]
- dampening_suppress_time
        Specify route suppress time for route-flap dampening. Valid values are integer and keyword 'default'.
        [Default: None]
- default_information_originate
        Default information originate.
        (Choices: true, false)[Default: None]
- default_metric
        Sets default metrics for routes redistributed into BGP. Valid values are Integer or keyword 'default'
        [Default: None]
- distance_ebgp
        Sets the administrative distance for eBGP routes. Valid values are Integer or keyword 'default'.
        [Default: None]
- distance_ibgp
        Sets the administrative distance for iBGP routes. Valid values are Integer or keyword 'default'.
        [Default: None]
- distance_local
        Sets the administrative distance for local BGP routes. Valid values are Integer or keyword 'default'.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- inject_map
        An array of route-map names which will specify prefixes to inject. Each array entry must first specify the
        inject-map name, secondly an exist-map name, and optionally the copy-attributes keyword which indicates that
        attributes should be copied from the aggregate. For example [['lax_inject_map', 'lax_exist_map'],
        ['nyc_inject_map', 'nyc_exist_map', 'copy-attributes'], ['fsd_inject_map', 'fsd_exist_map']].
        [Default: None]
- maximum_paths
        Configures the maximum number of equal-cost paths for load sharing. Valid value is an integer in the range 1-64.
        [Default: None]
- maximum_paths_ibgp
        Configures the maximum number of ibgp equal-cost paths for load sharing. Valid value is an integer in the range
        1-64.
        [Default: None]
- networks
        Networks to configure. Valid value is a list of network prefixes to advertise. The list must be in the form of an
        array. Each entry in the array must include a prefix address and an optional route-map. For example
        [['10.0.0.0/16', 'routemap_LA'], ['192.168.1.1', 'Chicago'], ['192.168.2.0/24], ['192.168.3.0/24',
        'routemap_NYC']].
        [Default: None]
- next_hop_route_map
        Configure a route-map for valid nexthops. Valid values are a string defining the name of the route-map.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- redistribute
        A list of redistribute directives. Multiple redistribute entries are allowed. The list must be in the form of a
        nested array. the first entry of each array defines the source-protocol to redistribute from; the second entry
        defines a route-map name. A route-map is highly advised but may be optional on some platforms, in which case it
        may be omitted from the array list. For example [['direct', 'rm_direct'], ['lisp', 'rm_lisp']].
        [Default: None]
= safi
        Sub Address Family Identifier.
        (Choices: unicast, multicast, evpn)
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- suppress_inactive
        Advertises only active routes to peers.
        (Choices: true, false)[Default: None]
- table_map
        Apply table-map to filter routes downloaded into URIB. Valid values are a string.
        [Default: None]
- table_map_filter
        Filters routes rejected by the route-map and does not download them to the RIB.
        (Choices: true, false)[Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
= vrf
        Name of the VRF. The name 'default' is a valid VRF representing the global bgp.

Notes:
  * `state=absent' removes the whole BGP ASN configuration
  * Default, where supported, restores params default value.
EXAMPLES:
# configure a simple address-family
- nxos_bgp_af:
    asn: 65535
    vrf: TESTING
    afi: ipv4
    safi: unicast
    advertise_l2vpn_evpn: true
    state: present

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"advertise_l2vpn_evpn": true, "afi": "ipv4",
             "asn": "65535", "safi": "unicast", "vrf": "TESTING"}
existing:
    description: k/v pairs of existing BGP AF configuration
    returned: verbose mode
    type: dict
    sample: {}
end_state:
    description: k/v pairs of BGP AF configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"additional_paths_install": false,
            "additional_paths_receive": false,
            "additional_paths_selection": "",
            "additional_paths_send": false,
            "advertise_l2vpn_evpn": true, "afi": "ipv4",
            "asn": "65535", "client_to_client": true,
            "dampen_igp_metric": "600", "dampening_half_time": "",
            "dampening_max_suppress_time": "", "dampening_reuse_time": "",
            "dampening_routemap": "", "dampening_state": false,
            "dampening_suppress_time": "",
            "default_information_originate": false, "default_metric": "",
            "distance_ebgp": "20", "distance_ibgp": "200",
            "distance_local": "220", "inject_map": [], "maximum_paths": "1",
            "maximum_paths_ibgp": "1", "networks": [],
            "next_hop_route_map": "", "redistribute": [], "safi": "unicast",
            "suppress_inactive": false, "table_map": "",
            "table_map_filter": false, "vrf": "TESTING"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router bgp 65535", "vrf TESTING",
            "address-family ipv4 unicast", "advertise l2vpn evpn"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_BGP_NEIGHBOR    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_bgp_neighbor.py)

  Manages BGP neighbors configurations on NX-OS switches.

Options (= is mandatory):

= asn
        BGP autonomous system number. Valid values are string, Integer in ASPLAIN or ASDOT notation.

- capability_negotiation
        Configure whether or not to negotiate capability with this neighbor.
        (Choices: true, false)[Default: None]
- connected_check
        Configure whether or not to check for directly connected peer.
        (Choices: true, false)[Default: None]
- description
        Description of the neighbor.
        [Default: None]
- dynamic_capability
        Configure whether or not to enable dynamic capability.
        (Choices: true, false)[Default: None]
- ebgp_multihop
        Specify multihop TTL for a remote peer. Valid values are integers between 2 and 255, or keyword 'default' to
        disable this property.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- local_as
        Specify the local-as number for the eBGP neighbor. Valid values are String or Integer in ASPLAIN or ASDOT
        notation, or 'default', which means not to configure it.
        [Default: None]
- log_neighbor_changes
        Specify whether or not to enable log messages for neighbor up/down event.
        (Choices: enable, disable, inherit)[Default: None]
- low_memory_exempt
        Specify whether or not to shut down this neighbor under memory pressure.
        (Choices: true, false)[Default: None]
- maximum_peers
        Specify Maximum number of peers for this neighbor prefix Valid values are between 1 and 1000, or 'default', which
        does not impose the limit.
        [Default: None]
= neighbor
        Neighbor Identifier. Valid values are string. Neighbors may use IPv4 or IPv6 notation, with or without prefix
        length.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- pwd
        Specify the password for neighbor. Valid value is string.
        [Default: None]
- pwd_type
        Specify the encryption type the password will use. Valid values are '3des' or 'cisco_type_7' encryption.
        (Choices: 3des, cisco_type_7)[Default: None]
- remote_as
        Specify Autonomous System Number of the neighbor. Valid values are String or Integer in ASPLAIN or ASDOT
        notation, or 'default', which means not to configure it.
        [Default: None]
- remove_private_as
        Specify the config to remove private AS number from outbound updates. Valid values are 'enable' to enable this
        config, 'disable' to disable this config, 'all' to remove all private AS number, or 'replace-as', to replace the
        private AS number.
        (Choices: enable, disable, all, replace-as)[Default: None]
- shutdown
        Configure to administratively shutdown this neighbor.
        (Choices: true, false)[Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- suppress_4_byte_as
        Configure to suppress 4-byte AS Capability.
        (Choices: true, false)[Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
- timers_holdtime
        Specify holdtime timer value. Valid values are integers between 0 and 3600 in terms of seconds, or 'default',
        which is 180.
        [Default: None]
- timers_keepalive
        Specify keepalive timer value. Valid values are integers between 0 and 3600 in terms of seconds, or 'default',
        which is 60.
        [Default: None]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- transport_passive_only
        Specify whether or not to only allow passive connection setup. Valid values are 'true', 'false', and 'default',
        which defaults to 'false'. This property can only be configured when the neighbor is in 'ip' address format
        without prefix length. This property and the transport_passive_mode property are mutually exclusive.
        (Choices: true, false)[Default: None]
- update_source
        Specify source interface of BGP session and updates.
        [Default: None]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vrf
        Name of the VRF. The name 'default' is a valid VRF representing the global bgp.
        [Default: default]
Notes:
  * `state=absent' removes the whole BGP neighbor configuration.
  * Default, where supported, restores params default value.
EXAMPLES:
# create a new neighbor
- nxos_bgp_neighbor:
    asn: 65535
    neighbor: 3.3.3.3
    local_as: 20
    remote_as: 30
    description: "just a description"
    update_source: Ethernet1/3
    shutdown: default
    state: present
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"asn": "65535", "description": "just a description",
            "local_as": "20", "neighbor": "3.3.3.3",
            "remote_as": "30", "shutdown": "default",
            "update_source": "Ethernet1/3", "vrf": "default"}
existing:
    description: k/v pairs of existing BGP neighbor configuration
    returned: verbose mode
    type: dict
    sample: {}
end_state:
    description: k/v pairs of BGP neighbor configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"asn": "65535", "capability_negotiation": false,
            "connected_check": false, "description": "just a description",
            "dynamic_capability": true, "ebgp_multihop": "",
            "local_as": "20", "log_neighbor_changes": "",
            "low_memory_exempt": false, "maximum_peers": "",
            "neighbor": "3.3.3.3", "pwd": "",
            "pwd_type": "", "remote_as": "30",
            "remove_private_as": "disable", "shutdown": false,
            "suppress_4_byte_as": false, "timers_holdtime": "180",
            "timers_keepalive": "60", "transport_passive_only": false,
            "update_source": "Ethernet1/3", "vrf": "default"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router bgp 65535", "neighbor 3.3.3.3",
            "remote-as 30", "update-source Ethernet1/3",
            "description just a description", "local-as 20"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_BGP_NEIGHBOR_AF    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_bgp_neighbor_af.py)

  Manages BGP address-family's neighbors configurations on NX-OS switches.

Options (= is mandatory):

- additional_paths_receive
        Valid values are enable for basic command enablement; disable for disabling the command at the neighbor af level
        (it adds the disable keyword to the basic command); and inherit to remove the command at this level (the command
        value is inherited from a higher BGP layer).
        (Choices: enable, disable, inherit)[Default: None]
- additional_paths_send
        Valid values are enable for basic command enablement; disable for disabling the command at the neighbor af level
        (it adds the disable keyword to the basic command); and inherit to remove the command at this level (the command
        value is inherited from a higher BGP layer).
        (Choices: enable, disable, inherit)[Default: None]
- advertise_map_exist
        Conditional route advertisement. This property requires two route maps, an advertise-map and an exist-map. Valid
        values are an array specifying both the advertise-map name and the exist-map name, or simply 'default' e.g.
        ['my_advertise_map', 'my_exist_map']. This command is mutually exclusive with the advertise_map_non_exist
        property.
        [Default: None]
- advertise_map_non_exist
        Conditional route advertisement. This property requires two route maps, an advertise-map and an exist-map. Valid
        values are an array specifying both the advertise-map name and the non-exist-map name, or simply 'default' e.g.
        ['my_advertise_map', 'my_non_exist_map']. This command is mutually exclusive with the advertise_map_exist
        property.
        [Default: None]
= afi
        Address Family Identifier.
        (Choices: ipv4, ipv6, vpnv4, vpnv6, l2vpn)
- allowas_in
        Activate allowas-in property
        [Default: None]
- allowas_in_max
        Optional max-occurrences value for allowas_in. Valid values are an integer value or 'default'. Can be used
        independently or in conjunction with allowas_in.
        [Default: None]
- as_override
        Activate the as-override feature.
        (Choices: true, false)[Default: None]
= asn
        BGP autonomous system number. Valid values are String, Integer in ASPLAIN or ASDOT notation.

- default_originate
        Activate the default-originate feature.
        (Choices: true, false)[Default: None]
- default_originate_route_map
        Optional route-map for the default_originate property. Can be used independently or in conjunction with
        `default_originate'. Valid values are a string defining a route-map name, or 'default'.
        [Default: None]
- filter_list_in
        Valid values are a string defining a filter-list name, or 'default'.
        [Default: None]
- filter_list_out
        Valid values are a string defining a filter-list name, or 'default'.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- max_prefix_interval
        Optional restart interval. Valid values are an integer. Requires max_prefix_limit.
        [Default: None]
- max_prefix_limit
        maximum-prefix limit value. Valid values are an integer value or 'default'.
        [Default: None]
- max_prefix_threshold
        Optional threshold percentage at which to generate a warning. Valid values are an integer value. Requires
        max_prefix_limit.
        [Default: None]
- max_prefix_warning
        Optional warning-only keyword. Requires max_prefix_limit.
        (Choices: true, false)[Default: None]
= neighbor
        Neighbor Identifier. Valid values are string. Neighbors may use IPv4 or IPv6 notation, with or without prefix
        length.

- next_hop_self
        Activate the next-hop-self feature.
        (Choices: true, false)[Default: None]
- next_hop_third_party
        Activate the next-hop-third-party feature.
        (Choices: true, false)[Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- prefix_list_in
        Valid values are a string defining a prefix-list name, or 'default'.
        [Default: None]
- prefix_list_out
        Valid values are a string defining a prefix-list name, or 'default'.
        [Default: None]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- route_map_in
        Valid values are a string defining a route-map name, or 'default'.
        [Default: None]
- route_map_out
        Valid values are a string defining a route-map name, or 'default'.
        [Default: None]
- route_reflector_client
        Router reflector client.
        (Choices: true, false)[Default: None]
= safi
        Sub Address Family Identifier.
        (Choices: unicast, multicast, evpn)
- send_community
        send-community attribute.
        (Choices: none, both, extended, standard, default)[Default: None]
- soft_reconfiguration_in
        Valid values are 'enable' for basic command enablement; 'always' to add the always keyword to the basic command;
        and 'inherit' to remove the command at this level (the command value is inherited from a higher BGP layer).
        (Choices: enable, always, inherit)[Default: None]
- soo
        Site-of-origin. Valid values are a string defining a VPN extcommunity or 'default'.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- suppress_inactive
        suppress-inactive feature.
        (Choices: true, false, default)[Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- unsuppress_map
        unsuppress-map. Valid values are a string defining a route-map name or 'default'.
        [Default: None]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vrf
        Name of the VRF. The name 'default' is a valid VRF representing the global bgp.
        [Default: default]
- weight
        Weight value. Valid values are an integer value or 'default'.
        [Default: None]
Notes:
  * `state=absent' removes the whole BGP address-family's neighbor configuration.
  * Default, when supported, removes properties
  * In order to default maximum-prefix configuration, only `max_prefix_limit=default' is needed.
EXAMPLES:
- name: configure RR client
  nxos_bgp_neighbor_af:
    asn: 65535
    neighbor: '3.3.3.3'
    afi: ipv4
    safi: unicast
    route_reflector_client: true
    state: present
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"afi": "ipv4", "asn": "65535",
            "neighbor": "3.3.3.3", "route_reflector_client": true,
            "safi": "unicast", "vrf": "default"}
existing:
    description: k/v pairs of existing configuration
    returned: verbose mode
    type: dict
    sample: {}
end_state:
    description: k/v pairs of configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"additional_paths_receive": "inherit",
            "additional_paths_send": "inherit",
            "advertise_map_exist": [], "advertise_map_non_exist": [],
            "afi": "ipv4", "allowas_in": false,
            "allowas_in_max": "", "as_override": false,
            "asn": "65535", "default_originate": false,
            "default_originate_route_map": "", "filter_list_in": "",
            "filter_list_out": "", "max_prefix_interval": "",
            "max_prefix_limit": "", "max_prefix_threshold": "",
            "max_prefix_warning": "", "neighbor": "3.3.3.3",
            "next_hop_self": false, "next_hop_third_party": true,
            "prefix_list_in": "", "prefix_list_out": "",
            "route_map_in": "", "route_map_out": "",
            "route_reflector_client": true, "safi": "unicast",
            "send_community": "",
            "soft_reconfiguration_in": "inherit", "soo": "",
            "suppress_inactive": false, "unsuppress_map": "",
            "vrf": "default", "weight": ""}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router bgp 65535", "neighbor 3.3.3.3",
            "address-family ipv4 unicast", "route-reflector-client"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_command.py)

  Sends an arbitrary command to an NXOS node and returns the results read from the device.  This module includes an
  argument that will cause the module to wait for a specific condition before returning or timing out if the condition is
  not met.

Options (= is mandatory):

= commands
        The commands to send to the remote NXOS device over the configured provider.  The resulting output from the
        command is returned.  If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of retires as expired.
        The `commands' argument also accepts an alternative form that allows for complex values that specify the command
        to run and the output format to return.   This can be done on a command by command basis.  The complex argument
        supports the keywords `command' and `output' where `command' is the command to run and `output' is one of 'text'
        or 'json'.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- interval
        Configures the interval in seconds to wait between retries of the command.  If the command does not pass the
        specified conditional, the interval indicates how to long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the `wait_for' must be
        satisfied.  If the value is set to `any' then only one of the values must be satisfied.
        [Default: all]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- retries
        Specifies the number of retries a command should by tried before it is considered failed.  The command is run on
        the target device every retry and evaluated against the `wait_for' conditionals.
        [Default: 10]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- wait_for
        Specifies what to evaluate from the output of the command and what conditionals to apply.  This argument will
        cause the task to wait for a particular conditional to be true before moving forward.   If the conditional is not
        true by the configured retries, the task fails.  See examples.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

---
- name: run show version on remote devices
  nxos_command:
    commands: show version
    provider: "{{ cli }}"

- name: run show version and check to see if output contains Cisco
  nxos_command:
    commands: show version
    wait_for: result[0] contains Cisco
    provider: "{{ cli }}"

- name: run multiple commands on remote nodes
  nxos_command:
    commands:
      - show version
      - show interfaces
    provider: "{{ cli }}"

- name: run multiple commands and evaluate the output
  nxos_command:
    commands:
      - show version
      - show interfaces
    wait_for:
      - result[0] contains Cisco
      - result[1] contains loopback0
    provider: "{{ cli }}"

- name: run commands and specify the output format
  nxos_command:
    commands:
      - command: show version
        output: json
    provider: "{{ cli }}"

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']
stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]
failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> NXOS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_config.py)

  Cisco NXOS configurations use a simple block indent file syntax for segmenting configuration into sections.  This
  module provides an implementation for working with NXOS configuration sections in a deterministic way.  This module
  works with either CLI or NXAPI transports.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- backup
        This argument will cause the module to create a full backup of the current `running-config' from the remote
        device before any changes are made.  The backup file is written to the `backup' folder in the playbook root
        directory.  If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuration to use as the base config for comparison.
        [Default: None]
- defaults
        The `defaults' argument will influence how the running-config is collected from the device.  When the value is
        set to true, the command used to collect the running-config is append with the all keyword.  When the value is
        set to false, the command is issued without the all keyword
        [Default: False]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        Note this argument should be considered deprecated.  To achieve the equivalent, set the `match=none' which is
        idempotent.  This argument will be removed in a future release.
        (Choices: true, false)[Default: False]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  If match is set to `exact', command lines must be an equal match.  Finally, if
        match is set to `none', the module will not attempt to compare the source configuration with the running
        configuration on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If the
        parents argument is omitted, the commands are checked against the set of top level or global commands.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct.
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running-config to startup-config.  This operation is
        performed after any changes are made to the current running config.  If no changes are made, the configuration is
        still saved to the startup config.  This option will always cause the module to return changed.
        [Default: False]
- src
        The `src' argument provides a path to the configuration file to load into the remote system.  The path can either
        be a full system path to the configuration file if the value starts with / or relative to the root of the
        implemented role or playbook. This argument is mutually exclusive with the `lines' and `parents' arguments.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

---
- name: configure top level configuration and save it
  nxos_config:
    lines: hostname {{ inventory_hostname }}
    save: yes
    provider: "{{ cli }}"

- nxos_config:
    lines:
      - 10 permit ip 1.1.1.1/32 any log
      - 20 permit ip 2.2.2.2/32 any log
      - 30 permit ip 3.3.3.3/32 any log
      - 40 permit ip 4.4.4.4/32 any log
      - 50 permit ip 5.5.5.5/32 any log
    parents: ip access-list test
    before: no ip access-list test
    match: exact
    provider: "{{ cli }}"

- nxos_config:
    lines:
      - 10 permit ip 1.1.1.1/32 any log
      - 20 permit ip 2.2.2.2/32 any log
      - 30 permit ip 3.3.3.3/32 any log
      - 40 permit ip 4.4.4.4/32 any log
    parents: ip access-list test
    before: no ip access-list test
    replace: block
    provider: "{{ cli }}"

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: Only when lines is specified.
  type: list
  sample: ['...', '...']
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/nxos_config.2016-07-16@22:28:34


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> NXOS_EVPN_GLOBAL    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_evpn_global.py)

  Handles the EVPN control plane for VXLAN.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= nv_overlay_evpn
        EVPN control plane.
        (Choices: true, false)
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
- nxos_evpn_global:
    nv_overlay_evpn: true

RETURN VALUES:
commands:
    description: The set of commands to be sent to the remote device
    returned: always
    type: list
    sample: ['nv overlay evpn']


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_EVPN_VNI    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_evpn_vni.py)

  Manages Cisco Ethernet Virtual Private Network (EVPN) VXLAN Network Identifier (VNI) configurations of a Nexus device.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
= route_distinguisher
        The VPN Route Distinguisher (RD). The RD is combined with the IPv4 or IPv6 prefix learned by the PE router to
        create a globally unique address.
        [Default: None]
- route_target_both
        Enables/Disables route-target settings for both import and export target communities using a single property.
        [Default: None]
- route_target_export
        Sets the route-target 'import' extended communities.
        [Default: None]
- route_target_import
        Sets the route-target 'import' extended communities.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
= vni
        The EVPN VXLAN Network Identifier.
        [Default: None]
Notes:
  * default, where supported, restores params default value.
  * RD override is not permitted. You should set it to the default values first and then reconfigure it.
  * `route_target_both', `route_target_import' and `route_target_export valid' values are a list of extended
        communities, (i.e. ['1.2.3.4:5', '33:55']) or the keywords 'auto' or 'default'.
  * The `route_target_both' property is discouraged due to the inconsistent behavior of the property across Nexus
        platforms and image versions. For this reason it is recommended to use explicit `route_target_export' and
        `route_target_import' properties instead of `route_target_both'.
  * RD valid values are a string in one of the route-distinguisher formats, the keyword 'auto', or the keyword
        'default'.
EXAMPLES:
- nxos_evpn_vni:
    vni: 6000
    route_distinguisher: "60:10"
    route_target_import:
        - "5000:10"
        - "4100:100"
    route_target_export: auto
    route_target_both: default
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"route_target_import": ["5000:10", "4100:100",
             "5001:10"],"vni": "6000"}
existing:
    description: k/v pairs of existing EVPN VNI configuration
    returned: verbose mode
    type: dict
    sample: {"route_distinguisher": "70:10", "route_target_both": [],
            "route_target_export": [], "route_target_import": [
            "4100:100", "5000:10"], "vni": "6000"}
end_state:
    description: k/v pairs of EVPN VNI configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"route_distinguisher": "70:10", "route_target_both": [],
             "route_target_export": [], "route_target_import": [
             "4100:100", "5000:10", "5001:10"], "vni": "6000"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["evpn", "vni 6000 l2", "route-target import 5001:10"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_facts.py)

  Collects facts from Cisco Nexus devices running the NX-OS operating system.  Fact collection is supported over both Cli
  and Nxapi transports.  This module prepends all of the base network fact keys with `ansible_net_<fact>'.  The facts
  module will always collect a base set of facts from the device and can enable or disable collection of additional
  facts.

Options (= is mandatory):

- gather_subset
        When supplied, this argument will restrict the facts collected to a given subset.  Possible values for this
        argument include all, hardware, config, legacy, and interfaces.  Can specify a list of values to include a larger
        subset.  Values can also be used with an initial `[!]' to specify that a specific subset should not be collected.
        [Default: !config]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

---
- nxos_facts:
    gather_subset: all

# Collect only the config and default facts
- nxos_facts:
    gather_subset:
      - config

# Do not collect hardware facts
- nxos_facts:
    gather_subset:
      - "!hardware"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the device
  returned: always
  type: list

# default
ansible_net_model:
  description: The model name returned from the device
  returned: always
  type: str
ansible_net_serialnum:
  description: The serial number of the remote device
  returned: always
  type: str
ansible_net_version:
  description: The operating system version running on the remote device
  returned: always
  type: str
ansible_net_hostname:
  description: The configured hostname of the device
  returned: always
  type: string
ansible_net_image:
  description: The image file the device is running
  returned: always
  type: string

# hardware
ansible_net_filesystems:
  description: All file system names available on the device
  returned: when hardware is configured
  type: list
ansible_net_memfree_mb:
  description: The available free memory on the remote device in Mb
  returned: when hardware is configured
  type: int
ansible_net_memtotal_mb:
  description: The total memory on the remote device in Mb
  returned: when hardware is configured
  type: int

# config
ansible_net_config:
  description: The current active config from the device
  returned: when config is configured
  type: str

# interfaces
ansible_net_all_ipv4_addresses:
  description: All IPv4 addresses configured on the device
  returned: when interfaces is configured
  type: list
ansible_net_all_ipv6_addresses:
  description: All IPv6 addresses configured on the device
  returned: when interfaces is configured
  type: list
ansible_net_interfaces:
  description: A hash of all interfaces running on the system
  returned: when interfaces is configured
  type: dict
ansible_net_neighbors:
  description: The list of LLDP neighbors from the remote device
  returned: when interfaces is configured
  type: dict

# legacy (pre Ansible 2.2)
fan_info:
  description: A hash of facts about fans in the remote device
  returned: when legacy is configured
  type: dict
hostname:
  description: The configured hostname of the remote device
  returned: when legacy is configured
  type: dict
interfaces_list:
  description: The list of interface names on the remote device
  returned: when legacy is configured
  type: dict
kickstart:
  description: The software version used to boot the system
  returned: when legacy is configured
  type: str
module:
  description: A hash of facts about the modules in a remote device
  returned: when legacy is configured
  type: dict
platform:
  description: The hardware platform reported by the remote device
  returned: when legacy is configured
  type: str
power_supply_info:
  description: A hash of facts about the power supplies in the remote device
  returned: when legacy is configured
  type: str
vlan_list:
  description: The list of VLAN IDs configured on the remote device
  returned: when legacy is configured
  type: list


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_FEATURE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_feature.py)

  Offers ability to enable and disable features in NX-OS.

Options (= is mandatory):

= feature
        Name of feature.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Desired state of the feature.
        (Choices: enabled, disabled)[Default: enabled]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
- name: Ensure lacp is enabled
  nxos_feature:
    feature: lacp
    state: enabled
    host: "{{ inventory_hostname }}"

- name: Ensure ospf is disabled
  nxos_feature:
    feature: ospf
    state: disabled
    host: "{{ inventory_hostname }}"

- name: Ensure vpc is enabled
  nxos_feature:
    feature: vpc
    state: enabled
    host: "{{ inventory_hostname }}"


RETURN VALUES:
commands:
    description: The set of commands to be sent to the remote device
    returned: always
    type: list
    sample: ['nv overlay evpn']


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_FILE_COPY    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_file_copy.py)

  Copy a file to the flash (or bootflash) remote network device on NXOS devices.

Options (= is mandatory):

- file_system
        The remote file system of the device. If omitted, devices that support a file_system parameter will use their
        default values.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= local_file
        Path to local file. Local directory must exist.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- remote_file
        Remote file path of the copy. Remote directories must exist. If omitted, the name of the local file will be used.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * The feature must be enabled with feature scp-server.
  * If the file is already present (md5 sums match), no transfer will take place.
  * Check mode will tell you if the file would be copied.
EXAMPLES:
- nxos_file_copy:
    local_file: "./test_file.txt"
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
transfer_status:
    description: Whether a file was transferred. "No Transfer" or "Sent".
    returned: success
    type: string
    sample: 'Sent'
local_file:
    description: The path of the local file.
    returned: success
    type: string
    sample: '/path/to/local/file'
remote_file:
    description: The path of the remote file.
    returned: success
    type: string
    sample: '/path/to/remote/file'


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_GIR    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_gir.py)

  Trigger a graceful removal or insertion (GIR) of the switch.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Specify desired state of the resource.
        (Choices: present, absent)[Default: present]
- system_mode_maintenance
        When `system_mode_maintenance=true' it puts all enabled protocols in maintenance mode (using the isolate
        command). When `system_mode_maintenance=false' it puts all enabled protocols in normal mode (using the no isolate
        command).
        (Choices: true, false)[Default: None]
- system_mode_maintenance_dont_generate_profile
        When `system_mode_maintenance_dont_generate_profile=true' it prevents the dynamic searching of enabled protocols
        and executes commands configured in a maintenance-mode profile. Use this option if you want the system to use a
        maintenance-mode profile that you have created. When `system_mode_maintenance_dont_generate_profile=false' it
        prevents the dynamic searching of enabled protocols and executes commands configured in a normal-mode profile.
        Use this option if you want the system to use a normal-mode profile that you have created.
        (Choices: true, false)[Default: None]
- system_mode_maintenance_on_reload_reset_reason
        Boots the switch into maintenance mode automatically in the event of a specified system crash.
        (Choices: hw_error, svc_failure, kern_failure, wdog_timeout, fatal_error, lc_failure, match_any,
        manual_reload)[Default: None]
- system_mode_maintenance_shutdown
        Shuts down all protocols, vPC domains, and interfaces except the management interface (using the shutdown
        command). This option is disruptive while `system_mode_maintenance' (which uses the isolate command) is not.
        (Choices: true, false)[Default: None]
- system_mode_maintenance_timeout
        Keeps the switch in maintenance mode for a specified number of minutes. Range is 5-65535.
        [Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * `state' has effect only in combination with `system_mode_maintenance_timeout' or
        `system_mode_maintenance_on_reload_reset_reason'.
  * Using `system_mode_maintenance' and `system_mode_maintenance_dont_generate_profile' would make the module fail,
        but the system mode will be triggered anyway.
EXAMPLES:
# Trigger system maintenance mode
- nxos_gir:
    system_mode_maintenance: true
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"
# Trigger system normal mode
- nxos_gir:
    system_mode_maintenance: false
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"
# Configure on-reload reset-reason for maintenance mode
- nxos_gir:
    system_mode_maintenance_on_reload_reset_reason: manual_reload
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"
# Add on-reload reset-reason for maintenance mode
- nxos_gir:
    system_mode_maintenance_on_reload_reset_reason: hw_error
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"
# Remove on-reload reset-reason for maintenance mode
- nxos_gir:
    system_mode_maintenance_on_reload_reset_reason: manual_reload
    state: absent
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"
# Set timeout for maintenance mode
- nxos_gir:
    system_mode_maintenance_timeout: 30
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"
# Remove timeout for maintenance mode
- nxos_gir:
    system_mode_maintenance_timeout: 30
    state: absent
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
final_system_mode:
    description: describe the last system mode
    returned: verbose mode
    type: string
    sample: normal
updates:
    description: commands sent to the device
    returned: verbose mode
    type: list
    sample: ["terminal dont-ask", "system mode maintenance timeout 10"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_GIR_PROFILE_MANAGEMENT    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_gir_profile_management.py)

  Manage a maintenance-mode or normal-mode profile with configuration commands that can be applied during graceful
  removal or graceful insertion.

Options (= is mandatory):

- commands
        List of commands to be included into the profile.
        [Default: None]
- config
        Specify the configuration string to be used for module operations.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- include_defaults
        Specify to retrieve or not the complete running configuration for module operations.
        (Choices: true, false)[Default: False]
= mode
        Configure the profile as Maintenance or Normal mode.
        (Choices: maintenance, normal)
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Specify desired state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * This module is not idempotent when `state=present'.
  * `state=absent' removes the whole profile.
EXAMPLES:
# Create a maintenance-mode profile
- nxos_gir_profile:
    mode: maintenance
    commands:
      - router eigrp 11
      - isolate
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"
# Remove the maintenance-mode profile
- nxos_gir_profile:
    mode: maintenance
    state: absent
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: list of commands passed into module.
    returned: verbose mode
    type: list
    sample: ["router eigrp 11", "isolate"]
existing:
    description: list of existing profile commands.
    returned: verbose mode
    type: list
    sample: ["router bgp 65535","isolate","router eigrp 10","isolate",
            "diagnostic bootup level complete"]
end_state:
    description: list of profile entries after module execution.
    returned: verbose mode
    type: list
    sample: ["router bgp 65535","isolate","router eigrp 10","isolate",
            "diagnostic bootup level complete","router eigrp 11", "isolate"]
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["configure maintenance profile maintenance-mode",
             "router eigrp 11","isolate"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_HSRP    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_hsrp.py)

  Manages HSRP configuration on NX-OS switches.

Options (= is mandatory):

- auth_string
        Authentication string.
        [Default: None]
- auth_type
        Authentication type.
        (Choices: text, md5)[Default: None]
= group
        HSRP group number.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Full name of interface that is being managed for HSRP.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- priority
        HSRP priority.
        [Default: None]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Specify desired state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- version
        HSRP version.
        (Choices: 1, 2)[Default: 2]
- vip
        HSRP virtual IP address.
        [Default: None]
Notes:
  * HSRP feature needs to be enabled first on the system.
  * SVIs must exist before using this module.
  * Interface must be a L3 port before using this module.
  * HSRP cannot be configured on loopback interfaces.
  * MD5 authentication is only possible with HSRPv2 while it is ignored if HSRPv1 is used instead, while it will
        not raise any error. Here we allow MD5 authentication only with HSRPv2 in order to enforce better practice.
EXAMPLES:
- name: Ensure HSRP is configured with following params on a SVI
  nxos_hsrp:
    group: 10
    vip: 10.1.1.1
    priority: 150
    interface: vlan10
    preempt: enabled
    host: 68.170.147.165

- name: Ensure HSRP is configured with following params on a SVI
  nxos_hsrp:
    group: 10
    vip: 10.1.1.1
    priority: 150
    interface: vlan10
    preempt: enabled
    host: 68.170.147.165
    auth_type: text
    auth_string: CISCO

- name: Remove HSRP config for given interface, group, and VIP
  nxos_hsrp:
    group: 10
    interface: vlan10
    vip: 10.1.1.1
    host: 68.170.147.165
    state: absent

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"group": "30", "version": "2", "vip": "10.30.1.1"}
existing:
    description: k/v pairs of existing hsrp info on the interface
    returned: always
    type: dict
    sample: {}
end_state:
    description: k/v pairs of hsrp after module execution
    returned: always
    type: dict
    sample: {"auth_string": "cisco", "auth_type": "text",
            "group": "30", "interface": "vlan10", "preempt": "disabled",
            "priority": "100", "version": "2", "vip": "10.30.1.1"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface vlan10", "hsrp version 2", "hsrp 30", "ip 10.30.1.1"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_IGMP    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_igmp.py)

  Manages IGMP global configuration configuration settings.

Options (= is mandatory):

- enforce_rtr_alert
        Enables or disables the enforce router alert option check for IGMPv2 and IGMPv3 packets.
        (Choices: true, false)[Default: None]
- flush_routes
        Removes routes when the IGMP process is restarted. By default, routes are not flushed.
        (Choices: true, false)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- restart
        Restarts the igmp process (using an exec config command).
        (Choices: true, false)[Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manages desired state of the resource.
        (Choices: present, default)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * When `state=default', all supported params will be reset to a default state.
  * If restart is set to true with other params set, the restart will happen last, i.e. after the configuration
        takes place.
EXAMPLES:
- name: Default igmp global params (all params except restart)
  nxos_igmp:
    state: default
    host: "{{ inventory_hostname }}"

- name: Ensure the following igmp global config exists on the device
  nxos_igmp:
    flush_routes: true
    enforce_rtr_alert: true
    host: "{{ inventory_hostname }}"

- name: Restart the igmp process
  nxos_igmp:
    restart: true
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"enforce_rtr_alert": true, "flush_routes": true}
existing:
    description: k/v pairs of existing IGMP configuration
    returned: verbose mode
    type: dict
    sample: {"enforce_rtr_alert": true, "flush_routes": false}
end_state:
    description: k/v pairs of IGMP configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"enforce_rtr_alert": true, "flush_routes": true}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["ip igmp flush-routes"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_IGMP_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_igmp_interface.py)

  Manages IGMP interface configuration settings.

Options (= is mandatory):

- group_timeout
        Sets the group membership timeout for IGMPv2. Values can range from 3 to 65,535 seconds. The default is 260
        seconds.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- immediate_leave
        Enables the device to remove the group entry from the multicast routing table immediately upon receiving a leave
        message for the group. Use this command to minimize the leave latency of IGMPv2 group memberships on a given IGMP
        interface because the device does not send group-specific queries. The default is disabled.
        (Choices: true, false)[Default: False]
= interface
        The full interface name for IGMP configuration. e.g. `Ethernet1/2'.

- last_member_qrt
        Sets the query interval waited after sending membership reports before the software deletes the group state.
        Values can range from 1 to 25 seconds. The default is 1 second.
        [Default: None]
- last_member_query_count
        Sets the number of times that the software sends an IGMP query in response to a host leave message. Values can
        range from 1 to 5. The default is 2.
        [Default: None]
- oif_prefix
        Configure a prefix for static outgoing interface (OIF).
        [Default: None]
- oif_routemap
        Configure a routemap for static outgoing interface (OIF).
        [Default: None]
- oif_source
        Configure a source for static outgoing interface (OIF).
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- querier_timeout
        Sets the querier timeout that the software uses when deciding to take over as the querier. Values can range from
        1 to 65535 seconds. The default is 255 seconds.
        [Default: None]
- query_interval
        Sets the frequency at which the software sends IGMP host query messages. Values can range from 1 to 18000
        seconds. he default is 125 seconds.
        [Default: None]
- query_mrt
        Sets the response time advertised in IGMP queries. Values can range from 1 to 25 seconds. The default is 10
        seconds.
        [Default: None]
- report_llg
        Configures report-link-local-groups. Enables sending reports for groups in 224.0.0.0/24. Reports are always sent
        for nonlink local groups. By default, reports are not sent for link local groups.
        (Choices: true, false)[Default: False]
- restart
        Restart IGMP.
        (Choices: true, false)[Default: None]
- robustness
        Sets the robustness variable. Values can range from 1 to 7. The default is 2.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- startup_query_count
        Query count used when the IGMP process starts up. The range is from 1 to 10. The default is 2.
        [Default: None]
- startup_query_interval
        Query interval used when the IGMP process starts up. The range is from 1 to 18000. The default is 31.
        [Default: None]
- state
        Manages desired state of the resource.
        (Choices: present, default)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- version
        IGMP version. It can be 2 or 3.
        (Choices: 2, 3)[Default: None]
Notes:
  * When `state=default', supported params will be reset to a default state. These include `version',
        `startup_query_interval', `startup_query_count', `robustness', `querier_timeout', `query_mrt',
        `query_interval', `last_member_qrt', `last_member_query_count', `group_timeout', `report_llg', and
        `immediate_leave'.
  * When `state=absent', all configs for `oif_prefix', `oif_source', and `oif_routemap' will be removed.
  * PIM must be enabled to use this module.
  * This module is for Layer 3 interfaces.
  * Route-map check not performed (same as CLI) check when configuring route-map with 'static-oif'
  * If restart is set to true with other params set, the restart will happen last, i.e. after the configuration
        takes place.
EXAMPLES:
- nxos_igmp_interface:
    interface: ethernet1/32
    startup_query_interval: 30
    state: present
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"asn": "65535", "router_id": "1.1.1.1", "vrf": "test"}
existing:
    description: k/v pairs of existing BGP configuration
    returned: always
    type: dict
    sample: {"asn": "65535", "bestpath_always_compare_med": false,
            "bestpath_aspath_multipath_relax": false,
            "bestpath_compare_neighborid": false,
            "bestpath_compare_routerid": false,
            "bestpath_cost_community_ignore": false,
            "bestpath_med_confed": false,
            "bestpath_med_missing_as_worst": false,
            "bestpath_med_non_deterministic": false, "cluster_id": "",
            "confederation_id": "", "confederation_peers": "",
            "graceful_restart": true, "graceful_restart_helper": false,
            "graceful_restart_timers_restart": "120",
            "graceful_restart_timers_stalepath_time": "300", "local_as": "",
            "log_neighbor_changes": false, "maxas_limit": "",
            "neighbor_down_fib_accelerate": false, "reconnect_interval": "60",
            "router_id": "11.11.11.11", "suppress_fib_pending": false,
            "timer_bestpath_limit": "", "timer_bgp_hold": "180",
            "timer_bgp_keepalive": "60", "vrf": "test"}
end_state:
    description: k/v pairs of BGP configuration after module execution
    returned: always
    type: dict
    sample: {"asn": "65535", "bestpath_always_compare_med": false,
            "bestpath_aspath_multipath_relax": false,
            "bestpath_compare_neighborid": false,
            "bestpath_compare_routerid": false,
            "bestpath_cost_community_ignore": false,
            "bestpath_med_confed": false,
            "bestpath_med_missing_as_worst": false,
            "bestpath_med_non_deterministic": false, "cluster_id": "",
            "confederation_id": "", "confederation_peers": "",
            "graceful_restart": true, "graceful_restart_helper": false,
            "graceful_restart_timers_restart": "120",
            "graceful_restart_timers_stalepath_time": "300", "local_as": "",
            "log_neighbor_changes": false, "maxas_limit": "",
            "neighbor_down_fib_accelerate": false, "reconnect_interval": "60",
            "router_id": "1.1.1.1",  "suppress_fib_pending": false,
            "timer_bestpath_limit": "", "timer_bgp_hold": "180",
            "timer_bgp_keepalive": "60", "vrf": "test"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router bgp 65535", "vrf test", "router-id 1.1.1.1"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_IGMP_SNOOPING    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_igmp_snooping.py)

  Manages IGMP snooping global configuration.

Options (= is mandatory):

- group_timeout
        Group membership timeout value for all VLANs on the device. Accepted values are integer in range 1-10080, `never'
        and `default'.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- link_local_grp_supp
        Global link-local groups suppression.
        (Choices: true, false)[Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- report_supp
        Global IGMPv1/IGMPv2 Report Suppression.
        [Default: None]
- snooping
        Enables/disables IGMP snooping on the switch.
        (Choices: true, false)[Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, default)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- v3_report_supp
        Global IGMPv3 Report Suppression and Proxy Reporting.
        (Choices: true, false)[Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * When `state=default', params will be reset to a default state.
  * `group_timeout' also accepts `never' as an input.
EXAMPLES:
# ensure igmp snooping params supported in this module are in there default state
- nxos_igmp_snooping:
    state: default
    host:  inventory_hostname }}
    username:  un }}
    password:  pwd }}

# ensure following igmp snooping params are in the desired state
- nxos_igmp_snooping:
   group_timeout: never
   snooping: true
   link_local_grp_supp: false
   optimize_mcast_flood: false
   report_supp: true
   v3_report_supp: true
   host: "{{ inventory_hostname }}"
   username: "{{ un }}"
   password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"group_timeout": "50", "link_local_grp_supp": true,
            "report_supp": false, "snooping": false, "v3_report_supp": false}
existing:
    description:
        - k/v pairs of existing configuration
    returned: always
    type: dict
    sample: {"group_timeout": "never", "link_local_grp_supp": false,
            "report_supp": true, "snooping": true, "v3_report_supp": true}
end_state:
    description: k/v pairs of configuration after module execution
    returned: always
    type: dict
    sample: {"group_timeout": "50", "link_local_grp_supp": true,
            "report_supp": false, "snooping": false, "v3_report_supp": false}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["ip igmp snooping link-local-groups-suppression",
             "ip igmp snooping group-timeout 50",
             "no ip igmp snooping report-suppression",
             "no ip igmp snooping v3-report-suppression",
             "no ip igmp snooping"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_INSTALL_OS    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_install_os.py)

  Install an operating system by setting the boot options like boot image and kickstart image.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- kickstart_image_file
        Name of the kickstart image file on flash.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= system_image_file
        Name of the system (or combined) image file on flash.

- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * The module will fail due to timeout issues, but the install will go on anyway. Ansible's block and rescue can
        be leveraged to handle this kind of failure and check actual module results. See EXAMPLE for more about
        this. The first task on the rescue block is needed to make sure the device has completed all checks and it
        started to reboot. The second task is needed to wait for the device to come back up. The last two tasks are
        used to verify the installation process was successful.
  * Do not include full file paths, just the name of the file(s) stored on the top level flash directory.
  * You must know if your platform supports taking a kickstart image as a parameter. If supplied but not supported,
        errors may occur.
  * This module attempts to install the software immediately, which may trigger a reboot.
  * In check mode, the module tells you if the current boot images are set to the desired images.
EXAMPLES:
- block:
    - name: Install OS
      nxos_install_os:
        system_image_file: nxos.7.0.3.I2.2d.bin
        host: "{{ inventory_hostname }}"
        username: "{{ un }}"
        password: "{{ pwd }}"
        transport: nxapi
  rescue:
    - name: Wait for device to perform checks
      wait_for:
        port: 22
        state: stopped
        timeout: 300
        delay: 60
        host: "{{ inventory_hostname }}"
    - name: Wait for device to come back up
      wait_for:
        port: 22
        state: started
        timeout: 300
        delay: 60
        host: "{{ inventory_hostname }}"
    - name: Check installed OS
      nxos_command:
        commands:
          - show version
        username: "{{ un }}"
        password: "{{ pwd }}"
        host: "{{ inventory_hostname }}"
        transport: nxapi
      register: output
    - assert:
        that:
          - output['stdout'][0]['kickstart_ver_str'] == '7.0(3)I4(1)'

RETURN VALUES:
install_state:
    description: Boot and install information.
    returned: always
    type: dictionary
    sample: {
        "kick": "n5000-uk9-kickstart.7.2.1.N1.1.bin",
        "sys": "n5000-uk9.7.2.1.N1.1.bin",
        "status": "This is the log of last installation.

            Continuing with installation process, please wait.

            The login will be disabled until the installation is completed.

            Performing supervisor state verification. 

            SUCCESS

            Supervisor non-disruptive upgrade successful.

            Install has been successful.
",
    }


MAINTAINERS: Gabriele Gerbibo (@GGabriele), Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_interface.py)

  Manages physical attributes of interfaces of NX-OS switches.

Options (= is mandatory):

- admin_state
        Administrative state of the interface.
        (Choices: up, down)[Default: up]
- description
        Interface description.
        [Default: None]
- fabric_forwarding_anycast_gateway
        Associate SVI with anycast gateway under VLAN configuration mode.
        (Choices: true, false)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Full name of interface, i.e. Ethernet1/1, port-channel10.
        [Default: None]
- interface_type
        Interface type to be unconfigured from the device.
        (Choices: loopback, portchannel, svi, nve)[Default: None]
- ip_forward
        Enable/Disable ip forward feature on SVIs.
        (Choices: enable, disable)[Default: None]
- mode
        Manage Layer 2 or Layer 3 state of the interface.
        (Choices: layer2, layer3)[Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Specify desired state of the resource.
        (Choices: present, absent, default)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * This module is also used to create logical interfaces such as svis and loopbacks.
  * Be cautious of platform specific idiosyncrasies. For example, when you default a loopback interface, the admin
        state toggles on certain versions of NX-OS.
  * The [nxos_overlay_global] `anycast_gateway_mac' attribute must be set before setting the
        `fabric_forwarding_anycast_gateway' property.
EXAMPLES:
- name: Ensure an interface is a Layer 3 port and that it has the proper description
  nxos_interface:
    interface: Ethernet1/1
    description: 'Configured by Ansible'
    mode: layer3
    host: 68.170.147.165

- name: Admin down an interface
  nxos_interface:
    interface: Ethernet2/1
    host: 68.170.147.165
    admin_state: down

- name: Remove all loopback interfaces
  nxos_interface:
    interface: loopback
    state: absent
    host: 68.170.147.165

- name: Remove all logical interfaces
  nxos_interface:
    interface_type: "{{ item }} "
    state: absent
    host: "{{ inventory_hostname }}"
  with_items:
    - loopback
    - portchannel
    - svi
    - nve

- name: Admin up all ethernet interfaces
  nxos_interface:
    interface: ethernet
    host: 68.170.147.165
    admin_state: up

- name: Admin down ALL interfaces (physical and logical)
  nxos_interface:
    interface: all
    host: 68.170.147.165
    admin_state: down

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"admin_state": "down"}
existing:
    description: k/v pairs of existing switchport
    returned: always
    type: dict
    sample:  {"admin_state": "up", "description": "None",
              "interface": "port-channel101", "mode": "layer2",
              "type": "portchannel", "ip_forward": "enable"}
end_state:
    description: k/v pairs of switchport after module execution
    returned: always
    type: dict
    sample:  {"admin_state": "down", "description": "None",
              "interface": "port-channel101", "mode": "layer2",
              "type": "portchannel", "ip_forward": "enable"}
updates:
    description: command list sent to the device
    returned: always
    type: list
    sample: ["interface port-channel101", "shutdown"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_INTERFACE_OSPF    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_interface_ospf.py)

  Manages configuration of an OSPF interface instance.

Options (= is mandatory):

= area
        Ospf area associated with this cisco_interface_ospf instance. Valid values are a string, formatted as an IP
        address (i.e. "0.0.0.0") or as an integer.

- cost
        The cost associated with this cisco_interface_ospf instance.
        [Default: None]
- dead_interval
        Time interval an ospf neighbor waits for a hello packet before tearing down adjacencies. Valid values are an
        integer or the keyword 'default'.
        [Default: None]
- hello_interval
        Time between sending successive hello packets. Valid values are an integer or the keyword 'default'.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Name of this cisco_interface resource. Valid value is a string.

- message_digest
        Enables or disables the usage of message digest authentication. Valid values are 'true' and 'false'.
        (Choices: true, false)[Default: None]
- message_digest_algorithm_type
        Algorithm used for authentication among neighboring routers within an area. Valid values is 'md5'.
        (Choices: md5)[Default: None]
- message_digest_encryption_type
        Specifies the scheme used for encrypting message_digest_password. Valid values are '3des' or 'cisco_type_7'
        encryption.
        (Choices: cisco_type_7, 3des)[Default: None]
- message_digest_key_id
        Md5 authentication key-id associated with the ospf instance. If this is present, message_digest_encryption_type,
        message_digest_algorithm_type and message_digest_password are mandatory. Valid value is an integer and 'default'.
        [Default: None]
- message_digest_password
        Specifies the message_digest password. Valid value is a string.
        [Default: None]
= ospf
        Name of the ospf instance.

- passive_interface
        Setting to true will prevent this interface from receiving HELLO packets. Valid values are 'true' and 'false'.
        (Choices: true, false)[Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * Default, where supported, restores params default value.
  * To remove an existing authentication configuration you should use `message_digest_key_id=default' plus all
        other options matching their existing values.
  * `state=absent' removes the whole OSPF interface configuration.
EXAMPLES:
- nxos_interface_ospf:
    interface: ethernet1/32
    ospf: 1
    area: 1
    cost: default
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"area": "1", "interface": "ethernet1/32", "ospf": "1"}
existing:
    description: k/v pairs of existing OSPF configuration
    returned: verbose mode
    type: dict
    sample: {"area": "", "cost": "", "dead_interval": "",
            "hello_interval": "", "interface": "ethernet1/32",
            "message_digest": false, "message_digest_algorithm_type": "",
            "message_digest_encryption_type": "",
            "message_digest_key_id": "", "message_digest_password": "",
            "ospf": "", "passive_interface": false}
end_state:
    description: k/v pairs of OSPF configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"area": "0.0.0.1", "cost": "", "dead_interval": "",
            "hello_interval": "", "interface": "ethernet1/32",
            "message_digest": false, "message_digest_algorithm_type": "",
            "message_digest_encryption_type": "", "message_digest_key_id": "",
            "message_digest_password": "", "ospf": "1",
            "passive_interface": false}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface Ethernet1/32", "ip router ospf 1 area 0.0.0.1"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_IP_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_ip_interface.py)

  Manages Layer 3 attributes for IPv4 and IPv6 interfaces.

Options (= is mandatory):

- addr
        IPv4 or IPv6 Address.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Full name of interface, i.e. Ethernet1/1, vlan10.

- mask
        Subnet mask for IPv4 or IPv6 Address in decimal format.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Specify desired state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * Interface must already be a L3 port when using this module.
  * Logical interfaces (po, loop, svi) must be created first.
  * `mask' must be inserted in decimal format (i.e. 24) for both IPv6 and IPv4.
  * A single interface can have multiple IPv6 configured.
EXAMPLES:
- name: Ensure ipv4 address is configured on Ethernet1/32
  nxos_ip_interface:
    interface: Ethernet1/32
    transport: nxapi
    version: v4
    state: present
    addr: 20.20.20.20
    mask: 24

- name: Ensure ipv6 address is configured on Ethernet1/31
  nxos_ip_interface:
    interface: Ethernet1/31
    transport: cli
    version: v6
    state: present
    addr: '2001::db8:800:200c:cccb'
    mask: 64

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"addr": "20.20.20.20", "interface": "ethernet1/32", "mask": "24"}
existing:
    description: k/v pairs of existing IP attributes on the interface
    returned: always
    type: dict
    sample: {"addresses": [{"addr": "11.11.11.11", "mask": 17}],
            "interface": "ethernet1/32", "prefix": "11.11.0.0",
            "type": "ethernet", "vrf": "default"}
end_state:
    description: k/v pairs of IP attributes after module execution
    returned: always
    type: dict
    sample: {"addresses": [{"addr": "20.20.20.20", "mask": 24}],
            "interface": "ethernet1/32", "prefix": "20.20.20.0",
            "type": "ethernet", "vrf": "default"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface ethernet1/32", "ip address 20.20.20.20/24"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_MTU    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/_nxos_mtu.py)

  Manages MTU settings on Nexus switch.

DEPRECATED: 
Deprecated in 2.3 use M(nxos_system)'s C(mtu) option.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- interface
        Full name of interface, i.e. Ethernet1/1.
        [Default: None]
- mtu
        MTU for a specific interface. Must be an even number between 576 and 9216.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Specify desired state of the resource.
        (Choices: present, absent)[Default: present]
- sysmtu
        System jumbo MTU. Must be an even number between 576 and 9216.
        [Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * Either `sysmtu' param is required or (`interface' AND `mtu') parameters are required.
  * `state=absent' unconfigures a given MTU if that value is currently present.
EXAMPLES:
# Ensure system mtu is 9126
- nxos_mtu:
    sysmtu: 9216
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Config mtu on Eth1/1 (routed interface)
- nxos_mtu:
    interface: Ethernet1/1
    mtu: 1600
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Config mtu on Eth1/3 (switched interface)
- nxos_mtu:
    interface: Ethernet1/3
    mtu: 9216
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Unconfigure mtu on a given interface
- nxos_mtu:
    interface: Ethernet1/3
    mtu: 9216
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"
    state: absent

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"mtu": "1700"}
existing:
    description:
        - k/v pairs of existing mtu/sysmtu on the interface/system
    returned: always
    type: dict
    sample: {"mtu": "1600", "sysmtu": "9216"}
end_state:
    description: k/v pairs of mtu/sysmtu values after module execution
    returned: always
    type: dict
    sample: {"mtu": "1700", sysmtu": "9216"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["interface vlan10", "mtu 1700"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> NXOS_NTP    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_ntp.py)

  Manages core NTP configuration.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- key_id
        Authentication key identifier to use with given NTP server or peer.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- peer
        Network address of NTP peer.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- prefer
        Makes given NTP server or peer the preferred NTP server or peer for the device.
        (Choices: enabled, disabled)[Default: None]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- server
        Network address of NTP server.
        [Default: None]
- source_addr
        Local source address from which NTP messages are sent.
        [Default: None]
- source_int
        Local source interface from which NTP messages are sent. Must be fully qualified interface name.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vrf_name
        Makes the device communicate with the given NTP server or peer over a specific VRF.
        [Default: None]
EXAMPLES:
# Set NTP Server with parameters
- nxos_ntp:
    server: 1.2.3.4
    key_id: 32
    prefer: enabled
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"address": "2.2.2.2", "key_id": "48",
            "peer_type": "server", "prefer": "enabled",
            "source": "3.3.3.3", "source_type": "source"}
existing:
    description:
        - k/v pairs of existing ntp server/peer
    returned: always
    type: dict
    sample: {"address": "2.2.2.2", "key_id": "32",
            "peer_type": "server", "prefer": "enabled",
            "source": "ethernet2/1", "source_type": "source-interface"}
end_state:
    description: k/v pairs of ntp info after module execution
    returned: always
    type: dict
    sample: {"address": "2.2.2.2", "key_id": "48",
            "peer_type": "server", "prefer": "enabled",
            "source": "3.3.3.3", "source_type": "source"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["ntp server 2.2.2.2 prefer key 48",
             "no ntp source-interface ethernet2/1", "ntp source 3.3.3.3"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_NTP_AUTH    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_ntp_auth.py)

  Manages NTP authentication.

Options (= is mandatory):

- auth_type
        Whether the given md5string is in cleartext or has been encrypted. If in cleartext, the device will encrypt it
        before storing it.
        (Choices: text, encrypt)[Default: text]
- authentication
        Turns NTP authentication on or off.
        (Choices: on, off)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= key_id
        Authentication key identifier (numeric).

= md5string
        MD5 String.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- trusted_key
        Whether the given key is required to be supplied by a time source for the device to synchronize to the time
        source.
        (Choices: true, false)[Default: False]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * If `state=absent', the module will attempt to remove the given key configuration. If a matching key
        configuration isn't found on the device, the module will fail.
  * If `state=absent' and `authentication=on', authentication will be turned off.
  * If `state=absent' and `authentication=off', authentication will be turned on.
EXAMPLES:
# Basic NTP authentication configuration
- nxos_ntp_auth:
    key_id: 32
    md5string: hello
    auth_type: text
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"auth_type": "text", "authentication": "off",
            "key_id": "32", "md5string": "helloWorld",
            "trusted_key": "true"}
existing:
    description:
        - k/v pairs of existing ntp authentication
    returned: always
    type: dict
    sample: {"authentication": "off", "trusted_key": "false"}
end_state:
    description: k/v pairs of ntp authentication after module execution
    returned: always
    type: dict
    sample: {"authentication": "off", "key_id": "32",
            "md5string": "kapqgWjwdg", "trusted_key": "true"}
state:
    description: state as sent in from the playbook
    returned: always
    type: string
    sample: "present"
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["ntp authentication-key 32 md5 helloWorld 0", "ntp trusted-key 32"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_NTP_OPTIONS    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_ntp_options.py)

  Manages NTP options, e.g. authoritative server and logging.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- logging
        Sets whether NTP logging is enabled on the device.
        (Choices: true, false)[Default: None]
- master
        Sets whether the device is an authoritative NTP server.
        (Choices: true, false)[Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- stratum
        If `master=true', an optional stratum can be supplied (1-15). The device default is 8.
        [Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * At least one of `master' or `logging' params must be supplied.
  * When `state=absent', boolean parameters are flipped, e.g. `master=true' will disable the authoritative server.
  * When `state=absent' and `master=true', the stratum will be removed as well.
  * When `state=absent' and `master=false', the stratum will be configured to its default value, 8.
EXAMPLES:
# Basic NTP options configuration
- nxos_ntp_options:
    master: true
    stratum: 12
    logging: false
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"logging": false, "master": true, "stratum": "11"}
existing:
    description:
        - k/v pairs of existing ntp options
    returned: always
    type: dict
    sample: {"logging": true, "master": true, "stratum": "8"}
end_state:
    description: k/v pairs of ntp options after module execution
    returned: always
    type: dict
    sample: {"logging": false, "master": true, "stratum": "11"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["no ntp logging", "ntp master 11"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_NXAPI    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_nxapi.py)

  Configures the NXAPI feature on devices running Cisco NXOS.  The NXAPI feature is absent from the configuration by
  default.  Since this module manages the NXAPI feature it only supports the use of the `Cli' transport.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- http
        Controls the operating state of the HTTP protocol as one of the underlying transports for NXAPI.  By default,
        NXAPI will enable the HTTP transport when the feature is first configured.  To disable the use of the HTTP
        transport, set the value of this argument to False.
        (Choices: yes, no)[Default: True]
- http_port
        Configure the port with which the HTTP server will listen on for requests.  By default, NXAPI will bind the HTTP
        service to the standard HTTP port 80.  This argument accepts valid port values in the range of 1 to 65535.
        [Default: 80]
- https
        Controls the operating state of the HTTPS protocol as one of the underlying transports for NXAPI.  By default,
        NXAPI will disable the HTTPS transport when the feature is first configured.  To enable the use of the HTTPS
        transport, set the value of this argument to True.
        (Choices: yes, no)[Default: False]
- https_port
        Configure the port with which the HTTPS server will listen on for requests.  By default, NXAPI will bind the
        HTTPS service to the standard HTTPS port 443.  This argument accepts valid port values in the range of 1 to
        65535.
        [Default: 443]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- sandbox
        The NXAPI feature provides a web base UI for developers for entering commands.  This feature is initially
        disabled when the NXAPI feature is configured for the first time.  When the `sandbox' argument is set to True,
        the developer sandbox URL will accept requests and when the value is set to False, the sandbox URL is
        unavailable.
        (Choices: yes, no)[Default: False]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        The `state' argument controls whether or not the NXAPI feature is configured on the remote device.  When the
        value is `present' the NXAPI feature configuration is present in the device running-config.  When the values is
        `absent' the feature configuration is removed from the running-config.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
- name: Enable NXAPI access with default configuration
  nxos_nxapi:
    state: present

- name: Enable NXAPI with no HTTP, HTTPS at port 9443 and sandbox disabled
  nxos_nxapi:
    enable_http: false
    https_port: 9443
    https: yes
    enable_sandbox: no

- name: remove NXAPI configuration
  nxos_nxapi:
    state: absent

RETURN VALUES:
updates:
  description:
    - Returns the list of commands that need to be pushed into the remote
      device to satisfy the arguments
  returned: always
  type: list
  sample: ['no feature nxapi']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> NXOS_OSPF    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_ospf.py)

  Manages configuration of an ospf instance.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= ospf
        Name of the ospf instance.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
- nxos_ospf:
    ospf: 1
    state: present
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"ospf": "1"}
existing:
    description: k/v pairs of existing configuration
    returned: verbose mode
    type: dict
    sample: {"ospf": ["2"]}
end_state:
    description: k/v pairs of configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"ospf": ["1", "2"]}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router ospf 1"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_OSPF_VRF    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_ospf_vrf.py)

  Manages a VRF for an OSPF router.

Options (= is mandatory):

- auto_cost
        Specifies the reference bandwidth used to assign OSPF cost. Valid values are an integer, in Mbps, or the keyword
        'default'.
        [Default: None]
- default_metric
        Specify the default Metric value. Valid values are an integer or the keyword 'default'.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- log_adjacency
        Controls the level of log messages generated whenever a neighbor changes state. Valid values are 'log', 'detail',
        and 'default'.
        (Choices: log, detail, default)[Default: None]
= ospf
        Name of the OSPF instance.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- router_id
        Router Identifier (ID) of the OSPF router VRF instance.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
- timer_throttle_lsa_hold
        Specify the hold interval for rate-limiting Link-State Advertisement (LSA) generation. Valid values are an
        integer, in milliseconds, or the keyword 'default'.
        [Default: None]
- timer_throttle_lsa_max
        Specify the max interval for rate-limiting Link-State Advertisement (LSA) generation. Valid values are an
        integer, in milliseconds, or the keyword 'default'.
        [Default: None]
- timer_throttle_lsa_start
        Specify the start interval for rate-limiting Link-State Advertisement (LSA) generation. Valid values are an
        integer, in milliseconds, or the keyword 'default'.
        [Default: None]
- timer_throttle_spf_hold
        Specify minimum hold time between Shortest Path First (SPF) calculations. Valid values are an integer, in
        milliseconds, or the keyword 'default'.
        [Default: None]
- timer_throttle_spf_max
        Specify the maximum wait time between Shortest Path First (SPF) calculations. Valid values are an integer, in
        milliseconds, or the keyword 'default'.
        [Default: None]
- timer_throttle_spf_start
        Specify initial Shortest Path First (SPF) schedule delay. Valid values are an integer, in milliseconds, or the
        keyword 'default'.
        [Default: None]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vrf
        Name of the resource instance. Valid value is a string. The name 'default' is a valid VRF representing the global
        OSPF.
        [Default: default]
Notes:
  * Value `default' restores params default value, if any. Otherwise it removes the existing param configuration.
EXAMPLES:
- nxos_ospf_vrf:
    ospf: 1
    timer_throttle_spf_start: 50
    timer_throttle_spf_hold: 1000
    timer_throttle_spf_max: 2000
    timer_throttle_lsa_start: 60
    timer_throttle_lsa_hold: 1100
    timer_throttle_lsa_max: 3000
    vrf: test
    state: present
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"ospf": "1", "timer_throttle_lsa_hold": "1100",
            "timer_throttle_lsa_max": "3000", "timer_throttle_lsa_start": "60",
            "timer_throttle_spf_hold": "1000",
            "timer_throttle_spf_max": "2000", "timer_throttle_spf_start": "50",
            "vrf": "test"}
existing:
    description: k/v pairs of existing configuration
    returned: verbose mode
    type: dict
    sample: {"auto_cost": "40000", "default_metric": "", "log_adjacency": "",
            "ospf": "1", "router_id": "", "timer_throttle_lsa_hold": "5000",
            "timer_throttle_lsa_max": "5000", "timer_throttle_lsa_start": "0",
            "timer_throttle_spf_hold": "1000",
            "timer_throttle_spf_max": "5000",
            "timer_throttle_spf_start": "200", "vrf": "test"}
end_state:
    description: k/v pairs of configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"auto_cost": "40000", "default_metric": "", "log_adjacency": "",
            "ospf": "1", "router_id": "", "timer_throttle_lsa_hold": "1100",
            "timer_throttle_lsa_max": "3000", "timer_throttle_lsa_start": "60",
            "timer_throttle_spf_hold": "1000",
            "timer_throttle_spf_max": "2000", "timer_throttle_spf_start": "50",
            "vrf": "test"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router ospf 1", "vrf test", "timers throttle lsa 60 1100 3000",
             "timers throttle spf 50 1000 2000"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_OVERLAY_GLOBAL    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_overlay_global.py)

  Configures anycast gateway MAC of the switch.

Options (= is mandatory):

= anycast_gateway_mac
        Anycast gateway mac of the switch.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * Default restores params default value
  * Supported MAC address format are "E.E.E", "EE-EE-EE-EE-EE-EE", "EE:EE:EE:EE:EE:EE" and "EEEE.EEEE.EEEE"
EXAMPLES:
- nxos_overlay_global:
    anycast_gateway_mac: "b.b.b"
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"asn": "65535", "router_id": "1.1.1.1", "vrf": "test"}
existing:
    description: k/v pairs of existing BGP configuration
    returned: verbose mode
    type: dict
    sample: {"asn": "65535", "bestpath_always_compare_med": false,
            "bestpath_aspath_multipath_relax": false,
            "bestpath_compare_neighborid": false,
            "bestpath_compare_routerid": false,
            "bestpath_cost_community_ignore": false,
            "bestpath_med_confed": false,
            "bestpath_med_missing_as_worst": false,
            "bestpath_med_non_deterministic": false, "cluster_id": "",
            "confederation_id": "", "confederation_peers": "",
            "graceful_restart": true, "graceful_restart_helper": false,
            "graceful_restart_timers_restart": "120",
            "graceful_restart_timers_stalepath_time": "300", "local_as": "",
            "log_neighbor_changes": false, "maxas_limit": "",
            "neighbor_down_fib_accelerate": false, "reconnect_interval": "60",
            "router_id": "11.11.11.11", "suppress_fib_pending": false,
            "timer_bestpath_limit": "", "timer_bgp_hold": "180",
            "timer_bgp_keepalive": "60", "vrf": "test"}
end_state:
    description: k/v pairs of BGP configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"asn": "65535", "bestpath_always_compare_med": false,
            "bestpath_aspath_multipath_relax": false,
            "bestpath_compare_neighborid": false,
            "bestpath_compare_routerid": false,
            "bestpath_cost_community_ignore": false,
            "bestpath_med_confed": false,
            "bestpath_med_missing_as_worst": false,
            "bestpath_med_non_deterministic": false, "cluster_id": "",
            "confederation_id": "", "confederation_peers": "",
            "graceful_restart": true, "graceful_restart_helper": false,
            "graceful_restart_timers_restart": "120",
            "graceful_restart_timers_stalepath_time": "300", "local_as": "",
            "log_neighbor_changes": false, "maxas_limit": "",
            "neighbor_down_fib_accelerate": false, "reconnect_interval": "60",
            "router_id": "1.1.1.1",  "suppress_fib_pending": false,
            "timer_bestpath_limit": "", "timer_bgp_hold": "180",
            "timer_bgp_keepalive": "60", "vrf": "test"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router bgp 65535", "vrf test", "router-id 1.1.1.1"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_PIM    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_pim.py)

  Manages configuration of a Protocol Independent Multicast (PIM) instance.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= ssm_range
        Configure group ranges for Source Specific Multicast (SSM). Valid values are multicast addresses or the keyword
        'none'.

- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
- nxos_pim:
    ssm_range: "232.0.0.0/8"
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"ssm_range": "232.0.0.0/8"}
existing:
    description: k/v pairs of existing PIM configuration
    returned: verbose mode
    type: dict
    sample: {"ssm_range": none}
end_state:
    description: k/v pairs of BGP configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"ssm_range": "232.0.0.0/8"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["ip pim ssm range 232.0.0.0/8"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_PIM_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_pim_interface.py)

  Manages PIM interface configuration settings.

Options (= is mandatory):

- border
        Configures interface to be a boundary of a PIM domain.
        (Choices: true, false)[Default: None]
- hello_auth_key
        Authentication for hellos on this interface.
        [Default: None]
- hello_interval
        Hello interval in milliseconds for this interface.
        (Choices: true, false)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Full name of the interface such as Ethernet1/33.

- jp_policy_in
        Policy for join-prune messages (inbound).
        [Default: None]
= jp_policy_out
        Policy for join-prune messages (outbound).
        [Default: None]
- jp_type_in
        Type of policy mapped to `jp_policy_in'.
        (Choices: prefix, routemap)[Default: None]
- jp_type_out
        Type of policy mapped to `jp_policy_out'.
        (Choices: prefix, routemap)[Default: None]
- neighbor_policy
        Configures a neighbor policy for filtering adjacencies.
        [Default: None]
- neighbor_type
        Type of policy mapped to neighbor_policy.
        (Choices: prefix, routemap)[Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- sparse
        Enable/disable sparse-mode on the interface.
        (Choices: true, false)[Default: True]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manages desired state of the resource.
        (Choices: present, default)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * When `state=default', supported params will be reset to a default state. These include `dr_prio',
        `hello_auth_key', `hello_interval', `jp_policy_out', `jp_policy_in', `jp_type_in', `jp_type_out', `border',
        `neighbor_policy', `neighbor_type'.
  * The `hello_auth_key' param is not idempotent.
  * `hello_auth_key' only supports clear text passwords.
  * When `state=absent', pim interface configuration will be set to defaults and pim-sm will be disabled on the
        interface.
  * PIM must be enabled on the device to use this module.
  * This module is for Layer 3 interfaces.
EXAMPLES:
# ensure PIM is not running on the interface
- nxos_pim_interface:
    interface: eth1/33
    state: absent
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# ensure the interface has pim-sm enabled with the appropriate priority and hello interval
- nxos_pim_interface:
    interface: eth1/33
    dr_prio: 10
    hello_interval: 40
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# ensure join-prune policies exist
- nxos_pim_interface:
    interface: eth1/33
    jp_policy_in: JPIN
    jp_policy_out: JPOUT
    jp_type_in: routemap
    jp_type_out: routemap
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# ensure defaults are in place
- nxos_pim_interface:
    interface: eth1/33
    state: default
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"interface": "eth1/33", "neighbor_policy": "test",
            "neighbor_type": "routemap", "sparse": true}
existing:
    description:
        - k/v pairs of existing configuration
    returned: always
    type: dict
    sample: {"border": false, "dr_prio": "1", "hello_interval": "30000",
            "isauth": false, "jp_bidir": false, "jp_policy_in": "JPIN",
            "jp_policy_out": "1", "jp_type_in": "routemap",
            "jp_type_out": null, "neighbor_policy": "test1",
            "neighbor_type": "prefix", "sparse": true}
end_state:
    description: k/v pairs of configuration after module execution
    returned: always
    type: dict
    sample: {"border": false, "dr_prio": "1", "hello_interval": "30000",
            "isauth": false, "jp_bidir": false, "jp_policy_in": "JPIN",
            "jp_policy_out": "1", "jp_type_in": "routemap",
            "jp_type_out": null, "neighbor_policy": "test",
            "neighbor_type": "routemap", "sparse": true}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["interface eth1/33", "ip pim neighbor-policy test",
            "ip pim neighbor-policy test"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_PIM_RP_ADDRESS    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_pim_rp_address.py)

  Manages configuration of an Protocol Independent Multicast (PIM) static rendezvous point (RP) address instance.

Options (= is mandatory):

- bidir
        Group range is treated in PIM bidirectional mode.
        (Choices: true, false)[Default: None]
- group_list
        Group range for static RP. Valid values are multicast addresses.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- prefix_list
        Prefix list policy for static RP. Valid values are prefix-list policy names.
        [Default: None]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- route_map
        Route map policy for static RP. Valid values are route-map policy names.
        [Default: None]
= rp_address
        Configures a Protocol Independent Multicast (PIM) static rendezvous point (RP) address. Valid values are unicast
        addresses.

- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * `state=absent' remove the whole rp-address configuration, if existing.
EXAMPLES:
- nxos_pim_rp_address:
    rp_address: "10.1.1.20"
    state: present
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"rp_address": "10.1.1.21"}
existing:
    description: list of existing pim rp-address configuration entries
    returned: verbose mode
    type: list
    sample: []
end_state:
    description: pim rp-address configuration entries after module execution
    returned: verbose mode
    type: list
    sample: [{"bidir": false, "group_list": "224.0.0.0/4",
            "rp_address": "10.1.1.21"}]
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["router bgp 65535", "vrf test", "router-id 1.1.1.1"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_PING    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_ping.py)

  Tests reachability using ping from switch to a remote destination.

Options (= is mandatory):

- count
        Number of packets to send.
        [Default: 2]
= dest
        IP address or hostname (resolvable by switch) of remote node.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- source
        Source IP Address.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vrf
        Outgoing VRF.
        [Default: None]
EXAMPLES:
- name: Test reachability to 8.8.8.8 using mgmt vrf
  nxos_ping:
    dest: 8.8.8.8
    vrf: management
    host: 68.170.147.165

- name: Test reachability to a few different public IPs using mgmt vrf
  nxos_ping:
    dest: nxos_ping
    vrf: management
    host: 68.170.147.165
  with_items:
    - 8.8.8.8
    - 4.4.4.4
    - 198.6.1.4

RETURN VALUES:
action:
    description:
        - Show what action has been performed
    returned: always
    type: string
    sample: "PING 8.8.8.8 (8.8.8.8): 56 data bytes"
updates:
    description: Show the command sent
    returned: always
    type: list
    sample: ["ping 8.8.8.8 count 2 vrf management"]
count:
    description: Show amount of packets sent
    returned: always
    type: string
    sample: "2"
dest:
    description: Show the ping destination
    returned: always
    type: string
    sample: "8.8.8.8"
rtt:
    description: Show RTT stats
    returned: always
    type: dict
    sample: {"avg": "6.264","max":"6.564",
            "min": "5.978"}
packets_rx:
    description: Packets successfully received
    returned: always
    type: string
    sample: "2"
packets_tx:
    description: Packets successfully transmitted
    returned: always
    type: string
    sample: "2"
packet_loss:
    description: Percentage of packets lost
    returned: always
    type: string
    sample: "0.00%"


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_PORTCHANNEL    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_portchannel.py)

  Manages port-channel specific configuration parameters.

Options (= is mandatory):

- force
        When true it forces port-channel members to match what is declared in the members param. This can be used to
        remove members.
        (Choices: true, false)[Default: False]
= group
        Channel-group number for the port-channel.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- members
        List of interfaces that will be managed in a given portchannel.
        [Default: None]
- min_links
        Min links required to keep portchannel up.
        [Default: None]
- mode
        Mode for the port-channel, i.e. on, active, passive.
        (Choices: active, passive, on)[Default: True]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * `state=absent' removes the portchannel config and interface if it already exists. If members to be removed are
        not explicitly passed, all existing members (if any), are removed.
  * Members must be a list.
  * LACP needs to be enabled first if active/passive modes are used.
EXAMPLES:
# Ensure port-channel99 is created, add two members, and set to mode on
- nxos_portchannel:
    group: 99
    members: ['Ethernet1/1','Ethernet1/2']
    mode: 'active'
    state: present
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"group": "12", "members": ["Ethernet2/5",
            "Ethernet2/6"], "mode": "on"}
existing:
    description:
        - k/v pairs of existing portchannel
    returned: always
    type: dict
    sample: {"group": "12", "members": ["Ethernet2/5",
            "Ethernet2/6"], "members_detail": {
            "Ethernet2/5": {"mode": "active", "status": "D"},
            "Ethernet2/6": {"mode": "active", "status": "D"}},
            "min_links": null, "mode": "active"}
end_state:
    description: k/v pairs of portchannel info after module execution
    returned: always
    type: dict
    sample: {"group": "12", "members": ["Ethernet2/5",
            "Ethernet2/6"], "members_detail": {
            "Ethernet2/5": {"mode": "on", "status": "D"},
            "Ethernet2/6": {"mode": "on", "status": "D"}},
            "min_links": null, "mode": "on"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["interface Ethernet2/6", "no channel-group 12",
             "interface Ethernet2/5", "no channel-group 12",
             "interface Ethernet2/6", "channel-group 12 mode on",
             "interface Ethernet2/5", "channel-group 12 mode on"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_REBOOT    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_reboot.py)

  Reboot a network device.

Options (= is mandatory):

- confirm
        Safeguard boolean. Set to true if you're sure you want to reboot.
        [Default: False]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * The module will fail due to timeout issues, but the reboot will be performed anyway.
EXAMPLES:
- nxos_reboot:
    confirm: true
    host: "{{ inventory_hostname }}"
    username: "{{ username }}"
    password: "{{ password }}"

RETURN VALUES:
rebooted:
    description: Whether the device was instructed to reboot.
    returned: success
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_ROLLBACK    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_rollback.py)

  This module offers the ability to set a configuration checkpoint file or rollback to a configuration checkpoint file on
  Cisco NXOS switches.

Options (= is mandatory):

- checkpoint_file
        Name of checkpoint file to create. Mutually exclusive with rollback_to.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- rollback_to
        Name of checkpoint file to rollback to. Mutually exclusive with checkpoint_file.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * Sometimes `transport=nxapi' may cause a timeout error.
EXAMPLES:
- nxos_rollback:
    checkpoint_file: backup.cfg
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"
- nxos_rollback:
    rollback_to: backup.cfg
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
filename:
    description: The filename of the checkpoint/rollback file.
    returned: success
    type: string
    sample: 'backup.cfg'
status:
    description: Which operation took place and whether it was successful.
    returned: success
    type: string
    sample: 'rollback executed'


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SMU    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_smu.py)

  Perform software maintenance upgrades (SMUs) on Cisco NX-OS devices.

Options (= is mandatory):

- file_system
        The remote file system of the device. If omitted, devices that support a file_system parameter will use their
        default values.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
= pkg
        Name of the remote package.

- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * The module can only activate and commit a package, not remove or deactivate it.
  * Use `transport=nxapi' to avoid connection timeout
EXAMPLES:
- nxos_smu:
    pkg: "nxos.CSCuz65185-n9k_EOR-1.0.0-7.0.3.I2.2d.lib32_n9000.rpm"
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
file_system:
    description: The remote file system of the device.
    returned: always
    type: string
    sample: "bootflash:"
pkg:
    description: Name of the remote package
    type: string
    returned: always
    sample: "nxos.CSCuz65185-n9k_EOR-1.0.0-7.0.3.I2.2d.lib32_n9000.rpm"
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["install add bootflash:nxos.CSCuz65185-n9k_EOR-1.0.0-7.0.3.I2.2d.lib32_n9000.rpm",
            "install activate bootflash:nxos.CSCuz65185-n9k_EOR-1.0.0-7.0.3.I2.2d.lib32_n9000.rpm force",
            "install commit bootflash:nxos.CSCuz65185-n9k_EOR-1.0.0-7.0.3.I2.2d.lib32_n9000.rpm"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SNAPSHOT    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_snapshot.py)

  Create snapshots of the running states of selected features, add new show commands for snapshot creation, delete and
  compare existing snapshots.

Options (= is mandatory):

= action
        Define what snapshot action the module would perform.
        (Choices: create, add, compare, delete)
- compare_option
        Snapshot options to be used when `action=compare'.
        (Choices: summary, ipv4routes, ipv6routes)[Default: None]
- comparison_results_file
        Name of the file where snapshots comparison will be store.
        [Default: None]
- description
        Snapshot description to be used when `action=create'.
        [Default: None]
- element_key1
        Specify the tags used to distinguish among row entries, to be used when `action=add'.
        [Default: None]
- element_key2
        Specify the tags used to distinguish among row entries, to be used when `action=add'.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- path
        Specify the path of the file where new created snapshot or snapshots comparison will be stored, to be used when
        `action=create' and `save_snapshot_locally=true' or `action=compare'.
        [Default: ./]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- row_id
        Specifies the tag of each row entry of the show command's XML output, to be used when `action=add'.
        [Default: None]
- save_snapshot_locally
        Specify to locally store a new created snapshot, to be used when `action=create'.
        (Choices: true, false)[Default: False]
- section
        Used to name the show command output, to be used when `action=add'.
        [Default: None]
- show_command
        Specify a new show command, to be used when `action=add'.
        [Default: None]
- snapshot1
        First snapshot to be used when `action=compare'.
        [Default: None]
- snapshot2
        Second snapshot to be used when `action=compare'.
        [Default: None]
- snapshot_name
        Snapshot name, to be used when `action=create' or `action=delete'.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * `transport=cli' may cause timeout errors.
  * The `element_key1' and `element_key2' parameter specify the tags used to distinguish among row entries. In most
        cases, only the element_key1 parameter needs to specified to be able to distinguish among row entries.
  * `action=compare' will always store a comparison report on a local file.
EXAMPLES:
# Create a snapshot and store it locally
- nxos_snapshot:
    action: create
    snapshot_name: test_snapshot
    description: Done with Ansible
    save_snapshot_locally: true
    path: /home/user/snapshots/
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Delete a snapshot
- nxos_snapshot:
    action: delete
    snapshot_name: test_snapshot
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Delete all existing snapshots
- nxos_snapshot:
    action: delete_all
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Add a show command for snapshots creation
- nxos_snapshot:
    section: myshow
    show_command: show ip interface brief
    row_id: ROW_intf
    element_key1: intf-name
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Compare two snapshots
- nxos_snapshot:
    action: compare
    snapshot1: pre_snapshot
    snapshot2: post_snapshot
    comparison_results_file: compare_snapshots.txt
    compare_option: summary
    path: '../snapshot_reports/'
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
existing_snapshots:
    description: list of existing snapshots.
    returned: verbose mode
    type: list
    sample: [{"date": "Tue Sep 13 10:58:08 2016",
              "description": "First snapshot", "name": "first_snap"},
            {"date": "Tue Sep 13 10:27:31 2016", "description": "Pre-snapshot",
            "name": "pre_snapshot"}]
final_snapshots:
    description: list of final snapshots.
    returned: verbose mode
    type: list
    sample: [{"date": "Tue Sep 13 10:58:08 2016",
              "description": "First snapshot", "name": "first_snap"},
            {"date": "Tue Sep 13 10:27:31 2016", "description": "Pre-snapshot",
            "name": "pre_snapshot"},
            {"date": "Tue Sep 13 10:37:50 2016", "description": "Post-snapshot",
            "name": "post_snapshot"}]
report_file:
    description: name of the file where the new snapshot or snapshots
                 comparison have been stored.
    returned: verbose mode
    type: string
    sample: "/home/gabriele/Desktop/ntc-ansible/ansible_snapshot"
updates:
    description: commands sent to the device
    returned: verbose mode
    type: list
    sample: ["snapshot create post_snapshot Post-snapshot"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SNMP_COMMUNITY    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_snmp_community.py)

  Manages SNMP community configuration.

Options (= is mandatory):

- access
        Access type for community.
        (Choices: ro, rw)[Default: None]
- acl
        ACL name to filter snmp requests.
        [Default: 1]
= community
        Case-sensitive community string.

- group
        Group to which the community belongs.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
# ensure snmp community is configured
- nxos_snmp_community:
    community: TESTING7
    group: network-operator
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"group": "network-operator"}
existing:
    description: k/v pairs of existing snmp community
    returned: always
    type: dict
    sample:  {}
end_state:
    description: k/v pairs of snmp community after module execution
    returned: always
    type: dict
    sample:  {"acl": "None", "group": "network-operator"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["snmp-server community TESTING7 group network-operator"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SNMP_CONTACT    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_snmp_contact.py)

  Manages SNMP contact information.

Options (= is mandatory):

= contact
        Contact information.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * `state=absent' removes the contact configuration if it is configured.
EXAMPLES:
# ensure snmp contact is configured
- nxos_snmp_contact:
    contact: Test
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"contact": "New_Test"}
existing:
    description: k/v pairs of existing snmp contact
    returned: always
    type: dict
    sample: {"contact": "Test"}
end_state:
    description: k/v pairs of snmp contact after module execution
    returned: always
    type: dict
    sample: {"contact": "New_Test"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["snmp-server contact New_Test"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SNMP_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_snmp_host.py)

  Manages SNMP host configuration parameters.

Options (= is mandatory):

- community
        Community string or v3 username.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
= snmp_host
        IP address of hostname of target host.

- src_intf
        Source interface.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- type
        type of message to send to host.
        (Choices: trap, inform)[Default: traps]
- udp
        UDP port number (0-65535).
        [Default: None]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- version
        SNMP version.
        (Choices: v2c, v3)[Default: v2c]
- vrf
        VRF to use to source traffic to source.
        [Default: None]
- vrf_filter
        Name of VRF to filter.
        [Default: None]
Notes:
  * `state=absent' removes the host configuration if it is configured.
EXAMPLES:
# ensure snmp host is configured
- nxos_snmp_host:
    snmp_host: 3.3.3.3
    community: TESTING
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"community": "TESTING", "snmp_host": "3.3.3.3",
            "snmp_type": "trap", "version": "v2c", "vrf_filter": "one_more_vrf"}
existing:
    description: k/v pairs of existing snmp host
    returned: always
    type: dict
    sample: {"community": "TESTING", "snmp_type": "trap",
            "udp": "162", "v3": "noauth", "version": "v2c",
            "vrf": "test_vrf", "vrf_filter": ["test_vrf",
            "another_test_vrf"]}
end_state:
    description: k/v pairs of switchport after module execution
    returned: always
    type: dict
    sample: {"community": "TESTING", "snmp_type": "trap",
            "udp": "162", "v3": "noauth", "version": "v2c",
            "vrf": "test_vrf", "vrf_filter": ["test_vrf",
            "another_test_vrf", "one_more_vrf"]}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["snmp-server host 3.3.3.3 filter-vrf another_test_vrf"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SNMP_LOCATION    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_snmp_location.py)

  Manages SNMP location configuration.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= location
        Location information.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
# ensure snmp location is configured
- nxos_snmp_location:
    location: Test
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# ensure snmp location is not configured
- nxos_snmp_location:
    location: Test
    state: absent
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"location": "New_Test"}
existing:
    description: k/v pairs of existing snmp location
    returned: always
    type: dict
    sample: {"location": "Test"}
end_state:
    description: k/v pairs of location info after module execution
    returned: always
    type: dict
    sample: {"location": "New_Test"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["snmp-server location New_Test"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SNMP_TRAPS    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_snmp_traps.py)

  Manages SNMP traps configurations.

Options (= is mandatory):

= group
        Case sensitive group.
        (Choices: aaa, bridge, callhome, cfs, config, entity, feature-control, hsrp, license, link, lldp, ospf, pim, rf,
        rmon, snmp, storm-control, stpx, sysmgr, system, upgrade, vtp, all)
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: enabled, disabled)[Default: enabled]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * This module works at the group level for traps.  If you need to only enable/disable 1 specific trap within a
        group, use the [nxos_command] module.
  * Be aware that you can set a trap only for an enabled feature.
EXAMPLES:
# ensure lldp trap configured
- nxos_snmp_traps:
    group: lldp
    state: enabled
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# ensure lldp trap is not configured
- nxos_snmp_traps:
    group: lldp
    state: disabled
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"group": "lldp"}
existing:
    description: k/v pairs of existing trap status
    returned: always
    type: dict
    sample: {"lldp": [{"enabled": "No",
            "trap": "lldpRemTablesChange"}]}
end_state:
    description: k/v pairs of trap info after module execution
    returned: always
    type: dict
    sample: {"lldp": [{"enabled": "Yes",
            "trap": "lldpRemTablesChange"}]}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: "snmp-server enable traps lldp ;"
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SNMP_USER    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_snmp_user.py)

  Manages SNMP user configuration.

Options (= is mandatory):

- auth
        Auth parameters for the user.
        (Choices: md5, sha)[Default: None]
- encrypt
        Enables AES-128 bit encryption when using privacy password.
        (Choices: true, false)[Default: None]
= group
        Group to which the user will belong to.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- privacy
        Privacy password for the user.
        [Default: None]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- pwd
        Auth password when using md5 or sha.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
= user
        Name of the user.

- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * Authentication parameters not idempotent.
EXAMPLES:
- nxos_snmp_user:
    user: ntc
    group: network-operator
    auth: md5
    pwd: test_password
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"authentication": "md5", "group": "network-operator",
            "pwd": "test_password", "user": "ntc"}
existing:
    description:
        - k/v pairs of existing configuration
    returned: always
    type: dict
    sample: {"authentication": "no", "encrypt": "none",
             "group": ["network-operator"], "user": "ntc"}
end_state:
    description: k/v pairs configuration vtp after module execution
    returned: always
    type: dict
    sample: {"authentication": "md5", "encrypt": "none",
             "group": ["network-operator"], "user": "ntc"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["snmp-server user ntc network-operator auth md5 test_password"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_STATIC_ROUTE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_static_route.py)

  Manages static route configuration

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= next_hop
        Next hop address or interface of static route. If interface, it must be the fully-qualified interface name.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- pref
        Preference or administrative difference of route (range 1-255).
        [Default: None]
= prefix
        Destination prefix of static route.

- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- route_name
        Name of the route. Used with the name parameter on the CLI.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Manage the state of the resource.
        (Choices: present, absent)
- tag
        Route tag value (numeric).
        [Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vrf
        VRF for static route.
        [Default: default]
Notes:
  * If no vrf is supplied, vrf is set to default.
  * If `state=absent', the route will be removed, regardless of the non-required parameters.
EXAMPLES:
- nxos_static_route:
    prefix: "192.168.20.64/24"
    next_hop: "3.3.3.3"
    route_name: testing
    pref: 100
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"next_hop": "3.3.3.3", "pref": "100",
            "prefix": "192.168.20.64/24", "route_name": "testing",
            "vrf": "default"}
existing:
    description: k/v pairs of existing configuration
    returned: verbose mode
    type: dict
    sample: {}
end_state:
    description: k/v pairs of configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"next_hop": "3.3.3.3", "pref": "100",
            "prefix": "192.168.20.0/24", "route_name": "testing",
            "tag": null}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["ip route 192.168.20.0/24 3.3.3.3 name testing 100"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SWITCHPORT    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_switchport.py)

  Manages Layer 2 interfaces

Options (= is mandatory):

- access_vlan
        If `mode=access', used as the access VLAN ID.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Full name of the interface, i.e. Ethernet1/1.
        [Default: None]
- mode
        Mode for the Layer 2 port.
        (Choices: access, trunk)[Default: None]
- native_vlan
        If `mode=trunk', used as the trunk native VLAN ID.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent, unconfigured)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- trunk_allowed_vlans
        if `mode=trunk', these are the only VLANs that will be configured on the trunk, i.e. "2-10,15".
        [Default: None]
- trunk_vlans
        If `mode=trunk', used as the VLAN range to ADD or REMOVE from the trunk.
        [Default: None]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * When `state=absent', VLANs can be added/removed from trunk links and the existing access VLAN can be
        'unconfigured' to just having VLAN 1 on that interface.
  * When working with trunks VLANs the keywords add/remove are always sent in the `switchport trunk allowed vlan`
        command. Use verbose mode to see commands sent.
  * When `state=unconfigured', the interface will result with having a default Layer 2 interface, i.e. vlan 1 in
        access mode.
EXAMPLES:
- name: Ensure Eth1/5 is in its default switchport state
  nxos_switchport:
    interface: eth1/5
    state: unconfigured
    host: "{{ inventory_hostname }}"

- name: Ensure Eth1/5 is configured for access vlan 20
  nxos_switchport:
    interface: eth1/5
    mode: access
    access_vlan: 20
    host: "{{ inventory_hostname }}"

- name: Ensure Eth1/5 only has vlans 5-10 as trunk vlans
  nxos_switchport:
    interface: eth1/5
    mode: trunk
    native_vlan: 10
    trunk_vlans: 5-10
    host: "{{ inventory_hostname }}"

- name: Ensure eth1/5 is a trunk port and ensure 2-50 are being tagged (doesn't mean others aren't also being tagged)
  nxos_switchport:
    interface: eth1/5
    mode: trunk
    native_vlan: 10
    trunk_vlans: 2-50
    host: "{{ inventory_hostname }}"

- name: Ensure these VLANs are not being tagged on the trunk
  nxos_switchport:
    interface: eth1/5
    mode: trunk
    trunk_vlans: 51-4094
    host: "{{ inventory_hostname }} "
    state: absent

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"access_vlan": "10", "interface": "eth1/5", "mode": "access"}
existing:
    description: k/v pairs of existing switchport
    returned: always
    type: dict
    sample:  {"access_vlan": "10", "access_vlan_name": "VLAN0010",
              "interface": "Ethernet1/5", "mode": "access",
              "native_vlan": "1", "native_vlan_name": "default",
              "switchport": "Enabled", "trunk_vlans": "1-4094"}
end_state:
    description: k/v pairs of switchport after module execution
    returned: always
    type: dict
    sample:  {"access_vlan": "10", "access_vlan_name": "VLAN0010",
              "interface": "Ethernet1/5", "mode": "access",
              "native_vlan": "1", "native_vlan_name": "default",
              "switchport": "Enabled", "trunk_vlans": "1-4094"}
updates:
    description: command string sent to the device
    returned: always
    type: list
    sample: ["interface eth1/5", "switchport access vlan 20"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_SYSTEM    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_system.py)

  This module provides declarative management of node system attributes on Cisco NXOS devices.  It provides an option to
  configure host system parameters or remove those parameters from the device active configuration.

Options (= is mandatory):

- domain_lookup
        Enables or disables the DNS lookup feature in Cisco NXOS.  This argument accepts boolean values.  When enabled,
        the system will try to resolve hostnames using DNS and when disabled, hostnames will not be resolved.
        [Default: (null)]
- domain_name
        Configures the default domain name suffix to be used when referencing this node by its FQDN.  This argument
        accepts either a list of domain names or a list of dicts that configure the domain name and VRF name.  See
        examples.
        [Default: (null)]
- domain_search
        Configures a list of domain name suffixes to search when performing DNS name resolution. This argument accepts
        either a list of domain names or a list of dicts that configure the domain name and VRF name.  See examples.
        [Default: (null)]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- hostname
        Configure the device hostname parameter. This option takes an ASCII string value.
        [Default: (null)]
- name_servers
        List of DNS name servers by IP address to use to perform name resolution lookups.  This argument accepts either a
        list of DNS servers or a list of hashes that configure the name server and VRF name.  See examples.
        [Default: (null)]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        State of the configuration values in the device's current active configuration.  When set to `present', the
        values should be configured in the device active configuration and when set to `absent' the values should not be
        in the device active configuration
        (Choices: present, absent)[Default: present]
- system_mtu
        Specifies the mtu, must be an integer.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
- name: configure hostname and domain-name
  nxos_system:
    hostname: nxos01
    domain_name: test.example.com

- name: remove configuration
  nxos_system:
    state: absent

- name: configure DNS lookup sources
  nxos_system:
    lookup_source: Management1

- name: configure name servers
  nxos_system:
    name_servers:
      - 8.8.8.8
      - 8.8.4.4

- name: configure name servers with VRF support
  nxos_system:
    name_servers:
      - { server: 8.8.8.8, vrf: mgmt }
      - { server: 8.8.4.4, vrf: mgmt }

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - hostname nxos01
    - ip domain-name test.example.com


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> NXOS_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/_nxos_template.py)

  Manages network device configurations over SSH or NXAPI.  This module allows implementers to work with the device
  running-config.  It provides a way to push a set of commands onto a network device by evaluating the current running-
  config and only pushing configuration commands that are not already configured.  The config source can be a set of
  commands or a template.

DEPRECATED: 
Deprecated in 2.2. Use M(nxos_config) instead.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- backup
        When this argument is configured true, the module will backup the running-config from the node prior to making
        any changes. The backup file will be written to backup_{{ hostname }} in the root of the playbook directory.
        (Choices: true, false)[Default: False]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuration to use as the base config for comparison.
        [Default: None]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        (Choices: true, false)[Default: False]
- include_defaults
        The module, by default, will collect the current device running-config to use as a base for comparisons to the
        commands in `src'.  Setting this value to true will cause the module to issue the command `show running-config
        all' to include all device settings.
        (Choices: true, false)[Default: False]
- src
        The path to the config source.  The source can be either a file with config or a template that will be merged
        during runtime.  By default the task will search for the source file in role or playbook root folder in templates
        directory.
        [Default: None]
EXAMPLES:
- name: push a configuration onto the device
  nxos_template:
    src: config.j2

- name: forceable push a configuration onto the device
  nxos_template:
    src: config.j2
    force: yes

- name: provide the base configuration for comparison
  nxos_template:
    src: candidate_config.txt
    config: current_config.txt

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['...', '...']

responses:
  description: The set of responses from issuing the commands on the device
  returned: when not check_mode
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> NXOS_UDLD    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_udld.py)

  Manages UDLD global configuration params.

Options (= is mandatory):

- aggressive
        Toggles aggressive mode.
        (Choices: enabled, disabled)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- msg_time
        Message time in seconds for UDLD packets.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- reset
        Ability to reset UDLD down interfaces.
        (Choices: true, false)[Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * When `state=absent', it unconfigures existing settings `msg_time' and set it to its default value of 15.  It is
        cleaner to always use `state=present'.
  * Module will fail if the udld feature has not been previously enabled.
EXAMPLES:
# ensure udld aggressive mode is globally disabled and se global message interval is 20
- nxos_udld:
    aggressive: disabled
    msg_time: 20
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Ensure agg mode is globally enabled and msg time is 15
- nxos_udld:
    aggressive: enabled
    msg_time: 15
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"aggressive": "enabled", "msg_time": "40"}
existing:
    description:
        - k/v pairs of existing udld configuration
    returned: always
    type: dict
    sample: {"aggressive": "disabled", "msg_time": "15"}
end_state:
    description: k/v pairs of udld configuration after module execution
    returned: always
    type: dict
    sample: {"aggressive": "enabled", "msg_time": "40"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["udld message-time 40", "udld aggressive"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_UDLD_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_udld_interface.py)

  Manages UDLD interface configuration params.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        FULL name of the interface, i.e. Ethernet1/1-

= mode
        Manages UDLD mode for an interface.
        (Choices: enabled, disabled, aggressive)
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * Feature UDLD must be enabled on the device to use this module.
EXAMPLES:
# ensure Ethernet1/1 is configured to be in aggressive mode
- nxos_udld_interface:
    interface: Ethernet1/1
    mode: aggressive
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# Remove the aggressive config only if it's currently in aggressive mode and then disable udld (switch default)
- nxos_udld_interface:
    interface: Ethernet1/1
    mode: aggressive
    state: absent
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# ensure Ethernet1/1 has aggressive mode enabled
- nxos_udld_interface:
    interface: Ethernet1/1
    mode: enabled
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"mode": "enabled"}
existing:
    description:
        - k/v pairs of existing configuration
    returned: always
    type: dict
    sample: {"mode": "aggressive"}
end_state:
    description: k/v pairs of configuration after module execution
    returned: always
    type: dict
    sample: {"mode": "enabled"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["interface ethernet1/33",
            "no udld aggressive ; no udld disable"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_USER    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_user.py)

  This module provides declarative management of the local usernames configured on Cisco Nexus devices.  It allows
  playbooks to manage either individual usernames or the collection of usernames in the current running config.  It also
  supports purging usernames from the configuration that are not explicitly defined.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- name
        The username to be configured on the remote Cisco Nexus device.  This argument accepts a stringv value and is
        mutually exclusive with the `users' argument.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- purge
        The `purge' argument instructs the module to consider the resource definition absolute.  It will remove any
        previously configured usernames on the device with the exception of the `admin` user which cannot be deleted per
        nxos constraints.
        [Default: False]
- role
        The `role' argument configures the role for the username in the device running configuration.  The argument
        accepts a string value defining the role name.  This argument does not check if the role has been configured on
        the device.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- sshkey
        The `sshkey' argument defines the SSH public key to configure for the username.  This argument accepts a valid
        SSH key value.
        [Default: None]
- state
        The `state' argument configures the state of the username definition as it relates to the device operational
        configuration.  When set to `present', the username(s) should be configured in the device active configuration
        and when set to `absent' the username(s) should not be in the device active configuration
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- update_password
        Since passwords are encrypted in the device running config, this argument will instruct the module when to change
        the password.  When set to `always', the password will always be updated in the device and when set to
        `on_create' the password will be updated only if the username is created.
        (Choices: on_create, always)[Default: always]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- users
        The set of username objects to be configured on the remote Cisco Nexus device.  The list entries can either be
        the username or a hash of username and properties.  This argument is mutually exclusive with the `name' argument.
        [Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
EXAMPLES:
- name: create a new user
  nxos_user:
    name: ansible
    sshkey: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
    state: present

- name: remove all users except admin
  nxos_user:
    purge: yes

- name: set multiple users role
  users:
    - name: netop
    - name: netend
  role: network-operator
  state: present

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - name ansible
    - name ansible password password
start:
  description: The time the job started
  returned: always
  type: str
  sample: "2016-11-16 10:38:15.126146"
end:
  description: The time the job ended
  returned: always
  type: str
  sample: "2016-11-16 10:38:25.595612"
delta:
  description: The time elapsed to perform all operations
  returned: always
  type: str
  sample: "0:00:10.469466"


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: core
> NXOS_VLAN    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vlan.py)

  Manages VLAN configurations on NX-OS switches.

Options (= is mandatory):

- admin_state
        Manage the VLAN administrative state of the VLAN equivalent to shut/no shut in VLAN config mode.
        (Choices: up, down)[Default: up]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- mapped_vni
        The Virtual Network Identifier (VNI) ID that is mapped to the VLAN. Valid values are integer and keyword
        'default'.
        [Default: None]
- name
        Name of VLAN.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vlan_id
        Single VLAN ID.
        [Default: None]
- vlan_range
        Range of VLANs such as 2-10 or 2,5,10-15, etc.
        [Default: None]
- vlan_state
        Manage the vlan operational state of the VLAN (equivalent to state {active | suspend} command.
        (Choices: active, suspend)[Default: active]
EXAMPLES:
- name: Ensure a range of VLANs are not present on the switch
  nxos_vlan:
    vlan_range: "2-10,20,50,55-60,100-150"
    state: absent
    transport: nxapi

- name: Ensure VLAN 50 exists with the name WEB and is in the shutdown state
  nxos_vlan:
    vlan_id: 50
    admin_state: down
    name: WEB
    transport: nxapi

- name: Ensure VLAN is NOT on the device
  nxos_vlan:
    vlan_id: 50
    state: absent
    transport: nxapi

RETURN VALUES:
commands:
    description: Set of command strings to send to the remote device
    returned: always
    type: list
    sample: ["vlan 20", "vlan 55", "vn-segment 5000"]


MAINTAINERS: Jason Edelman (@jedelman8)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VPC    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vpc.py)

  Manages global VPC configuration

Options (= is mandatory):

= auto_recovery
        Enables/Disables auto recovery
        (Choices: true, false)
- delay_restore
        manages delay restore command and config value in seconds
        [Default: None]
= domain
        VPC domain

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
= peer_gw
        Enables/Disables peer gateway
        (Choices: true, false)
- pkl_dest
        Destination (remote) IP address used for peer keepalive link
        [Default: None]
- pkl_src
        Source IP address used for peer keepalive link
        [Default: None]
- pkl_vrf
        VRF used for peer keepalive link
        [Default: management]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- role_priority
        Role priority for device. Remember lower is better.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Manages desired state of the resource
        (Choices: present, absent)
- system_priority
        System priority device.  Remember they must match between peers.
        [Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * The feature vpc must be enabled before this module can be used
  * If not using management vrf, vrf must be globally on the device before using in the pkl config
  * Although source IP isn't required on the command line it is required when using this module.  The PKL VRF must
        also be configured prior to using this module.
  * Both pkl_src and pkl_dest are needed when changing PKL VRF.
EXAMPLES:
# configure a simple asn
- nxos_vpc:
    domain: 100
    role_priority: 1000
    system_priority: 2000
    pkl_dest: 192.168.100.4
    pkl_src: 10.1.100.20
    peer_gw: true
    auto_recovery: true
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"auto_recovery": true, "domain": "100",
            "peer_gw": true, "pkl_dest": "192.168.100.4",
            "pkl_src": "10.1.100.20", "pkl_vrf": "management",
            "role_priority": "1000", "system_priority": "2000"}
existing:
    description: k/v pairs of existing VPC configuration
    returned: always
    type: dict
    sample: {"auto_recovery": true, "delay_restore": null,
            "domain": "100", "peer_gw": true,
            "pkl_dest": "192.168.100.2", "pkl_src": "10.1.100.20",
            "pkl_vrf": "management", "role_priority": "1000",
            "system_priority": "2000"}
end_state:
    description: k/v pairs of VPC configuration after module execution
    returned: always
    type: dict
    sample: {"auto_recovery": true, "domain": "100",
            "peer_gw": true, "pkl_dest": "192.168.100.4",
            "pkl_src": "10.1.100.20", "pkl_vrf": "management",
            "role_priority": "1000", "system_priority": "2000"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["vpc domain 100",
            "peer-keepalive destination 192.168.100.4 source 10.1.100.20 vrf management",
            "auto-recovery", "peer-gateway"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VPC_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vpc_interface.py)

  Manages interface VPC configuration

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- peer_link
        Set to true/false for peer link config on associated portchannel.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
= portchannel
        Group number of the portchannel that will be configured.

- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
= state
        Manages desired state of the resource.
        (Choices: present, absent)
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vpc
        VPC group/id that will be configured on associated portchannel.
        [Default: None]
Notes:
  * Either vpc or peer_link param is required, but not both.
  * `state=absent' removes whatever VPC config is on a port-channel if one exists.
  * Re-assigning a vpc or peerlink from one portchannel to another is not supported.  The module will force the
        user to unconfigure an existing vpc/pl before configuring the same value on a new portchannel
EXAMPLES:
- nxos_vpc_portchannel:
    portchannel: 10
    vpc: 100
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"portchannel": "100", "vpc": "10"}
existing:
    description: k/v pairs of existing configuration
    returned: always
    type: dict
    sample: {}
end_state:
    description: k/v pairs of configuration after module execution
    returned: always
    type: dict
    sample:  {"peer-link": false, "portchannel": "100", "vpc": "10"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface port-channel100", "vpc 10"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VRF    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vrf.py)

  Manages global VRF configuration.

Options (= is mandatory):

- admin_state
        Administrative state of the VRF.
        (Choices: up, down)[Default: up]
- description
        Description of the VRF.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- route_distinguisher
        VPN Route Distinguisher (RD). Valid values are a string in one of the route-distinguisher formats (ASN2:NN,
        ASN4:NN, or IPV4:NN); the keyword 'auto', or the keyword 'default'.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manages desired state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vni
        Specify virtual network identifier. Valid values are Integer or keyword 'default'.
        [Default: None]
= vrf
        Name of VRF to be managed.

Notes:
  * Cisco NX-OS creates the default VRF by itself. Therefore, you're not allowed to use default as `vrf' name in
        this module.
  * `vrf' name must be shorter than 32 chars.
  * VRF names are not case sensible in NX-OS. Anyway, the name is stored just like it's inserted by the user and
        it'll not be changed again unless the VRF is removed and re-created. i.e. `vrf=NTC' will create a VRF named
        NTC, but running it again with `vrf=ntc' will not cause a configuration change.
EXAMPLES:
- name: Ensure ntc VRF exists on switch
  nxos_vrf:
    vrf: ntc
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"admin_state": "Up", "description": "Test test",
            "vrf": "ntc"}
existing:
    description: k/v pairs of existing vrf
    returned: always
    type: dict
    sample: {"admin_state": "Up", "description": "Old test",
            "vrf": "old_ntc"}
end_state:
    description: k/v pairs of vrf info after module execution
    returned: always
    type: dict
    sample: {"admin_state": "Up", "description": "Test test",
            "vrf": "ntc"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["vrf context ntc", "shutdown"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VRF_AF    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vrf_af.py)

  Manages VRF AF

Options (= is mandatory):

= afi
        Address-Family Identifier (AFI).
        (Choices: ipv4, ipv6)[Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- route_target_both_auto_evpn
        Enable/Disable the EVPN route-target 'auto' setting for both import and export target communities.
        (Choices: true, false)[Default: None]
= safi
        Sub Address-Family Identifier (SAFI).
        (Choices: unicast, multicast)[Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
= vrf
        Name of the VRF.

Notes:
  * Default, where supported, restores params default value.
EXAMPLES:
- nxos_vrf_af:
    interface: nve1
    vni: 6000
    ingress_replication: true
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"afi": "ipv4", "route_target_both_auto_evpn": true,
            "safi": "unicast", "vrf": "test"}
existing:
    description: k/v pairs of existing configuration
    returned: verbose mode
    type: dict
    sample: {"afi": "ipv4", "route_target_both_auto_evpn": false,
            "safi": "unicast", "vrf": "test"}
end_state:
    description: k/v pairs of configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"afi": "ipv4", "route_target_both_auto_evpn": true,
            "safi": "unicast", "vrf": "test"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["vrf context test", "address-family ipv4 unicast",
            "route-target both auto evpn"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VRF_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vrf_interface.py)

  Manages interface specific VRF configuration.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Full name of interface to be managed, i.e. Ethernet1/1.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manages desired state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
= vrf
        Name of VRF to be managed.

Notes:
  * VRF needs to be added globally with [nxos_vrf] before adding a VRF to an interface.
  * Remove a VRF from an interface will still remove all L3 attributes just as it does from CLI.
  * VRF is not read from an interface until IP address is configured on that interface.
EXAMPLES:
- name: Ensure vrf ntc exists on Eth1/1
  nxos_vrf_interface:
    vrf: ntc
    interface: Ethernet1/1
    host: 68.170.147.165
    state: present

- name: Ensure ntc VRF does not exist on Eth1/1
  nxos_vrf_interface:
    vrf: ntc
    interface: Ethernet1/1
    host: 68.170.147.165
    state: absent

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"interface": "loopback16", "vrf": "ntc"}
existing:
    description: k/v pairs of existing vrf on the interface
    returned: always
    type: dict
    sample: {"interface": "loopback16", "vrf": ""}
end_state:
    description: k/v pairs of vrf after module execution
    returned: always
    type: dict
    sample: {"interface": "loopback16", "vrf": "ntc"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface loopback16", "vrf member ntc"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VRRP    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vrrp.py)

  Manages VRRP configuration on NX-OS switches.

Options (= is mandatory):

- admin_state
        Used to enable or disable the VRRP process.
        (Choices: shutdown, no shutdown)[Default: no shutdown]
- authentication
        Clear text authentication string.
        [Default: None]
= group
        VRRP group number.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

= interface
        Full name of interface that is being managed for VRRP.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- priority
        VRRP priority.
        [Default: None]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Specify desired state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vip
        VRRP virtual IP address.
        [Default: None]
Notes:
  * VRRP feature needs to be enabled first on the system.
  * SVIs must exist before using this module.
  * Interface must be a L3 port before using this module.
  * `state=absent' removes the VRRP group if it exists on the device.
  * VRRP cannot be configured on loopback interfaces.
EXAMPLES:
- name: Ensure vrrp group 100 and vip 10.1.100.1 is on vlan10
  nxos_vrrp:
    interface: vlan10
    group: 100
    vip: 10.1.100.1
    host: 68.170.147.165

- name: Ensure removal of the vrrp group config
  # vip is required to ensure the user knows what they are removing
  nxos_vrrp:
    interface: vlan10
    group: 100
    vip: 10.1.100.1
    state: absent
    host: 68.170.147.165

- name: Re-config with more params
  nxos_vrrp:
    interface: vlan10
    group: 100
    vip: 10.1.100.1
    preempt: false
    priority: 130
    authentication: AUTHKEY
    host: 68.170.147.165

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"authentication": "testing", "group": "150", "vip": "10.1.15.1",
            "admin_state": "no shutdown"}
existing:
    description: k/v pairs of existing vrrp info on the interface
    returned: always
    type: dict
    sample: {}
end_state:
    description: k/v pairs of vrrp after module execution
    returned: always
    type: dict
    sample: {"authentication": "testing", "group": "150", "interval": "1",
            "preempt": true, "priority": "100", "vip": "10.1.15.1",
            "admin_state": "no shutdown"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface vlan10", "vrrp 150", "address 10.1.15.1",
            "authentication text testing", "no shutdown"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Jason Edelman (@jedelman8), Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VTP_DOMAIN    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vtp_domain.py)

  Manages VTP domain configuration.

Options (= is mandatory):

= domain
        VTP domain name.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * VTP feature must be active on the device to use this module.
  * This module is used to manage only VTP domain names.
  * VTP domain names are case-sensible.
  * If it's never been configured before, VTP version is set to 1 by default. Otherwise, it leaves the previous
        configured version untouched. Use [nxos_vtp_version] to change it.
  * Use this in combination with [nxos_vtp_password] and [nxos_vtp_version] to fully manage VTP operations.
EXAMPLES:
# ENSURE VTP DOMAIN IS CONFIGURED
- nxos_vtp_domain:
    domain: ntc
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"domain": "ntc"}
existing:
    description:
        - k/v pairs of existing vtp domain
    returned: always
    type: dict
    sample: {"domain": "testing", "version": "2", "vtp_password": ""}
end_state:
    description: k/v pairs of vtp domain after module execution
    returned: always
    type: dict
    sample: {"domain": "ntc", "version": "2", "vtp_password": ""}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["vtp domain ntc"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VTP_PASSWORD    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vtp_password.py)

  Manages VTP password configuration.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Manage the state of the resource
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
- vtp_password
        VTP password
        [Default: None]
Notes:
  * VTP feature must be active on the device to use this module.
  * This module is used to manage only VTP passwords.
  * Use this in combination with [nxos_vtp_domain] and [nxos_vtp_version] to fully manage VTP operations.
  * You can set/remove password only if a VTP domain already exist.
  * If `state=absent' and no `vtp_password' is provided, it remove the current VTP password.
  * If `state=absent' and `vtp_password' is provided, the proposed `vtp_password' has to match the existing one in
        order to remove it.
EXAMPLES:
# ENSURE VTP PASSWORD IS SET
- nxos_vtp_password:
    password: ntc
    state: present
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

# ENSURE VTP PASSWORD IS REMOVED
- nxos_vtp_password:
    password: ntc
    state: absent
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"vtp_password": "new_ntc"}
existing:
    description:
        - k/v pairs of existing vtp
    returned: always
    type: dict
    sample: {"domain": "ntc", "version": "1", "vtp_password": "ntc"}
end_state:
    description: k/v pairs of vtp after module execution
    returned: always
    type: dict
    sample: {"domain": "ntc", "version": "1", "vtp_password": "new_ntc"}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["vtp password new_ntc"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VTP_VERSION    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vtp_version.py)

  Manages VTP version configuration.

Options (= is mandatory):

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
= version
        VTP version number.
        (Choices: 1, 2)
Notes:
  * VTP feature must be active on the device to use this module.
  * This module is used to manage only VTP version.
  * Use this in combination with [nxos_vtp_password] and [nxos_vtp_version] to fully manage VTP operations.
EXAMPLES:
# ENSURE VTP VERSION IS 2
- nxos_vtp_version:
    version: 2
    host: "{{ inventory_hostname }}"
    username: "{{ un }}"
    password: "{{ pwd }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: always
    type: dict
    sample: {"version": "2"}
existing:
    description:
        - k/v pairs of existing vtp
    returned: always
    type: dict
    sample: {"domain": "testing", "version": "1", "vtp_password": ""}
end_state:
    description: k/v pairs of vtp after module execution
    returned: always
    type: dict
    sample: {"domain": "testing", "version": "2", "vtp_password": ""}
updates:
    description: command sent to the device
    returned: always
    type: list
    sample: ["vtp version 2"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VXLAN_VTEP    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vxlan_vtep.py)

  Manages VXLAN Network Virtualization Endpoint (NVE) overlay interface that terminates VXLAN tunnels.

Options (= is mandatory):

- description
        Description of the NVE interface.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- host_reachability
        Specify mechanism for host reachability advertisement.
        (Choices: true, false)[Default: None]
= interface
        Interface name for the VXLAN Network Virtualization Endpoint.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- shutdown
        Administratively shutdown the NVE interface.
        (Choices: true, false)[Default: False]
- source_interface
        Specify the loopback interface whose IP address should be used for the NVE interface.
        [Default: None]
- source_interface_hold_down_time
        Suppresses advertisement of the NVE loopback address until the overlay has converged.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
Notes:
  * The module is used to manage NVE properties, not to create NVE interfaces. Use [nxos_interface] if you wish to
        do so.
  * `state=absent' removes the interface.
  * Default, where supported, restores params default value.
EXAMPLES:
- nxos_vxlan_vtep:
    interface: nve1
    description: default
    host_reachability: default
    source_interface: Loopback0
    source_interface_hold_down_time: 30
    shutdown: default
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"description": "simple description", "host_reachability": true,
        "interface": "nve1", "shutdown": true, "source_interface": "loopback0",
        "source_interface_hold_down_time": "30"}
existing:
    description: k/v pairs of existing VXLAN VTEP configuration
    returned: verbose mode
    type: dict
    sample: {}
end_state:
    description: k/v pairs of VXLAN VTEP configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"description": "simple description", "host_reachability": true,
        "interface": "nve1", "shutdown": true, "source_interface": "loopback0",
        "source_interface_hold_down_time": "30"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface nve1", "source-interface loopback0",
        "source-interface hold-down-time 30", "description simple description",
        "shutdown", "host-reachability protocol bgp"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> NXOS_VXLAN_VTEP_VNI    (/usr/lib/python2.7/site-packages/ansible/modules/network/nxos/nxos_vxlan_vtep_vni.py)

  Creates a Virtual Network Identifier member (VNI) for an NVE overlay interface.

Options (= is mandatory):

- assoc_vrf
        This attribute is used to identify and separate processing VNIs that are associated with a VRF and used for
        routing. The VRF and VNI specified with this command must match the configuration of the VNI under the VRF.
        (Choices: true, false)[Default: None]
- config
        Configuration string to be used for module operations. If not specified, the module will use the current running
        configuration.
        [Default: None]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.

- include_defaults
        Specify to use or not the complete running configuration for module operations.
        (Choices: true, true)[Default: True]
- ingress_replication
        Specifies mechanism for host reachability advertisement.
        (Choices: bgp, static)[Default: None]
= interface
        Interface name for the VXLAN Network Virtualization Endpoint.

- multicast_group
        The multicast group (range) of the VNI. Valid values are string and keyword 'default'.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `nxapi' transports. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- peer_list
        Set the ingress-replication static peer list. Valid values are an array, a space-separated string of ip
        addresses, or the keyword 'default'.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `nxapi'.  The port value will default to the appropriate transport common port if none is provided in the
        task.  (cli=22, http=80, https=443).
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `nxos' arguments to be passed as a dict object.  All constraints (required,
        choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- save
        Specify to save the running configuration after module operations.
        (Choices: true, false)[Default: False]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transport. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- state
        Determines whether the config should be present or not on the device.
        (Choices: present, absent)[Default: present]
- suppress_arp
        Suppress arp under layer 2 VNI.
        (Choices: true, false)[Default: None]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error. NX-API can be
        slow to return on long-running commands (sh mac, sh bgp, etc).
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over cli (ssh) or nxapi.
        [Default: cli]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport=nxapi', otherwise this value is
        ignored.
        (Choices: yes, no)[Default: False]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the nxapi authentication depending on which transport is used. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.  If the transport argument is not nxapi, this value is ignored.
        (Choices: yes, no)[Default: (null)]
= vni
        ID of the Virtual Network Identifier.

Notes:
  * default, where supported, restores params default value.
EXAMPLES:
- nxos_vxlan_vtep_vni:
    interface: nve1
    vni: 6000
    ingress_replication: default
    username: "{{ un }}"
    password: "{{ pwd }}"
    host: "{{ inventory_hostname }}"

RETURN VALUES:
proposed:
    description: k/v pairs of parameters passed into module
    returned: verbose mode
    type: dict
    sample: {"ingress_replication": "default", "interface": "nve1", "vni": "6000"}
existing:
    description: k/v pairs of existing configuration
    returned: verbose mode
    type: dict
    sample: {}
end_state:
    description: k/v pairs of configuration after module execution
    returned: verbose mode
    type: dict
    sample: {"assoc_vrf": false, "ingress_replication": "", "interface": "nve1",
             "multicast_group": "", "peer_list": [],
             "suppress_arp": false, "vni": "6000"}
updates:
    description: commands sent to the device
    returned: always
    type: list
    sample: ["interface nve1", "member vni 6000"]
changed:
    description: check to see if a change was made on the device
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Gabriele Gerbino (@GGabriele)

METADATA:
	Status: ['preview']
	Supported_by: community
> OHAI    (/usr/lib/python2.7/site-packages/ansible/modules/system/ohai.py)

  Similar to the [facter] module, this runs the `Ohai' discovery program (http://wiki.opscode.com/display/chef/Ohai) on
  the remote host and returns JSON inventory data. `Ohai' data is a bit more verbose and nested than `facter'.

Requirements:  ohai

EXAMPLES:
# Retrieve (ohai) data from all Web servers and store in one-file per host
ansible webservers -m ohai --tree=/tmp/ohaidata


MAINTAINERS: Ansible Core Team, Michael DeHaan (@mpdehaan)

METADATA:
	Status: ['preview']
	Supported_by: community
> OMAPI_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/network/omapi_host.py)

  Create, update and remove OMAPI hosts into compatible DHCPd servers.

Options (= is mandatory):

- ddns
        Enable dynamic DNS updates for this host.
        [Default: False]
- host
        Sets OMAPI server host to interact with.
        [Default: localhost]
- ip
        Sets the lease host IP address.
        [Default: None]
= key
        Sets the TSIG key content for authenticating against OMAPI server.

= key_name
        Sets the TSIG key name for authenticating against OMAPI server.

= macaddr
        Sets the lease host MAC address.

- name
        Sets the host lease hostname (mandatory if state=present).
        [Default: None]
- port
        Sets the OMAPI server port to interact with.
        [Default: 7911]
= state
        Create or remove OMAPI host.
        (Choices: present, absent)
- statements
        Attach a list of OMAPI DHCP statements with host lease (without ending semicolon).
        [Default: []]
Requirements:  pypureomapi

EXAMPLES:
- name: Remove a host using OMAPI
  omapi_host:
    key_name: "defomapi"
    key: "+bFQtBCta6j2vWkjPkNFtgA=="
    host: "10.1.1.1"
    macaddr: "00:66:ab:dd:11:44"
    state: absent

- name: Add a host using OMAPI
  omapi_host:
    key_name: "defomapi"
    key: "+bFQtBCta6j2vWkjPkNFtgA=="
    host: "10.98.4.55"
    macaddr: "44:dd:ab:dd:11:44"
    name: "server01"
    ip: "192.168.88.99"
    ddns: yes
    statements:
      - 'filename "pxelinux.0"'
      - 'next-server 1.1.1.1'
    state: present

RETURN VALUES:
changed:
    description: If module has modified a host
    returned: success
    type: string
lease:
    description: dictionnary containing host informations
    returned: success
    type: complex
    contains:
        ip-address:
            description: IP address, if there is.
            returned: success
            type: string
            sample: '192.168.1.5'
        hardware-address:
            description: MAC address
            returned: success
            type: string
            sample: '00:11:22:33:44:55'
        hardware-type:
            description: hardware type, generally '1'
            returned: success
            type: int
            sample: 1
        name:
            description: hostname
            returned: success
            type: string
            sample: 'mydesktop'


MAINTAINERS: Loic Blot (@nerzhul)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPEN_ISCSI    (/usr/lib/python2.7/site-packages/ansible/modules/system/open_iscsi.py)

  Discover targets on given portal, (dis)connect targets, mark targets to manually or auto start, return device nodes of
  connected targets.

Options (= is mandatory):

- auto_node_startup
        whether the target node should be automatically connected at startup
        (Choices: True, False)[Default: (null)]
- discover
        whether the list of target nodes on the portal should be (re)discovered and added to the persistent iscsi
        database. Keep in mind that iscsiadm discovery resets configurtion, like node.startup to manual, hence combined
        with auto_node_startup=yes will always return a changed state.
        (Choices: True, False)[Default: (null)]
- login
        whether the target node should be connected
        (Choices: True, False)[Default: (null)]
- node_auth
        discovery.sendtargets.auth.authmethod
        [Default: CHAP]
- node_pass
        discovery.sendtargets.auth.password
        [Default: (null)]
- node_user
        discovery.sendtargets.auth.username
        [Default: (null)]
- port
        the port on which the iscsi target process listens
        [Default: 3260]
- portal
        the ip address of the iscsi target
        [Default: (null)]
- show_nodes
        whether the list of nodes in the persistent iscsi database should be returned by the module
        (Choices: True, False)[Default: (null)]
- target
        the iscsi target name
        [Default: (null)]
Requirements:  open_iscsi library and tools (iscsiadm)

EXAMPLES:
# perform a discovery on 10.1.2.3 and show available target nodes
- open_iscsi:
    show_nodes: yes
    discover: yes
    portal: 10.1.2.3

# discover targets on portal and login to the one available
# (only works if exactly one target is exported to the initiator)
- open_iscsi:
    portal: '{{ iscsi_target }}'
    login: yes
    discover: yes

# description: connect to the named target, after updating the local
# persistent database (cache)
- open_iscsi:
    login: yes
    target: 'iqn.1986-03.com.sun:02:f8c1f9e0-c3ec-ec84-c9c9-8bfb0cd5de3d'

# description: discconnect from the cached named target
- open_iscsi:
    login: no
    target: 'iqn.1986-03.com.sun:02:f8c1f9e0-c3ec-ec84-c9c9-8bfb0cd5de3d'


MAINTAINERS: Serge van Ginderachter (@srvg)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPENBSD_PKG    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/openbsd_pkg.py)

  Manage packages on OpenBSD using the pkg tools.

Options (= is mandatory):

- build
        Build the package from source instead of downloading and installing a binary. Requires that the port source tree
        is already installed. Automatically builds and installs the 'sqlports' package, if it is not already installed.
        (Choices: True, False)[Default: False]
- clean
        When updating or removing packages, delete the extra configuration file(s) in the old packages which are
        annotated with @extra in the packaging-list.
        (Choices: True, False)[Default: False]
= name
        Name of the package.

- ports_dir
        When used in combination with the 'build' option, allows overriding the default ports source directory.
        [Default: /usr/ports]
- quick
        Replace or delete packages quickly; do not bother with checksums before removing normal files.
        (Choices: True, False)[Default: False]
= state
        `present' will make sure the package is installed. `latest' will make sure the latest version of the package is
        installed. `absent' will make sure the specified package is not installed.
        (Choices: present, latest, absent)
Requirements:  python >= 2.5

EXAMPLES:
# Make sure nmap is installed
- openbsd_pkg:
    name: nmap
    state: present

# Make sure nmap is the latest version
- openbsd_pkg:
    name: nmap
    state: latest

# Make sure nmap is not installed
- openbsd_pkg:
    name: nmap
    state: absent

# Make sure nmap is installed, build it from source if it is not
- openbsd_pkg:
    name: nmap
    state: present
    build: yes

# Specify a pkg flavour with '--'
- openbsd_pkg:
    name: vim--no_x11
    state: present

# Specify the default flavour to avoid ambiguity errors
- openbsd_pkg:
    name: vim--
    state: present

# Specify a package branch (requires at least OpenBSD 6.0)
- openbsd_pkg:
    name: python%3.5
    state: present

# Update all packages on the system
- openbsd_pkg:
    name: '*'
    state: latest

# Purge a package and it's configuration files
- openbsd_pkg: name=mpd clean=yes state=absent

# Quickly remove a package without checking checksums
- openbsd_pkg: name=qt5 quick=yes state=absent


MAINTAINERS: Patrik Lundin (@eest)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPENDJ_BACKENDPROP    (/usr/lib/python2.7/site-packages/ansible/modules/identity/opendj/opendj_backendprop.py)

  This module will update settings for OpenDJ with the command set-backend-prop. It will check first via de get-backend-
  prop if configuration needs to be applied.

Options (= is mandatory):

= backend
        The name of the backend on which the property needs to be updated.

= hostname
        The hostname of the OpenDJ server.

= name
        The configuration setting to update.

- opendj_bindir
        The path to the bin directory of OpenDJ.
        [Default: /opt/opendj/bin]
- password
        The password for the cn=Directory Manager user.
        Either password or passwordfile is needed.
        [Default: (null)]
- passwordfile
        Location to the password file which holds the password for the cn=Directory Manager user.
        Either password or passwordfile is needed.
        [Default: (null)]
= port
        The Admin port on which the OpenDJ instance is available.

- state
        If configuration needs to be added/updated
        [Default: present]
- username
        The username to connect to.
        [Default: cn=Directory Manager]
= value
        The value for the configuration item.

EXAMPLES:
  - name: "Add or update OpenDJ backend properties"
    action: opendj_backendprop
            hostname=localhost
            port=4444
            username="cn=Directory Manager"
            password=password
            backend=userRoot
            name=index-entry-limit
            value=5000

RETURN VALUES:


MAINTAINERS: Werner Dijkerman

METADATA:
	Status: ['preview']
	Supported_by: community
> OPENSSL_PRIVATEKEY    (/usr/lib/python2.7/site-packages/ansible/modules/crypto/openssl_privatekey.py)

  This module allows one to (re)generate OpenSSL private keys. It uses the pyOpenSSL python library to interact with
  openssl. One can generate either RSA or DSA private keys. Keys are generated in PEM format.

Options (= is mandatory):

- force
        Should the key be regenerated even it it already exists
        (Choices: True, False)[Default: False]
= path
        Name of the file in which the generated TLS/SSL private key will be written. It will have 0600 mode.

- size
        Size (in bits) of the TLS/SSL key to generate
        [Default: 4096]
- state
        Whether the private key should exist or not, taking action if the state is different from what is stated.
        (Choices: present, absent)[Default: present]
- type
        The algorithm used to generate the TLS/SSL private key
        (Choices: RSA, DSA)[Default: RSA]
Requirements:  python-pyOpenSSL

EXAMPLES:
# Generate an OpenSSL private key with the default values (4096 bits, RSA)
# and no public key
- openssl_privatekey:
    path: /etc/ssl/private/ansible.com.pem

# Generate an OpenSSL private key with a different size (2048 bits)
- openssl_privatekey:
    path: /etc/ssl/private/ansible.com.pem
    size: 2048

# Force regenerate an OpenSSL private key if it already exists
- openssl_privatekey:
    path: /etc/ssl/private/ansible.com.pem
    force: True

# Generate an OpenSSL private key with a different algorithm (DSA)
- openssl_privatekey:
    path: /etc/ssl/private/ansible.com.pem
    type: DSA

RETURN VALUES:
size:
    description: Size (in bits) of the TLS/SSL private key
    returned:
        - changed
        - success
    type: integer
    sample: 4096
type:
    description: Algorithm used to generate the TLS/SSL private key
    returned:
        - changed
        - success
    type: string
    sample: RSA
filename:
    description: Path to the generated TLS/SSL private key file
    returned:
        - changed
        - success
    type: string
    sample: /etc/ssl/private/ansible.com.pem


MAINTAINERS: Yanis Guenane (@Spredzy)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPENSSL_PUBLICKEY    (/usr/lib/python2.7/site-packages/ansible/modules/crypto/openssl_publickey.py)

  This module allows one to (re)generate OpenSSL public keys from their private keys. It uses the pyOpenSSL python
  library to interact with openssl. Keys are generated in PEM format. This module works only if the version of PyOpenSSL
  is recent enough (> 16.0.0)

Options (= is mandatory):

- force
        Should the key be regenerated even it it already exists
        (Choices: True, False)[Default: False]
= path
        Name of the file in which the generated TLS/SSL public key will be written.

= privatekey_path
        Path to the TLS/SSL private key from which to genereate the public key.

- state
        Whether the public key should exist or not, taking action if the state is different from what is stated.
        (Choices: present, absent)[Default: present]
Requirements:  python-pyOpenSSL

EXAMPLES:
# Generate an OpenSSL public key.
- openssl_publickey:
    path: /etc/ssl/public/ansible.com.pem
    privatekey_path: /etc/ssl/private/ansible.com.pem

# Force regenerate an OpenSSL public key if it already exists
- openssl_publickey:
    path: /etc/ssl/public/ansible.com.pem
    privatekey_path: /etc/ssl/private/ansible.com.pem
    force: True

# Remove an OpenSSL public key
- openssl_publickey:
    path: /etc/ssl/public/ansible.com.pem
    privatekey_path: /etc/ssl/private/ansible.com.pem
    state: absent

RETURN VALUES:
privatekey:
    description: Path to the TLS/SSL private key the public key was generated from
    returned:
        - changed
        - success
    type: string
    sample: /etc/ssl/private/ansible.com.pem
filename:
    description: Path to the generated TLS/SSL public key file
    returned:
        - changed
        - success
    type: string
    sample: /etc/ssl/public/ansible.com.pem


MAINTAINERS: Yanis Guenane (@Spredzy)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPENVSWITCH_BRIDGE    (/usr/lib/python2.7/site-packages/ansible/modules/network/ovs/openvswitch_bridge.py)

  Manage Open vSwitch bridges

Options (= is mandatory):

= bridge
        Name of bridge or fake bridge to manage

- external_ids
        A dictionary of external-ids. Omitting this parameter is a No-op. To  clear all external-ids pass an empty value.
        [Default: None]
- fail_mode
        Set bridge fail-mode. The default value (None) is a No-op.
        (Choices: secure, standalone)[Default: None]
- parent
        Bridge parent of the fake bridge to manage
        [Default: None]
- set
        Set a single property on a bridge.
        [Default: None]
- state
        Whether the bridge should exist
        (Choices: present, absent)[Default: present]
- timeout
        How long to wait for ovs-vswitchd to respond
        [Default: 5]
- vlan
        The VLAN id of the fake bridge to manage (must be between 0 and 4095)
        [Default: None]
Requirements:  ovs-vsctl

EXAMPLES:
# Create a bridge named br-int
- openvswitch_bridge:
    bridge: br-int
    state: present

# Create a fake bridge named br-int within br-parent on the VLAN 405
- openvswitch_bridge:
    bridge: br-int
    parent: br-parent
    vlan: 405
    state: present

# Create an integration bridge
- openvswitch_bridge:
    bridge: br-int
    state: present
    fail_mode: secure
  args:
    external_ids:
      bridge-id: br-int


MAINTAINERS: David Stygstra (@stygstra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPENVSWITCH_DB    (/usr/lib/python2.7/site-packages/ansible/modules/network/ovs/openvswitch_db.py)

  Set column values in record in database table.

Options (= is mandatory):

= column
        Identifies the column in the record.

= key
        Identifies the key in the record column

= record
        Identifies the recoard in the table.

= table
        Identifies the table in the database.

- timeout
        How long to wait for ovs-vswitchd to respond
        [Default: 5]
= value
        Expected value for the table, record, column and key.

Requirements:  ovs-vsctl >= 2.3.3

EXAMPLES:
# Increase the maximum idle time to 50 seconds before pruning unused kernel
# rules.
- openvswitch_db:
    table: open_vswitch
    record: .
    col: other_config
    key: max-idle
    value: 50000

# Disable in band copy
- openvswitch_db:
    table: Bridge
    record: br-int
    col: other_config
    key: disable-in-band
    value: true


MAINTAINERS: Mark Hamilton (mhamilton@vmware.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPENVSWITCH_PORT    (/usr/lib/python2.7/site-packages/ansible/modules/network/ovs/openvswitch_port.py)

  Manage Open vSwitch ports

Options (= is mandatory):

= bridge
        Name of bridge to manage

- external_ids
        Dictionary of external_ids applied to a port.
        [Default: {}]
= port
        Name of port to manage on the bridge

- set
        Set a single property on a port.
        [Default: None]
- state
        Whether the port should exist
        (Choices: present, absent)[Default: present]
- tag
        VLAN tag for this port
        [Default: (null)]
- timeout
        How long to wait for ovs-vswitchd to respond
        [Default: 5]
Requirements:  ovs-vsctl

EXAMPLES:
# Creates port eth2 on bridge br-ex
- openvswitch_port:
    bridge: br-ex
    port: eth2
    state: present

# Creates port eth6
- openvswitch_port:
    bridge: bridge-loop
    port: eth6
    state: present
    set: Interface eth6

# Creates port vlan10 with tag 10 on bridge br-ex
- openvswitch_port:
    bridge: br-ex
    port: vlan10
    tag: 10
    state: present
    set: Interface vlan10

# Assign interface id server1-vifeth6 and mac address 00:00:5E:00:53:23
# to port vifeth6 and setup port to be managed by a controller.
- openvswitch_port:
    bridge: br-int
    port: vifeth6
    state: present
  args:
    external_ids:
      iface-id: '{{ inventory_hostname }}-vifeth6'
      attached-mac: '00:00:5E:00:53:23'
      vm-id: '{{ inventory_hostname }}'
      iface-status: active


MAINTAINERS: David Stygstra (@stygstra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPENWRT_INIT    (/usr/lib/python2.7/site-packages/ansible/modules/system/openwrt_init.py)

  Controls OpenWrt services on remote hosts.

Options (= is mandatory):

- enabled
        Whether the service should start on boot. *At least one of state and enabled are required.*
        (Choices: yes, no)[Default: None]
= name
        Name of the service.

- pattern
        If the service does not respond to the 'running' command, name a substring to look for as would be found in the
        output of the `ps' command as a stand-in for a 'running' result.  If the string is found, the service will be
        assumed to be running.
        [Default: (null)]
- state
        `started'/`stopped' are idempotent actions that will not run commands unless necessary. `restarted' will always
        bounce the service. `reloaded' will always reload.
        (Choices: started, stopped, restarted, reloaded)[Default: None]
Notes:
  * One option other than name is required.
Requirements:  An OpenWrt system

EXAMPLES:
# Example action to start service httpd, if not running
- openwrt_init:
    state: started
    name: httpd

# Example action to stop service cron, if running
- openwrt_init:
    name: cron
    state: stopped

# Example action to reload service httpd, in all cases
- openwrt_init:
    name: httpd
    state: reloaded

# Example action to enable service httpd
- openwrt_init:
    name: httpd
    enabled: yes

RETURN VALUES:


MAINTAINERS: Andrew Gaffney (@agaffney)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPKG    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/opkg.py)

  Manages OpenWrt packages

Options (= is mandatory):

- force
        opkg --force parameter used
        (Choices: , depends, maintainer, reinstall, overwrite, downgrade, space, postinstall, remove, checksum, removal-
        of-dependent-packages)[Default: absent]
= name
        name of package to install/remove

- state
        state of the package
        (Choices: present, absent)[Default: present]
- update_cache
        update the package db first
        (Choices: yes, no)[Default: no]
EXAMPLES:
- opkg:
    name: foo
    state: present

- opkg:
    name: foo
    state: present
    update_cache: yes

- opkg:
    name: foo
    state: absent

- opkg:
    name: foo,bar
    state: absent

- opkg:
    name: foo
    state: present
    force: overwrite


MAINTAINERS: Patrick Pelletier (@skinp)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPS_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/openswitch/ops_command.py)

  Sends arbitrary commands to an OpenSwitch node and returns the results read from the device. This module includes an
  argument that will cause the module to wait for a specific condition before returning or timing out if the condition is
  not met.

Options (= is mandatory):

= commands
        List of commands to send to the remote ops device over the configured provider. The resulting output from the
        command is returned. If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of retires as expired.

= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.  Note this argument does not affect the SSH
        argument.

- interval
        Configures the interval in seconds to wait between `retries' of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the `wait_for' must be
        satisfied.  If the value is set to `any' then only one of the values must be satisfied.
        (Choices: any, all)[Default: all]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `rest' transports.  Note this argument does not affect the SSH transport. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `rest'.  The port value will default to the appropriate transport common port if none is provided in the task.
        (cli=22, http=80, https=443).  Note this argument does not affect the SSH transport.
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `openswitch' arguments to be passed as a dict object.  All constraints
        (required, choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- retries
        Specifies the number of retries a command should by tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditions.
        [Default: 10]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transports. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error.
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over ssh, cli or REST.
        (Choices: ssh, cli, rest)[Default: ssh]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport' argument is configured as rest.
        If the transport argument is not `rest', this value is ignored.
        (Choices: yes, no)[Default: True]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the eAPI authentication depending on which transport is used. Note this
        argument does not affect the SSH transport. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
- wait_for
        List of conditions to evaluate against the output of the command. The task will wait for each condition to be
        true before moving forward. If the conditional is not true within the configured number of retries, the task
        fails. See examples.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: netop
    password: netop
    transport: cli

---
- ops_command:
    commands:
      - show version
    provider: "{{ cli }}"

- ops_command:
    commands:
      - show version
    wait_for:
      - "result[0] contains OpenSwitch"
    provider: "{{ cli }}"

- ops_command:
    commands:
      - show version
      - show interfaces
    provider: "{{ cli }}"

RETURN VALUES:
stdout:
  description: the set of responses from the commands
  returned: always
  type: list
  sample: ['...', '...']

stdout_lines:
  description: The value of stdout split into a list
  returned: always
  type: list
  sample: [['...', '...'], ['...'], ['...']]

failed_conditions:
  description: the conditionals that failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/openswitch/ops_config.py)

  OpenSwitch configurations use a simple block indent file syntax for segmenting configuration into sections.  This
  module provides an implementation for working with ops configuration sections in a deterministic way.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuration to use as the base config for comparison.
        [Default: None]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        Note this argument should be considered deprecated.  To achieve the equivalent, set the `match=none' which is
        idempotent.  This argument will be removed in a future release.
        (Choices: yes, no)[Default: False]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.  Note this argument does not affect the SSH
        argument.

- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  If match is set to `exact', command lines must be an equal match.  Finally, if
        match is set to `none', the module will not attempt to compare the source configuration with the running
        configuration on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If the
        parents argument is omitted, the commands are checked against the set of top level or global commands.
        [Default: None]
- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `rest' transports.  Note this argument does not affect the SSH transport. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `rest'.  The port value will default to the appropriate transport common port if none is provided in the task.
        (cli=22, http=80, https=443).  Note this argument does not affect the SSH transport.
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `openswitch' arguments to be passed as a dict object.  All constraints
        (required, choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct.
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running- config to the startup-config at the conclusion of
        the module running.  If check mode is specified, this argument is ignored.
        (Choices: yes, no)[Default: False]
- src
        The `src' argument provides a path to the configuration file to load into the remote system.  The path can either
        be a full system path to the configuration file if the value starts with / or relative to the root of the
        implemented role or playbook. This argument is mutually exclusive with the `lines' and `parents' arguments.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transports. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error.
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over ssh, cli or REST.
        (Choices: ssh, cli, rest)[Default: ssh]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport' argument is configured as rest.
        If the transport argument is not `rest', this value is ignored.
        (Choices: yes, no)[Default: True]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the eAPI authentication depending on which transport is used. Note this
        argument does not affect the SSH transport. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: netop
    password: netop

---
- name: configure hostname over cli
  ops_config:
    lines:
      - "hostname {{ inventory_hostname }}"
    provider: "{{ cli }}"


- name: configure vlan 10 over cli
  ops_config:
    lines:
      - no shutdown
    parents:
      - vlan 10
    provider: "{{ cli }}"

- name: load config from file
  ops_config:
    src: ops01.cfg
    backup: yes
    provider: "{{ cli }}"

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['...', '...']
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/ops_config.2016-07-16@22:28:34


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/openswitch/ops_facts.py)

  Collects facts from devices running the OpenSwitch operating system.  Fact collection is supported over both Cli and
  Rest transports.  This module prepends all of the base network fact keys with `ansible_net_<fact>'.  The facts module
  will always collect a base set of facts from the device and can enable or disable collection of additional facts. The
  facts collected from pre Ansible 2.2 are still available and are collected for backwards compatibility; however, these
  facts should be considered deprecated and will be removed in a future release.

Options (= is mandatory):

- config
        When enabled, this argument will collect the current running configuration from the remote device.  If the
        `transport=rest' then the collected configuration will be the full system configuration.
        (Choices: True, False)[Default: False]
- endpoints
        Accepts a list of endpoints to retrieve from the remote device using the REST API.  The endpoints should be valid
        endpoints available on the device.  This argument is only valid when the `transport=rest'.
        [Default: None]
- gather_subset
        When supplied, this argument will restrict the facts collected to a given subset.  Possible values for this
        argument include all, hardware, config, legacy, and interfaces.  Can specify a list of values to include a larger
        subset.  Values can also be used with an initial `[!]' to specify that a specific subset should not be collected.
        [Default: !config]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.  Note this argument does not affect the SSH
        argument.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `rest' transports.  Note this argument does not affect the SSH transport. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `rest'.  The port value will default to the appropriate transport common port if none is provided in the task.
        (cli=22, http=80, https=443).  Note this argument does not affect the SSH transport.
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `openswitch' arguments to be passed as a dict object.  All constraints
        (required, choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transports. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error.
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over ssh, cli or REST.
        (Choices: ssh, cli, rest)[Default: ssh]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport' argument is configured as rest.
        If the transport argument is not `rest', this value is ignored.
        (Choices: yes, no)[Default: True]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the eAPI authentication depending on which transport is used. Note this
        argument does not affect the SSH transport. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: netop
    password: netop
    transport: cli
  rest:
    host: "{{ inventory_hostname }}"
    username: netop
    password: netop
    transport: rest

---
- ops_facts:
    gather_subset: all
    provider: "{{ rest }}"

# Collect only the config and default facts
- ops_facts:
    gather_subset: config
    provider: "{{ cli }}"

# Do not collect config facts
- ops_facts:
    gather_subset:
      - "!config"
    provider: "{{ cli }}"

- name: collect device facts
  ops_facts:
    provider: "{{ cli }}"

- name: include the config
  ops_facts:
    config: yes
    provider: "{{ rest }}"

- name: include a set of rest endpoints
  ops_facts:
    endpoints:
      - /system/interfaces/1
      - /system/interfaces/2
    provider: "{{ rest }}"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the device
  returned: always
  type: list

# default
ansible_net_model:
  description: The model name returned from the device
  returned: when transport is cli
  type: str
ansible_net_serialnum:
  description: The serial number of the remote device
  returned: when transport is cli
  type: str
ansible_net_version:
  description: The operating system version running on the remote device
  returned: always
  type: str
ansible_net_hostname:
  description: The configured hostname of the device
  returned: always
  type: string
ansible_net_image:
  description: The image file the device is running
  returned: when transport is cli
  type: string

# config
ansible_net_config:
  description: The current active config from the device
  returned: when config is enabled
  type: str

# legacy (pre Ansible 2.2)
config:
  description: The current system configuration
  returned: when enabled
  type: string
  sample: '....'
hostname:
  description: returns the configured hostname
  returned: always
  type: string
  sample: ops01
version:
  description: The current version of OpenSwitch
  returned: always
  type: string
  sample: '0.3.0'
endpoints:
  description: The JSON response from the URL endpoint
  returned: when endpoints argument is defined and transport is rest
  type: list
  sample: [{....}, {....}]


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> OPS_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/network/openswitch/_ops_template.py)

  The OpenSwitch platform provides a library for pushing JSON structured configuration files into the current running-
  config.  This module will read the current configuration from OpenSwitch and compare it against a provided candidate
  configuration. If there are changes, the candidate configuration is merged with the current configuration and pushed
  into OpenSwitch

DEPRECATED: 
Deprecated in 2.2. Use M(ops_config) instead.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- backup
        When this argument is configured true, the module will backup the running-config from the node prior to making
        any changes. The backup file will be written to backups/ in the root of the playbook directory.
        (Choices: yes, no)[Default: False]
- config
        The module, by default, will connect to the remote device and retrieve the current running-config to use as a
        base for comparing against the contents of source.  There are times when it is not desirable to have the task get
        the current running-config for every task in a playbook.  The `config' argument allows the implementer to pass in
        the configuration to use as the base config for comparison.
        [Default: None]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        (Choices: yes, no)[Default: False]
= host
        Specifies the DNS host name or address for connecting to the remote device over the specified transport.  The
        value of host is used as the destination address for the transport.  Note this argument does not affect the SSH
        argument.

- password
        Specifies the password to use to authenticate the connection to the remote device.  This is a common argument
        used for either `cli' or `rest' transports.  Note this argument does not affect the SSH transport. If the value
        is not specified in the task, the value of environment variable `ANSIBLE_NET_PASSWORD' will be used instead.
        [Default: None]
- port
        Specifies the port to use when building the connection to the remote device.  This value applies to either `cli'
        or `rest'.  The port value will default to the appropriate transport common port if none is provided in the task.
        (cli=22, http=80, https=443).  Note this argument does not affect the SSH transport.
        [Default: 0 (use common port)]
- provider
        Convenience method that allows all `openswitch' arguments to be passed as a dict object.  All constraints
        (required, choices, etc) must be met either by individual arguments or values in this dict.
        [Default: None]
= src
        The path to the config source.  The source can be either a file with config or a template that will be merged
        during runtime.  By default the task will search for the source file in role or playbook root folder in templates
        directory.

- ssh_keyfile
        Specifies the SSH key to use to authenticate the connection to the remote device.  This argument is only used for
        the `cli' transports. If the value is not specified in the task, the value of environment variable
        `ANSIBLE_NET_SSH_KEYFILE' will be used instead.
        [Default: (null)]
- timeout
        Specifies the timeout in seconds for communicating with the network device for either connecting or sending
        commands.  If the timeout is exceeded before the operation is completed, the module will error.
        [Default: 10]
= transport
        Configures the transport connection to use when connecting to the remote device.  The transport argument supports
        connectivity to the device over ssh, cli or REST.
        (Choices: ssh, cli, rest)[Default: ssh]
- use_ssl
        Configures the `transport' to use SSL if set to true only when the `transport' argument is configured as rest.
        If the transport argument is not `rest', this value is ignored.
        (Choices: yes, no)[Default: True]
- username
        Configures the username to use to authenticate the connection to the remote device.  This value is used to
        authenticate either the CLI login or the eAPI authentication depending on which transport is used. Note this
        argument does not affect the SSH transport. If the value is not specified in the task, the value of environment
        variable `ANSIBLE_NET_USERNAME' will be used instead.
        [Default: (null)]
EXAMPLES:
- name: set hostname with file lookup
  ops_template:
    src: ./hostname.json
    backup: yes
    remote_user: admin
    become: yes

- name: set hostname with var
  ops_template:
    src: "{{ config }}"
    remote_user: admin
    become: yes

RETURN VALUES:
updates:
  description: The list of configuration updates to be merged
  returned: always
  type: dict
  sample: {obj, obj}
responses:
  description: returns the responses when configuring using cli
  returned: when transport == cli
  type: list
  sample: [...]


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> ORDNANCE_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/ordnance/ordnance_config.py)

  Ordnance router configurations use a simple block indent file syntax for segmenting configuration into sections.  This
  module provides an implementation for working with these configuration sections in a deterministic way.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- backup
        This argument will cause the module to create a full backup of the current `running-config' from the remote
        device before any changes are made.  The backup file is written to the `backup' folder in the playbook root
        directory.  If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- commands
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.
        [Default: None]
- config
        The `config' argument allows the playbook designer to supply the base configuration to be used to validate
        configuration changes necessary.  If this argument is provided, the module will not download the running-config
        from the remote node.
        [Default: None]
- defaults
        This argument specifies whether or not to collect all defaults when getting the remote device running config.
        When enabled, the module will get the current config by issuing the command `show running-config all'.
        (Choices: yes, no)[Default: False]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  If match is set to `exact', command lines must be an equal match.  Finally, if
        match is set to `none', the module will not attempt to compare the source configuration with the running
        configuration on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- multiline_delimiter
        This arugment is used when pushing a multiline configuration element to the Ordnance router.  It specifies the
        character to use as the delimiting character.  This only applies to the configuration action
        [Default: @]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If the
        parents argument is omitted, the commands are checked against the set of top level or global commands.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct.
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running- config to the startup-config at the conclusion of
        the module running.  If check mode is specified, this argument is ignored.
        (Choices: yes, no)[Default: False]
- src
        Specifies the source path to the file that contains the configuration or configuration template to load.  The
        path to the source file can either be the full path on the Ansible control host or a relative path from the
        playbook or role root directory.  This argument is mutually exclusive with `lines'.
        [Default: None]
EXAMPLES:
---
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: RouterName
    password: password
    transport: cli

---
- name: configure top level configuration
  ordnance_config:
    lines: hostname {{ inventory_hostname }}
    provider: "{{ cli }}"

- name: configure interface settings
  ordnance_config:
    lines:
      - description test interface
      - ip address 172.31.1.1 255.255.255.0
    parents: interface Ethernet1
    provider: "{{ cli }}"

- name: configure bgp router
  ordnance_config:
    lines:
      - neighbor 1.1.1.1 remote-as 1234
      - network 10.0.0.0/24
    parents: router bgp 65001
    provider: "{{ cli }}"


RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: Only when commands is specified.
  type: list
  sample: ['...', '...']
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/ordnance_config.2016-07-16@22:28:34


MAINTAINERS: Alexander Turner (alex.turner@ordnance.io)

METADATA:
	Status: ['preview']
	Supported_by: community
> ORDNANCE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/ordnance/ordnance_facts.py)

  Collects a base set of device facts from an Ordnance Virtual router over SSH. This module prepends all of the base
  network fact keys with `ansible_net_<fact>'.  The facts module will always collect a base set of facts from the device
  and can enable or disable collection of additional facts.

Options (= is mandatory):

- gather_subset
        When supplied, this argument will restrict the facts collected to a given subset.  Possible values for this
        argument include all, hardware, config, and interfaces.  Can specify a list of values to include a larger subset.
        Values can also be used with an initial `[!]' to specify that a specific subset should not be collected.
        [Default: !config]
EXAMPLES:
---
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: RouterName
    password: ordnance
    transport: cli

---
# Collect all facts from the device
- ordnance_facts:
    gather_subset: all
    provider: "{{ cli }}"

# Collect only the config and default facts
- ordnance_facts:
    gather_subset:
      - config
    provider: "{{ cli }}"

# Do not collect hardware facts
- ordnance_facts:
    gather_subset:
      - "!hardware"
    provider: "{{ cli }}"

RETURN VALUES:
ansible_net_gather_subset:
  description: The list of fact subsets collected from the virtual router
  returned: always
  type: list

# config
ansible_net_config:
  description: The current active config from the virtual router
  returned: when config is configured
  type: str

# interfaces
ansible_net_all_ipv4_addresses:
  description: All IPv4 addresses configured on the virtual router
  returned: when interfaces is configured
  type: list
ansible_net_all_ipv6_addresses:
  description: All IPv6 addresses configured on the virtual router
  returned: when interfaces is configured
  type: list
ansible_net_interfaces:
  description: A hash of all interfaces running on the virtual router
  returned: when interfaces is configured
  type: dict


MAINTAINERS: Alexander Turner (alex.turner@ordnance.io)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_AUTH    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_auth.py)

  Retrieve an auth token from an OpenStack Cloud

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
- name: Authenticate to the cloud and retrieve the service catalog
  os_auth:
    cloud: rax-dfw

- name: Show service catalog
  debug:
    var: service_catalog


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_CLIENT_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_client_config.py)

  Get `openstack' client config data from clouds.yaml or environment

Options (= is mandatory):

- clouds
        List of clouds to limit the return list to. No value means return information on all configured clouds
        [Default: []]
Notes:
  * Facts are placed in the `openstack.clouds' variable.
Requirements:  os-client-config

EXAMPLES:
- name: Get list of clouds that do not support security groups
  os_client_config:

- debug:
    var: "{{ item }}"
  with_items: "{{ openstack.clouds | rejectattr('secgroup_source', 'none') | list }}"

- name: Get the information back just about the mordred cloud
  os_client_config:
    clouds:
      - mordred


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_FLAVOR_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_flavor_facts.py)

  Retrieve facts about available OpenStack instance flavors. By default, facts about ALL flavors are retrieved. Filters
  can be applied to get facts for only matching flavors. For example, you can filter on the amount of RAM available to
  the flavor, or the number of virtual CPUs available to the flavor, or both. When specifying multiple filters, *ALL*
  filters must match on a flavor before that flavor is returned as a fact.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- ephemeral
        A string used for filtering flavors based on the amount of ephemeral storage. Format is the same as the `ram'
        parameter
        [Default: False]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- limit
        Limits the number of flavors returned. All matching flavors are returned by default.
        [Default: None]
- name
        A flavor name. Cannot be used with `ram' or `vcpus' or `ephemeral'.
        [Default: None]
- ram
        A string used for filtering flavors based on the amount of RAM (in MB) desired. This string accepts the following
        special values: 'MIN' (return flavors with the minimum amount of RAM), and 'MAX' (return flavors with the maximum
        amount of RAM).
        A specific amount of RAM may also be specified. Any flavors with this exact amount of RAM will be returned.
        A range of acceptable RAM may be given using a special syntax. Simply prefix the amount of RAM with one of these
        acceptable range values: '<', '>', '<=', '>='. These values represent less than, greater than, less than or equal
        to, and greater than or equal to, respectively.
        [Default: False]
- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- vcpus
        A string used for filtering flavors based on the number of virtual CPUs desired. Format is the same as the `ram'
        parameter.
        [Default: False]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * This module creates a new top-level `openstack_flavors' fact, which contains a list of unsorted flavors.
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Gather facts about all available flavors
- os_flavor_facts:
    cloud: mycloud

# Gather facts for the flavor named "xlarge-flavor"
- os_flavor_facts:
    cloud: mycloud
    name: "xlarge-flavor"

# Get all flavors that have exactly 512 MB of RAM.
- os_flavor_facts:
    cloud: mycloud
    ram: "512"

# Get all flavors that have 1024 MB or more of RAM.
- os_flavor_facts:
    cloud: mycloud
    ram: ">=1024"

# Get a single flavor that has the minimum amount of RAM. Using the 'limit'
# option will guarantee only a single flavor is returned.
- os_flavor_facts:
    cloud: mycloud
    ram: "MIN"
    limit: 1

# Get all flavors with 1024 MB of RAM or more, AND exactly 2 virtual CPUs.
- os_flavor_facts:
    cloud: mycloud
    ram: ">=1024"
    vcpus: "2"

# Get all flavors with 1024 MB of RAM or more, exactly 2 virtual CPUs, and
# less than 30gb of ephemeral storage.
- os_flavor_facts:
    cloud: mycloud
    ram: ">=1024"
    vcpus: "2"
    ephemeral: "<30"

RETURN VALUES:
openstack_flavors:
    description: Dictionary describing the flavors.
    returned: On success.
    type: dictionary
    contains:
        id:
            description: Flavor ID.
            returned: success
            type: string
            sample: "515256b8-7027-4d73-aa54-4e30a4a4a339"
        name:
            description: Flavor name.
            returned: success
            type: string
            sample: "tiny"
        disk:
            description: Size of local disk, in GB.
            returned: success
            type: int
            sample: 10
        ephemeral:
            description: Ephemeral space size, in GB.
            returned: success
            type: int
            sample: 10
        ram:
            description: Amount of memory, in MB.
            returned: success
            type: int
            sample: 1024
        swap:
            description: Swap space size, in MB.
            returned: success
            type: int
            sample: 100
        vcpus:
            description: Number of virtual CPUs.
            returned: success
            type: int
            sample: 2
        is_public:
            description: Make flavor accessible to the public.
            returned: success
            type: bool
            sample: true


MAINTAINERS: David Shrewsbury (@Shrews)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_FLOATING_IP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_floating_ip.py)

  Add or Remove a floating IP to an instance

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- fixed_address
        To which fixed IP of server the floating IP address should be attached to.
        [Default: (null)]
- floating_ip_address
        A floating IP address to attach or to detach. Required only if `state' is absent. When `state' is present can be
        used to specify a IP address to attach.
        [Default: (null)]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- nat_destination
        The name or id of a neutron private network that the fixed IP to attach floating IP is on
        [Default: None]
- network
        The name or ID of a neutron external network or a nova pool name.
        [Default: (null)]
- purge
        When `state' is absent, indicates whether or not to delete the floating IP completely, or only detach it from the
        server. Default is to detach only.
        [Default: False]
- region_name
        Name of the region.
        [Default: (null)]
- reuse
        When `state' is present, and `floating_ip_address' is not present, this parameter can be used to specify whether
        we should try to reuse a floating IP address already allocated to the project.
        [Default: False]
= server
        The name or ID of the instance to which the IP address should be assigned.

- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Assign a floating IP to the fist interface of `cattle001` from an exiting
# external network or nova pool. A new floating IP from the first available
# external network is allocated to the project.
- os_floating_ip:
     cloud: dguerri
     server: cattle001

# Assign a new floating IP to the instance fixed ip `192.0.2.3` of
# `cattle001`. If a free floating IP is already allocated to the project, it is
# reused; if not, a new one is created.
- os_floating_ip:
     cloud: dguerri
     state: present
     reuse: yes
     server: cattle001
     network: ext_net
     fixed_address: 192.0.2.3
     wait: true
     timeout: 180

# Assign a new floating IP from the network `ext_net` to the instance fixed
# ip in network `private_net` of `cattle001`.
- os_floating_ip:
     cloud: dguerri
     state: present
     server: cattle001
     network: ext_net
     nat_destination: private_net
     wait: true
     timeout: 180

# Detach a floating IP address from a server
- os_floating_ip:
     cloud: dguerri
     state: absent
     floating_ip_address: 203.0.113.2
     server: cattle001


MAINTAINERS: Davide Guerri <davide.guerri@hp.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_group.py)

  Manage OpenStack Identity Groups. Groups can be created, deleted or updated. Only the `description' value can be
  updated.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- description
        Group description
        [Default: None]
- domain_id
        Domain id to create the group in if the cloud supports domains.
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Group name

- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a group named "demo"
- os_group:
    cloud: mycloud
    state: present
    name: demo
    description: "Demo Group"
    domain_id: demoid

# Update the description on existing "demo" group
- os_group:
    cloud: mycloud
    state: present
    name: demo
    description: "Something else"
    domain_id: demoid

# Delete group named "demo"
- os_group:
    cloud: mycloud
    state: absent
    name: demo

RETURN VALUES:
group:
    description: Dictionary describing the group.
    returned: On success when I(state) is 'present'.
    type: dictionary
    contains:
        id:
            description: Unique group ID
            type: string
            sample: "ee6156ff04c645f481a6738311aea0b0"
        name:
            description: Group name
            type: string
            sample: "demo"
        description:
            description: Group description
            type: string
            sample: "Demo Group"
        domain_id:
            description: Domain for the group
            type: string
            sample: "default"


MAINTAINERS: Monty Taylor (@emonty), David Shrewsbury (@Shrews)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_IMAGE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_image.py)

  Add or Remove images from the OpenStack Image Repository

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- container_format
        The format of the container
        [Default: bare]
- disk_format
        The format of the disk that is getting uploaded
        [Default: qcow2]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- filename
        The path to the file which has to be uploaded
        [Default: None]
- is_public
        Whether the image can be accessed publicly. Note that publicizing an image requires admin role by default.
        [Default: yes]
- kernel
        The name of an existing kernel image that will be associated with this image
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- min_disk
        The minimum disk space (in GB) required to boot this image
        [Default: None]
- min_ram
        The minimum ram (in MB) required to boot this image
        [Default: None]
= name
        Name that has to be given to the image
        [Default: None]
- owner
        The owner of the image
        [Default: None]
- properties
        Additional properties to be associated with this image
        [Default: {}]
- ramdisk
        The name of an existing ramdisk image that will be associated with this image
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Upload an image from a local file named cirros-0.3.0-x86_64-disk.img
- os_image:
    auth:
      auth_url: http://localhost/auth/v2.0
      username: admin
      password: passme
      project_name: admin
    name: cirros
    container_format: bare
    disk_format: qcow2
    state: present
    filename: cirros-0.3.0-x86_64-disk.img
    kernel: cirros-vmlinuz
    ramdisk: cirros-initrd
    properties:
      cpu_arch: x86_64
      distro: ubuntu


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_IMAGE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_image_facts.py)

  Retrieve facts about a image image from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
= image
        Name or ID of the image

- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * Facts are placed in the `openstack' variable.
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
- name: Gather facts about a previously created image named image1
  os_image_facts:
    auth:
      auth_url: https://your_api_url.com:9000/v2.0
      username: user
      password: password
      project_name: someproject
    image: image1

- name: Show openstack facts
  debug:
    var: openstack

RETURN VALUES:
openstack_image:
    description: has all the openstack facts about the image
    returned: always, but can be null
    type: complex
    contains:
        id:
            description: Unique UUID.
            returned: success
            type: string
        name:
            description: Name given to the image.
            returned: success
            type: string
        status:
            description: Image status.
            returned: success
            type: string
        created_at:
            description: Image created at timestamp.
            returned: success
            type: string
        deleted:
            description: Image deleted flag.
            returned: success
            type: boolean
        container_format:
            description: Container format of the image.
            returned: success
            type: string
        min_ram:
            description: Min amount of RAM required for this image.
            returned: success
            type: int
        disk_format:
            description: Disk format of the image.
            returned: success
            type: string
        updated_at:
            description: Image updated at timestamp.
            returned: success
            type: string
        properties:
            description: Additional properties associated with the image.
            returned: success
            type: dict
        min_disk:
            description: Min amount of disk space required for this image.
            returned: success
            type: int
        protected:
            description: Image protected flag.
            returned: success
            type: boolean
        checksum:
            description: Checksum for the image.
            returned: success
            type: string
        owner:
            description: Owner for the image.
            returned: success
            type: string
        is_public:
            description: Is public flag of the image.
            returned: success
            type: boolean
        deleted_at:
            description: Image deleted at timestamp.
            returned: success
            type: string
        size:
            description: Size of the image.
            returned: success
            type: int


MAINTAINERS: Davide Agnello (@dagnello)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_IRONIC    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_ironic.py)

  Create or Remove Ironic nodes from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- chassis_uuid
        Associate the node with a pre-defined chassis.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
= driver
        The name of the Ironic Driver to use with this node.
        [Default: None]
- driver_info
        Information for this server's driver. Will vary based on which driver is in use. Any sub-field which is populated
        will be validated during creation.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- ironic_url
        If noauth mode is utilized, this is required to be set to the endpoint URL for the Ironic API.  Use with "auth"
        and "auth_type" settings set to None.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- name
        unique name identifier to be given to the resource.
        [Default: None]
= nics
        A list of network interface cards, eg, " - mac: aa:bb:cc:aa:bb:cc"

- properties
        Definition of the physical characteristics of this server, used for scheduling purposes
        [Default: (null)]
- region_name
        Name of the region.
        [Default: (null)]
- skip_update_of_driver_password
        Allows the code that would assert changes to nodes to skip the update if the change is a single line consisting
        of the password field.  As of Kilo, by default, passwords are always masked to API requests, which means the
        logic as a result always attempts to re-assert the password field.
        [Default: False]
- state
        Indicates desired state of the resource
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- uuid
        globally unique identifier (UUID) to be given to the resource. Will be auto-generated if not specified, and name
        is specified.
        Definition of a UUID will always take precedence to a name value.
        [Default: None]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  jsonpatch, python >= 2.7, shade

EXAMPLES:
# Enroll a node with some basic properties and driver info
- os_ironic:
    cloud: "devstack"
    driver: "pxe_ipmitool"
    uuid: "00000000-0000-0000-0000-000000000002"
    properties:
      cpus: 2
      cpu_arch: "x86_64"
      ram: 8192
      disk_size: 64
    nics:
      - mac: "aa:bb:cc:aa:bb:cc"
      - mac: "dd:ee:ff:dd:ee:ff"
    driver_info:
      power:
        ipmi_address: "1.2.3.4"
        ipmi_username: "admin"
        ipmi_password: "adminpass"
    chassis_uuid: "00000000-0000-0000-0000-000000000001"



MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_IRONIC_INSPECT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_ironic_inspect.py)

  Requests Ironic to set a node into inspect state in order to collect metadata regarding the node. This command may be
  out of band or in-band depending on the ironic driver configuration. This is only possible on nodes in 'manageable' and
  'available' state.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- ironic_url
        If noauth mode is utilized, this is required to be set to the endpoint URL for the Ironic API. Use with "auth"
        and "auth_type" settings set to None.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- mac
        unique mac address that is used to attempt to identify the host.
        [Default: None]
- name
        unique name identifier to identify the host in Ironic.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- uuid
        globally unique identifier (UUID) to identify the host.
        [Default: None]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Invoke node inspection
- os_ironic_inspect:
    name: "testnode1"

RETURN VALUES:
ansible_facts:
    description: Dictionary of new facts representing discovered properties of the node..
    returned: changed
    type: dictionary
    contains:
        memory_mb:
            description: Amount of node memory as updated in the node properties
            type: string
            sample: "1024"
        cpu_arch:
            description: Detected CPU architecture type
            type: string
            sample: "x86_64"
        local_gb:
            description: Total size of local disk storage as updaed in node properties.
            type: string
            sample: "10"
        cpus:
            description: Count of cpu cores defined in the updated node properties.
            type: string
            sample: "1"


MAINTAINERS: Julia Kreger (@juliakreger)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_IRONIC_NODE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_ironic_node.py)

  Deploy to nodes controlled by Ironic.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- config_drive
        A configdrive file or HTTP(S) URL that will be passed along to the node.
        [Default: None]
- deploy
        Indicates if the resource should be deployed. Allows for deployment logic to be disengaged and control of the
        node power or maintenance state to be changed.
        (Choices: true, false)[Default: True]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- instance_info
        Definition of the instance information which is used to deploy the node.  This information is only required when
        an instance is set to present.
        [Default: (null)]
- ironic_url
        If noauth mode is utilized, this is required to be set to the endpoint URL for the Ironic API.  Use with "auth"
        and "auth_type" settings set to None.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- maintenance
        A setting to allow the direct control if a node is in maintenance mode.
        [Default: False]
- maintenance_reason
        A string expression regarding the reason a node is in a maintenance mode.
        [Default: None]
- power
        A setting to allow power state to be asserted allowing nodes that are not yet deployed to be powered on, and
        nodes that are deployed to be powered off.
        (Choices: present, absent)[Default: present]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Indicates desired state of the resource
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- uuid
        globally unique identifier (UUID) to be given to the resource.
        [Default: None]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Activate a node by booting an image with a configdrive attached
os_ironic_node:
  cloud: "openstack"
  uuid: "d44666e1-35b3-4f6b-acb0-88ab7052da69"
  state: present
  power: present
  deploy: True
  maintenance: False
  config_drive: "http://192.168.1.1/host-configdrive.iso"
  instance_info:
    image_source: "http://192.168.1.1/deploy_image.img"
    image_checksum: "356a6b55ecc511a20c33c946c4e678af"
    image_disk_format: "qcow"
  delegate_to: localhost


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_KEYPAIR    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_keypair.py)

  Add or Remove key pair from OpenStack

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name that has to be given to the key pair
        [Default: None]
- public_key
        The public key that would be uploaded to nova and injected into VMs upon creation.
        [Default: None]
- public_key_file
        Path to local file containing ssh public key. Mutually exclusive with public_key.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Creates a key pair with the running users public key
- os_keypair:
      cloud: mordred
      state: present
      name: ansible_key
      public_key_file: /home/me/.ssh/id_rsa.pub

# Creates a new key pair and the private key returned after the run.
- os_keypair:
      cloud: rax-dfw
      state: present
      name: ansible_key

RETURN VALUES:
id:
    description: Unique UUID.
    returned: success
    type: string
name:
    description: Name given to the keypair.
    returned: success
    type: string
public_key:
    description: The public key value for the keypair.
    returned: success
    type: string
private_key:
    description: The private key value for the keypair.
    returned: Only when a keypair is generated for the user (e.g., when creating one
              and a public key is not specified).
    type: string


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_KEYSTONE_DOMAIN    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_keystone_domain.py)

  Create, update, or delete OpenStack Identity domains. If a domain with the supplied name already exists, it will be
  updated with the new description and enabled attributes.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- description
        Description of the domain
        [Default: None]
- enabled
        Is the domain enabled
        [Default: True]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name that has to be given to the instance

- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a domain
- os_keystone_domain:
     cloud: mycloud
     state: present
     name: demo
     description: Demo Domain

# Delete a domain
- os_keystone_domain:
     cloud: mycloud
     state: absent
     name: demo

RETURN VALUES:
domain:
    description: Dictionary describing the domain.
    returned: On success when I(state) is 'present'
    type: dictionary
    contains:
        id:
            description: Domain ID.
            type: string
            sample: "474acfe5-be34-494c-b339-50f06aa143e4"
        name:
            description: Domain name.
            type: string
            sample: "demo"
        description:
            description: Domain description.
            type: string
            sample: "Demo Domain"
        enabled:
            description: Domain description.
            type: boolean
            sample: True

id:
    description: The domain ID.
    returned: On success when I(state) is 'present'
    type: string
    sample: "474acfe5-be34-494c-b339-50f06aa143e4"


MAINTAINERS: Haneef Ali, Monty

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_KEYSTONE_DOMAIN_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_keystone_domain_facts.py)

  Retrieve facts about a one or more OpenStack domains

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- filters
        A dictionary of meta data to use for further filtering.  Elements of this dictionary may be additional
        dictionaries.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name or ID of the domain

- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Gather facts about previously created domain
- os_keystone_domain_facts:
    cloud: awesomecloud
- debug:
    var: openstack_domains

# Gather facts about a previously created domain by name
- os_keystone_domain_facts:
    cloud: awesomecloud
    name: demodomain
- debug:
    var: openstack_domains

# Gather facts about a previously created domain with filter
- os_keystone_domain_facts:
    cloud: awesomecloud
    name: demodomain
    filters:
      enabled: False
- debug:
    var: openstack_domains

RETURN VALUES:
openstack_domains:
    description: has all the OpenStack facts about domains
    returned: always, but can be null
    type: complex
    contains:
        id:
            description: Unique UUID.
            returned: success
            type: string
        name:
            description: Name given to the domain.
            returned: success
            type: string
        description:
            description: Description of the domain.
            returned: success
            type: string
        enabled:
            description: Flag to indicate if the domain is enabled.
            returned: success
            type: bool


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_KEYSTONE_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_keystone_role.py)

  Manage OpenStack Identity Roles.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Role Name

- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a role named "demo"
- os_keystone_role:
    cloud: mycloud
    state: present
    name: demo

# Delete the role named "demo"
- os_keystone_role:
    cloud: mycloud
    state: absent
    name: demo

RETURN VALUES:
role:
    description: Dictionary describing the role.
    returned: On success when I(state) is 'present'.
    type: dictionary
    contains:
        id:
            description: Unique role ID.
            type: string
            sample: "677bfab34c844a01b88a217aa12ec4c2"
        name:
            description: Role name.
            type: string
            sample: "demo"


MAINTAINERS: Monty Taylor (@emonty), David Shrewsbury (@Shrews)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_KEYSTONE_SERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_keystone_service.py)

  Create, update, or delete OpenStack Identity service. If a service with the supplied name already exists, it will be
  updated with the new description and enabled attributes.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- description
        Description of the service
        [Default: None]
- enabled
        Is the service enabled
        [Default: True]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name of the service

- region_name
        Name of the region.
        [Default: (null)]
= service_type
        The type of service

- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a service for glance
- os_keystone_service:
     cloud: mycloud
     state: present
     name: glance
     service_type: image
     description: OpenStack Image Service
# Delete a service
- os_keystone_service:
     cloud: mycloud
     state: absent
     name: glance
     service_type: image

RETURN VALUES:
service:
    description: Dictionary describing the service.
    returned: On success when I(state) is 'present'
    type: dictionary
    contains:
        id:
            description: Service ID.
            type: string
            sample: "3292f020780b4d5baf27ff7e1d224c44"
        name:
            description: Service name.
            type: string
            sample: "glance"
        service_type:
            description: Service type.
            type: string
            sample: "image"
        description:
            description: Service description.
            type: string
            sample: "OpenStack Image Service"
        enabled:
            description: Service status.
            type: boolean
            sample: True
id:
    description: The service ID.
    returned: On success when I(state) is 'present'
    type: string
    sample: "3292f020780b4d5baf27ff7e1d224c44"


MAINTAINERS: Sam Yaple (@SamYaple)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_NETWORK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_network.py)

  Add or remove network from OpenStack.

Options (= is mandatory):

- admin_state_up
        Whether the state should be marked as up or down.
        [Default: True]
- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- external
        Whether this network is externally accessible.
        [Default: False]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name to be assigned to the network.

- project
        Project name or ID containing the network (name admin-only)
        [Default: None]
- provider_network_type
        The type of physical network that maps to this network resource.
        [Default: None]
- provider_physical_network
        The physical network where this network object is implemented.
        [Default: None]
- provider_segmentation_id
        An isolated segment on the physical network. The `network_type' attribute defines the segmentation model. For
        example, if the `network_type' value is vlan, this ID is a vlan identifier. If the `network_type' value is gre,
        this ID is a gre key.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- shared
        Whether this network is shared or not.
        [Default: False]
- state
        Indicate desired state of the resource.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Create an externally accessible network named 'ext_network'.
- os_network:
    cloud: mycloud
    state: present
    name: ext_network
    external: true

RETURN VALUES:
network:
    description: Dictionary describing the network.
    returned: On success when I(state) is 'present'.
    type: dictionary
    contains:
        id:
            description: Network ID.
            type: string
            sample: "4bb4f9a5-3bd2-4562-bf6a-d17a6341bb56"
        name:
            description: Network name.
            type: string
            sample: "ext_network"
        shared:
            description: Indicates whether this network is shared across all tenants.
            type: bool
            sample: false
        status:
            description: Network status.
            type: string
            sample: "ACTIVE"
        mtu:
            description: The MTU of a network resource.
            type: integer
            sample: 0
        admin_state_up:
            description: The administrative state of the network.
            type: bool
            sample: true
        port_security_enabled:
            description: The port security status
            type: bool
            sample: true
        router:external:
            description: Indicates whether this network is externally accessible.
            type: bool
            sample: true
        tenant_id:
            description: The tenant ID.
            type: string
            sample: "06820f94b9f54b119636be2728d216fc"
        subnets:
            description: The associated subnets.
            type: list
            sample: []
        "provider:physical_network":
            description: The physical network where this network object is implemented.
            type: string
            sample: my_vlan_net
        "provider:network_type":
            description: The type of physical network that maps to this network resource.
            type: string
            sample: vlan
        "provider:segmentation_id":
            description: An isolated segment on the physical network.
            type: string
            sample: 101


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_NETWORKS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_networks_facts.py)

  Retrieve facts about one or more networks from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- filters
        A dictionary of meta data to use for further filtering.  Elements of this dictionary may be additional
        dictionaries.
        [Default: (null)]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- name
        Name or ID of the Network
        [Default: (null)]
- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
- name: Gather facts about previously created networks
  os_networks_facts:
    auth:
      auth_url: https://your_api_url.com:9000/v2.0
      username: user
      password: password
      project_name: someproject

- name: Show openstack networks
  debug:
    var: openstack_networks

- name: Gather facts about a previously created network by name
  os_networks_facts:
    auth:
      auth_url: https://your_api_url.com:9000/v2.0
      username: user
      password: password
      project_name: someproject
    name:  network1

- name: Show openstack networks
  debug:
    var: openstack_networks

- name: Gather facts about a previously created network with filter
  # Note: name and filters parameters are Not mutually exclusive
  os_networks_facts:
    auth:
      auth_url: https://your_api_url.com:9000/v2.0
      username: user
      password: password
      project_name: someproject
    filters:
      tenant_id: 55e2ce24b2a245b09f181bf025724cbe
      subnets:
        - 057d4bdf-6d4d-4728-bb0f-5ac45a6f7400
        - 443d4dc0-91d4-4998-b21c-357d10433483

- name: Show openstack networks
  debug:
    var: openstack_networks

RETURN VALUES:
openstack_networks:
    description: has all the openstack facts about the networks
    returned: always, but can be null
    type: complex
    contains:
        id:
            description: Unique UUID.
            returned: success
            type: string
        name:
            description: Name given to the network.
            returned: success
            type: string
        status:
            description: Network status.
            returned: success
            type: string
        subnets:
            description: Subnet(s) included in this network.
            returned: success
            type: list of strings
        tenant_id:
            description: Tenant id associated with this network.
            returned: success
            type: string
        shared:
            description: Network shared flag.
            returned: success
            type: boolean


MAINTAINERS: Davide Agnello (@dagnello)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_NOVA_FLAVOR    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_nova_flavor.py)

  Add or remove flavors from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- disk
        Size of local disk, in GB.
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- ephemeral
        Ephemeral space size, in GB.
        [Default: 0]
- extra_specs
        Metadata dictionary
        [Default: None]
- flavorid
        ID for the flavor. This is optional as a unique UUID will be assigned if a value is not specified.
        [Default: auto]
- is_public
        Make flavor accessible to the public.
        [Default: True]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Flavor name.

- ram
        Amount of memory, in MB.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- rxtx_factor
        RX/TX factor.
        [Default: 1.0]
- state
        Indicate desired state of the resource. When `state' is 'present', then `ram', `vcpus', and `disk' are all
        required. There are no default values for those parameters.
        (Choices: present, absent)[Default: present]
- swap
        Swap space size, in MB.
        [Default: 0]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- vcpus
        Number of virtual CPUs.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
- name: "Create 'tiny' flavor with 1024MB of RAM, 1 virtual CPU, and 10GB of local disk, and 10GB of ephemeral."
  os_nova_flavor:
    cloud: mycloud
    state: present
    name: tiny
    ram: 1024
    vcpus: 1
    disk: 10
    ephemeral: 10

- name: "Delete 'tiny' flavor"
  os_nova_flavor:
    cloud: mycloud
    state: absent
    name: tiny

- name: Create flavor with metadata
  os_nova_flavor:
    cloud: mycloud
    state: present
    name: tiny
    ram: 1024
    vcpus: 1
    disk: 10
    extra_specs:
      "quota:disk_read_iops_sec": 5000
      "aggregate_instance_extra_specs:pinned": false

RETURN VALUES:
flavor:
    description: Dictionary describing the flavor.
    returned: On success when I(state) is 'present'
    type: dictionary
    contains:
        id:
            description: Flavor ID.
            returned: success
            type: string
            sample: "515256b8-7027-4d73-aa54-4e30a4a4a339"
        name:
            description: Flavor name.
            returned: success
            type: string
            sample: "tiny"
        disk:
            description: Size of local disk, in GB.
            returned: success
            type: int
            sample: 10
        ephemeral:
            description: Ephemeral space size, in GB.
            returned: success
            type: int
            sample: 10
        ram:
            description: Amount of memory, in MB.
            returned: success
            type: int
            sample: 1024
        swap:
            description: Swap space size, in MB.
            returned: success
            type: int
            sample: 100
        vcpus:
            description: Number of virtual CPUs.
            returned: success
            type: int
            sample: 2
        is_public:
            description: Make flavor accessible to the public.
            returned: success
            type: bool
            sample: true
        extra_specs:
            description: Flavor metadata
            returned: success
            type: dict
            sample:
                "quota:disk_read_iops_sec": 5000
                "aggregate_instance_extra_specs:pinned": false


MAINTAINERS: David Shrewsbury (@Shrews)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_NOVA_HOST_AGGREGATE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_nova_host_aggregate.py)

  Create, update, or delete OpenStack host aggregates. If a aggregate with the supplied name already exists, it will be
  updated with the new name, new availability zone, new metadata and new list of hosts.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Availability zone to create aggregate into.
        [Default: None]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- hosts
        List of hosts to set for an aggregate.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- metadata
        Metadata dict.
        [Default: None]
= name
        Name of the aggregate.

- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a host aggregate
- os_nova_host_aggregate:
    cloud: mycloud
    state: present
    name: db_aggregate
    hosts:
      - host1
      - host2
    metadata:
      type: dbcluster
# Delete an aggregate
- os_nova_host_aggregate:
    cloud: mycloud
    state: absent
    name: db_aggregate

RETURN VALUES:



MAINTAINERS: Jakub Jursa

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_OBJECT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_object.py)

  Create or Delete objects and containers from OpenStack

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
= container
        The name of the container in which to create the object

- container_access
        desired container access level.
        (Choices: private, public)[Default: private]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- filename
        Path to local file to be uploaded.
        [Default: (null)]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- name
        Name to be give to the object. If omitted, operations will be on the entire container
        [Default: (null)]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
- name: "Create a object named 'fstab' in the 'config' container"
  os_object:
    cloud: mordred
    state: present
    name: fstab
    container: config
    filename: /etc/fstab

- name: Delete a container called config and all of its contents
  os_object:
    cloud: rax-iad
    state: absent
    container: config


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_PORT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_port.py)

  Add, Update or Remove ports from an OpenStack cloud. A `state' of 'present' will ensure the port is created or updated
  if required.

Options (= is mandatory):

- admin_state_up
        Sets admin state.
        [Default: None]
- allowed_address_pairs
        Allowed address pairs list.  Allowed address pairs are supported with dictionary structure. e.g.
        allowed_address_pairs: - ip_address: 10.1.0.12 mac_address: ab:cd:ef:12:34:56 - ip_address: ...
        [Default: None]
- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- device_id
        Device ID of device using this port.
        [Default: None]
- device_owner
        The ID of the entity that uses this port.
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- extra_dhcp_opts
        Extra dhcp options to be assigned to this port.  Extra options are supported with dictionary structure. e.g.
        extra_dhcp_opts: - opt_name: opt name1 opt_value: value1 - opt_name: ...
        [Default: None]
- fixed_ips
        Desired IP and/or subnet for this port.  Subnet is referenced by subnet_id and IP is referenced by ip_address.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- mac_address
        MAC address of this port.
        [Default: None]
- name
        Name that has to be given to the port.
        [Default: None]
= network
        Network ID or name this port belongs to.

- no_security_groups
        Do not associate a security group with this port.
        [Default: False]
- region_name
        Name of the region.
        [Default: (null)]
- security_groups
        Security group(s) ID(s) or name(s) associated with the port (comma separated string or YAML list)
        [Default: None]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Create a port
- os_port:
    state: present
    auth:
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
      username: admin
      password: admin
      project_name: admin
    name: port1
    network: foo

# Create a port with a static IP
- os_port:
    state: present
    auth:
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
      username: admin
      password: admin
      project_name: admin
    name: port1
    network: foo
    fixed_ips:
      - ip_address: 10.1.0.21

# Create a port with No security groups
- os_port:
    state: present
    auth:
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
      username: admin
      password: admin
      project_name: admin
    name: port1
    network: foo
    no_security_groups: True

# Update the existing 'port1' port with multiple security groups (version 1)
- os_port:
    state: present
    auth:
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/d
      username: admin
      password: admin
      project_name: admin
    name: port1
    security_groups: 1496e8c7-4918-482a-9172-f4f00fc4a3a5,057d4bdf-6d4d-472...

# Update the existing 'port1' port with multiple security groups (version 2)
- os_port:
    state: present
    auth:
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/d
      username: admin
      password: admin
      project_name: admin
    name: port1
    security_groups:
      - 1496e8c7-4918-482a-9172-f4f00fc4a3a5
      - 057d4bdf-6d4d-472...

RETURN VALUES:
id:
    description: Unique UUID.
    returned: success
    type: string
name:
    description: Name given to the port.
    returned: success
    type: string
network_id:
    description: Network ID this port belongs in.
    returned: success
    type: string
security_groups:
    description: Security group(s) associated with this port.
    returned: success
    type: list of strings
status:
    description: Port's status.
    returned: success
    type: string
fixed_ips:
    description: Fixed ip(s) associated with this port.
    returned: success
    type: list of dicts
tenant_id:
    description: Tenant id associated with this port.
    returned: success
    type: string
allowed_address_pairs:
    description: Allowed address pairs with this port.
    returned: success
    type: list of dicts
admin_state_up:
    description: Admin state up flag for this port.
    returned: success
    type: bool


MAINTAINERS: Davide Agnello (@dagnello)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_PORT_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_port_facts.py)

  Retrieve facts about ports from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- filters
        A dictionary of meta data to use for further filtering. Elements of this dictionary will be matched against the
        returned port dictionaries. Matching is currently limited to strings within the port dictionary, or strings
        within nested dictionaries.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- port
        Unique name or ID of a port.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * Facts are placed in the `openstack_ports' variable.
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Gather facts about all ports
- os_port_facts:
    cloud: mycloud

# Gather facts about a single port
- os_port_facts:
    cloud: mycloud
    port: 6140317d-e676-31e1-8a4a-b1913814a471

# Gather facts about all ports that have device_id set to a specific value
# and with a status of ACTIVE.
- os_port_facts:
    cloud: mycloud
    filters:
      device_id: 1038a010-3a37-4a9d-82ea-652f1da36597
      status: ACTIVE

RETURN VALUES:
openstack_ports:
    description: List of port dictionaries. A subset of the dictionary keys
                 listed below may be returned, depending on your cloud provider.
    returned: always, but can be null
    type: complex
    contains:
        admin_state_up:
            description: The administrative state of the router, which is
                         up (true) or down (false).
            returned: success
            type: boolean
            sample: true
        allowed_address_pairs:
            description: A set of zero or more allowed address pairs. An
                         address pair consists of an IP address and MAC address.
            returned: success
            type: list
            sample: []
        "binding:host_id":
            description: The UUID of the host where the port is allocated.
            returned: success
            type: string
            sample: "b4bd682d-234a-4091-aa5b-4b025a6a7759"
        "binding:profile":
            description: A dictionary the enables the application running on
                         the host to pass and receive VIF port-specific
                         information to the plug-in.
            returned: success
            type: dict
            sample: {}
        "binding:vif_details":
            description: A dictionary that enables the application to pass
                         information about functions that the Networking API
                         provides.
            returned: success
            type: dict
            sample: {"port_filter": true}
        "binding:vif_type":
            description: The VIF type for the port.
            returned: success
            type: dict
            sample: "ovs"
        "binding:vnic_type":
            description: The virtual network interface card (vNIC) type that is
                         bound to the neutron port.
            returned: success
            type: string
            sample: "normal"
        device_id:
            description: The UUID of the device that uses this port.
            returned: success
            type: string
            sample: "b4bd682d-234a-4091-aa5b-4b025a6a7759"
        device_owner:
            description: The UUID of the entity that uses this port.
            returned: success
            type: string
            sample: "network:router_interface"
        dns_assignment:
            description: DNS assignment information.
            returned: success
            type: list
        dns_name:
            description: DNS name
            returned: success
            type: string
            sample: ""
        extra_dhcp_opts:
            description: A set of zero or more extra DHCP option pairs.
                         An option pair consists of an option value and name.
            returned: success
            type: list
            sample: []
        fixed_ips:
            description: The IP addresses for the port. Includes the IP address
                         and UUID of the subnet.
            returned: success
            type: list
        id:
            description: The UUID of the port.
            returned: success
            type: string
            sample: "3ec25c97-7052-4ab8-a8ba-92faf84148de"
        ip_address:
            description: The IP address.
            returned: success
            type: string
            sample: "127.0.0.1"
        mac_address:
            description: The MAC address.
            returned: success
            type: string
            sample: "00:00:5E:00:53:42"
        name:
            description: The port name.
            returned: success
            type: string
            sample: "port_name"
        network_id:
            description: The UUID of the attached network.
            returned: success
            type: string
            sample: "dd1ede4f-3952-4131-aab6-3b8902268c7d"
        port_security_enabled:
            description: The port security status. The status is enabled (true) or disabled (false).
            returned: success
            type: boolean
            sample: false
        security_groups:
            description: The UUIDs of any attached security groups.
            returned: success
            type: list
        status:
            description: The port status.
            returned: success
            type: string
            sample: "ACTIVE"
        tenant_id:
            description: The UUID of the tenant who owns the network.
            returned: success
            type: string
            sample: "51fce036d7984ba6af4f6c849f65ef00"


MAINTAINERS: David Shrewsbury (@Shrews)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_PROJECT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_project.py)

  Manage OpenStack Projects. Projects can be created, updated or deleted using this module. A project will be updated if
  `name' matches an existing project and `state' is present. The value for `name' cannot be updated without deleting and
  re-creating the project.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- description
        Description for the project
        [Default: None]
- domain_id
        Domain id to create the project in if the cloud supports domains. The domain_id parameter requires shade >= 1.8.0
        [Default: None]
- enabled
        Is the project enabled
        [Default: True]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name for the project

- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a project
- os_project:
    cloud: mycloud
    state: present
    name: demoproject
    description: demodescription
    domain_id: demoid
    enabled: True

# Delete a project
- os_project:
    cloud: mycloud
    state: absent
    name: demoproject

RETURN VALUES:
project:
    description: Dictionary describing the project.
    returned: On success when I(state) is 'present'
    type: dictionary
    contains:
        id:
            description: Project ID
            type: string
            sample: "f59382db809c43139982ca4189404650"
        name:
            description: Project name
            type: string
            sample: "demoproject"
        description:
            description: Project description
            type: string
            sample: "demodescription"
        enabled:
            description: Boolean to indicate if project is enabled
            type: bool
            sample: True


MAINTAINERS: Alberto Gireud (@agireud)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_PROJECT_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_project_facts.py)

  Retrieve facts about a one or more OpenStack projects

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- domain
        Name or ID of the domain containing the project if the cloud supports domains
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- filters
        A dictionary of meta data to use for further filtering.  Elements of this dictionary may be additional
        dictionaries.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name or ID of the project

- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Gather facts about previously created projects
- os_project_facts:
    cloud: awesomecloud
- debug:
    var: openstack_projects

# Gather facts about a previously created project by name
- os_project_facts:
    cloud: awesomecloud
    name: demoproject
- debug:
    var: openstack_projects

# Gather facts about a previously created project in a specific domain
- os_project_facts:
    cloud: awesomecloud
    name: demoproject
    domain: admindomain
- debug:
    var: openstack_projects

# Gather facts about a previously created project in a specific domain with filter
- os_project_facts:
    cloud: awesomecloud
    name: demoproject
    domain: admindomain
    filters:
      enabled: False
- debug:
    var: openstack_projects

RETURN VALUES:
openstack_projects:
    description: has all the OpenStack facts about projects
    returned: always, but can be null
    type: complex
    contains:
        id:
            description: Unique UUID.
            returned: success
            type: string
        name:
            description: Name given to the project.
            returned: success
            type: string
        description:
            description: Description of the project
            returned: success
            type: string
        enabled:
            description: Flag to indicate if the project is enabled
            returned: success
            type: bool
        domain_id:
            description: Domain ID containing the project (keystone v3 clouds only)
            returned: success
            type: bool


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_QUOTA    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_quota.py)

  Manage OpenStack Quotas. Quotas can be created, updated or deleted using this module. A quota will be updated if
  matches an existing project and is present.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- backup_gigabytes
        Maximum size of backups in GB's.
        [Default: None]
- backups
        Maximum number of backups allowed.
        [Default: None]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- cores
        Maximum number of CPU's per project.
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- fixed_ips
        Number of fixed IP's to allow.
        [Default: None]
- floating_ips
        Number of floating IP's to allow in Compute.
        [Default: None]
- floatingip
        Number of floating IP's to allow in Network.
        [Default: None]
- gigabytes
        Maximum volume storage allowed for project.
        [Default: None]
- gigabytes_lvm
        Maximum size in GB's of individual lvm volumes.
        [Default: None]
- injected_file_size
        Maximum file size in bytes.
        [Default: None]
- injected_files
        Number of injected files to allow.
        [Default: None]
- injected_path_size
        Maximum path size.
        [Default: None]
- instances
        Maximum number of instances allowed.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- key_pairs
        Number of key pairs to allow.
        [Default: None]
= name
        Name of the OpenStack Project to manage.

- network
        Number of networks to allow.
        [Default: None]
- per_volume_gigabytes
        Maximum size in GB's of individual volumes.
        [Default: None]
- port
        Number of Network ports to allow, this needs to be greater than the instances limit.
        [Default: None]
- properties
        Number of properties to allow.
        [Default: None]
- ram
        Maximum amount of ram in MB to allow.
        [Default: None]
- rbac_policy
        Number of policies to allow.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- router
        Number of routers to allow.
        [Default: None]
- security_group
        Number of security groups to allow.
        [Default: None]
- security_group_rule
        Number of rules per security group to allow.
        [Default: None]
- server_group_members
        Number of server group members to allow.
        [Default: None]
- server_groups
        Number of server groups to allow.
        [Default: None]
- snapshots
        Number of snapshots to allow.
        [Default: None]
- snapshots_lvm
        Number of LVM snapshots to allow.
        [Default: None]
- state
        A value of present sets the quota and a value of absent resets the quota to system defaults.
        [Default: present]
- subnet
        Number of subnets to allow.
        [Default: None]
- subnetpool
        Number of subnet pools to allow.
        [Default: None]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- volumes
        Number of volumes to allow.
        [Default: None]
- volumes_lvm
        Number of LVM volumes to allow.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade, shade > 1.9.0

EXAMPLES:
# List a Project Quota
- os_quota:
    cloud: mycloud
    name: demoproject

# Set a Project back to the defaults
- os_quota:
    cloud: mycloud
    name: demoproject
    state: absent

# Update a Project Quota for cores
- os_quota:
    cloud: mycloud
    name: demoproject
    cores: 100

# Update a Project Quota
- os_quota:
    name: demoproject
    cores: 1000
    volumes: 20
    volumes_type:
      - volume_lvm: 10

# Complete example based on list of projects
- name: Update quotas
  os_quota:
    name: "{{ item.name }}"
    backup_gigabytes: "{{ item.backup_gigabytes }}"
    backups: "{{ item.backups }}"
    cores: "{{ item.cores }}"
    fixed_ips: "{{ item.fixed_ips }}"
    floating_ips: "{{ item.floating_ips }}"
    floatingip: "{{ item.floatingip }}"
    gigabytes: "{{ item.gigabytes }}"
    injected_file_size: "{{ item.injected_file_size }}"
    injected_files: "{{ item.injected_files }}"
    injected_path_size: "{{ item.injected_path_size }}"
    instances: "{{ item.instances }}"
    port: "{{ item.port }}"
    key_pairs: "{{ item.key_pairs }}"
    per_volume_gigabytes: "{{ item.per_volume_gigabytes }}"
    properties: "{{ item.properties }}"
    ram: "{{ item.ram }}"
    security_group_rule: "{{ item.security_group_rule }}"
    security_group: "{{ item.security_group }}"
    server_group_members: "{{ item.server_group_members }}"
    server_groups: "{{ item.server_groups }}"
    snapshots: "{{ item.snapshots }}"
    volumes: "{{ item.volumes }}"
    volumes_types:
      volumes_lvm: "{{ item.volumes_lvm }}"
    snapshots_types:
      snapshots_lvm: "{{ item.snapshots_lvm }}"
    gigabytes_types:
      gigabytes_lvm: "{{ item.gigabytes_lvm }}"
  with_items:
    - "{{ projects }}"
  when: item.state == "present"

RETURN VALUES:
openstack_quotas:
    description: Dictionary describing the project quota.
    returned: Regardless if changes where made or note
    type: dictionary
    contains example:
    "openstack_quotas": {
        "compute": {
            "cores": 150,
            "fixed_ips": -1,
            "floating_ips": 10,
            "injected_file_content_bytes": 10240,
            "injected_file_path_bytes": 255,
            "injected_files": 5,
            "instances": 100,
            "key_pairs": 100,
            "metadata_items": 128,
            "ram": 153600,
            "security_group_rules": 20,
            "security_groups": 10,
            "server_group_members": 10,
            "server_groups": 10
        },
        "network": {
            "floatingip": 50,
            "network": 10,
            "port": 160,
            "rbac_policy": 10,
            "router": 10,
            "security_group": 10,
            "security_group_rule": 100,
            "subnet": 10,
            "subnetpool": -1
        },
        "volume": {
            "backup_gigabytes": 1000,
            "backups": 10,
            "gigabytes": 1000,
            "gigabytes_lvm": -1,
            "per_volume_gigabytes": -1,
            "snapshots": 10,
            "snapshots_lvm": -1,
            "volumes": 10,
            "volumes_lvm": -1
        }
    }



MAINTAINERS: Michael Gale (gale.michael@gmail.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_RECORDSET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_recordset.py)

  Manage OpenStack DNS recordsets. Recordsets can be created, deleted or updated. Only the `records', `description', and
  `ttl' values can be updated.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- description
        Description of the recordset
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name of the recordset

= records
        List of recordset definitions

= recordset_type
        Recordset type

- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- ttl
        TTL (Time To Live) value in seconds
        [Default: None]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
= zone
        Zone managing the recordset

Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a recordset named "www.example.net."
- os_recordset:
    cloud: mycloud
    state: present
    zone: example.net.
    name: www
    recordset_type: primary
    records: ['10.1.1.1']
    description: test recordset
    ttl: 3600

# Update the TTL on existing "www.example.net." recordset
- os_recordset:
    cloud: mycloud
    state: present
    zone: example.net.
    name: www
    ttl: 7200

# Delete recorset named "www.example.net."
- os_recordset:
    cloud: mycloud
    state: absent
    zone: example.net.
    name: www

RETURN VALUES:
recordset:
    description: Dictionary describing the recordset.
    returned: On success when I(state) is 'present'.
    type: dictionary
    contains:
        id:
            description: Unique recordset ID
            type: string
            sample: "c1c530a3-3619-46f3-b0f6-236927b2618c"
        name:
            description: Recordset name
            type: string
            sample: "www.example.net."
        zone_id:
            description: Zone id
            type: string
            sample: 9508e177-41d8-434e-962c-6fe6ca880af7
        type:
            description: Recordset type
            type: string
            sample: "A"
        description:
            description: Recordset description
            type: string
            sample: "Test description"
        ttl:
            description: Zone TTL value
            type: int
            sample: 3600
        records:
            description: Recordset records
            type: list
            sample: ['10.0.0.1']


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_ROUTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_router.py)

  Create or Delete routers from OpenStack. Although Neutron allows routers to share the same name, this module enforces
  name uniqueness to be more user friendly.

Options (= is mandatory):

- admin_state_up
        Desired admin state of the created or existing router.
        [Default: True]
- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- enable_snat
        Enable Source NAT (SNAT) attribute.
        [Default: True]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- external_fixed_ips
        The IP address parameters for the external gateway network. Each is a dictionary with the subnet name or ID
        (subnet) and the IP address to assign on the subnet (ip). If no IP is specified, one is automatically assigned
        from that subnet.
        [Default: None]
- interfaces
        List of subnets to attach to the router internal interface.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name to be give to the router

- network
        Unique name or ID of the external gateway network.
        required `interfaces' or `enable_snat' are provided.
        [Default: None]
- project
        Unique name or ID of the project.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Create a simple router, not attached to a gateway or subnets.
- os_router:
    cloud: mycloud
    state: present
    name: simple_router

# Create a simple router, not attached to a gateway or subnets for a given project.
- os_router:
    cloud: mycloud
    state: present
    name: simple_router
    project: myproj

# Creates a router attached to ext_network1 on an IPv4 subnet and one
# internal subnet interface.
- os_router:
    cloud: mycloud
    state: present
    name: router1
    network: ext_network1
    external_fixed_ips:
      - subnet: public-subnet
        ip: 172.24.4.2
    interfaces:
      - private-subnet

# Update existing router1 external gateway to include the IPv6 subnet.
# Note that since 'interfaces' is not provided, any existing internal
# interfaces on an existing router will be left intact.
- os_router:
    cloud: mycloud
    state: present
    name: router1
    network: ext_network1
    external_fixed_ips:
      - subnet: public-subnet
        ip: 172.24.4.2
      - subnet: ipv6-public-subnet
        ip: 2001:db8::3

# Delete router1
- os_router:
    cloud: mycloud
    state: absent
    name: router1

RETURN VALUES:
router:
    description: Dictionary describing the router.
    returned: On success when I(state) is 'present'
    type: dictionary
    contains:
        id:
            description: Router ID.
            type: string
            sample: "474acfe5-be34-494c-b339-50f06aa143e4"
        name:
            description: Router name.
            type: string
            sample: "router1"
        admin_state_up:
            description: Administrative state of the router.
            type: boolean
            sample: true
        status:
            description: The router status.
            type: string
            sample: "ACTIVE"
        tenant_id:
            description: The tenant ID.
            type: string
            sample: "861174b82b43463c9edc5202aadc60ef"
        external_gateway_info:
            description: The external gateway parameters.
            type: dictionary
            sample: {
                      "enable_snat": true,
                      "external_fixed_ips": [
                         {
                           "ip_address": "10.6.6.99",
                           "subnet_id": "4272cb52-a456-4c20-8f3c-c26024ecfa81"
                         }
                       ]
                    }
        routes:
            description: The extra routes configuration for L3 router.
            type: list


MAINTAINERS: David Shrewsbury (@Shrews)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SECURITY_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_security_group.py)

  Add or Remove security groups from an OpenStack cloud.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- description
        Long description of the purpose of the security group
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name that has to be given to the security group. This module requires that security group names be unique.

- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Create a security group
- os_security_group:
    cloud: mordred
    state: present
    name: foo
    description: security group for foo servers

# Update the existing 'foo' security group description
- os_security_group:
    cloud: mordred
    state: present
    name: foo
    description: updated description for the foo security group


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SECURITY_GROUP_RULE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_security_group_rule.py)

  Add or Remove rule from an existing security group

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- direction
        The direction in which the security group rule is applied. Not all providers support egress.
        (Choices: egress, ingress)[Default: ingress]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- ethertype
        Must be IPv4 or IPv6, and addresses represented in CIDR must match the ingress or egress rules. Not all providers
        support IPv6.
        (Choices: IPv4, IPv6)[Default: IPv4]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- port_range_max
        Ending port
        [Default: None]
- port_range_min
        Starting port
        [Default: None]
- protocol
        IP protocols TCP UDP ICMP 112 (VRRP)
        (Choices: tcp, udp, icmp, 112, None)[Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- remote_group
        Name or ID of the Security group to link (exclusive with remote_ip_prefix)
        [Default: (null)]
- remote_ip_prefix
        Source IP address(es) in CIDR notation (exclusive with remote_group)
        [Default: (null)]
= security_group
        Name or ID of the security group

- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.7, shade

EXAMPLES:
# Create a security group rule
- os_security_group_rule:
    cloud: mordred
    security_group: foo
    protocol: tcp
    port_range_min: 80
    port_range_max: 80
    remote_ip_prefix: 0.0.0.0/0

# Create a security group rule for ping
- os_security_group_rule:
    cloud: mordred
    security_group: foo
    protocol: icmp
    remote_ip_prefix: 0.0.0.0/0

# Another way to create the ping rule
- os_security_group_rule:
    cloud: mordred
    security_group: foo
    protocol: icmp
    port_range_min: -1
    port_range_max: -1
    remote_ip_prefix: 0.0.0.0/0

# Create a TCP rule covering all ports
- os_security_group_rule:
    cloud: mordred
    security_group: foo
    protocol: tcp
    port_range_min: 1
    port_range_max: 65535
    remote_ip_prefix: 0.0.0.0/0

# Another way to create the TCP rule above (defaults to all ports)
- os_security_group_rule:
    cloud: mordred
    security_group: foo
    protocol: tcp
    remote_ip_prefix: 0.0.0.0/0

# Create a rule for VRRP with numbered protocol 112
- os_security_group_rule:
    security_group: loadbalancer_sg
    protocol: 112
    remote_group: loadbalancer-node_sg

RETURN VALUES:
id:
  description: Unique rule UUID.
  type: string
direction:
  description: The direction in which the security group rule is applied.
  type: string
  sample: 'egress'
ethertype:
  description: One of IPv4 or IPv6.
  type: string
  sample: 'IPv4'
port_range_min:
  description: The minimum port number in the range that is matched by
               the security group rule.
  type: int
  sample: 8000
port_range_max:
  description: The maximum port number in the range that is matched by
               the security group rule.
  type: int
  sample: 8000
protocol:
  description: The protocol that is matched by the security group rule.
  type: string
  sample: 'tcp'
remote_ip_prefix:
  description: The remote IP prefix to be associated with this security group rule.
  type: string
  sample: '0.0.0.0/0'
security_group_id:
  description: The security group ID to associate with this security group rule.
  type: string


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SERVER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_server.py)

  Create or Remove compute instances from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- auto_ip
        Ensure instance has public ip however the cloud wants to do that
        [Default: yes]
- availability_zone
        Availability zone in which to create the server.
        [Default: (null)]
- boot_from_volume
        Should the instance boot from a persistent volume created based on the image given. Mututally exclusive with
        boot_volume.
        [Default: False]
- boot_volume
        Volume name or id to use as the volume to boot from. Implies boot_from_volume. Mutually exclusive with image and
        boot_from_volume.
        [Default: None]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- config_drive
        Whether to boot the server with config drive enabled
        [Default: no]
- delete_fip
        When `state' is absent and this option is true, any floating IP associated with the instance will be deleted
        along with the instance.
        [Default: False]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- flavor
        The name or id of the flavor in which the new instance has to be created. Mutually exclusive with flavor_ram
        [Default: 1]
- flavor_include
        Text to use to filter flavor names, for the case, such as Rackspace, where there are multiple flavors that have
        the same ram count. flavor_include is a positive match filter - it must exist in the flavor name.
        [Default: (null)]
- flavor_ram
        The minimum amount of ram in MB that the flavor in which the new instance has to be created must have. Mutually
        exclusive with flavor.
        [Default: 1]
- floating_ip_pools
        Name of floating IP pool from which to choose a floating IP
        [Default: None]
- floating_ips
        list of valid floating IPs that pre-exist to assign to this node
        [Default: None]
= image
        The name or id of the base image to boot.

- image_exclude
        Text to use to filter image names, for the case, such as HP, where there are multiple image names matching the
        common identifying portions. image_exclude is a negative match filter - it is text that may not exist in the
        image name. Defaults to "(deprecated)"
        [Default: (null)]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- key_name
        The key pair name to be used when creating a instance
        [Default: None]
- meta
        A list of key value pairs that should be provided as a metadata to the new instance or a string containing a list
        of key-value pairs. Eg:  meta: "key1=value1,key2=value2"
        [Default: None]
= name
        Name that has to be given to the instance

- network
        Name or ID of a network to attach this instance to. A simpler version of the nics parameter, only one of network
        or nics should be supplied.
        [Default: None]
- nics
        A list of networks to which the instance's interface should be attached. Networks may be referenced by net-id
        /net-name/port-id or port-name.
        Also this accepts a string containing a list of (net/port)-(id/name) Eg: nics: "net-id=uuid-1,port-name=myport"
        Only one of network or nics should be supplied.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- reuse_ips
        When `auto_ip' is true and this option is true, the `auto_ip' code will attempt to re-use unassigned floating ips
        in the project before creating a new one. It is important to note that it is impossible to safely do this
        concurrently, so if your use case involves concurrent server creation, it is highly recommended to set this to
        false and to delete the floating ip associated with a server when the server is deleted using `delete_fip'.
        [Default: True]
- scheduler_hints
        Arbitrary key/value pairs to the scheduler for custom use
        [Default: None]
- security_groups
        Names of the security groups to which the instance should be added. This may be a YAML list or a comma separated
        string.
        [Default: None]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- terminate_volume
        If true, delete volume when deleting instance (if booted from volume)
        [Default: False]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- userdata
        Opaque blob of data which is made available to the instance
        [Default: None]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- volume_size
        The size of the volume to create in GB if booting from volume based on an image.
        [Default: (null)]
- volumes
        A list of preexisting volumes names or ids to attach to the instance
        [Default: []]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
- name: Create a new instance and attaches to a network and passes metadata to the instance
  os_server:
       state: present
       auth:
         auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
         username: admin
         password: admin
         project_name: admin
       name: vm1
       image: 4f905f38-e52a-43d2-b6ec-754a13ffb529
       key_name: ansible_key
       timeout: 200
       flavor: 4
       nics:
         - net-id: 34605f38-e52a-25d2-b6ec-754a13ffb723
         - net-name: another_network
       meta:
         hostname: test1
         group: uge_master

# Create a new instance in HP Cloud AE1 region availability zone az2 and
# automatically assigns a floating IP
- name: launch a compute instance
  hosts: localhost
  tasks:
    - name: launch an instance
      os_server:
        state: present
        auth:
          auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
          username: username
          password: Equality7-2521
          project_name: username-project1
        name: vm1
        region_name: region-b.geo-1
        availability_zone: az2
        image: 9302692b-b787-4b52-a3a6-daebb79cb498
        key_name: test
        timeout: 200
        flavor: 101
        security_groups: default
        auto_ip: yes

# Create a new instance in named cloud mordred availability zone az2
# and assigns a pre-known floating IP
- name: launch a compute instance
  hosts: localhost
  tasks:
    - name: launch an instance
      os_server:
        state: present
        cloud: mordred
        name: vm1
        availability_zone: az2
        image: 9302692b-b787-4b52-a3a6-daebb79cb498
        key_name: test
        timeout: 200
        flavor: 101
        floating_ips:
          - 12.34.56.79

# Create a new instance with 4G of RAM on Ubuntu Trusty, ignoring
# deprecated images
- name: launch a compute instance
  hosts: localhost
  tasks:
    - name: launch an instance
      os_server:
        name: vm1
        state: present
        cloud: mordred
        region_name: region-b.geo-1
        image: Ubuntu Server 14.04
        image_exclude: deprecated
        flavor_ram: 4096

# Create a new instance with 4G of RAM on Ubuntu Trusty on a Performance node
- name: launch a compute instance
  hosts: localhost
  tasks:
    - name: launch an instance
      os_server:
        name: vm1
        cloud: rax-dfw
        state: present
        image: Ubuntu 14.04 LTS (Trusty Tahr) (PVHVM)
        flavor_ram: 4096
        flavor_include: Performance

# Creates a new instance and attaches to multiple network
- name: launch a compute instance
  hosts: localhost
  tasks:
    - name: launch an instance with a string
      os_server:
        auth:
           auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
           username: admin
           password: admin
           project_name: admin
        name: vm1
        image: 4f905f38-e52a-43d2-b6ec-754a13ffb529
        key_name: ansible_key
        timeout: 200
        flavor: 4
        nics: "net-id=4cb08b20-62fe-11e5-9d70-feff819cdc9f,net-id=542f0430-62fe-11e5-9d70-feff819cdc9f..."

- name: Creates a new instance and attaches to a network and passes metadata to the instance
  os_server:
       state: present
       auth:
         auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
         username: admin
         password: admin
         project_name: admin
       name: vm1
       image: 4f905f38-e52a-43d2-b6ec-754a13ffb529
       key_name: ansible_key
       timeout: 200
       flavor: 4
       nics:
         - net-id: 34605f38-e52a-25d2-b6ec-754a13ffb723
         - net-name: another_network
       meta: "hostname=test1,group=uge_master"

- name:  Creates a new instance and attaches to a specific network
  os_server:
    state: present
    auth:
      auth_url: https://region-b.geo-1.identity.hpcloudsvc.com:35357/v2.0/
      username: admin
      password: admin
      project_name: admin
    name: vm1
    image: 4f905f38-e52a-43d2-b6ec-754a13ffb529
    key_name: ansible_key
    timeout: 200
    flavor: 4
    network: another_network

# Create a new instance with 4G of RAM on a 75G Ubuntu Trusty volume
- name: launch a compute instance
  hosts: localhost
  tasks:
    - name: launch an instance
      os_server:
        name: vm1
        state: present
        cloud: mordred
        region_name: ams01
        image: Ubuntu Server 14.04
        flavor_ram: 4096
        boot_from_volume: True
        volume_size: 75

# Creates a new instance with 2 volumes attached
- name: launch a compute instance
  hosts: localhost
  tasks:
    - name: launch an instance
      os_server:
        name: vm1
        state: present
        cloud: mordred
        region_name: ams01
        image: Ubuntu Server 14.04
        flavor_ram: 4096
        volumes:
        - photos
        - music


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SERVER_ACTIONS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_server_actions.py)

  Perform server actions on an existing compute instance from OpenStack. This module does not return any data other than
  changed true/false. When `action' is 'rebuild', then `image' parameter is required.

Options (= is mandatory):

- action
        Perform the given action. The lock and unlock actions always return changed as the servers API does not provide
        lock status.
        (Choices: stop, start, pause, unpause, lock, unlock, suspend, resume, rebuild)[Default: present]
- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- image
        Image the server should be rebuilt with
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
= server
        Name or ID of the instance

- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Pauses a compute instance
- os_server_actions:
       action: pause
       auth:
         auth_url: https://mycloud.openstack.blueboxgrid.com:5001/v2.0
         username: admin
         password: admin
         project_name: admin
       server: vm1
       timeout: 200


MAINTAINERS: Jesse Keating (@j2sol)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SERVER_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_server_facts.py)

  Retrieve facts about server instances from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- detailed
        when true, return additional detail about servers at the expense of additional API calls.
        [Default: False]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- server
        restrict results to servers with names or UUID matching this glob expression (e.g., C<web*>).
        [Default: None]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * This module creates a new top-level `openstack_servers' fact, which contains a list of servers.
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Gather facts about all servers named C<web*>:
- os_server_facts:
    cloud: rax-dfw
    server: web*
- debug:
    var: openstack_servers


MAINTAINERS: Monty

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SERVER_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_server_group.py)

  Add or remove server groups from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Server group name.

- policies
        A list of one or more policy names to associate with the server group. The list must contain at least one policy
        name. The current valid policy names are anti-affinity, affinity, soft-anti-affinity and soft-affinity.
        [Default: (null)]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Indicate desired state of the resource. When `state' is 'present', then `policies' is required.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a server group with 'affinity' policy.
- os_server_group:
    state: present
    auth:
      auth_url: https://api.cloud.catalyst.net.nz:5000/v2.0
      username: admin
      password: admin
      project_name: admin
    name: my_server_group
    policies:
      - affinity

# Delete 'my_server_group' server group.
- os_server_group:
    state: absent
    auth:
      auth_url: https://api.cloud.catalyst.net.nz:5000/v2.0
      username: admin
      password: admin
      project_name: admin
    name: my_server_group

RETURN VALUES:
id:
    description: Unique UUID.
    returned: success
    type: string
name:
    description: The name of the server group.
    returned: success
    type: string
policies:
    description: A list of one or more policy names of the server group.
    returned: success
    type: list of strings
members:
    description: A list of members in the server group.
    returned: success
    type: list of strings
metadata:
    description: Metadata key and value pairs.
    returned: success
    type: dict
project_id:
    description: The project ID who owns the server group.
    returned: success
    type: string
user_id:
    description: The user ID who owns the server group.
    returned: success
    type: string


MAINTAINERS: Lingxian Kong (@kong)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SERVER_VOLUME    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_server_volume.py)

  Attach or Detach volumes from OpenStack VM's

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- device
        Device you want to attach. Defaults to auto finding a device name.
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
= server
        Name or ID of server you want to attach a volume to

- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
= volume
        Name or id of volume you want to attach to a server

- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Attaches a volume to a compute host
- name: attach a volume
  hosts: localhost
  tasks:
  - name: attach volume to host
    os_server_volume:
      state: present
      cloud: mordred
      server: Mysql-server
      volume: mysql-data
      device: /dev/vdb


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_STACK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_stack.py)

  Add or Remove a Stack to an OpenStack Heat

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- environment
        List of environment files that should be used for the stack creation
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name of the stack that should be created, name could be char and digit, no space

- parameters
        Dictionary of parameters for the stack creation
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- rollback
        Rollback stack creation
        [Default: False]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- template
        Path of the template file to use for the stack creation
        [Default: None]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
---
- name: create stack
  ignore_errors: True
  register: stack_create
  os_stack:
    name: "{{ stack_name }}"
    state: present
    template: "/path/to/my_stack.yaml"
    environment:
    - /path/to/resource-registry.yaml
    - /path/to/environment.yaml
    parameters:
        bmc_flavor: m1.medium
        bmc_image: CentOS
        key_name: default
        private_net: "{{ private_net_param }}"
        node_count: 2
        name: undercloud
        image: CentOS
        my_flavor: m1.large
        external_net: "{{ external_net_param }}"

RETURN VALUES:
id:
    description: Stack ID.
    type: string
    sample: "97a3f543-8136-4570-920e-fd7605c989d6"

stack:
    action:
        description: Action, could be Create or Update.
        type: string
        sample: "CREATE"
    creation_time:
        description: Time when the action has been made.
        type: string
        sample: "2016-07-05T17:38:12Z"
    description:
        description: Description of the Stack provided in the heat template.
        type: string
        sample: "HOT template to create a new instance and networks"
    id:
        description: Stack ID.
        type: string
        sample: "97a3f543-8136-4570-920e-fd7605c989d6"
    name:
        description: Name of the Stack
        type: string
        sample: "test-stack"
    identifier:
        description: Identifier of the current Stack action.
        type: string
        sample: "test-stack/97a3f543-8136-4570-920e-fd7605c989d6"
    links:
        description: Links to the current Stack.
        type: list of dict
        sample: "[{'href': 'http://foo:8004/v1/7f6a/stacks/test-stack/97a3f543-8136-4570-920e-fd7605c989d6']"
    outputs:
        description: Output returned by the Stack.
        type: list of dict
        sample: "{'description': 'IP address of server1 in private network',
                    'output_key': 'server1_private_ip',
                    'output_value': '10.1.10.103'}"
    parameters:
        description: Parameters of the current Stack
        type: dict
        sample: "{'OS::project_id': '7f6a3a3e01164a4eb4eecb2ab7742101',
                    'OS::stack_id': '97a3f543-8136-4570-920e-fd7605c989d6',
                    'OS::stack_name': 'test-stack',
                    'stack_status': 'CREATE_COMPLETE',
                    'stack_status_reason': 'Stack CREATE completed successfully',
                    'status': 'COMPLETE',
                    'template_description': 'HOT template to create a new instance and networks',
                    'timeout_mins': 60,
                    'updated_time': null}"


MAINTAINERS: Mathieu Bultel (matbu), Steve Baker (steveb)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SUBNET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_subnet.py)

  Add or Remove a subnet to an OpenStack network

Options (= is mandatory):

- allocation_pool_end
        From the subnet pool the last IP that should be assigned to the virtual machines.
        [Default: None]
- allocation_pool_start
        From the subnet pool the starting address from which the IP should be allocated.
        [Default: None]
- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cidr
        The CIDR representation of the subnet that should be assigned to the subnet. Required when `state' is 'present'
        and a subnetpool is not specified.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- dns_nameservers
        List of DNS nameservers for this subnet.
        [Default: None]
- enable_dhcp
        Whether DHCP should be enabled for this subnet.
        [Default: True]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- gateway_ip
        The ip that would be assigned to the gateway for this subnet
        [Default: None]
- host_routes
        A list of host route dictionaries for the subnet.
        [Default: None]
- ip_version
        The IP version of the subnet 4 or 6
        [Default: 4]
- ipv6_address_mode
        IPv6 address mode
        (Choices: dhcpv6-stateful, dhcpv6-stateless, slaac)[Default: None]
- ipv6_ra_mode
        IPv6 router advertisement mode
        (Choices: dhcpv6-stateful, dhcpv6-stateless, slaac)[Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        The name of the subnet that should be created. Although Neutron allows for non-unique subnet names, this module
        enforces subnet name uniqueness.

- network_name
        Name of the network to which the subnet should be attached
        Required when `state' is 'present'
        [Default: (null)]
- no_gateway_ip
        The gateway IP would not be assigned for this subnet
        [Default: False]
- project
        Project name or ID containing the subnet (name admin-only)
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- use_default_subnetpool
        Use the default subnetpool for `ip_version' to obtain a CIDR.
        [Default: False]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a new (or update an existing) subnet on the specified network
- os_subnet:
    state: present
    network_name: network1
    name: net1subnet
    cidr: 192.168.0.0/24
    dns_nameservers:
       - 8.8.8.7
       - 8.8.8.8
    host_routes:
       - destination: 0.0.0.0/0
         nexthop: 12.34.56.78
       - destination: 192.168.0.0/24
         nexthop: 192.168.0.1

# Delete a subnet
- os_subnet:
    state: absent
    name: net1subnet

# Create an ipv6 stateless subnet
- os_subnet:
    state: present
    name: intv6
    network_name: internal
    ip_version: 6
    cidr: 2db8:1::/64
    dns_nameservers:
        - 2001:4860:4860::8888
        - 2001:4860:4860::8844
    ipv6_ra_mode: dhcpv6-stateless
    ipv6_address_mode: dhcpv6-stateless


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_SUBNETS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_subnets_facts.py)

  Retrieve facts about one or more subnets from OpenStack.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- filters
        A dictionary of meta data to use for further filtering.  Elements of this dictionary may be additional
        dictionaries.
        [Default: (null)]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- subnet
        Name or ID of the subnet
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
- name: Gather facts about previously created subnets
  os_subnets_facts:
    auth:
      auth_url: https://your_api_url.com:9000/v2.0
      username: user
      password: password
      project_name: someproject

- name: Show openstack subnets
  debug:
    var: openstack_subnets

- name: Gather facts about a previously created subnet by name
  os_subnets_facts:
    auth:
      auth_url: https://your_api_url.com:9000/v2.0
      username: user
      password: password
      project_name: someproject
    name: subnet1

- name: Show openstack subnets
  debug:
    var: openstack_subnets

- name: Gather facts about a previously created subnet with filter
  # Note: name and filters parameters are not mutually exclusive
  os_subnets_facts:
    auth:
      auth_url: https://your_api_url.com:9000/v2.0
      username: user
      password: password
      project_name: someproject
    filters:
      tenant_id: 55e2ce24b2a245b09f181bf025724cbe

- name: Show openstack subnets
  debug:
    var: openstack_subnets

RETURN VALUES:
openstack_subnets:
    description: has all the openstack facts about the subnets
    returned: always, but can be null
    type: complex
    contains:
        id:
            description: Unique UUID.
            returned: success
            type: string
        name:
            description: Name given to the subnet.
            returned: success
            type: string
        network_id:
            description: Network ID this subnet belongs in.
            returned: success
            type: string
        cidr:
            description: Subnet's CIDR.
            returned: success
            type: string
        gateway_ip:
            description: Subnet's gateway ip.
            returned: success
            type: string
        enable_dhcp:
            description: DHCP enable flag for this subnet.
            returned: success
            type: bool
        ip_version:
            description: IP version for this subnet.
            returned: success
            type: int
        tenant_id:
            description: Tenant id associated with this subnet.
            returned: success
            type: string
        dns_nameservers:
            description: DNS name servers for this subnet.
            returned: success
            type: list of strings
        allocation_pools:
            description: Allocation pools associated with this subnet.
            returned: success
            type: list of dicts


MAINTAINERS: Davide Agnello (@dagnello)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_USER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_user.py)

  Manage OpenStack Identity users. Users can be created, updated or deleted using this module. A user will be updated if
  `name' matches an existing user and `state' is present. The value for `name' cannot be updated without deleting and re-
  creating the user.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- default_project
        Project name or ID that the user should be associated with by default
        [Default: None]
- domain
        Domain to create the user in if the cloud supports domains
        [Default: None]
- email
        Email address for the user
        [Default: None]
- enabled
        Is the user enabled
        [Default: True]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Username for the user

- password
        Password for the user
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- update_password
        `always' will attempt to update password.  `on_create' will only set the password for newly created users.
        (Choices: always, on_create)[Default: always]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a user
- os_user:
    cloud: mycloud
    state: present
    name: demouser
    password: secret
    email: demo@example.com
    domain: default
    default_project: demo

# Delete a user
- os_user:
    cloud: mycloud
    state: absent
    name: demouser

# Create a user but don't update password if user exists
- os_user:
    cloud: mycloud
    state: present
    name: demouser
    password: secret
    update_password: on_create
    email: demo@example.com
    domain: default
    default_project: demo

RETURN VALUES:
user:
    description: Dictionary describing the user.
    returned: On success when I(state) is 'present'
    type: dictionary
    contains:
        default_project_id:
            description: User default project ID. Only present with Keystone >= v3.
            type: string
            sample: "4427115787be45f08f0ec22a03bfc735"
        domain_id:
            description: User domain ID. Only present with Keystone >= v3.
            type: string
            sample: "default"
        email:
            description: User email address
            type: string
            sample: "demo@example.com"
        id:
            description: User ID
            type: string
            sample: "f59382db809c43139982ca4189404650"
        name:
            description: User name
            type: string
            sample: "demouser"


MAINTAINERS: David Shrewsbury

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_USER_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_user_facts.py)

  Retrieve facts about a one or more OpenStack users

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- domain
        Name or ID of the domain containing the user if the cloud supports domains
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- filters
        A dictionary of meta data to use for further filtering.  Elements of this dictionary may be additional
        dictionaries.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
= name
        Name or ID of the user

- region_name
        Name of the region.
        [Default: (null)]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Gather facts about previously created users
- os_user_facts:
    cloud: awesomecloud
- debug:
    var: openstack_users

# Gather facts about a previously created user by name
- os_user_facts:
    cloud: awesomecloud
    name: demouser
- debug:
    var: openstack_users

# Gather facts about a previously created user in a specific domain
- os_user_facts:
    cloud: awesomecloud
    name: demouser
    domain: admindomain
- debug:
    var: openstack_users

# Gather facts about a previously created user in a specific domain with filter
- os_user_facts:
    cloud: awesomecloud
    name: demouser
    domain: admindomain
    filters:
      enabled: False
- debug:
    var: openstack_users

RETURN VALUES:
openstack_users:
    description: has all the OpenStack facts about users
    returned: always, but can be null
    type: complex
    contains:
        id:
            description: Unique UUID.
            returned: success
            type: string
        name:
            description: Name given to the user.
            returned: success
            type: string
        enabled:
            description: Flag to indicate if the user is enabled
            returned: success
            type: bool
        domain_id:
            description: Domain ID containing the user
            returned: success
            type: string
        default_project_id:
            description: Default project ID of the user
            returned: success
            type: string
        email:
            description: Email of the user
            returned: success
            type: string
        username:
            description: Username of the user
            returned: success
            type: string


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_USER_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_user_group.py)

  Add and remove users from groups

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
= group
        Name or id for the group.

- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the user be present or absent in the group
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
= user
        Name or id for the user

- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Add the demo user to the demo group
- os_user_group:
  cloud: mycloud
  user: demo
  group: demo


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_USER_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_user_role.py)

  Grant and revoke roles in either project or domain context for OpenStack Identity Users.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- domain
        ID of the domain to scope the role association to. Valid only with keystone version 3, and required if `project'
        is not specified.
        [Default: None]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- group
        Name or ID for the group. Valid only with keystone version 3. If `group' is not specified, then `user' is
        required. Both may not be specified.
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- project
        Name or ID of the project to scope the role association to. If you are using keystone version 2, then this value
        is required.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
= role
        Name or ID for the role.

- state
        Should the roles be present or absent on the user.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- user
        Name or ID for the user. If `user' is not specified, then `group' is required. Both may not be specified.
        [Default: None]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Grant an admin role on the user admin in the project project1
- os_user_role:
    cloud: mycloud
    user: admin
    role: admin
    project: project1

# Revoke the admin role from the user barney in the newyork domain
- os_user_role:
    cloud: mycloud
    state: absent
    user: barney
    role: admin
    domain: newyork

RETURN VALUES:
#


MAINTAINERS: Monty Taylor (@emonty), David Shrewsbury (@Shrews)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_VOLUME    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_volume.py)

  Create or Remove cinder block storage volumes

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- display_description
        String describing the volume
        [Default: None]
= display_name
        Name of volume

- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- image
        Image name or id for boot from volume
        [Default: None]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- region_name
        Name of the region.
        [Default: (null)]
- size
        Size of volume in GB. This parameter is required when the `state' parameter is 'present'.
        [Default: None]
- snapshot_id
        Volume snapshot id to create from
        [Default: None]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- volume
        Volume name or id to create from
        [Default: None]
- volume_type
        Volume type for volume
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Creates a new volume
- name: create a volume
  hosts: localhost
  tasks:
  - name: create 40g test volume
    os_volume:
      state: present
      cloud: mordred
      availability_zone: az2
      size: 40
      display_name: test_volume


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['preview']
	Supported_by: community
> OS_ZONE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/os_zone.py)

  Manage OpenStack DNS zones. Zones can be created, deleted or updated. Only the `email', `description', `ttl' and
  `masters' values can be updated.

Options (= is mandatory):

- api_timeout
        How long should the socket layer wait before timing out for API calls. If this is omitted, nothing will be passed
        to the requests library.
        [Default: None]
- auth
        Dictionary containing auth information as needed by the cloud's auth plugin strategy. For the default `password'
        plugin, this would contain `auth_url', `username', `password', `project_name' and any information about domains
        if the cloud supports them. For other plugins, this param will need to contain whatever parameters that auth
        plugin requires. This parameter is not needed if a named cloud is provided or OpenStack OS_* environment
        variables are present.
        [Default: (null)]
- auth_type
        Name of the auth plugin to use. If the cloud uses something other than password authentication, the name of the
        plugin should be indicated here and the contents of the `auth' parameter should be updated accordingly.
        [Default: password]
- availability_zone
        Ignored. Present for backwards compatability
        [Default: (null)]
- cacert
        A path to a CA Cert bundle that can be used as part of verifying SSL API requests.
        [Default: None]
- cert
        A path to a client certificate to use as part of the SSL transaction.
        [Default: None]
- cloud
        Named cloud to operate against. Provides default values for `auth' and `auth_type'. This parameter is not needed
        if `auth' is provided or if OpenStack OS_* environment variables are present.
        [Default: (null)]
- description
        Zone description
        [Default: None]
- email
        Email of the zone owner (only applies if zone_type is primary)
        [Default: (null)]
- endpoint_type
        Endpoint URL type to fetch from the service catalog.
        (Choices: public, internal, admin)[Default: public]
- key
        A path to a client key to use as part of the SSL transaction.
        [Default: None]
- masters
        Master nameservers (only applies if zone_type is secondary)
        [Default: None]
= name
        Zone name

- region_name
        Name of the region.
        [Default: (null)]
- state
        Should the resource be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        How long should ansible wait for the requested resource.
        [Default: 180]
- ttl
        TTL (Time To Live) value in seconds
        [Default: None]
- validate_certs
        Whether or not SSL API requests should be verified. Before 2.3 this defaulted to True.
        [Default: None]
- wait
        Should ansible wait until the requested resource is complete.
        (Choices: yes, no)[Default: yes]
- zone_type
        Zone type
        (Choices: primary, secondary)[Default: None]
Notes:
  * The standard OpenStack environment variables, such as `OS_USERNAME' may be used instead of providing explicit
        values.
  * Auth information is driven by os-client-config, which means that values can come from a yaml config file in
        /etc/ansible/openstack.yaml, /etc/openstack/clouds.yaml or ~/.config/openstack/clouds.yaml, then from
        standard environment variables, then finally by explicit parameters in plays. More information can be found
        at http://docs.openstack.org/developer/os-client-config
Requirements:  python >= 2.6, python >= 2.7, shade

EXAMPLES:
# Create a zone named "example.net"
- os_zone:
    cloud: mycloud
    state: present
    name: example.net.
    zone_type: primary
    email: test@example.net
    description: Test zone
    ttl: 3600

# Update the TTL on existing "example.net." zone
- os_zone:
    cloud: mycloud
    state: present
    name: example.net.
    ttl: 7200

# Delete zone named "example.net."
- os_zone:
    cloud: mycloud
    state: absent
    name: example.net.

RETURN VALUES:
zone:
    description: Dictionary describing the zone.
    returned: On success when I(state) is 'present'.
    type: dictionary
    contains:
        id:
            description: Unique zone ID
            type: string
            sample: "c1c530a3-3619-46f3-b0f6-236927b2618c"
        name:
            description: Zone name
            type: string
            sample: "example.net."
        type:
            description: Zone type
            type: string
            sample: "PRIMARY"
        email:
            description: Zone owner email
            type: string
            sample: "test@example.net"
        description:
            description: Zone description
            type: string
            sample: "Test description"
        ttl:
            description: Zone TTL value
            type: int
            sample: 3600
        masters:
            description: Zone master nameservers
            type: list
            sample: []


MAINTAINERS: Ricardo Carrillo Cruz (@rcarrillocruz)

METADATA:
	Status: ['preview']
	Supported_by: community
> OSX_DEFAULTS    (/usr/lib/python2.7/site-packages/ansible/modules/system/osx_defaults.py)

  osx_defaults allows users to read, write, and delete Mac OS X user defaults from Ansible scripts. Mac OS X applications
  and other programs use the defaults system to record user preferences and other information that must be maintained
  when the applications aren't running (such as default font for new documents, or the position of an Info panel).

Options (= is mandatory):

- array_add
        Add new elements to the array for a key which has an array as its value.
        (Choices: true, false)[Default: False]
- domain
        The domain is a domain name of the form com.companyname.appname.
        [Default: NSGlobalDomain]
- host
        The host on which the preference should apply. The special value "currentHost" corresponds to the "-currentHost"
        switch of the defaults commandline tool.
        [Default: None]
= key
        The key of the user preference

- state
        The state of the user defaults
        (Choices: present, absent)[Default: present]
- type
        The type of value to write.
        (Choices: array, bool, boolean, date, float, int, integer, string)[Default: string]
- value
        The value to write. Only required when state = present.
        [Default: None]
Notes:
  * Apple Mac caches defaults. You may need to logout and login to apply the changes.
EXAMPLES:
- osx_defaults:
    domain: com.apple.Safari
    key: IncludeInternalDebugMenu
    type: bool
    value: true
    state: present

- osx_defaults:
    domain: NSGlobalDomain
    key: AppleMeasurementUnits
    type: string
    value: Centimeters
    state: present

- osx_defaults:
    domain: com.apple.screensaver
    host: currentHost
    key: showClock
    type: int
    value: 1

- osx_defaults:
    key: AppleMeasurementUnits
    type: string
    value: Centimeters

- osx_defaults:
    key: AppleLanguages
    type: array
    value:
      - en
      - nl

- osx_defaults:
    domain: com.geekchimp.macable
    key: ExampleKeyToRemove
    state: absent


MAINTAINERS: Franck Nijhof (@frenck)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> OSX_SAY    (/usr/lib/python2.7/site-packages/ansible/modules/notification/osx_say.py)

  makes an OS computer speak!  Amuse your friends, annoy your coworkers!

Options (= is mandatory):

= msg
        What to say

- voice
        What voice to use
        [Default: (null)]
Notes:
  * If you like this module, you may also be interested in the osx_say callback in the plugins/ directory of the
        source checkout.
Requirements:  say

EXAMPLES:
- osx_say:
    msg: '{{ inventory_hostname }} is all done'
    voice: Zarvox
  delegate_to: localhost


MAINTAINERS: Ansible Core Team, Michael DeHaan (@mpdehaan)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> OVH_IP_LOADBALANCING_BACKEND    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovh/ovh_ip_loadbalancing_backend.py)

  Manage OVH (French European hosting provider) LoadBalancing IP backends

Options (= is mandatory):

= application_key
        The applicationKey to use

= application_secret
        The application secret to use

= backend
        The IP address of the backend to update / modify / delete

= consumer_key
        The consumer key to use

= endpoint
        The endpoint to use ( for instance ovh-eu)

= name
        Name of the LoadBalancing internal name (ip-X.X.X.X)

- probe
        Determines the type of probe to use for this backend
        (Choices: none, http, icmp, oco)[Default: none]
- state
        Determines whether the backend is to be created/modified or deleted
        (Choices: present, absent)[Default: present]
- timeout
        The timeout in seconds used to wait for a task to be completed.
        [Default: 120]
- weight
        Determines the weight for this backend
        [Default: 8]
Notes:
  * Uses the python OVH Api https://github.com/ovh/python-ovh. You have to create an application (a key and secret)
        with a consummer key as described into https://eu.api.ovh.com/g934.first_step_with_api
Requirements:  ovh >  0.3.5

EXAMPLES:
# Adds or modify the backend '212.1.1.1' to a
# loadbalancing 'ip-1.1.1.1'
- ovh_ip_loadbalancing:
    name: ip-1.1.1.1
    backend: 212.1.1.1
    state: present
    probe: none
    weight: 8
    endpoint: ovh-eu
    application_key: yourkey
    application_secret: yoursecret
    consumer_key: yourconsumerkey

# Removes a backend '212.1.1.1' from a loadbalancing 'ip-1.1.1.1'
- ovh_ip_loadbalancing:
    name: ip-1.1.1.1
    backend: 212.1.1.1
    state: absent
    endpoint: ovh-eu
    application_key: yourkey
    application_secret: yoursecret
    consumer_key: yourconsumerkey

RETURN VALUES:


MAINTAINERS: Pascal HERAUD @pascalheraud

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/ovirt.py)

  This module only supports oVirt/RHEV version 3. A newer module [ovirt_vms] supports oVirt/RHV version 4. Allows you to
  create new instances, either from scratch or an image, in addition to deleting or stopping instances on the oVirt/RHEV
  platform.

Options (= is mandatory):

- disk_alloc
        define if disk is thin or preallocated
        (Choices: thin, preallocated)[Default: thin]
- disk_int
        interface type of the disk
        (Choices: virtio, ide)[Default: virtio]
- image
        template to use for the instance
        [Default: None]
- instance_cores
        define the instance's number of cores
        [Default: 1]
- instance_cpus
        the instance's number of cpu's
        [Default: 1]
- instance_disksize
        size of the instance's disk in GB
        [Default: None]
- instance_dns
        define the instance's Primary DNS server
        [Default: (null)]
- instance_domain
        define the instance's Domain
        [Default: (null)]
- instance_hostname
        define the instance's Hostname
        [Default: (null)]
- instance_ip
        define the instance's IP
        [Default: (null)]
- instance_key
        define the instance's Authorized key
        [Default: (null)]
- instance_mem
        the instance's amount of memory in MB
        [Default: None]
= instance_name
        the name of the instance to use
        [Default: None]
- instance_netmask
        define the instance's Netmask
        [Default: (null)]
- instance_network
        the logical network the machine should belong to
        [Default: rhevm]
- instance_nic
        name of the network interface in oVirt/RHEV
        [Default: None]
- instance_os
        type of Operating System
        [Default: None]
- instance_rootpw
        define the instance's Root password
        [Default: (null)]
- instance_type
        define if the instance is a server or desktop
        (Choices: server, desktop)[Default: server]
= password
        password of the user to authenticate with
        [Default: None]
- region
        the oVirt/RHEV datacenter where you want to deploy to
        [Default: None]
- resource_type
        whether you want to deploy an image or create an instance from scratch.
        (Choices: new, template)[Default: None]
- sdomain
        the Storage Domain where you want to create the instance's disk on.
        [Default: None]
- state
        create, terminate or remove instances
        (Choices: present, absent, shutdown, started, restarted)[Default: present]
= url
        the url of the oVirt instance
        [Default: None]
= user
        the user to authenticate with
        [Default: None]
- zone
        deploy the image to this oVirt cluster
        [Default: None]
Requirements:  python >= 2.6, ovirt-engine-sdk-python

EXAMPLES:
# Basic example provisioning from image.

ovirt:
    user: admin@internal
    url: https://ovirt.example.com
    instance_name: ansiblevm04
    password: secret
    image: centos_64
    zone: cluster01
    resource_type: template"

# Full example to create new instance from scratch
ovirt:
    instance_name: testansible
    resource_type: new
    instance_type: server
    user: admin@internal
    password: secret
    url: https://ovirt.example.com
    instance_disksize: 10
    zone: cluster01
    region: datacenter1
    instance_cpus: 1
    instance_nic: nic1
    instance_network: rhevm
    instance_mem: 1000
    disk_alloc: thin
    sdomain: FIBER01
    instance_cores: 1
    instance_os: rhel_6x64
    disk_int: virtio"

# stopping an instance
ovirt:
    instance_name: testansible
    state: stopped
    user: admin@internal
    password: secret
    url: https://ovirt.example.com

# starting an instance
ovirt:
    instance_name: testansible
    state: started
    user: admin@internal
    password: secret
    url: https://ovirt.example.com

# starting an instance with cloud init information
ovirt:
    instance_name: testansible
    state: started
    user: admin@internal
    password: secret
    url: https://ovirt.example.com
    hostname: testansible
    domain: ansible.local
    ip: 192.0.2.100
    netmask: 255.255.255.0
    gateway: 192.0.2.1
    rootpw: bigsecret



MAINTAINERS: Vincent Van der Kussen (@vincentvdk)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_AFFINITY_GROUPS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_affinity_groups.py)

  This module manage affinity groups in oVirt. It can also manage assignments of those groups to VMs.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- cluster
        Name of the cluster of the affinity group.
        [Default: (null)]
- description
        Description of the affinity group.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- host_enforcing
        If `true' VM cannot start on host if it does not satisfy the `host_rule'.
        `This parameter is support since oVirt 4.1 version.'
        [Default: (null)]
- host_rule
        If `positive' `all' VMs in this group should run on the this host.
        If `negative' `no' VMs in this group should run on the this host.
        `This parameter is support since oVirt 4.1 version.'
        (Choices: positive, negative)[Default: (null)]
- hosts
        List of the hosts names, which should have assigned this affinity group.
        `This parameter is support since oVirt 4.1 version.'
        [Default: (null)]
= name
        Name of the the affinity group to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- state
        Should the affinity group be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- vm_enforcing
        If `true' VM cannot start if it does not satisfy the `vm_rule'.
        [Default: (null)]
- vm_rule
        If `positive' `all' VMs in this group should run on the host defined by `host_rule'.
        If `negative' `no' VMs in this group should run on the host defined by `host_rule'.
        If `disabled' this affinity group doesn't take effect.
        (Choices: positive, negative, disabled)[Default: (null)]
- vms
        List of the VMs names, which should have assigned this affinity group.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create(if not exists) and assign affinity group to VMs vm1 and vm2 and host host1
- ovirt_affinity_groups:
    name: mygroup
    cluster: mycluster
    vm_enforcing: true
    vm_rule: positive
    host_enforcing: true
    host_rule: positive
    vms:
      - vm1
      - vm2
    hosts:
      - host1

# Detach VMs from affinity group and disable VM rule:
- ovirt_affinity_groups:
    name: mygroup
    cluster: mycluster
    vm_enforcing: false
    vm_rule: disabled
    host_enforcing: true
    host_rule: positive
    vms: []
    hosts:
      - host1
      - host2

# Remove affinity group
- ovirt_affinity_groups:
    state: absent
    cluster: mycluster
    name: mygroup

RETURN VALUES:
id:
    description: ID of the affinity group which is managed
    returned: On success if affinity group is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
affinity_group:
    description: "Dictionary of all the affinity group attributes. Affinity group attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/affinity_group."
    returned: On success if affinity group is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_AFFINITY_LABELS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_affinity_labels.py)

  This module manage affinity labels in oVirt. It can also manage assignments of those labels to hosts and VMs.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- cluster
        Name of the cluster where vms and hosts resides.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- hosts
        List of the hosts names, which should have assigned this affinity label.
        [Default: (null)]
= name
        Name of the the affinity label to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- state
        Should the affinity label be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- vms
        List of the VMs names, which should have assigned this affinity label.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create(if not exists) and assign affinity label to vms vm1 and vm2 and host host1
- ovirt_affinity_labels:
    name: mylabel
    cluster: mycluster
    vms:
      - vm1
      - vm2
    hosts:
      - host1

# To detach all VMs from label
- ovirt_affinity_labels:
    name: mylabel
    cluster: mycluster
    vms: []

# Remove affinity label
- ovirt_affinity_labels:
    state: absent
    name: mylabel

RETURN VALUES:
id:
    description: ID of the affinity label which is managed
    returned: On success if affinity label is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
affinity_label:
    description: "Dictionary of all the affinity label attributes. Affinity label attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/affinity_label."
    returned: On success if affinity label is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_AFFINITY_LABELS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_affinity_labels_facts.py)

  Retrieve facts about one or more oVirt affinity labels.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- host
        Name of the host, which affinity labels should be listed.
        [Default: (null)]
- name
        Name of the affinity labels which should be listed.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- vm
        Name of the VM, which affinity labels should be listed.
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_affinity_labels' fact, which contains a list of affinity labels.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all affinity labels, which names start with C(label):
- ovirt_affinity_labels_facts:
    name: label*
- debug:
    var: affinity_labels

# Gather facts about all affinity labels, which are assigned to VMs
# which names start with C(postgres):
- ovirt_affinity_labels_facts:
    vm: postgres*
- debug:
    var: affinity_labels

# Gather facts about all affinity labels, which are assigned to hosts
# which names start with C(west):
- ovirt_affinity_labels_facts:
    host: west*
- debug:
    var: affinity_labels

# Gather facts about all affinity labels, which are assigned to hosts
# which names start with C(west) or VMs which names start with C(postgres):
- ovirt_affinity_labels_facts:
    host: west*
    vm: postgres*
- debug:
    var: affinity_labels

RETURN VALUES:
ovirt_affinity_labels:
    description: "List of dictionaries describing the affinity labels. Affinity labels attribues are mapped to dictionary keys,
                  all affinity labels attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/affinity_label."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_AUTH    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_auth.py)

  This module authenticates to oVirt engine and creates SSO token, which should be later used in all other oVirt modules,
  so all modules don't need to perform login and logout. This module returns an Ansible fact called `ovirt_auth'. Every
  module can use this fact as `auth' parameter, to perform authentication.

Options (= is mandatory):

- ca_file
        A PEM file containing the trusted CA certificates. The certificate presented by the server will be verified using
        these CA certificates. If `ca_file' parameter is not set, system wide CA certificate store is used.
        [Default: (null)]
- compress
        A boolean flag indicating if the SDK should ask the server to send compressed responses. The default is `True'.
        Note that this is a hint for the server, and that it may return uncompressed data even when this parameter is set
        to `True'.
        [Default: (null)]
- insecure
        A boolean flag that indicates if the server TLS certificate and host name should be checked.
        [Default: (null)]
- kerberos
        A boolean flag indicating if Kerberos authentication should be used instead of the default basic authentication.
        [Default: (null)]
= password
        The password of the user.

- state
        Specifies if a token should be created or revoked.
        (Choices: present, absent)[Default: present]
- timeout
        The maximum total time to wait for the response, in seconds. A value of zero (the default) means wait forever. If
        the timeout expires before the response is received an exception will be raised.
        [Default: (null)]
= url
        A string containing the base URL of the server. For example: `https://server.example.com/ovirt-engine/api'.

= username
        The name of the user. For example: `admin@internal'.

Notes:
  * Everytime you use ovirt_auth module to obtain ticket, you need to also revoke the ticket, when you no longer
        need it, otherwise the ticket would be revoked by engine when it expires. For an example of how to achieve
        that, please take a look at `examples' section.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
  * Note that in oVirt 4.1 if you want to use a user which is not administrator you must enable the
        `ENGINE_API_FILTER_BY_DEFAULT' variable in engine. In oVirt 4.2 and later it's enabled by default.
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
tasks:
  - block:
       # Create a vault with `ovirt_password` variable which store your
       # oVirt user's password, and include that yaml file with variable:
       - include_vars: ovirt_password.yml

       - name: Obtain SSO token with using username/password credentials
         ovirt_auth:
           url: https://ovirt.example.com/ovirt-engine/api
           username: admin@internal
           ca_file: ca.pem
           password: "{{ ovirt_password }}"

       # Previous task generated I(ovirt_auth) fact, which you can later use
       # in different modules as follows:
       - ovirt_vms:
           auth: "{{ ovirt_auth }}"
           state: absent
           name: myvm

    always:
      - name: Always revoke the SSO token
        ovirt_auth:
          state: absent
          ovirt_auth: "{{ ovirt_auth }}"

RETURN VALUES:
ovirt_auth:
    description: Authentication facts, needed to perform authentication to oVirt.
    returned: success
    type: dictionary
    contains:
        token:
            description: SSO token which is used for connection to oVirt engine.
            returned: success
            type: string
            sample: "kdfVWp9ZgeewBXV-iq3Js1-xQJZPSEQ334FLb3eksoEPRaab07DhZ8ED8ghz9lJd-MQ2GqtRIeqhvhCkrUWQPw"
        url:
            description: URL of the oVirt engine API endpoint.
            returned: success
            type: string
            sample: "https://ovirt.example.com/ovirt-engine/api"
        ca_file:
            description: CA file, which is used to verify SSL/TLS connection.
            returned: success
            type: string
            sample: "ca.pem"
        insecure:
            description: Flag indicating if insecure connection is used.
            returned: success
            type: bool
            sample: False
        timeout:
            description: Number of seconds to wait for response.
            returned: success
            type: int
            sample: 0
        compress:
            description: Flag indicating if compression is used for connection.
            returned: success
            type: bool
            sample: True
        kerberos:
            description: Flag indicating if kerberos is used for authentication.
            returned: success
            type: bool
            sample: False


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_CLUSTERS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_clusters.py)

  Module to manage clusters in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- ballooning
        If `True' enable memory balloon optimization. Memory balloon is used to re-distribute / reclaim the host memory
        based on VM needs in a dynamic way.
        [Default: (null)]
- comment
        Comment of the cluster.
        [Default: (null)]
- compatibility_version
        The compatibility version of the cluster. All hosts in this cluster must support at least this compatibility
        version.
        [Default: (null)]
- cpu_arch
        CPU architecture of cluster.
        (Choices: x86_64, ppc64, undefined)[Default: (null)]
- cpu_type
        CPU codename. For example `Intel SandyBridge Family'.
        [Default: (null)]
- data_center
        Datacenter name where cluster reside.
        [Default: (null)]
- description
        Description of the cluster.
        [Default: (null)]
- fence_connectivity_threshold
        The threshold used by `fence_skip_if_connectivity_broken'.
        [Default: (null)]
- fence_enabled
        If `True' enables fencing on the cluster.
        Fencing is enabled by default.
        [Default: (null)]
- fence_skip_if_connectivity_broken
        If `True' fencing will be temporarily disabled if the percentage of hosts in the cluster that are experiencing
        connectivity issues is greater than or equal to the defined threshold.
        The threshold can be specified by `fence_connectivity_threshold'.
        [Default: (null)]
- fence_skip_if_sd_active
        If `True' any hosts in the cluster that are Non Responsive and still connected to storage will not be fenced.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- gluster
        If `True', hosts in this cluster will be used as Gluster Storage server nodes, and not for running virtual
        machines.
        By default the cluster is created for virtual machine hosts.
        [Default: (null)]
- ha_reservation
        If `True' enable the oVirt to monitor cluster capacity for highly available virtual machines.
        [Default: (null)]
- host_reason
        If `True' enable an optional reason field when a host is placed into maintenance mode from the Manager, allowing
        the administrator to provide an explanation for the maintenance.
        [Default: (null)]
- ksm
        I `True' MoM enables to run Kernel Same-page Merging `KSM' when necessary and when it can yield a memory saving
        benefit that outweighs its CPU cost.
        [Default: (null)]
- ksm_numa
        If `True' enables KSM `ksm' for best berformance inside NUMA nodes.
        [Default: (null)]
- memory_policy
        `disabled' - Disables memory page sharing.
        `server' - Sets the memory page sharing threshold to 150% of the system memory on each host.
        `desktop' - Sets the memory page sharing threshold to 200% of the system memory on each host.
        (Choices: disabled, server, desktop)[Default: (null)]
- migration_auto_converge
        If `True' auto-convergence is used during live migration of virtual machines.
        Used only when `migration_policy' is set to `legacy'.
        Following options are supported:
        `true' - Override the global setting to `true'.
        `false' - Override the global setting to `false'.
        `inherit' - Use value which is set globally.
        (Choices: true, false, inherit)[Default: (null)]
- migration_bandwidth
        The bandwidth settings define the maximum bandwidth of both outgoing and incoming migrations per host.
        Following bandwith options are supported:
        `auto' - Bandwidth is copied from the `rate limit' [Mbps] setting in the data center host network QoS.
        `hypervisor_default' - Bandwidth is controlled by local VDSM setting on sending host.
        `custom' - Defined by user (in Mbps).
        (Choices: auto, hypervisor_default, custom)[Default: (null)]
- migration_bandwidth_limit
        Set the `custom' migration bandwidth limit.
        This parameter is used only when `migration_bandwidth' is `custom'.
        [Default: (null)]
- migration_compressed
        If `True' compression is used during live migration of the virtual machine.
        Used only when `migration_policy' is set to `legacy'.
        Following options are supported:
        `true' - Override the global setting to `true'.
        `false' - Override the global setting to `false'.
        `inherit' - Use value which is set globally.
        (Choices: true, false, inherit)[Default: (null)]
- migration_policy
        A migration policy defines the conditions for live migrating virtual machines in the event of host failure.
        Following policies are supported:
        `legacy' - Legacy behavior of 3.6 version.
        `minimal_downtime' - Virtual machines should not experience any significant downtime.
        `suspend_workload' - Virtual machines may experience a more significant downtime.
        (Choices: legacy, minimal_downtime, suspend_workload)[Default: (null)]
= name
        Name of the the cluster to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- network
        Management network of cluster to access cluster hosts.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- resilience_policy
        The resilience policy defines how the virtual machines are prioritized in the migration.
        Following values are supported:
        `do_not_migrate' -  Prevents virtual machines from being migrated.
        `migrate' - Migrates all virtual machines in order of their defined priority.
        `migrate_highly_available' - Migrates only highly available virtual machines to prevent overloading other hosts.
        (Choices: do_not_migrate, migrate, migrate_highly_available)[Default: (null)]
- rng_sources
        List that specify the random number generator devices that all hosts in the cluster will use.
        Supported generators are: `hwrng' and `random'.
        [Default: (null)]
- scheduling_policy
        Name of the scheduling policy to be used for cluster.
        [Default: (null)]
- serial_policy
        Specify a serial number policy for the virtual machines in the cluster.
        Following options are supported:
        `vm' - Sets the virtual machine's UUID as its serial number.
        `host' - Sets the host's UUID as the virtual machine's serial number.
        `custom' - Allows you to specify a custom serial number in `serial_policy_value'.
        [Default: (null)]
- serial_policy_value
        Allows you to specify a custom serial number.
        This parameter is used only when `serial_policy' is `custom'.
        [Default: (null)]
- spice_proxy
        The proxy by which the SPICE client will connect to virtual machines.
        The address must be in the following format: `protocol://[host]:[port]'
        [Default: (null)]
- state
        Should the cluster be present or absent
        (Choices: present, absent)[Default: present]
- switch_type
        Type of switch to be used by all networks in given cluster. Either `legacy' which is using linux brigde or `ovs'
        using Open vSwitch.
        (Choices: legacy, ovs)[Default: (null)]
- threads_as_cores
        If `True' the exposed host threads would be treated as cores which can be utilized by virtual machines.
        [Default: (null)]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- trusted_service
        If (True) enable integration with an OpenAttestation server.
        [Default: (null)]
- virt
        If `True', hosts in this cluster will be used to run virtual machines.
        [Default: (null)]
- vm_reason
        If `True' enable an optional reason field when a virtual machine is shut down from the Manager, allowing the
        administrator to provide an explanation for the maintenance.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create cluster
- ovirt_clusters:
    data_center: mydatacenter
    name: mycluster
    cpu_type: Intel SandyBridge Family
    description: mycluster
    compatibility_version: 4.0

# Create virt service cluster:
- ovirt_clusters:
    data_center: mydatacenter
    name: mycluster
    cpu_type: Intel Nehalem Family
    description: mycluster
    switch_type: legacy
    compatibility_version: 4.0
    ballooning: true
    gluster: false
    threads_as_cores: true
    ha_reservation: true
    trusted_service: false
    host_reason: false
    vm_reason: true
    ksm_numa: true
    memory_policy: server
    rng_sources:
      - hwrng
      - random

# Remove cluster
- ovirt_clusters:
    state: absent
    name: mycluster

RETURN VALUES:
id:
    description: ID of the cluster which is managed
    returned: On success if cluster is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
cluster:
    description: "Dictionary of all the cluster attributes. Cluster attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/cluster."
    returned: On success if cluster is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_CLUSTERS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_clusters_facts.py)

  Retrieve facts about one or more oVirt clusters.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search cluster X from datacenter Y use following pattern: name=X and datacenter=Y
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_clusters' fact, which contains a list of clusters.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all clusters which names start with C<production>:
- ovirt_clusters_facts:
    pattern: name=production*
- debug:
    var: ovirt_clusters

RETURN VALUES:
ovirt_clusters:
    description: "List of dictionaries describing the clusters. Cluster attribues are mapped to dictionary keys,
                  all clusters attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/cluster."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_DATACENTERS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_datacenters.py)

  Module to manage data centers in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- comment
        Comment of the data center.
        [Default: (null)]
- compatibility_version
        Compatibility version of the data center.
        [Default: (null)]
- description
        Description of the data center.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- local
        `True' if the data center should be local, `False' if should be shared.
        Default value is set by engine.
        [Default: (null)]
- mac_pool
        MAC pool to be used by this datacenter.
        IMPORTANT: This option is deprecated in oVirt 4.1. You should use `mac_pool' in `ovirt_clusters' module, as MAC
        pools are set per cluster since 4.1.
        [Default: (null)]
= name
        Name of the the data center to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- quota_mode
        Quota mode of the data center. One of `disabled', `audit' or `enabled'
        (Choices: disabled, audit, enabled)[Default: (null)]
- state
        Should the data center be present or absent
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create datacenter
- ovirt_datacenters:
    name: mydatacenter
    local: True
    compatibility_version: 4.0
    quota_mode: enabled

# Remove datacenter
- ovirt_datacenters:
    state: absent
    name: mydatacenter

RETURN VALUES:
id:
    description: "ID of the managed datacenter"
    returned: "On success if datacenter is found."
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
data_center:
    description: "Dictionary of all the datacenter attributes. Datacenter attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/datacenter."
    returned: "On success if datacenter is found."


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_DATACENTERS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_datacenters_facts.py)

  Retrieve facts about one or more oVirt datacenters.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search datacenter `X' use following pattern: `name=X'
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_datacenters' fact, which contains a list of datacenters.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all data centers which names start with C(production):
- ovirt_datacenters_facts:
    pattern: name=production*
- debug:
    var: ovirt_datacenters

RETURN VALUES:
ovirt_datacenters:
    description: "List of dictionaries describing the datacenters. Datacenter attribues are mapped to dictionary keys,
                  all datacenters attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/data_center."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_DISKS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_disks.py)

  Module to manage Virtual Machine and floating disks in oVirt.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- bootable
        `True' if the disk should be bootable. By default when disk is created it isn't bootable.
        [Default: (null)]
- download_image_path
        Path on a file system where disk should be downloaded.
        Note that you must have an valid oVirt engine CA in your system trust store or you must provide it in `ca_file'
        parameter.
        Note that the disk is not downloaded when the file already exists, but you can forcibly download the disk when
        using `force' I (true).
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- force
        Please take a look at `image_path' documentation to see the correct usage of this parameter.
        [Default: (null)]
- format
        Specify format of the disk.
        If (cow) format is used, disk will by created as sparse, so space will be allocated for the volume as needed,
        also known as `thin provision'.
        If (raw) format is used, disk storage will be allocated right away, also known as `preallocated'.
        Note that this option isn't idempotent as it's not currently possible to change format of the disk via API.
        (Choices: raw, cow)[Default: (null)]
- id
        ID of the disk to manage. Either `id' or `name' is required.
        [Default: (null)]
- interface
        Driver of the storage interface.
        (Choices: virtio, ide, virtio_scsi)[Default: virtio]
- logical_unit
        Dictionary which describes LUN to be directly attached to VM:
        `address' - Address of the storage server. Used by iSCSI.
        `port' - Port of the storage server. Used by iSCSI.
        `target' - iSCSI target.
        `lun_id' - LUN id.
        `username' - CHAP Username to be used to access storage server. Used by iSCSI.
        `password' - CHAP Password of the user to be used to access storage server. Used by iSCSI.
        `storage_type' - Storage type either `fcp' or `iscsi'.
        [Default: (null)]
- name
        Name of the disk to manage. Either `id' or `name'/`alias' is required.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- profile
        Disk profile name to be attached to disk. By default profile is chosen by oVirt engine.
        [Default: (null)]
- shareable
        `True' if the disk should be shareable. By default when disk is created it isn't shareable.
        [Default: (null)]
- size
        Size of the disk. Size should be specified using IEC standard units. For example 10GiB, 1024MiB, etc.
        Size can be only increased, not decreased.
        [Default: (null)]
- state
        Should the Virtual Machine disk be present/absent/attached/detached.
        (Choices: present, absent, attached, detached)[Default: present]
- storage_domain
        Storage domain name where disk should be created. By default storage is chosen by oVirt engine.
        [Default: (null)]
- storage_domains
        Storage domain names where disk should be copied.
        `**IMPORTANT**'
        There is no reliable way to achieve idempotency, so every time you specify this parameter the disks are copied,
        so please handle your playbook accordingly to not copy the disks all the time. This is valid only for VM and
        floating disks, template disks works as expected.
        [Default: (null)]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- upload_image_path
        Path to disk image, which should be uploaded.
        Note that currently we support only compability version 0.10 of the qcow disk.
        Note that you must have an valid oVirt engine CA in your system trust store or you must provide it in `ca_file'
        parameter.
        Note that there is no reliable way to achieve idempotency, so if you want to upload the disk even if the disk
        with `id' or `name' exists, then please use `force' `true'. If you will use `force' `false', which is default,
        then the disk image won't be uploaded.
        [Default: (null)]
- vm_id
        ID of the Virtual Machine to manage. Either `vm_id' or `vm_name' is required if `state' is `attached' or
        `detached'.
        [Default: (null)]
- vm_name
        Name of the Virtual Machine to manage. Either `vm_id' or `vm_name' is required if `state' is `attached' or
        `detached'.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create and attach new disk to VM
- ovirt_disks:
    name: myvm_disk
    vm_name: rhel7
    size: 10GiB
    format: cow
    interface: virtio

# Attach logical unit to VM rhel7
- ovirt_disks:
    vm_name: rhel7
    logical_unit:
      target: iqn.2016-08-09.brq.str-01:omachace
      id: 1IET_000d0001
      address: 10.34.63.204
    interface: virtio

# Detach disk from VM
- ovirt_disks:
    state: detached
    name: myvm_disk
    vm_name: rhel7
    size: 10GiB
    format: cow
    interface: virtio

# Upload local image to disk and attach it to vm:
# Since Ansible 2.3
- ovirt_disks:
    name: mydisk
    vm_name: myvm
    interface: virtio
    size: 10GiB
    format: cow
    image_path: /path/to/mydisk.qcow2
    storage_domain: data

# Download disk to local file system:
# Since Ansible 2.3
- ovirt_disks:
    id: 7de90f31-222c-436c-a1ca-7e655bd5b60c
    download_image_path: /home/user/mydisk.qcow2

RETURN VALUES:
id:
    description: "ID of the managed disk"
    returned: "On success if disk is found."
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
disk:
    description: "Dictionary of all the disk attributes. Disk attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/disk."
    returned: "On success if disk is found and C(vm_id) or C(vm_name) wasn't passed."

disk_attachment:
    description: "Dictionary of all the disk attachment attributes. Disk attachment attributes can be found
                  on your oVirt instance at following url:
                  https://ovirt.example.com/ovirt-engine/api/model#types/disk_attachment."
    returned: "On success if disk is found and C(vm_id) or C(vm_name) was passed and VM was found."


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_EXTERNAL_PROVIDERS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_external_providers.py)

  Module to manage external providers in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- authentication_url
        Keystone authentication URL of the openstack provider.
        Applicable for those types: `os_image', `os_volume' and `network'.
        [Default: (null)]
- data_center
        Name of the data center where provider should be attached.
        Applicable for those type: `os_volume'.
        [Default: (null)]
- description
        Description of the external provider.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- name
        Name of the the external provider to manage.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- network_type
        Type of the external network provider either external (for example OVN) or neutron.
        Applicable if `type' is `network'.
        (Choices: external, neutron)[Default: [u'external']]
- password
        Password of the user specified in `username' parameter.
        Applicable for all types.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- read_only
        Specify if the network should be read only.
        Applicable if `type' is `network'.
        [Default: (null)]
- state
        Should the external be present or absent
        (Choices: present, absent)[Default: present]
- tenant_name
        Name of the tenant.
        Applicable for those types: `os_image', `os_volume' and `network'.
        [Default: (null)]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- type
        Type of the external provider.
        (Choices: os_image, network, os_volume, foreman)[Default: (null)]
- url
        URL where external provider is hosted.
        Applicable for those types: `os_image', `os_volume', `network' and `foreman'.
        [Default: (null)]
- username
        Username to be used for login to external provider.
        Applicable for all types.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add image external provider:
- ovirt_external_providers:
    name: image_provider
    type: os_image
    url: http://10.34.63.71:9292
    username: admin
    password: 123456
    tenant: admin
    auth_url: http://10.34.63.71:35357/v2.0/

# Add foreman provider:
- ovirt_external_providers:
    name: foreman_provider
    type: foreman
    url: https://foreman.example.com
    username: admin
    password: 123456

# Add external network provider for OVN:
- ovirt_external_providers:
    name: ovn_provider
    type: network
    network_type: external
    url: http://1.2.3.4:9696

# Remove image external provider:
- ovirt_external_providers:
    state: absent
    name: image_provider
    type: os_image

RETURN VALUES:
id:
    description: ID of the external provider which is managed
    returned: On success if external provider is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
external_host_provider:
    description: "Dictionary of all the external_host_provider attributes. External provider attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/external_host_provider."
    returned: "On success and if parameter 'type: foreman' is used."
    type: dictionary
openstack_image_provider:
    description: "Dictionary of all the openstack_image_provider attributes. External provider attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/openstack_image_provider."
    returned: "On success and if parameter 'type: os_image' is used."
    type: dictionary
openstack_volume_provider:
    description: "Dictionary of all the openstack_volume_provider attributes. External provider attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/openstack_volume_provider."
    returned: "On success and if parameter 'type: os_volume' is used."
    type: dictionary
openstack_network_provider:
    description: "Dictionary of all the openstack_network_provider attributes. External provider attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/openstack_network_provider."
    returned: "On success and if parameter 'type: network' is used."
    type: dictionary


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_EXTERNAL_PROVIDERS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_external_providers_facts.py)

  Retrieve facts about one or more oVirt external providers.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- name
        Name of the external provider, can be used as glob expression.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
= type
        Type of the external provider.
        (Choices: os_image, os_network, os_volume, foreman)
Notes:
  * This module creates a new top-level `ovirt_external_providers' fact, which contains a list of
        external_providers.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all image external providers named C<glance>:
- ovirt_external_providers_facts:
    type: os_image
    name: glance
- debug:
    var: ovirt_external_providers

RETURN VALUES:
external_host_providers:
    description: "List of dictionaries of all the external_host_provider attributes. External provider attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/external_host_provider."
    returned: "On success and if parameter 'type: foreman' is used."
    type: list
openstack_image_providers:
    description: "List of dictionaries of all the openstack_image_provider attributes. External provider attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/openstack_image_provider."
    returned: "On success and if parameter 'type: os_image' is used."
    type: list
openstack_volume_providers:
    description: "List of dictionaries of all the openstack_volume_provider attributes. External provider attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/openstack_volume_provider."
    returned: "On success and if parameter 'type: os_volume' is used."
    type: list
openstack_network_providers:
    description: "List of dictionaries of all the openstack_network_provider attributes. External provider attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/openstack_network_provider."
    returned: "On success and if parameter 'type: os_network' is used."
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_GROUPS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_groups.py)

  Module to manage groups in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

= authz_name
        Authorization provider of the group. In previous versions of oVirt known as domain.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
= name
        Name of the the group to manage.

- namespace
        Namespace of the authorization provider, where group resides.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- state
        Should the group be present/absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add group group1 from authorization provider example.com-authz
ovirt_groups:
    name: group1
    domain: example.com-authz

# Add group group1 from authorization provider example.com-authz
# In case of multi-domain Active Directory setup, you should pass
# also namespace, so it adds correct group:
ovirt_groups:
    name: group1
    namespace: dc=ad2,dc=example,dc=com
    domain: example.com-authz

# Remove group group1 with authorization provider example.com-authz
ovirt_groups:
    state: absent
    name: group1
    domain: example.com-authz

RETURN VALUES:
id:
    description: ID of the group which is managed
    returned: On success if group is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
group:
    description: "Dictionary of all the group attributes. Group attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/group."
    returned: On success if group is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_GROUPS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_groups_facts.py)

  Retrieve facts about one or more oVirt groups.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search group X use following pattern: name=X
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_groups' fact, which contains a list of groups.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all groups which names start with C(admin):
- ovirt_groups_facts:
    pattern: name=admin*
- debug:
    var: ovirt_groups

RETURN VALUES:
ovirt_groups:
    description: "List of dictionaries describing the groups. Group attribues are mapped to dictionary keys,
                  all groups attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/group."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_HOST_NETWORKS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_host_networks.py)

  Module to manage host networks in oVirt.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- bond
        Dictionary describing network bond:
        `name' - Bond name.
        `mode' - Bonding mode.
        `interfaces' - List of interfaces to create a bond.
        [Default: (null)]
- check
        If `true' verify connectivity between host and engine.
        Network configuration changes will be rolled back if connectivity between engine and the host is lost after
        changing network configuration.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- interface
        Name of the network interface where logical network should be attached.
        [Default: (null)]
- labels
        List of names of the network label to be assigned to bond or interface.
        [Default: (null)]
= name
        Name of the the host to manage networks for.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- networks
        List of dictionary describing networks to be attached to interface or bond:
        `name' - Name of the logical network to be assigned to bond or interface.
        `boot_protocol' - Boot protocol one of the `none', `static' or `dhcp'.
        `address' - IP address in case of `static' boot protocol is used.
        `prefix' - Routing prefix in case of `static' boot protocol is used.
        `gateway' - Gateway in case of `static' boot protocol is used.
        `version' - IP version. Either v4 or v6. Default is v4.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- save
        If `true' network configuration will be persistent, by default they are temporary.
        [Default: (null)]
- state
        Should the host be present/absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create bond on eth0 and eth1 interface, and put 'myvlan' network on top of it:
- name: Bonds
  ovirt_host_networks:
    name: myhost
    bond:
      name: bond0
      mode: 2
      interfaces:
        - eth1
        - eth2
    networks:
      - name: myvlan
        boot_protocol: static
        address: 1.2.3.4
        prefix: 24
        gateway: 1.2.3.4
        version: v4

# Remove bond0 bond from host interfaces:
- ovirt_host_networks:
    state: absent
    name: myhost
    bond:
      name: bond0

# Assign myvlan1 and myvlan2 vlans to host eth0 interface:
- ovirt_host_networks:
    name: myhost
    interface: eth0
    networks:
      - name: myvlan1
      - name: myvlan2

# Remove myvlan2 vlan from host eth0 interface:
- ovirt_host_networks:
    state: absent
    name: myhost
    interface: eth0
    networks:
      - name: myvlan2

# Remove all networks/vlans from host eth0 interface:
- ovirt_host_networks:
    state: absent
    name: myhost
    interface: eth0

RETURN VALUES:
id:
    description: ID of the host NIC which is managed
    returned: On success if host NIC is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
host_nic:
    description: "Dictionary of all the host NIC attributes. Host NIC attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/host_nic."
    returned: On success if host NIC is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_HOST_PM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_host_pm.py)

  Module to manage power management of hosts in oVirt.

Options (= is mandatory):

- address
        Address of the power management interface.
        [Default: (null)]
= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- encrypt_options
        If (true) options will be encrypted when send to agent.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
= name
        Name of the the host to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- options
        Dictionary of additional fence agent options.
        Additional information about options can be found at https://fedorahosted.org/cluster/wiki/FenceArguments.
        [Default: (null)]
- order
        Integer value specifying, by default it's added at the end.
        [Default: (null)]
- password
        Password of the user specified in `username' parameter.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- port
        Power management interface port.
        [Default: (null)]
- slot
        Power management slot.
        [Default: (null)]
- state
        Should the host be present/absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- type
        Type of the power management. oVirt predefined values are `drac5', `ipmilan', `rsa', `bladecenter', `alom',
        `apc', `apc_snmp', `eps', `wti', `rsb', `cisco_ucs', `drac7', `hpblade', `ilo', `ilo2', `ilo3', `ilo4',
        `ilo_ssh', but user can have defined custom type.
        [Default: (null)]
- username
        Username to be used to connect to power management interface.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add fence agent to host 'myhost'
- ovirt_host_pm:
    name: myhost
    address: 1.2.3.4
    options:
      myoption1: x
      myoption2: y
    username: admin
    password: admin
    port: 3333
    type: ipmilan

# Remove ipmilan fence agent with address 1.2.3.4 on host 'myhost'
- ovirt_host_pm:
    state: absent
    name: myhost
    address: 1.2.3.4
    type: ipmilan

RETURN VALUES:
id:
    description: ID of the agent which is managed
    returned: On success if agent is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
agent:
    description: "Dictionary of all the agent attributes. Agent attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/agent."
    returned: On success if agent is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_HOSTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_hosts.py)

  Module to manage hosts in oVirt

Options (= is mandatory):

- address
        Host address. It can be either FQDN (preferred) or IP address.
        [Default: (null)]
= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- cluster
        Name of the cluster, where host should be created.
        [Default: (null)]
- comment
        Description of the host.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- force
        If True host will be forcibly moved to desired state.
        [Default: False]
- hosted_engine
        If `deploy' it means this host should deploy also hosted engine components.
        If `undeploy' it means this host should un-deploy hosted engine components and this host will not function as
        part of the High Availability cluster.
        [Default: (null)]
- kdump_integration
        Specify if host will have enabled Kdump integration.
        (Choices: enabled, disabled)[Default: enabled]
- kernel_params
        List of kernel boot parameters.
        Following are most common kernel parameters used for host:
        Hostdev Passthrough & SR-IOV: intel_iommu=on
        Nested Virtualization: kvm-intel.nested=1
        Unsafe Interrupts: vfio_iommu_type1.allow_unsafe_interrupts=1
        PCI Reallocation: pci=realloc
        `Note:'
        Modifying kernel boot parameters settings can lead to a host boot failure. Please consult the product
        documentation before doing any changes.
        Kernel boot parameters changes require host deploy and restart. The host needs to be `reinstalled' suceesfully
        and then to be `rebooted' for kernel boot parameters to be applied.
        [Default: (null)]
= name
        Name of the the host to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- override_display
        Override the display address of all VMs on this host with specified address.
        [Default: (null)]
- override_iptables
        If True host iptables will be overridden by host deploy script.
        Note that `override_iptables' is `false' by default in oVirt.
        [Default: (null)]
- password
        Password of the root. It's required in case `public_key' is set to `False'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- public_key
        `True' if the public key should be used to authenticate to host.
        It's required in case `password' is not set.
        [Default: False]
- spm_priority
        SPM priority of the host. Integer value from 1 to 10, where higher number means higher priority.
        [Default: (null)]
- state
        State which should a host to be in after successful completion.
        (Choices: present, absent, maintenance, upgraded, started, restarted, stopped, reinstalled)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add host with username/password supporting SR-IOV.
# Note that override_iptables is false by default in oVirt:
- ovirt_hosts:
    cluster: Default
    name: myhost
    address: 10.34.61.145
    password: secret
    override_iptables: true
    kernel_params:
      - intel_iommu=on

# Add host using public key
- ovirt_hosts:
    public_key: true
    cluster: Default
    name: myhost2
    address: 10.34.61.145
    override_iptables: true

# Deploy hosted engine host
- ovirt_hosts:
    cluster: Default
    name: myhost2
    password: secret
    address: 10.34.61.145
    override_iptables: true
    hosted_engine: deploy

# Maintenance
- ovirt_hosts:
    state: maintenance
    name: myhost

# Restart host using power management:
- ovirt_hosts:
    state: restarted
    name: myhost

# Upgrade host
- ovirt_hosts:
    state: upgraded
    name: myhost

# Reinstall host using public key
- ovirt_hosts:
    state: reinstalled
    name: myhost
    public_key: true

# Remove host
- ovirt_hosts:
    state: absent
    name: myhost
    force: True

RETURN VALUES:
id:
    description: ID of the host which is managed
    returned: On success if host is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
host:
    description: "Dictionary of all the host attributes. Host attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/host."
    returned: On success if host is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_HOSTS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_hosts_facts.py)

  Retrieve facts about one or more oVirt hosts.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search host X from datacenter Y use following pattern: name=X and datacenter=Y
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_hosts' fact, which contains a list of hosts.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all hosts which names start with C(host) and
# belong to data center C(west):
- ovirt_hosts_facts:
    pattern: name=host* and datacenter=west
- debug:
    var: ovirt_hosts

RETURN VALUES:
ovirt_hosts:
    description: "List of dictionaries describing the hosts. Host attribues are mapped to dictionary keys,
                  all hosts attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/host."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_MAC_POOLS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_mac_pools.py)

  This module manage MAC pools in oVirt.

Options (= is mandatory):

- allow_duplicates
        If (true) allow a MAC address to be used multiple times in a pool.
        Default value is set by oVirt engine to `false'.
        [Default: (null)]
= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- description
        Description of the MAC pool.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
= name
        Name of the the MAC pool to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- ranges
        List of MAC ranges. The from and to should be splitted by comma.
        For example: 00:1a:4a:16:01:51,00:1a:4a:16:01:61
        [Default: (null)]
- state
        Should the mac pool be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create MAC pool:
- ovirt_mac_pools:
    name: mymacpool
    allow_duplicates: false
    ranges:
      - 00:1a:4a:16:01:51,00:1a:4a:16:01:61
      - 00:1a:4a:16:02:51,00:1a:4a:16:02:61

# Remove MAC pool:
- ovirt_mac_pools:
    state: absent
    name: mymacpool

RETURN VALUES:
id:
    description: ID of the MAC pool which is managed
    returned: On success if MAC pool is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
template:
    description: "Dictionary of all the MAC pool attributes. MAC pool attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/mac_pool."
    returned: On success if MAC pool is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_NETWORKS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_networks.py)

  Module to manage logical networks in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- clusters
        List of dictionaries describing how the network is managed in specific cluster.
        `name' - Cluster name.
        `assigned' - `true' if the network should be assigned to cluster. Default is `true'.
        `required' - `true' if the network must remain operational for all hosts associated with this network.
        `display' - `true' if the network should marked as display network.
        `migration' - `true' if the network should marked as migration network.
        `gluster' - `true' if the network should marked as gluster network.
        [Default: (null)]
- comment
        Comment of the network.
        [Default: (null)]
- data_center
        Datacenter name where network reside.
        [Default: (null)]
- description
        Description of the network.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- mtu
        Maximum transmission unit (MTU) of the network.
        [Default: (null)]
= name
        Name of the the network to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- state
        Should the network be present or absent
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- vlan_tag
        Specify VLAN tag.
        [Default: (null)]
- vm_network
        If `True' network will be marked as network for VM.
        VM network carries traffic relevant to the virtual machine.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create network
- ovirt_networks:
    data_center: mydatacenter
    name: mynetwork
    vlan_tag: 1
    vm_network: true

# Remove network
- ovirt_networks:
    state: absent
    name: mynetwork

RETURN VALUES:
id:
    description: "ID of the managed network"
    returned: "On success if network is found."
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
network:
    description: "Dictionary of all the network attributes. Network attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/network."
    returned: "On success if network is found."


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_NETWORKS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_networks_facts.py)

  Retrieve facts about one or more oVirt networks.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search network starting with string vlan1 use: name=vlan1*
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_networks' fact, which contains a list of networks.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all networks which names start with C(vlan1):
- ovirt_networks_facts:
    pattern: name=vlan1*
- debug:
    var: ovirt_networks

RETURN VALUES:
ovirt_networks:
    description: "List of dictionaries describing the networks. Network attribues are mapped to dictionary keys,
                  all networks attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/network."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_NICS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_nics.py)

  Module to manage network interfaces of Virtual Machines in oVirt.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- interface
        Type of the network interface.
        (Choices: virtio, e1000, rtl8139, pci_passthrough, rtl8139_virtio, spapr_vlan)[Default: virtio]
- mac_address
        Custom MAC address of the network interface, by default it's obtained from MAC pool.
        [Default: (null)]
= name
        Name of the network interface to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- network
        Logical network to which the VM network interface should use, by default Empty network is used if network is not
        specified.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- profile
        Virtual network interface profile to be attached to VM network interface.
        [Default: (null)]
- state
        Should the Virtual Machine NIC be present/absent/plugged/unplugged.
        (Choices: present, absent, plugged, unplugged)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
= vm
        Name of the Virtual Machine to manage.

- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add NIC to VM
- ovirt_nics:
    state: present
    vm: myvm
    name: mynic
    interface: e1000
    mac_address: 00:1a:4a:16:01:56
    profile: ovirtmgmt
    network: ovirtmgmt

# Plug NIC to VM
- ovirt_nics:
    state: plugged
    vm: myvm
    name: mynic

# Unplug NIC from VM
- ovirt_nics:
    state: unplugged
    vm: myvm
    name: mynic

# Remove NIC from VM
- ovirt_nics:
    state: absent
    vm: myvm
    name: mynic

RETURN VALUES:
id:
    description: ID of the network interface which is managed
    returned: On success if network interface is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
nic:
    description: "Dictionary of all the network interface attributes. Network interface attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/nic."
    returned: On success if network interface is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_NICS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_nics_facts.py)

  Retrieve facts about one or more oVirt virtual machine network interfaces.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- name
        Name of the NIC, can be used as glob expression.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
= vm
        Name of the VM where NIC is attached.

Notes:
  * This module creates a new top-level `ovirt_nics' fact, which contains a list of NICs.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all NICs which names start with C(eth) for VM named C(centos7):
- ovirt_nics_facts:
    vm: centos7
    name: eth*
- debug:
    var: ovirt_nics

RETURN VALUES:
ovirt_nics:
    description: "List of dictionaries describing the network interfaces. NIC attribues are mapped to dictionary keys,
                  all NICs attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/nic."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_PERMISSIONS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_permissions.py)

  Module to manage permissions of users/groups in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

= authz_name
        Authorization provider of the user/group. In previous versions of oVirt known as domain.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- group_name
        Name of the the group to manage.
        Note that if group don't exist in the system this module will fail, you should ensure the group exists by using
        [ovirt_groups] module.
        [Default: (null)]
- namespace
        Namespace of the authorization provider, where user/group resides.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- object_id
        ID of the object where the permissions should be managed.
        [Default: (null)]
- object_name
        Name of the object where the permissions should be managed.
        [Default: (null)]
- object_type
        The object where the permissions should be managed.
        (Choices: data_center, cluster, host, storage_domain, network, disk, vm, vm_pool, template, cpu_profile,
        disk_profile, vnic_profile, system)[Default: vm]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- role
        Name of the the role to be assigned to user/group on specific object.
        [Default: UserRole]
- state
        Should the permission be present/absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- user_name
        Username of the the user to manage. In most LDAPs it's `uid' of the user, but in Active Directory you must
        specify `UPN' of the user.
        Note that if user don't exist in the system this module will fail, you should ensure the user exists by using
        [ovirt_users] module.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add user user1 from authorization provider example.com-authz
- ovirt_permissions:
    user_name: user1
    authz_name: example.com-authz
    object_type: vm
    object_name: myvm
    role: UserVmManager

# Remove permission from user
- ovirt_permissions:
    state: absent
    user_name: user1
    authz_name: example.com-authz
    object_type: cluster
    object_name: mycluster
    role: ClusterAdmin

RETURN VALUES:
id:
    description: ID of the permission which is managed
    returned: On success if permission is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
permission:
    description: "Dictionary of all the permission attributes. Permission attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/permission."
    returned: On success if permission is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_PERMISSIONS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_permissions_facts.py)

  Retrieve facts about one or more oVirt permissions.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

= authz_name
        Authorization provider of the user/group. In previous versions of oVirt known as domain.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- group_name
        Name of the the group to manage.
        [Default: (null)]
- namespace
        Namespace of the authorization provider, where user/group resides.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- user_name
        Username of the the user to manage. In most LDAPs it's `uid' of the user, but in Active Directory you must
        specify `UPN' of the user.
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_permissions' fact, which contains a list of permissions.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all permissions of user with username C(john):
- ovirt_permissions_facts:
    user_name: john
    authz_name: example.com-authz
- debug:
    var: ovirt_permissions

RETURN VALUES:
ovirt_permissions:
    description: "List of dictionaries describing the permissions. Permission attribues are mapped to dictionary keys,
                  all permissions attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/permission."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_QUOTAS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_quotas.py)

  Module to manage datacenter quotas in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- cluster_grace
        Cluster grace(hard limit) defined in percentage (1-100).
        [Default: (null)]
- cluster_threshold
        Cluster threshold(soft limit) defined in percentage (0-100).
        [Default: (null)]
- clusters
        List of dictionary of cluster limits, which is valid to specific cluster.
        If cluster isn't spefied it's valid to all clusters in system:
        `cluster' - Name of the cluster.
        `memory' - Memory limit (in GiB).
        `cpu' - CPU limit.
        [Default: (null)]
= data_center
        Name of the datacenter where quota should be managed.

- description
        Description of the the quota to manage.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
= name
        Name of the the quota to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- state
        Should the quota be present/absent.
        (Choices: present, absent)[Default: present]
- storage_grace
        Storage grace(hard limit) defined in percentage (1-100).
        [Default: (null)]
- storage_threshold
        Storage threshold(soft limit) defined in percentage (0-100).
        [Default: (null)]
- storages
        List of dictionary of storage limits, which is valid to specific storage.
        If storage isn't spefied it's valid to all storages in system:
        `storage' - Name of the storage.
        `size' - Size limit (in GiB).
        [Default: (null)]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add cluster quota to cluster cluster1 with memory limit 20GiB and CPU limit to 10:
ovirt_quotas:
    name: quota1
    data_center: dcX
    clusters:
        - name: cluster1
          memory: 20
          cpu: 10

# Add cluster quota to all clusters with memory limit 30GiB and CPU limit to 15:
ovirt_quotas:
    name: quota2
    data_center: dcX
    clusters:
        - memory: 30
          cpu: 15

# Add storage quota to storage data1 with size limit to 100GiB
ovirt_quotas:
    name: quota3
    data_center: dcX
    storage_grace: 40
    storage_threshold: 60
    storages:
        - name: data1
          size: 100

# Remove quota quota1 (Note the quota must not be assigned to any VM/disk):
ovirt_quotas:
    state: absent
    data_center: dcX
    name: quota1

RETURN VALUES:
id:
    description: ID of the quota which is managed
    returned: On success if quota is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
quota:
    description: "Dictionary of all the quota attributes. Quota attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/quota."
    returned: On success if quota is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_QUOTAS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_quotas_facts.py)

  Retrieve facts about one or more oVirt quotas.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

= data_center
        Name of the datacenter where quota resides.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- name
        Name of the quota, can be used as glob expression.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_quotas' fact, which contains a list of quotas.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about quota named C<myquota> in Default datacenter:
- ovirt_quotas_facts:
    data_center: Default
    name: myquota
- debug:
    var: ovirt_quotas

RETURN VALUES:
ovirt_quotas:
    description: "List of dictionaries describing the quotas. Quota attribues are mapped to dictionary keys,
                  all quotas attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/quota."
    returned: On success.
    type: list


MAINTAINERS: Red Hat

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_SNAPSHOTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_snapshots.py)

  Module to manage Virtual Machine Snapshots in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- description
        Description of the snapshot.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- snapshot_id
        ID of the snapshot to manage.
        [Default: (null)]
- state
        Should the Virtual Machine snapshot be restore/present/absent.
        (Choices: restore, present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- use_memory
        If `true' and `state' is `present' save memory of the Virtual Machine if it's running.
        If `true' and `state' is `restore' restore memory of the Virtual Machine.
        Note that Virtual Machine will be paused while saving the memory.
        [Default: (null)]
= vm_name
        Name of the Virtual Machine to manage.

- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * Note that without a guest agent the data on the created snapshot may be inconsistent.
  * Deleting a snapshot does not remove any information from the virtual machine - it simply removes a return-
        point. However, restoring a virtual machine from a snapshot deletes any content that was written to the
        virtual machine after the time the snapshot was taken.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create snapshot:
- ovirt_snapshots:
    vm_name: rhel7
    description: MySnapshot
  register: snapshot

# Create snapshot and save memory:
- ovirt_snapshots:
    vm_name: rhel7
    description: SnapWithMem
    use_memory: true
  register: snapshot

# Restore snapshot:
- ovirt_snapshots:
    state: restore
    vm_name: rhel7
    snapshot_id: "{{ snapshot.id }}"

# Remove snapshot:
- ovirt_snapshots:
    state: absent
    vm_name: rhel7
    snapshot_id: "{{ snapshot.id }}"

RETURN VALUES:
id:
    description: ID of the snapshot which is managed
    returned: On success if snapshot is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
snapshot:
    description: "Dictionary of all the snapshot attributes. Snapshot attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/snapshot."
    returned: On success if snapshot is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_SNAPSHOTS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_snapshots_facts.py)

  Retrieve facts about one or more oVirt virtual machine snapshots.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- description
        Description of the snapshot, can be used as glob expression.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- snapshot_id
        Id of the snaphost we want to retrieve facts about.
        [Default: (null)]
= vm
        Name of the VM with snapshot.

Notes:
  * This module creates a new top-level `ovirt_snapshots' fact, which contains a list of snapshots.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all snapshots which description start with C(update) for VM named C(centos7):
- ovirt_snapshots_facts:
    vm: centos7
    description: update*
- debug:
    var: ovirt_snapshots

RETURN VALUES:
ovirt_snapshots:
    description: "List of dictionaries describing the snapshot. Snapshot attribtues are mapped to dictionary keys,
                  all snapshot attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/snapshot."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_STORAGE_DOMAINS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_storage_domains.py)

  Module to manage storage domains in oVirt

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- comment
        Comment of the storage domain.
        [Default: (null)]
- data_center
        Data center name where storage domain should be attached.
        This parameter isn't idempotent, it's not possible to change data center of storage domain.
        [Default: (null)]
- description
        Description of the storage domain.
        [Default: (null)]
- destroy
        Logical remove of the storage domain. If `true' retains the storage domain's data for import.
        This parameter is relevant only when `state' is `absent'.
        [Default: (null)]
- domain_function
        Function of the storage domain.
        This parameter isn't idempotent, it's not possible to change domain function of storage domain.
        (Choices: data, iso, export)[Default: data]
- fcp
        Dictionary with values for fibre channel storage type:
        `address' - Address of the fibre channel storage server.
        `port' - Port of the fibre channel storage server.
        `lun_id' - LUN id.
        Note that these parameters are not idempotent.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- format
        If `True' storage domain will be formatted after removing it from oVirt.
        This parameter is relevant only when `state' is `absent'.
        [Default: (null)]
- glusterfs
        Dictionary with values for GlusterFS storage type:
        `address' - Address of the Gluster server. E.g.: myserver.mydomain.com
        `path' - Path of the mount point. E.g.: /path/to/my/data
        `mount_options' - Option which will be passed when mounting storage.
        Note that these parameters are not idempotent.
        [Default: (null)]
- host
        Host to be used to mount storage.
        [Default: (null)]
- iscsi
        Dictionary with values for iSCSI storage type:
        `address' - Address of the iSCSI storage server.
        `port' - Port of the iSCSI storage server.
        `target' - The target IQN for the storage device.
        `lun_id' - LUN id.
        `username' - A CHAP user name for logging into a target.
        `password' - A CHAP password for logging into a target.
        `override_luns' - If `True' ISCSI storage domain luns will be overriden before adding.
        Note that these parameters are not idempotent.
        [Default: (null)]
- name
        Name of the the storage domain to manage.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- nfs
        Dictionary with values for NFS storage type:
        `address' - Address of the NFS server. E.g.: myserver.mydomain.com
        `path' - Path of the mount point. E.g.: /path/to/my/data
        `version' - NFS version. One of: `auto', `v3', `v4' or `v4_1'.
        `timeout' - The time in tenths of a second to wait for a response before retrying NFS requests. Range 0 to 65535.
        `retrans' - The number of times to retry a request before attempting further recovery actions. Range 0 to 65535.
        Note that these parameters are not idempotent.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- posixfs
        Dictionary with values for PosixFS storage type:
        `path' - Path of the mount point. E.g.: /path/to/my/data
        `vfs_type' - Virtual File System type.
        `mount_options' - Option which will be passed when mounting storage.
        Note that these parameters are not idempotent.
        [Default: (null)]
- state
        Should the storage domain be present/absent/maintenance/unattached
        (Choices: present, absent, maintenance, unattached)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add data NFS storage domain
- ovirt_storage_domains:
    name: data_nfs
    host: myhost
    data_center: mydatacenter
    nfs:
      address: 10.34.63.199
      path: /path/data

# Add data iSCSI storage domain:
- ovirt_storage_domains:
    name: data_iscsi
    host: myhost
    data_center: mydatacenter
    iscsi:
      target: iqn.2016-08-09.domain-01:nickname
      lun_id: 1IET_000d0002
      address: 10.34.63.204

# Add data glusterfs storage domain
-  ovirt_storage_domains:
    name: glusterfs_1
    host: myhost
    data_center: mydatacenter
    glusterfs:
      address: 10.10.10.10
      path: /path/data

# Import export NFS storage domain:
- ovirt_storage_domains:
    domain_function: export
    host: myhost
    data_center: mydatacenter
    nfs:
      address: 10.34.63.199
      path: /path/export

# Create ISO NFS storage domain
- ovirt_storage_domains:
    name: myiso
    domain_function: iso
    host: myhost
    data_center: mydatacenter
    nfs:
      address: 10.34.63.199
      path: /path/iso

# Remove storage domain
- ovirt_storage_domains:
    state: absent
    name: mystorage_domain
    format: true

RETURN VALUES:
id:
    description: ID of the storage domain which is managed
    returned: On success if storage domain is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
storage_domain:
    description: "Dictionary of all the storage domain attributes. Storage domain attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/storage_domain."
    returned: On success if storage domain is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_STORAGE_DOMAINS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_storage_domains_facts.py)

  Retrieve facts about one or more oVirt storage domains.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search storage domain X from datacenter Y use following pattern: name=X and datacenter=Y
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_storage_domains' fact, which contains a list of storage domains.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all storage domains which names start with C(data) and
# belong to data center C(west):
- ovirt_storage_domains_facts:
    pattern: name=data* and datacenter=west
- debug:
    var: ovirt_storage_domains

RETURN VALUES:
ovirt_storage_domains:
    description: "List of dictionaries describing the storage domains. Storage_domain attribues are mapped to dictionary keys,
                  all storage domains attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/storage_domain."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_TAGS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_tags.py)

  This module manage tags in oVirt. It can also manage assignments of those tags to entities.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- description
        Description of the the tag to manage.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- hosts
        List of the hosts names, which should have assigned this tag.
        [Default: (null)]
= name
        Name of the the tag to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- parent
        Name of the parent tag.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- state
        Should the tag be present or absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- vms
        List of the VMs names, which should have assigned this tag.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create(if not exists) and assign tag to vms vm1 and vm2:
- ovirt_tags:
    name: mytag
    vms:
      - vm1
      - vm2

# To detach all VMs from tag:
- ovirt_tags:
    name: mytag
    vms: []

# Remove tag
- ovirt_tags:
    state: absent
    name: mytag

RETURN VALUES:
id:
    description: ID of the tag which is managed
    returned: On success if tag is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
tag:
    description: "Dictionary of all the tag attributes. Tag attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/tag."
    returned: On success if tag is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_TAGS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_tags_facts.py)

  Retrieve facts about one or more oVirt tags.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- host
        Name of the host, which tags should be listed.
        [Default: (null)]
- name
        Name of the tag which should be listed.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- vm
        Name of the VM, which tags should be listed.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_tags' fact, which contains a list of tags
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all tags, which names start with C(tag):
- ovirt_tags_facts:
    name: tag*
- debug:
    var: tags

# Gather facts about all tags, which are assigned to VM C(postgres):
- ovirt_tags_facts:
    vm: postgres
- debug:
    var: tags

# Gather facts about all tags, which are assigned to host C(west):
- ovirt_tags_facts:
    host: west
- debug:
    var: tags

RETURN VALUES:
ovirt_tags:
    description: "List of dictionaries describing the tags. Tags attribues are mapped to dictionary keys,
                  all tags attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/tag."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_TEMPLATES    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_templates.py)

  Module to manage virtual machine templates in oVirt.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- clone_permissions
        If `True' then the permissions of the VM (only the direct ones, not the inherited ones) will be copied to the
        created template.
        This parameter is used only when `state' `present'.
        [Default: False]
- cluster
        Name of the cluster, where template should be created/imported.
        [Default: (null)]
- cpu_profile
        CPU profile to be set to template.
        [Default: (null)]
- description
        Description of the template.
        [Default: (null)]
- exclusive
        When `state' is `exported' this parameter indicates if the existing templates with the same name should be
        overwritten.
        [Default: (null)]
- export_domain
        When `state' is `exported' or `imported' this parameter specifies the name of the export storage domain.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- image_disk
        When `state' is `imported' and `image_provider' is used this parameter specifies the name of disk to be imported
        as template.
        [Default: (null)]
- image_provider
        When `state' is `imported' this parameter specifies the name of the image provider to be used.
        [Default: (null)]
= name
        Name of the the template to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- state
        Should the template be present/absent/exported/imported
        (Choices: present, absent, exported, imported)[Default: present]
- storage_domain
        When `state' is `imported' this parameter specifies the name of the destination data storage domain.
        [Default: (null)]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- vm
        Name of the VM, which will be used to create template.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create template from vm
- ovirt_templates:
    cluster: Default
    name: mytemplate
    vm: rhel7
    cpu_profile: Default
    description: Test

# Import template
- ovirt_templates:
  state: imported
  name: mytemplate
  export_domain: myexport
  storage_domain: mystorage
  cluster: mycluster

# Remove template
- ovirt_templates:
    state: absent
    name: mytemplate

RETURN VALUES:
id:
    description: ID of the template which is managed
    returned: On success if template is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
template:
    description: "Dictionary of all the template attributes. Template attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/template."
    returned: On success if template is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_TEMPLATES_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_templates_facts.py)

  Retrieve facts about one or more oVirt templates.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search template X from datacenter Y use following pattern: name=X and datacenter=Y
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_templates' fact, which contains a list of templates.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all templates which names start with C(centos) and
# belongs to data center C(west):
- ovirt_templates_facts:
    pattern: name=centos* and datacenter=west
- debug:
    var: ovirt_templates

RETURN VALUES:
ovirt_templates:
    description: "List of dictionaries describing the templates. Template attribues are mapped to dictionary keys,
                  all templates attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/template."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_USERS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_users.py)

  Module to manage users in oVirt.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

= authz_name
        Authorization provider of the user. In previous versions of oVirt known as domain.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
= name
        Name of the the user to manage. In most LDAPs it's `uid' of the user, but in Active Directory you must specify
        `UPN' of the user.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- state
        Should the user be present/absent.
        (Choices: present, absent)[Default: present]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Add user user1 from authorization provider example.com-authz
ovirt_users:
    name: user1
    domain: example.com-authz

# Add user user1 from authorization provider example.com-authz
# In case of Active Directory specify UPN:
ovirt_users:
    name: user1@ad2.example.com
    domain: example.com-authz

# Remove user user1 with authorization provider example.com-authz
ovirt_users:
    state: absent
    name: user1
    authz_name: example.com-authz

RETURN VALUES:
id:
    description: ID of the user which is managed
    returned: On success if user is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
user:
    description: "Dictionary of all the user attributes. User attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/user."
    returned: On success if user is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_USERS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_users_facts.py)

  Retrieve facts about one or more oVirt users.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search user X use following pattern: name=X
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_users' fact, which contains a list of users.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all users which first names start with C(john):
- ovirt_users_facts:
    pattern: name=john*
- debug:
    var: ovirt_users

RETURN VALUES:
ovirt_users:
    description: "List of dictionaries describing the users. User attribues are mapped to dictionary keys,
                  all users attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/user."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_VMPOOLS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_vmpools.py)

  Module to manage VM pools in oVirt.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- cluster
        Name of the cluster, where VM pool should be created.
        [Default: (null)]
- description
        Description of the VM pool.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
= name
        Name of the the VM pool to manage.

- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- prestarted
        Number of pre-started VMs defines the number of VMs in run state, that are waiting to be attached to Users.
        Default value is set by engine.
        [Default: (null)]
- state
        Should the VM pool be present/absent.
        Note that when `state' is `absent' all VMs in VM pool are stopped and removed.
        (Choices: present, absent)[Default: present]
- template
        Name of the template, which will be used to create VM pool.
        [Default: (null)]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- type
        Type of the VM pool. Either manual or automatic.
        `manual' - The administrator is responsible for explicitly returning the virtual machine to the pool. The virtual
        machine reverts to the original base image after the administrator returns it to the pool.
        `Automatic' - When the virtual machine is shut down, it automatically reverts to its base image and is returned
        to the virtual machine pool.
        Default value is set by engine.
        (Choices: manual, automatic)[Default: (null)]
- vm_count
        Number of VMs in the pool.
        Default value is set by engine.
        [Default: (null)]
- vm_per_user
        Maximum number of VMs a single user can attach to from this pool.
        Default value is set by engine.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Create VM pool from template
- ovirt_vmpools:
    cluster: mycluster
    name: myvmpool
    template: rhel7
    vm_count: 2
    prestarted: 2
    vm_per_user: 1

# Remove vmpool, note that all VMs in pool will be stopped and removed:
- ovirt_vmpools:
    state: absent
    name: myvmpool

RETURN VALUES:
id:
    description: ID of the VM pool which is managed
    returned: On success if VM pool is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
vm_pool:
    description: "Dictionary of all the VM pool attributes. VM pool attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/vm_pool."
    returned: On success if VM pool is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_VMPOOLS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_vmpools_facts.py)

  Retrieve facts about one or more oVirt vmpools.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search vmpool X: name=X
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_vmpools' fact, which contains a list of vmpools.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all vm pools which names start with C(centos):
- ovirt_vmpools_facts:
    pattern: name=centos*
- debug:
    var: ovirt_vmpools

RETURN VALUES:
ovirt_vm_pools:
    description: "List of dictionaries describing the vmpools. Vm pool attribues are mapped to dictionary keys,
                  all vmpools attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/vm_pool."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_VMS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_vms.py)

  This module manages whole lifecycle of the Virtual Machine(VM) in oVirt. Since VM can hold many states in oVirt, this
  see notes to see how the states of the VM are handled.

Options (= is mandatory):

= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- boot_devices
        List of boot devices which should be used to boot. Choices `network', `hd' and `cdrom'.
        For example: ['cdrom', 'hd']. Default value is set by oVirt engine.
        [Default: (null)]
- cd_iso
        ISO file from ISO storage domain which should be attached to Virtual Machine.
        If you pass empty string the CD will be ejected from VM.
        If used with `state' `running' or `present' and VM is running the CD will be attached to VM.
        If used with `state' `running' or `present' and VM is down the CD will be attached to VM persistently.
        [Default: (null)]
- clone
        If `True' then the disks of the created virtual machine will be cloned and independent of the template.
        This parameter is used only when `state' is `running' or `present' and VM didn't exist before.
        [Default: False]
- clone_permissions
        If `True' then the permissions of the template (only the direct ones, not the inherited ones) will be copied to
        the created virtual machine.
        This parameter is used only when `state' is `running' or `present' and VM didn't exist before.
        [Default: False]
- cloud_init
        Dictionary with values for Unix-like Virtual Machine initialization using cloud init:
        `host_name' - Hostname to be set to Virtual Machine when deployed.
        `timezone' - Timezone to be set to Virtual Machine when deployed.
        `user_name' - Username to be used to set password to Virtual Machine when deployed.
        `root_password' - Password to be set for user specified by `user_name' parameter.
        `authorized_ssh_keys' - Use this SSH keys to login to Virtual Machine.
        `regenerate_ssh_keys' - If `True' SSH keys will be regenerated on Virtual Machine.
        `custom_script' - Cloud-init script which will be executed on Virtual Machine when deployed.
        `dns_servers' - DNS servers to be configured on Virtual Machine.
        `dns_search' - DNS search domains to be configured on Virtual Machine.
        `nic_boot_protocol' - Set boot protocol of the network interface of Virtual Machine. Can be one of none, dhcp or
        static.
        `nic_ip_address' - If boot protocol is static, set this IP address to network interface of Virtual Machine.
        `nic_netmask' - If boot protocol is static, set this netmask to network interface of Virtual Machine.
        `nic_gateway' - If boot protocol is static, set this gateway to network interface of Virtual Machine.
        `nic_name' - Set name to network interface of Virtual Machine.
        `nic_on_boot' - If `True' network interface will be set to start on boot.
        [Default: (null)]
- cloud_init_nics
        List of dictionaries representing network interafaces to be setup by cloud init.
        This option is used, when user needs to setup more network interfaces via cloud init.
        If one network interface is enough, user should use `cloud_init' `nic_*' parameters. `cloud_init' `nic_*'
        parameters are merged with `cloud_init_nics' parameters.
        Dictionary can contain following values:
        `nic_boot_protocol' - Set boot protocol of the network interface of Virtual Machine. Can be one of none, dhcp or
        static.
        `nic_ip_address' - If boot protocol is static, set this IP address to network interface of Virtual Machine.
        `nic_netmask' - If boot protocol is static, set this netmask to network interface of Virtual Machine.
        `nic_gateway' - If boot protocol is static, set this gateway to network interface of Virtual Machine.
        `nic_name' - Set name to network interface of Virtual Machine.
        `nic_on_boot' - If `True' network interface will be set to start on boot.
        [Default: (null)]
- cluster
        Name of the cluster, where Virtual Machine should be created. Required if creating VM.
        [Default: (null)]
- comment
        Comment of the Virtual Machine.
        [Default: (null)]
- cpu_cores
        Number of virtual CPUs cores of the Virtual Machine. Default value is set by oVirt engine.
        [Default: (null)]
- cpu_shares
        Set a CPU shares for this Virtual Machine. Default value is set by oVirt engine.
        [Default: (null)]
- cpu_sockets
        Number of virtual CPUs sockets of the Virtual Machine. Default value is set by oVirt engine.
        [Default: (null)]
- delete_protected
        If `True' Virtual Machine will be set as delete protected.
        If `False' Virtual Machine won't be set as delete protected.
        If no value is passed, default value is set by oVirt engine.
        [Default: (null)]
- description
        Description of the Virtual Machine.
        [Default: (null)]
- disks
        List of disks, which should be attached to Virtual Machine. Disk is described by following dictionary:
        `name' - Name of the disk. Either `name' or `id' is reuqired.
        `id' - ID of the disk. Either `name' or `id' is reuqired.
        `interface' - Interface of the disk, either `virtio' or `IDE', default is `virtio'.
        `bootable' - `True' if the disk should be bootable, default is non bootable.
        `activate' - `True' if the disk should be activated, default is activated.
        `Note:'
        This parameter is used only when `state' is `running' or `present' and is able to only attach disks. To manage
        disks of the VM in more depth please use [ovirt_disks] module instead.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- force
        Please check to `Synopsis' to more detailed description of force parameter, it can behave differently in
        different situations.
        [Default: False]
- high_availability
        If `True' Virtual Machine will be set as highly available.
        If `False' Virtual Machine won't be set as highly available.
        If no value is passed, default value is set by oVirt engine.
        [Default: (null)]
- host
        Specify host where Virtual Machine should be running. By default the host is chosen by engine scheduler.
        This parameter is used only when `state' is `running' or `present'.
        [Default: (null)]
- id
        ID of the the Virtual Machine to manage.
        [Default: (null)]
- initrd_path
        Path to an initial ramdisk to be used with the kernel specified by `kernel_path' option.
        Ramdisk image must be stored on either the ISO domain or on the host's storage.
        [Default: (null)]
- instance_type
        Name of virtual machine's hardware configuration.
        By default no instance type is used.
        [Default: (null)]
- kernel_params
        Kernel command line parameters (formatted as string) to be used with the kernel specified by `kernel_path'
        option.
        [Default: (null)]
- kernel_path
        Path to a kernel image used to boot the virtual machine.
        Kernel image must be stored on either the ISO domain or on the host's storage.
        [Default: (null)]
- memory
        Amount of memory of the Virtual Machine. Prefix uses IEC 60027-2 standard (for example 1GiB, 1024MiB).
        Default value is set by engine.
        [Default: (null)]
- memory_guaranteed
        Amount of minimal guaranteed memory of the Virtual Machine. Prefix uses IEC 60027-2 standard (for example 1GiB,
        1024MiB).
        `memory_guaranteed' parameter can't be lower than `memory' parameter. Default value is set by engine.
        [Default: (null)]
- name
        Name of the the Virtual Machine to manage. If VM don't exists `name' is required. Otherwise `id' or `name' can be
        used.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- nics
        List of NICs, which should be attached to Virtual Machine. NIC is described by following dictionary:
        `name' - Name of the NIC.
        `profile_name' - Profile name where NIC should be attached.
        `interface' -  Type of the network interface. One of following: `virtio', `e1000', `rtl8139', default is
        `virtio'.
        `mac_address' - Custom MAC address of the network interface, by default it's obtained from MAC pool.
        `Note:'
        This parameter is used only when `state' is `running' or `present' and is able to only create NICs. To manage
        NICs of the VM in more depth please use [ovirt_nics] module instead.
        [Default: (null)]
- operating_system
        Operating system of the Virtual Machine. Default value is set by oVirt engine.
        (Choices: rhel_6_ppc64, other, freebsd, windows_2003x64, windows_10, rhel_6x64, rhel_4x64, windows_2008x64,
        windows_2008R2x64, debian_7, windows_2012x64, ubuntu_14_04, ubuntu_12_04, ubuntu_13_10, windows_8x64,
        other_linux_ppc64, windows_2003, other_linux, windows_10x64, windows_2008, rhel_3, rhel_5, rhel_4, other_ppc64,
        sles_11, rhel_6, windows_xp, rhel_7x64, freebsdx64, rhel_7_ppc64, windows_7, rhel_5x64, ubuntu_14_04_ppc64,
        sles_11_ppc64, windows_8, windows_2012R2x64, windows_2008r2x64, ubuntu_13_04, ubuntu_12_10,
        windows_7x64)[Default: (null)]
- poll_interval
        Number of the seconds the module waits until another poll request on entity status is sent.
        [Default: 3]
- serial_policy
        Specify a serial number policy for the Virtual Machine.
        Following options are supported:
        `vm' - Sets the Virtual Machine's UUID as its serial number.
        `host' - Sets the host's UUID as the Virtual Machine's serial number.
        `custom' - Allows you to specify a custom serial number in `serial_policy_value'.
        [Default: (null)]
- serial_policy_value
        Allows you to specify a custom serial number.
        This parameter is used only when `serial_policy' is `custom'.
        [Default: (null)]
- state
        Should the Virtual Machine be running/stopped/present/absent/suspended/next_run.
        `present' and `running' are equal states.
        `next_run' state updates the VM and if the VM has next run configuration it will be rebooted.
        Please check `notes' to more detailed description of states.
        (Choices: running, stopped, present, absent, suspended, next_run)[Default: present]
- stateless
        If `True' Virtual Machine will be set as stateless.
        If `False' Virtual Machine will be unset as stateless.
        If no value is passed, default value is set by oVirt engine.
        [Default: (null)]
- sysprep
        Dictionary with values for Windows Virtual Machine initialization using sysprep:
        `host_name' - Hostname to be set to Virtual Machine when deployed.
        `active_directory_ou' - Active Directory Organizational Unit, to be used for login of user.
        `org_name' - Organization name to be set to Windows Virtual Machine.
        `domain' - Domain to be set to Windows Virtual Machine.
        `timezone' - Timezone to be set to Windows Virtual Machine.
        `ui_language' - UI language of the Windows Virtual Machine.
        `system_locale' - System localization of the Windows Virtual Machine.
        `input_locale' - Input localization of the Windows Virtual Machine.
        `windows_license_key' - License key to be set to Windows Virtual Machine.
        `user_name' - Username to be used for set password to Windows Virtual Machine.
        `root_password' - Password to be set for username to Windows Virtual Machine.
        [Default: (null)]
- template
        Name of the template, which should be used to create Virtual Machine. Required if creating VM.
        If template is not specified and VM doesn't exist, VM will be created from `Blank' template.
        [Default: (null)]
- template_version
        Version number of the template to be used for VM.
        By default the latest available version of the template is used.
        [Default: (null)]
- timeout
        The amount of time in seconds the module should wait for the instance to get into desired state.
        [Default: 180]
- timezone
        Sets time zone offset of the guest hardware clock.
        For example: Etc/GMT
        [Default: (null)]
- type
        Type of the Virtual Machine. Default value is set by oVirt engine.
        (Choices: server, desktop)[Default: (null)]
- use_latest_template_version
        Specify if latest template version should be used, when running a stateless VM.
        If this parameter is set to `true' stateless VM is created.
        [Default: (null)]
- wait
        `True' if the module should wait for the entity to get into desired state.
        [Default: (null)]
Notes:
  * If VM is in `UNASSIGNED' or `UNKNOWN' state before any operation, the module will fail. If VM is in
        `IMAGE_LOCKED' state before any operation, we try to wait for VM to be `DOWN'. If VM is in `SAVING_STATE'
        state before any operation, we try to wait for VM to be `SUSPENDED'. If VM is in `POWERING_DOWN' state
        before any operation, we try to wait for VM to be `UP' or `DOWN'. VM can get into `UP' state from
        `POWERING_DOWN' state, when there is no ACPI or guest agent running inside VM, or if the shutdown operation
        fails. When user specify `UP' `state', we always wait to VM to be in `UP' state in case VM is `MIGRATING',
        `REBOOTING', `POWERING_UP', `RESTORING_STATE', `WAIT_FOR_LAUNCH'. In other states we run start operation on
        VM. When user specify `stopped' `state', and If user pass `force' parameter set to `true' we forcibly stop
        the VM in any state. If user don't pass `force' parameter, we always wait to VM to be in UP state in case
        VM is `MIGRATING', `REBOOTING', `POWERING_UP', `RESTORING_STATE', `WAIT_FOR_LAUNCH'. If VM is in `PAUSED'
        or `SUSPENDED' state, we start the VM. Then we gracefully shutdown the VM. When user specify `suspended'
        `state', we always wait to VM to be in UP state in case VM is `MIGRATING', `REBOOTING', `POWERING_UP',
        `RESTORING_STATE', `WAIT_FOR_LAUNCH'. If VM is in `PAUSED' or `DOWN' state, we start the VM. Then we
        suspend the VM. When user specify `absent' `state', we forcibly stop the VM in any state and remove it.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: `pip: name=ovirt-engine-sdk-python version=4.0.0'
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Creates a new Virtual Machine from template named 'rhel7_template'
ovirt_vms:
    state: present
    name: myvm
    template: rhel7_template

# Creates a stateless VM which will always use latest template version:
ovirt_vms:
    name: myvm
    template: rhel7
    cluster: mycluster
    use_latest_template_version: true

# Creates a new server rhel7 Virtual Machine from Blank template
# on brq01 cluster with 2GiB memory and 2 vcpu cores/sockets
# and attach bootable disk with name rhel7_disk and attach virtio NIC
ovirt_vms:
    state: present
    cluster: brq01
    name: myvm
    memory: 2GiB
    cpu_cores: 2
    cpu_sockets: 2
    cpu_shares: 1024
    type: server
    operating_system: rhel_7x64
    disks:
      - name: rhel7_disk
        bootable: True
    nics:
      - name: nic1

# Run VM with cloud init:
ovirt_vms:
    name: rhel7
    template: rhel7
    cluster: Default
    memory: 1GiB
    high_availability: true
    cloud_init:
      nic_boot_protocol: static
      nic_ip_address: 10.34.60.86
      nic_netmask: 255.255.252.0
      nic_gateway: 10.34.63.254
      nic_name: eth1
      nic_on_boot: true
      host_name: example.com
      custom_script: |
        write_files:
         - content: |
             Hello, world!
           path: /tmp/greeting.txt
           permissions: '0644'
      user_name: root
      root_password: super_password

# Run VM with cloud init, with multiple network interfaces:
ovirt_vms:
  name: rhel7_4
  template: rhel7
  cluster: mycluster
  cloud_init_nics:
    - nic_name: eth0
      nic_boot_protocol: dhcp
      nic_on_boot: true
    - nic_name: eth1
      nic_boot_protocol: static
      nic_ip_address: 10.34.60.86
      nic_netmask: 255.255.252.0
      nic_gateway: 10.34.63.254
      nic_on_boot: true

# Run VM with sysprep:
ovirt_vms:
    name: windows2012R2_AD
    template: windows2012R2
    cluster: Default
    memory: 3GiB
    high_availability: true
    sysprep:
      host_name: windowsad.example.com
      user_name: Administrator
      root_password: SuperPassword123

# Migrate/Run VM to/on host named 'host1'
ovirt_vms:
    state: running
    name: myvm
    host: host1

# Change Vm's CD:
ovirt_vms:
    name: myvm
    cd_iso: drivers.iso

# Eject Vm's CD:
ovirt_vms:
    name: myvm
    cd_iso: ''

# Boot VM from CD:
ovirt_vms:
    name: myvm
    cd_iso: centos7_x64.iso
    boot_devices:
        - cdrom

# Stop vm:
ovirt_vms:
    state: stopped
    name: myvm

# Upgrade memory to already created VM:
ovirt_vms:
    name: myvm
    memory: 4GiB

# Hot plug memory to already created and running VM:
# (VM won't be restarted)
ovirt_vms:
    name: myvm
    memory: 4GiB

# When change on the VM needs restart of the VM, use next_run state,
# The VM will be updated and rebooted if there are any changes.
# If present state would be used, VM won't be restarted.
ovirt_vms:
    state: next_run
    name: myvm
    boot_devices:
      - network

# Remove VM, if VM is running it will be stopped:
ovirt_vms:
    state: absent
    name: myvm

RETURN VALUES:
id:
    description: ID of the VM which is managed
    returned: On success if VM is found.
    type: str
    sample: 7de90f31-222c-436c-a1ca-7e655bd5b60c
vm:
    description: "Dictionary of all the VM attributes. VM attributes can be found on your oVirt instance
                  at following url: https://ovirt.example.com/ovirt-engine/api/model#types/vm."
    returned: On success if VM is found.


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> OVIRT_VMS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/ovirt/ovirt_vms_facts.py)

  Retrieve facts about one or more oVirt virtual machines.

Options (= is mandatory):

- all_content
        If `true' all the attributes of the virtual machines should be included in the response.
        [Default: (null)]
= auth
        Dictionary with values needed to create HTTP/HTTPS connection to oVirt:
        `username'[`required'] - The name of the user, something like `admin@internal'. Default value is set by
        `OVIRT_USERNAME' environment variable.
        `password'[`required'] - The password of the user. Default value is set by `OVIRT_PASSWORD' environment variable.
        `url'[`required'] - A string containing the base URL of the server, usually something like
        ``https://server.example.com/ovirt-engine/api'`. Default value is set by `OVIRT_URL' environment variable.
        `token' - Token to be used instead of login with username/password. Default value is set by `OVIRT_TOKEN'
        environment variable.
        `insecure' - A boolean flag that indicates if the server TLS certificate and host name should be checked.
        `ca_file' - A PEM file containing the trusted CA certificates. The certificate presented by the server will be
        verified using these CA certificates. If ``ca_file'` parameter is not set, system wide CA certificate store is
        used. Default value is set by `OVIRT_CAFILE' environment variable.
        `kerberos' - A boolean flag indicating if Kerberos authentication should be used instead of the default basic
        authentication.

- case_sensitive
        If `true' performed search will take case into account.
        [Default: (null)]
- fetch_nested
        If `True' the module will fetch additional data from the API.
        It will fetch IDs of the VMs disks, snapshots, etc. User can configure to fetch other attributes of the nested
        entities by specifying `nested_attributes'.
        [Default: (null)]
- max
        The maximum number of results to return.
        [Default: (null)]
- nested_attributes
        Specifies list of the attributes which should be fetched from the API.
        This parameter apply only when `fetch_nested' is `true'.
        [Default: (null)]
- pattern
        Search term which is accepted by oVirt search backend.
        For example to search VM X from cluster Y use following pattern: name=X and cluster=Y
        [Default: (null)]
Notes:
  * This module creates a new top-level `ovirt_vms' fact, which contains a list of virtual machines.
  * In order to use this module you have to install oVirt Python SDK. To ensure it's installed with correct version
        you can create the following task: pip: name=ovirt-engine-sdk-python version=4.0.0
Requirements:  python >= 2.7, ovirt-engine-sdk-python >= 4.0.0

EXAMPLES:
# Examples don't contain auth parameter for simplicity,
# look at ovirt_auth module to see how to reuse authentication:

# Gather facts about all VMs which names start with C(centos) and
# belong to cluster C(west):
- ovirt_vms_facts:
    pattern: name=centos* and cluster=west
- debug:
    var: ovirt_vms

RETURN VALUES:
ovirt_vms:
    description: "List of dictionaries describing the VMs. VM attribues are mapped to dictionary keys,
                  all VMs attributes can be found at following url: https://ovirt.example.com/ovirt-engine/api/model#types/vm."
    returned: On success.
    type: list


MAINTAINERS: Ondra Machacek (@machacekondra)

METADATA:
	Status: ['preview']
	Supported_by: community
> PACEMAKER_CLUSTER    (/usr/lib/python2.7/site-packages/ansible/modules/clustering/pacemaker_cluster.py)

  This module can manage a pacemaker cluster and nodes from Ansible using the pacemaker cli.

Options (= is mandatory):

- force
        Force the change of the cluster state
        [Default: True]
- node
        Specify which node of the cluster you want to manage. None == the cluster status itself, 'all' == check the
        status of all nodes.
        [Default: None]
= state
        Indicate desired state of the cluster
        (Choices: online, offline, restart, cleanup)
- timeout
        Timeout when the module should considered that the action has failed
        [Default: 300]
Requirements:  python >= 2.6

EXAMPLES:
---
- name: Set cluster Online
  hosts: localhost
  gather_facts: no
  tasks:
    - name: get cluster state
      pacemaker_cluster: state=online

RETURN VALUES:
change:
    description: True if the cluster state has changed
    type: bool
out:
    description: The output of the current state of the cluster. It return a
                 list of the nodes state.
    type: string
    sample: 'out: [["  overcloud-controller-0", " Online"]]}'
rc:
    description: exit code of the module
    type: bool


MAINTAINERS: Mathieu Bultel (matbu)

METADATA:
	Status: ['preview']
	Supported_by: community
> PACKAGE    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/package.py)

  Installs, upgrade and removes packages using the underlying OS package manager.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

= name
        Package name, or package specifier with version, like `name-1.0'.
        Be aware that packages are not always named the same and this module will not 'translate' them per distro.

= state
        Whether to install (`present', `latest'), or remove (`absent') a package.

- use
        The required package manager module to use (yum, apt, etc). The default 'auto' will use existing facts or try to
        autodetect it.
        You should only use this field if the automatic selection is not working for some reason.
        [Default: auto]
Notes:
  * This module actually calls the pertinent package modules for each system (apt, yum, etc).
Requirements:  Whatever is required for the package plugins specific for each system.

EXAMPLES:
- name: install the latest version of ntpdate
  package:
    name: ntpdate
    state: latest

# This uses a variable as this changes per distribution.
- name: remove the apache package
  package:
    name: "{{ apache }}"
    state: absent


MAINTAINERS: Ansible Inc

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> PACKET_DEVICE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/packet/packet_device.py)

  create, destroy, update, start, stop, and reboot a Packet Host machine. When the machine is created it can optionally
  wait for it to have an IP address before returning. This module has a dependency on packet >= 1.0. API is documented at
  https://www.packet.net/help/api/#page:devices,header:devices-devices-post.

Options (= is mandatory):

- auth_token
        Packet api token. You can also supply it in env var `PACKET_API_TOKEN'.
        [Default: (null)]
- count
        The number of devices to create. Count number can be included in hostname via the %d string formatter.
        [Default: (null)]
- count_offset
        From which number to start the count.
        [Default: (null)]
- device_ids
        List of device IDs on which to operate.
        [Default: (null)]
- facility
        Facility slug for device creation. As of 2016, it should be one of [ewr1, sjc1, ams1, nrt1].
        [Default: (null)]
- features
        Dict with "features" for device creation. See Packet API docs for details.
        [Default: (null)]
- hostnames
        A hostname of a device, or a list of hostnames.
        If given string or one-item list, you can use the `"%d"' Python string format to expand numbers from count.
        If only one hostname, it might be expanded to list if count>1.
        [Default: (null)]
- lock
        Whether to lock a created device.
        [Default: False]
- operating_system
        OS slug for device creation. See Packet docs or API for current list.
        [Default: (null)]
- plan
        Plan slug for device creation. See Packet docs or API for current list.
        [Default: (null)]
= project_id
        ID of project of the device.

- state
        Desired state of the device.
        (Choices: present, absent, active, inactive, rebooted)[Default: present]
- user_data
        Userdata blob made available to the machine
        [Default: None]
- wait
        Whether to wait for the instance to be assigned IP address before returning.
        [Default: False]
- wait_timeout
        How long to wait for IP address of new devices before quitting. In seconds.
        [Default: 60]
Requirements:  packet-python, python >= 2.6

EXAMPLES:
# All the examples assume that you have your Packet api token in env var PACKET_API_TOKEN.
# You can also pass it to the auth_token parameter of the module instead.

# Creating devices

- name: create 1 device
  hosts: localhost
  tasks:
  - packet_device:
      project_id: 89b497ee-5afc-420a-8fb5-56984898f4df
      hostnames: myserver
      operating_system: ubuntu_16_04
      plan: baremetal_0
      facility: sjc1

- name: create 3 ubuntu devices called server-01, server-02 and server-03
  hosts: localhost
  tasks:
  - packet_device:
      project_id: 89b497ee-5afc-420a-8fb5-56984898f4df
      hostnames: server-%02d
      count: 3
      operating_system: ubuntu_16_04
      plan: baremetal_0
      facility: sjc1

- name: Create 3 coreos devices with userdata, wait until they get IPs and then wait for SSH
  hosts: localhost
  tasks:
  - name: create 3 devices and register their facts
    packet_device:
      hostnames: [coreos-one, coreos-two, coreos-three]
      operating_system: coreos_stable
      plan: baremetal_0
      facility: ewr1
      locked: true
      project_id: 89b497ee-5afc-420a-8fb5-56984898f4df
      user_data: |
        #cloud-config
        ssh_authorized_keys:
          - ssh-dss AAAAB3NzaC1kc3MAAACBAIfNT5S0ncP4BBJBYNhNPxFF9lqVhfPeu6SM1LoCocxqDc1AT3zFRi8hjIf6TLZ2AA4FYbcAWxLMhiBxZRVldT9GdBXile78kAK5z3bKTwq152DCqpxwwbaTIggLFhsU8wrfBsPWnDuAxZ0h7mmrCjoLIE3CNLDA/NmV3iB8xMThAAAAFQCStcesSgR1adPORzBxTr7hug92LwAAAIBOProm3Gk+HWedLyE8IfofLaOeRnbBRHAOL4z0SexKkVOnQ/LGN/uDIIPGGBDYTvXgKZT+jbHeulRJ2jKgfSpGKN4JxFQ8uzVH492jEiiUJtT72Ss1dCV4PmyERVIw+f54itihV3z/t25dWgowhb0int8iC/OY3cGodlmYb3wdcQAAAIBuLbB45djZXzUkOTzzcRDIRfhaxo5WipbtEM2B1fuBt2gyrvksPpH/LK6xTjdIIb0CxPu4OCxwJG0aOz5kJoRnOWIXQGhH7VowrJhsqhIc8gN9ErbO5ea8b1L76MNcAotmBDeTUiPw01IJ8MdDxfmcsCslJKgoRKSmQpCwXQtN2g== tomk@hp2
        coreos:
          etcd:
            discovery: https://discovery.etcd.io/6a28e078895c5ec737174db2419bb2f3
            addr: $private_ipv4:4001
            peer-addr: $private_ipv4:7001
          fleet:
            public-ip: $private_ipv4
          units:
            - name: etcd.service
              command: start
            - name: fleet.service
              command: start
    register: newhosts

  - name: wait for ssh
    wait_for:
      delay: 1
      host: "{{ item.public_ipv4 }}"
      port: 22
      state: started
      timeout: 500
    with_items: "{{ newhosts.devices }}"


# Other states of devices

- name: remove 3 devices by uuid
  hosts: localhost
  tasks:
  - packet_device:
      project_id: 89b497ee-5afc-420a-8fb5-56984898f4df
      state: absent
      device_ids:
        - 1fb4faf8-a638-4ac7-8f47-86fe514c30d8
        - 2eb4faf8-a638-4ac7-8f47-86fe514c3043
        - 6bb4faf8-a638-4ac7-8f47-86fe514c301f

RETURN VALUES:
changed:
    description: True if a device was altered in any way (created, modified or removed)
    type: bool
    sample: True
    returned: always
devices:
    description: Information about each device that was processed
    type: array
    sample: '[{"hostname": "my-server.com", "id": "server-id", "public-ipv4": "147.229.15.12", "private-ipv4": "10.0.15.12", "public-ipv6": ""2604:1380:2:5200::3"}]'
    returned: always


MAINTAINERS: Tomas Karasek <tom.to.the.k@gmail.com>, Matt Baldwin <baldwin@stackpointcloud.com>, Thibaud Morel l'Horset <teebes@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> PACKET_SSHKEY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/packet/packet_sshkey.py)

  Create/delete an SSH key in Packet host. API is documented at https://www.packet.net/help/api/#page:ssh-keys,header
  :ssh-keys-ssh-keys-post.

Options (= is mandatory):

- auth_token
        Packet api token. You can also supply it in env var `PACKET_API_TOKEN'.
        [Default: (null)]
- fingerprint
        Fingerprint of the key which you want to remove.
        [Default: (null)]
- id
        UUID of the key which you want to remove.
        [Default: (null)]
- key
        Public Key string ({type} {base64 encoded key} {description}).
        [Default: (null)]
- key_file
        File with the public key.
        [Default: (null)]
- label
        Label for the key. If you keep it empty, it will be read from key string.
        [Default: (null)]
- state
        Indicate desired state of the target.
        (Choices: present, absent)[Default: present]
Requirements:  python >= 2.6, packet-python

EXAMPLES:
# All the examples assume that you have your Packet API token in env var PACKET_API_TOKEN.
# You can also pass the api token in module param auth_token.

- name: create sshkey from string
  hosts: localhost
  tasks:
    packet_sshkey:
      key: ssh-dss AAAAB3NzaC1kc3MAAACBAIfNT5S0ncP4BBJBYNhNPxFF9lqVhfPeu6SM1LoCocxqDc1AT3zFRi8hjIf6TLZ2AA4FYbcAWxLMhiBxZRVldT9GdBXile78kAK5z3bKTwq152DCqpxwwbaTIggLFhsU8wrfBsPWnDuAxZ0h7mmrCjoLIE3CNLDA/NmV3iB8xMThAAAAFQCStcesSgR1adPORzBxTr7hug92LwAAAIBOProm3Gk+HWedLyE8IfofLaOeRnbBRHAOL4z0SexKkVOnQ/LGN/uDIIPGGBDYTvXgKZT+jbHeulRJ2jKgfSpGKN4JxFQ8uzVH492jEiiUJtT72Ss1dCV4PmyERVIw+f54itihV3z/t25dWgowhb0int8iC/OY3cGodlmYb3wdcQAAAIBuLbB45djZXzUkOTzzcRDIRfhaxo5WipbtEM2B1fuBt2gyrvksPpH/LK6xTjdIIb0CxPu4OCxwJG0aOz5kJoRnOWIXQGhH7VowrJhsqhIc8gN9ErbO5ea8b1L76MNcAotmBDeTUiPw01IJ8MdDxfmcsCslJKgoRKSmQpCwXQtN2g== tomk@hp2

- name: create sshkey from file
  hosts: localhost
  tasks:
    packet_sshkey:
      label: key from file
      key_file: ~/ff.pub

- name: remove sshkey by id
  hosts: localhost
  tasks:
    packet_sshkey:
      state: absent
      id: eef49903-7a09-4ca1-af67-4087c29ab5b6

RETURN VALUES:
changed:
    description: True if a sshkey was created or removed.
    type: bool
    sample: True
    returned: always
sshkeys:
    description: Information about sshkeys that were createe/removed.
    type: array
    sample: [
        {
            "fingerprint": "5c:93:74:7c:ed:07:17:62:28:75:79:23:d6:08:93:46",
            "id": "41d61bd8-3342-428b-a09c-e67bdd18a9b7",
            "key": "ssh-dss AAAAB3NzaC1kc3MAAACBAIfNT5S0ncP4BBJBYNhNPxFF9lqVhfPeu6SM1LoCocxqDc1AT3zFRi8hjIf6TLZ2AA4FYbcAWxLMhiBxZRVldT9GdBXile78kAK5z3bKTwq152DCqpxwwbaTIggLFhsU8wrfBsPWnDuAxZ0h7mmrCjoLIE3CNLDA/NmV3iB8xMThAAAAFQCStcesSgR1adPORzBxTr7hug92LwAAAIBOProm3Gk+HWedLyE8IfofLaOeRnbBRHAOL4z0SexKkVOnQ/LGN/uDIIPGGBDYTvXgKZT+jbHeulRJ2jKgfSpGKN4JxFQ8uzVH492jEiiUJtT72Ss1dCV4PmyERVIw+f54itihV3z/t25dWgowhb0int8iC/OY3cGodlmYb3wdcQAAAIBuLbB45djZXzUkOTzzcRDIRfhaxo5WipbtEM2B1fuBt2gyrvksPpH/LK6xTjdIIb0CxPu4OCxwJG0aOz5kJoRnOWIXQGhH7VowrJhsqhIc8gN9ErbO5ea8b1L76MNcAotmBDeTUiPw01IJ8MdDxfmcsCslJKgoRKSmQpCwXQtN2g== tomk@hp2",
            "label": "mynewkey33"
        }
    ]
    returned: always


MAINTAINERS: Tomas Karasek <tom.to.the.k@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> PACMAN    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/pacman.py)

  Manage packages with the `pacman' package manager, which is used by Arch Linux and its variants.

Options (= is mandatory):

- force
        When removing package - force remove package, without any checks. When update_cache - force redownload repo
        databases.
        (Choices: yes, no)[Default: False]
- name
        Name of the package to install, upgrade, or remove.
        [Default: None]
- recurse
        When removing a package, also remove its dependencies, provided that they are not required by other packages and
        were not explicitly installed by a user.
        (Choices: yes, no)[Default: False]
- state
        Desired state of the package.
        (Choices: present, absent, latest)[Default: present]
- update_cache
        Whether or not to refresh the master package lists. This can be run as part of a package installation or as a
        separate step.
        (Choices: yes, no)[Default: False]
- upgrade
        Whether or not to upgrade whole system
        (Choices: yes, no)[Default: False]
EXAMPLES:
# Install package foo
- pacman:
    name: foo
    state: present

# Upgrade package foo
- pacman:
    name: foo
    state: latest
    update_cache: yes

# Remove packages foo and bar
- pacman:
    name: foo,bar
    state: absent

# Recursively remove package baz
- pacman:
    name: baz
    state: absent
    recurse: yes

# Run the equivalent of "pacman -Sy" as a separate step
- pacman:
    update_cache: yes

# Run the equivalent of "pacman -Su" as a separate step
- pacman:
    upgrade: yes

# Run the equivalent of "pacman -Syu" as a separate step
- pacman:
    update_cache: yes
    upgrade: yes

# Run the equivalent of "pacman -Rdd", force remove package baz
- pacman:
    name: baz
    state: absent
    force: yes

RETURN VALUES:
packages:
    description: a list of packages that have been changed
    returned: when upgrade is set to yes
    type: list of strings
    sample: ['package', 'other-package']


MAINTAINERS: Indrajit Raychaudhuri (@indrajitr), 'Aaron Bull Schaefer (@elasticdog)' <aaron@elasticdog.com>, Afterburn

METADATA:
	Status: ['preview']
	Supported_by: community
> PAGERDUTY    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/pagerduty.py)

  This module will let you create PagerDuty maintenance windows

Options (= is mandatory):

- desc
        Short description of maintenance window.
        (Choices: )[Default: Created by Ansible]
- hours
        Length of maintenance window in hours.
        (Choices: )[Default: 1]
- minutes
        Maintenance window in minutes (this is added to the hours).
        (Choices: )[Default: 0]
= name
        PagerDuty unique subdomain.
        (Choices: )[Default: None]
= passwd
        PagerDuty user password.
        (Choices: )[Default: None]
= requester_id
        ID of user making the request. Only needed when using a token and creating a maintenance_window.
        (Choices: )[Default: None]
- service
        A comma separated list of PagerDuty service IDs.
        (Choices: )[Default: None]
= state
        Create a maintenance window or get a list of ongoing windows.
        (Choices: running, started, ongoing, absent)[Default: None]
= token
        A pagerduty token, generated on the pagerduty site. Can be used instead of user/passwd combination.
        (Choices: )[Default: None]
= user
        PagerDuty user ID.
        (Choices: )[Default: None]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
Requirements:  PagerDuty API access

EXAMPLES:
# List ongoing maintenance windows using a user/passwd
- pagerduty:
    name: companyabc
    user: example@example.com
    passwd: password123
    state: ongoing

# List ongoing maintenance windows using a token
- pagerduty:
    name: companyabc
    token: xxxxxxxxxxxxxx
    state: ongoing

# Create a 1 hour maintenance window for service FOO123, using a user/passwd
- pagerduty:
    name: companyabc
    user: example@example.com
    passwd: password123
    state: running
    service: FOO123

# Create a 5 minute maintenance window for service FOO123, using a token
- pagerduty:
    name: companyabc
    token: xxxxxxxxxxxxxx
    hours: 0
    minutes: 5
    state: running
    service: FOO123


# Create a 4 hour maintenance window for service FOO123 with the description "deployment".
- pagerduty:
    name: companyabc
    user: example@example.com
    passwd: password123
    state: running
    service: FOO123
    hours: 4
    desc: deployment
  register: pd_window

# Delete the previous maintenance window
- pagerduty:
    name: companyabc
    user: example@example.com
    passwd: password123
    state: absent
    service: '{{ pd_window.result.maintenance_window.id }}'


MAINTAINERS: Andrew Newdigate (@suprememoocow), Justin Johns, Bruce Pennypacker, Dylan Silva (@thaumos)

METADATA:
	Status: ['preview']
	Supported_by: community
> PAGERDUTY_ALERT    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/pagerduty_alert.py)

  This module will let you trigger, acknowledge or resolve a PagerDuty incident by sending events

Options (= is mandatory):

= api_key
        The pagerduty API key (readonly access), generated on the pagerduty site.

- client
        The name of the monitoring client that is triggering this event.
        [Default: (null)]
- client_url
        The URL of the monitoring client that is triggering this event.
        [Default: (null)]
- desc
        For `triggered' `state' - Required. Short description of the problem that led to this trigger. This field (or a
        truncated version) will be used when generating phone calls, SMS messages and alert emails. It will also appear
        on the incidents tables in the PagerDuty UI. The maximum length is 1024 characters.
        For `acknowledged' or `resolved' `state' - Text that will appear in the incident's log associated with this
        event.
        [Default: Created via Ansible]
- incident_key
        Identifies the incident to which this `state' should be applied.
        For `triggered' `state' - If there's no open (i.e. unresolved) incident with this key, a new one will be created.
        If there's already an open incident with a matching key, this event will be appended to that incident's log. The
        event key provides an easy way to "de-dup" problem reports.
        For `acknowledged' or `resolved' `state' - This should be the incident_key you received back when the incident
        was first opened by a trigger event. Acknowledge events referencing resolved or nonexistent incidents will be
        discarded.
        [Default: (null)]
= name
        PagerDuty unique subdomain.

= service_key
        The GUID of one of your "Generic API" services.
        This is the "service key" listed on a Generic API's service detail page.

= state
        Type of event to be sent.
        (Choices: triggered, acknowledged, resolved)
Requirements:  PagerDuty API access

EXAMPLES:
# Trigger an incident with just the basic options
- pagerduty_alert:
    name: companyabc
    service_key: xxx
    api_key: yourapikey
    state: triggered
    desc: problem that led to this trigger

# Trigger an incident with more options
- pagerduty_alert:
    service_key: xxx
    api_key: yourapikey
    state: triggered
    desc: problem that led to this trigger
    incident_key: somekey
    client: Sample Monitoring Service
    client_url: http://service.example.com

# Acknowledge an incident based on incident_key
- pagerduty_alert:
    service_key: xxx
    api_key: yourapikey
    state: acknowledged
    incident_key: somekey
    desc: "some text for incident's log"

# Resolve an incident based on incident_key
- pagerduty_alert:
    service_key: xxx
    api_key: yourapikey
    state: resolved
    incident_key: somekey
    desc: "some text for incident's log"


MAINTAINERS: Amanpreet Singh (@aps-sids)

METADATA:
	Status: ['preview']
	Supported_by: community
> PAM_LIMITS    (/usr/lib/python2.7/site-packages/ansible/modules/system/pam_limits.py)

  The `pam_limits' module modify PAM limits, default in /etc/security/limits.conf. For the full documentation, see man
  limits.conf(5).

Options (= is mandatory):

- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- comment
        Comment associated with the limit.
        [Default: ]
- dest
        Modify the limits.conf path.
        [Default: /etc/security/limits.conf]
= domain
        A username, @groupname, wildcard, uid/gid range.

= limit_item
        The limit to be set
        (Choices: core, data, fsize, memlock, nofile, rss, stack, cpu, nproc, as, maxlogins, maxsyslogins, priority,
        locks, sigpending, msgqueue, nice, rtprio, chroot)
= limit_type
        Limit type, see `man limits' for an explanation
        (Choices: hard, soft, -)
- use_max
        If set to `yes', the maximal value will be used or conserved. If the specified value is superior to the value in
        the file, file content is replaced with the new value, else content is not modified.
        (Choices: yes, no)[Default: no]
- use_min
        If set to `yes', the minimal value will be used or conserved. If the specified value is inferior to the value in
        the file, file content is replaced with the new value, else content is not modified.
        (Choices: yes, no)[Default: no]
= value
        The value of the limit.

EXAMPLES:
# Add or modify nofile soft limit for the user joe
- pam_limits:
    domain: joe
    limit_type: soft
    limit_item: nofile
    value: 64000

# Add or modify fsize hard limit for the user smith. Keep or set the maximal value.
- pam_limits:
    domain: smith
    limit_type: hard
    limit_item: fsize
    value: 1000000
    use_max: yes

# Add or modify memlock, both soft and hard, limit for the user james with a comment.
- pam_limits:
    domain: james
    limit_type: '-'
    limit_item: memlock
    value: unlimited
    comment: unlimited memory lock for james


MAINTAINERS: Sebastien Rohaut (@usawa)

METADATA:
	Status: ['preview']
	Supported_by: community
> PAMD    (/usr/lib/python2.7/site-packages/ansible/modules/system/pamd.py)

  Edit PAM service's type, control, module path and module arguments. In order for a PAM rule to be modified, the type,
  control and module_path must match an existing rule.  See man(5) pam.d for details.

Options (= is mandatory):

= control
        The control of the PAM rule being modified.  This may be a complicated control with brackets.  If this is the
        case, be sure to put "[bracketed controls]" in quotes.  The type, control and module_path all must match a rule
        to be modified.

- module_arguments
        When state is 'updated', the module_arguments will replace existing module_arguments.  When state is
        'args_absent' args matching those listed in module_arguments will be removed.  When state is 'args_present' any
        args listed in module_arguments are added if missing from the existing rule.  Furthermore, if the module argument
        takes a value denoted by '=', the value will be changed to that specified in module_arguments.
        [Default: (null)]
= module_path
        The module path of the PAM rule being modified.  The type, control and module_path all must match a rule to be
        modified.

= name
        The name generally refers to the PAM service file to change, for example system-auth.

- new_control
        The control to assign to the new rule.
        [Default: (null)]
- new_module_path
        The control to assign to the new rule.
        [Default: (null)]
- new_type
        The type to assign to the new rule.
        [Default: (null)]
- path
        This is the path to the PAM service files
        [Default: /etc/pam.d/]
- state
        The default of 'updated' will modify an existing rule if type, control and module_path all match an existing
        rule.  With 'before', the new rule will be inserted before a rule matching type, control and module_path.
        Similarly, with 'after', the new rule will be inserted after an existing rule matching type, control and
        module_path.  With either 'before' or 'after' new_type, new_control, and new_module_path must all be specified.
        If state is 'args_absent' or 'args_present', new_type, new_control, and new_module_path will be ignored.
        (Choices: updated, before, after, args_present, args_absent)[Default: updated]
= type
        The type of the PAM rule being modified.  The type, control and module_path all must match a rule to be modified.

EXAMPLES:
- name: Update pamd rule's control in /etc/pam.d/system-auth
  pamd:
    name: system-auth
    type: auth
    control: required
    module_path: pam_faillock.so
    new_control: sufficient

- name: Update pamd rule's complex control in /etc/pam.d/system-auth
  pamd:
    name: system-auth
    type: session
    control: '[success=1 default=ignore]'
    module_path: pam_succeed_if.so
    new_control: '[success=2 default=ignore]'

- name: Insert a new rule before an existing rule
  pamd:
    name: system-auth
    type: auth
    control: required
    module_path: pam_faillock.so
    new_type: auth
    new_control: sufficient
    new_module_path: pam_faillock.so
    state: before

- name: Insert a new rule after an existing rule
  pamd:
    name: system-auth
    type: auth
    control: required
    module_path: pam_faillock.so
    new_type: auth
    new_control: sufficient
    new_module_path: pam_faillock.so
    state: after

- name: Remove module arguments from an existing rule
  pamd:
    name: system-auth
    type: auth
    control: required
    module_path: pam_faillock.so
    module_arguments: ''
    state: updated

- name: Replace all module arguments in an existing rule
  pamd:
    name: system-auth
    type: auth
    control: required
    module_path: pam_faillock.so
    module_arguments: 'preauth
        silent
        deny=3
        unlock_time=604800
        fail_interval=900'
    state: updated

- name: Remove specific arguments from a rule
  pamd:
    name: system-auth
    type: session control='[success=1 default=ignore]'
    module_path: pam_succeed_if.so
    module_arguments: 'crond quiet'
    state: args_absent

- name: Ensure specific arguments are present in a rule
  pamd:
    name: system-auth
    type: session
    control: '[success=1 default=ignore]'
    module_path: pam_succeed_if.so
    module_arguments: 'crond quiet'
    state: args_present

- name: Update specific argument value in a rule
  pamd:
    name: system-auth
    type: auth
    control: required
    module_path: pam_faillock.so
    module_arguments: 'fail_interval=300'
    state: args_present

RETURN VALUES:
dest:
    description: path to pam.d service that was changed
    returned: success
    type: string
    sample: "/etc/pam.d/system-auth"
...


MAINTAINERS: Kenneth D. Evensen (@kevensen)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_ADDRESS    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_address.py)

  Create address service object of different types [IP Range, FQDN, or IP Netmask].

Options (= is mandatory):

= address
        IP address with or without mask, range, or FQDN.
        [Default: None]
= address_name
        Human readable name of the address.
        [Default: None]
- commit
        Commit configuration to the Firewall if it is changed.
        [Default: True]
- description
        Description of the address object.
        [Default: None]
= ip_address
        IP address (or hostname) of PAN-OS device being configured.

= password
        Password credentials to use for authentication.

- tag
        Tag of the address object.
        [Default: None]
- type
        This is the type of the object created.
        (Choices: ip-netmask, fqdn, ip-range)[Default: ip-nemask]
- username
        Username credentials to use for authentication.
        [Default: admin]
Requirements:  pan-python can be obtained from PyPi https://pypi.python.org/pypi/pan-python

EXAMPLES:
- name: create IP-Netmask Object
  panos_address:
    ip_address: "192.168.1.1"
    password: 'admin'
    address_name: 'google_dns'
    address: '8.8.8.8/32'
    description: 'Google DNS'
    tag: 'Outbound'
    commit: False

- name: create IP-Range Object
  panos_address:
    ip_address: "192.168.1.1"
    password: 'admin'
    type: 'ip-range'
    address_name: 'apple-range'
    address: '17.0.0.0-17.255.255.255'
    commit: False

- name: create FQDN Object
  panos_address:
    ip_address: "192.168.1.1"
    password: 'admin'
    type: 'fqdn'
    address_name: 'google.com'
    address: 'www.google.com'

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ken Celenza (@itdependsnetworks), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_ADMIN    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_admin.py)

  PanOS module that allows changes to the user account passwords by doing API calls to the Firewall using pan-api as the
  protocol.

Options (= is mandatory):

= admin_password
        password for admin user

- admin_username
        username for admin user
        [Default: admin]
- commit
        commit if changed
        [Default: True]
= ip_address
        IP address (or hostname) of PAN-OS device

= password
        password for authentication

- role
        role for admin user
        [Default: None]
- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
# Set the password of user admin to "badpassword"
# Doesn't commit the candidate config
  - name: set admin password
    panos_admin:
      ip_address: "192.168.1.1"
      password: "admin"
      admin_username: admin
      admin_password: "badpassword"
      commit: False

RETURN VALUES:
status:
    description: success status
    returned: success
    type: string
    sample: "okey dokey"


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_ADMPWD    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_admpwd.py)

  Change the admin password of PAN-OS via SSH using a SSH key for authentication. Useful for AWS instances where the
  first login should be done via SSH.

Options (= is mandatory):

= ip_address
        IP address (or hostname) of PAN-OS device

= key_filename
        filename of the SSH Key to use for authentication

= newpassword
        password to configure for admin on the PAN-OS device

- username
        username for initial authentication
        [Default: admin]
Requirements:  paramiko

EXAMPLES:
# Tries for 10 times to set the admin password of 192.168.1.1 to "badpassword"
# via SSH, authenticating using key /tmp/ssh.key
- name: set admin password
  panos_admpwd:
    ip_address: "192.168.1.1"
    username: "admin"
    key_filename: "/tmp/ssh.key"
    newpassword: "badpassword"
  register: result
  until: not result|failed
  retries: 10
  delay: 30

RETURN VALUES:
status:
    description: success status
    returned: success
    type: string
    sample: "Last login: Fri Sep 16 11:09:20 2016 from 10.35.34.56.....Configuration committed successfully"


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_CERT_GEN_SSH    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_cert_gen_ssh.py)

  This module generates a self-signed certificate that can be used by GlobalProtect client, SSL connector, or otherwise.
  Root certificate must be preset on the system first. This module depends on paramiko for ssh.

Options (= is mandatory):

= cert_cn
        Certificate CN (common name) embeded in the certificate signature.
        [Default: None]
= cert_friendly_name
        Human friendly certificate name (not CN but just a friendly name).
        [Default: None]
= ip_address
        IP address (or hostname) of PAN-OS device being configured.
        [Default: None]
= key_filename
        Location of the filename that is used for the auth. Either `key_filename' or `password' is required.
        [Default: None]
= password
        Password credentials to use for auth. Either `key_filename' or `password' is required.
        [Default: None]
- rsa_nbits
        Number of bits used by the RSA algorithm for the certificate generation.
        [Default: 2048]
= signed_by
        Undersigning authority (CA) that MUST already be presents on the device.
        [Default: None]
Notes:
  * Checkmode is not supported.
Requirements:  paramiko

EXAMPLES:
# Generates a new self-signed certificate using ssh
- name: generate self signed certificate
  panos_cert_gen_ssh:
    ip_address: "192.168.1.1"
    password: "paloalto"
    cert_cn: "1.1.1.1"
    cert_friendly_name: "test123"
    signed_by: "root-ca"

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_CHECK    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_check.py)

  Check if PAN-OS device is ready for being configured (no pending jobs). The check could be done once or multiple times
  until the device is ready.

Options (= is mandatory):

- interval
        time waited between checks
        [Default: 0]
= ip_address
        IP address (or hostname) of PAN-OS device

= password
        password for authentication

- timeout
        timeout of API calls
        [Default: 0]
- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
# single check on 192.168.1.1 with credentials admin/admin
- name: check if ready
  panos_check:
    ip_address: "192.168.1.1"
    password: "admin"

# check for 10 times, every 30 seconds, if device 192.168.1.1
# is ready, using credentials admin/admin
- name: wait for reboot
  panos_check:
    ip_address: "192.168.1.1"
    password: "admin"
  register: result
  until: not result|failed
  retries: 10
  delay: 30

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_COMMIT    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_commit.py)

  PanOS module that will commit firewall's candidate configuration on the device. The new configuration will become
  active immediately.

Options (= is mandatory):

- interval
        interval for checking commit job
        [Default: 0.5]
= ip_address
        IP address (or hostname) of PAN-OS device

= password
        password for authentication

- sync
        if commit should be synchronous
        [Default: True]
- timeout
        timeout for commit job
        [Default: None]
- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
# Commit candidate config on 192.168.1.1 in sync mode
- panos_commit:
    ip_address: "192.168.1.1"
    username: "admin"
    password: "admin"

RETURN VALUES:
status:
    description: success status
    returned: success
    type: string
    sample: "okey dokey"


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_DAG    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_dag.py)

  Create a dynamic address group object in the firewall used for policy rules

Options (= is mandatory):

- commit
        commit if changed
        [Default: True]
= dag_filter
        dynamic filter user by the dynamic address group
        [Default: None]
= dag_name
        name of the dynamic address group
        [Default: None]
= ip_address
        IP address (or hostname) of PAN-OS device
        [Default: None]
= password
        password for authentication
        [Default: None]
- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
- name: dag
  panos_dag:
    ip_address: "192.168.1.1"
    password: "admin"
    dag_name: "dag-1"
    dag_filter: "'aws-tag.aws:cloudformation:logical-id.ServerInstance' and 'instanceState.running'"

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_IMPORT    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_import.py)

  Import file on PAN-OS device

Options (= is mandatory):

- category
        Category of file uploaded. The default is software.
        [Default: software]
- file
        Location of the file to import into device.
        [Default: None]
= ip_address
        IP address (or hostname) of PAN-OS device.

= password
        Password for device authentication.

- url
        URL of the file that will be imported to device.
        [Default: None]
- username
        Username for device authentication.
        [Default: admin]
Requirements:  pan-python, requests, requests_toolbelt

EXAMPLES:
# import software image PanOS_vm-6.1.1 on 192.168.1.1
- name: import software image into PAN-OS
  panos_import:
    ip_address: 192.168.1.1
    username: admin
    password: admin
    file: /tmp/PanOS_vm-6.1.1
    category: software

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_interface.py)

  Configure data-port (DP) network interface for DHCP. By default DP interfaces are static.

Options (= is mandatory):

- commit
        Commit if changed
        [Default: True]
- create_default_route
        Whether or not to add default route with router learned via DHCP.
        [Default: false]
= if_name
        Name of the interface to configure.

= ip_address
        IP address (or hostname) of PAN-OS device being configured.

= password
        Password credentials to use for auth.

- username
        Username credentials to use for auth.
        [Default: admin]
= zone_name
        Name of the zone for the interface. If the zone does not exist it is created but if the zone exists and it is not
        of the layer3 type the operation will fail.

Notes:
  * Checkmode is not supported.
Requirements:  pan-python can be obtained from PyPi https://pypi.python.org/pypi/pan-python

EXAMPLES:
- name: enable DHCP client on ethernet1/1 in zone public
  interface:
    password: "admin"
    ip_address: "192.168.1.1"
    if_name: "ethernet1/1"
    zone_name: "public"
    create_default_route: "yes"

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_LIC    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_lic.py)

  Apply an authcode to a device. The authcode should have been previously registered on the Palo Alto Networks support
  portal. The device should have Internet access.

Options (= is mandatory):

= auth_code
        authcode to be applied

- force
        whether to apply authcode even if device is already licensed
        [Default: false]
= ip_address
        IP address (or hostname) of PAN-OS device

= password
        password for authentication

- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
    - hosts: localhost
      connection: local
      tasks:
        - name: fetch license
          panos_lic:
            ip_address: "192.168.1.1"
            password: "paloalto"
            auth_code: "IBADCODE"
          register: result
    - name: Display serialnumber (if already registered)
      debug:
        var: "{{result.serialnumber}}"

RETURN VALUES:
serialnumber:
    description: serialnumber of the device in case that it has been already registered
    returned: success
    type: string
    sample: 007200004214


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_LOADCFG    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_loadcfg.py)

  Load configuration on PAN-OS device

Options (= is mandatory):

- commit
        commit if changed
        [Default: True]
- file
        configuration file to load
        [Default: None]
= ip_address
        IP address (or hostname) of PAN-OS device

= password
        password for authentication

- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
# Import and load config file from URL
  - name: import configuration
    panos_import:
      ip_address: "192.168.1.1"
      password: "admin"
      url: "{{ConfigURL}}"
      category: "configuration"
    register: result
  - name: load configuration
    panos_loadcfg:
      ip_address: "192.168.1.1"
      password: "admin"
      file: "{{result.filename}}"

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_MGTCONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_mgtconfig.py)

  Configure management settings of device

Options (= is mandatory):

- commit
        commit if changed
        [Default: True]
- dns_server_primary
        address of primary DNS server
        [Default: None]
- dns_server_secondary
        address of secondary DNS server
        [Default: None]
= ip_address
        IP address (or hostname) of PAN-OS device

- panorama_primary
        address of primary Panorama server
        [Default: None]
- panorama_secondary
        address of secondary Panorama server
        [Default: None]
= password
        password for authentication

- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
- name: set dns and panorama
  panos_mgtconfig:
    ip_address: "192.168.1.1"
    password: "admin"
    dns_server_primary: "1.1.1.1"
    dns_server_secondary: "1.1.1.2"
    panorama_primary: "1.1.1.3"
    panorama_secondary: "1.1.1.4"

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_NAT_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_nat_policy.py)

  Create a policy nat rule. Keep in mind that we can either end up configuring source NAT, destination NAT, or both.
  Instead of splitting it into two we will make a fair attempt to determine which one the user wants.

Options (= is mandatory):

- commit
        commit if changed
        [Default: True]
- destination
        list of destination addresses
        [Default: [u'any']]
- dnat_address
        dnat translated address
        [Default: None]
- dnat_port
        dnat translated port
        [Default: None]
= from_zone
        list of source zones

= ip_address
        IP address (or hostname) of PAN-OS device

- override
        attempt to override rule if one with the same name already exists
        [Default: false]
= password
        password for authentication

= rule_name
        name of the SNAT rule

- service
        service
        [Default: any]
- snat_address
        snat translated address
        [Default: None]
- snat_bidirectional
        bidirectional flag
        [Default: false]
- snat_interface
        snat interface
        [Default: None]
- snat_interface_address
        snat interface address
        [Default: None]
- snat_type
        type of source translation
        [Default: None]
- source
        list of source addresses
        [Default: [u'any']]
= to_zone
        destination zone

- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
# Create a source and destination nat rule
  - name: create nat SSH221 rule for 10.0.1.101
    panos_nat:
      ip_address: "192.168.1.1"
      password: "admin"
      rule_name: "Web SSH"
      from_zone: ["external"]
      to_zone: "external"
      source: ["any"]
      destination: ["10.0.0.100"]
      service: "service-tcp-221"
      snat_type: "dynamic-ip-and-port"
      snat_interface: "ethernet1/2"
      dnat_address: "10.0.1.101"
      dnat_port: "22"
      commit: False

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_PG    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_pg.py)

  Create a security profile group

Options (= is mandatory):

- commit
        commit if changed
        [Default: True]
- data_filtering
        name of the data filtering profile
        [Default: None]
- file_blocking
        name of the file blocking profile
        [Default: None]
= ip_address
        IP address (or hostname) of PAN-OS device

= password
        password for authentication

= pg_name
        name of the security profile group

- spyware
        name of the spyware profile
        [Default: None]
- url_filtering
        name of the url filtering profile
        [Default: None]
- username
        username for authentication
        [Default: admin]
- virus
        name of the anti-virus profile
        [Default: None]
- vulnerability
        name of the vulnerability profile
        [Default: None]
- wildfire
        name of the wildfire analysis profile
        [Default: None]
Requirements:  pan-python

EXAMPLES:
- name: setup security profile group
  panos_pg:
    ip_address: "192.168.1.1"
    password: "admin"
    username: "admin"
    pg_name: "pg-default"
    virus: "default"
    spyware: "default"
    vulnerability: "default"

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_RESTART    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_restart.py)

  Restart a device

Options (= is mandatory):

= ip_address
        IP address (or hostname) of PAN-OS device

= password
        password for authentication

- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
- panos_restart:
    ip_address: "192.168.1.1"
    username: "admin"
    password: "admin"

RETURN VALUES:
status:
    description: success status
    returned: success
    type: string
    sample: "okey dokey"


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_SECURITY_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_security_policy.py)

  Security policies allow you to enforce rules and take action, and can be as general or specific as needed. The policy
  rules are compared against the incoming traffic in sequence, and because the first rule that matches the traffic is
  applied, the more specific rules must precede the more general ones.

Options (= is mandatory):

- action
        Action to apply once rules maches.
        [Default: allow]
- antivirus
        Name of the already defined antivirus profile.
        [Default: None]
- api_key
        API key that can be used instead of `username'/`password' credentials.
        [Default: (null)]
- application
        List of applications.
        [Default: any]
- commit
        Commit configuration if changed.
        [Default: True]
- data_filtering
        Name of the already defined data_filtering profile.
        [Default: None]
- description
        Description for the security rule.
        [Default: None]
- destination
        List of destination addresses.
        [Default: any]
- devicegroup
        Device groups are used for the Panorama interaction with Firewall(s). The group must exists on Panorama. If
        device group is not define we assume that we are contacting Firewall.
        [Default: None]
- file_blocking
        Name of the already defined file_blocking profile.
        [Default: None]
- from_zone
        List of source zones.
        [Default: any]
- group_profile
        Security profile group that is already defined in the system. This property supersedes antivirus, vulnerability,
        spyware, url_filtering, file_blocking, data_filtering, and wildfire_analysis properties.
        [Default: None]
- hip_profiles
        If you are using GlobalProtect with host information profile (HIP) enabled, you can also base the policy on
        information collected by GlobalProtect. For example, the user access level can be determined HIP that notifies
        the firewall about the user's local configuration.
        [Default: any]
= ip_address
        IP address (or hostname) of PAN-OS device being configured.

- log_end
        Whether to log at session end.
        [Default: True]
- log_start
        Whether to log at session start.
        [Default: False]
= password
        Password credentials to use for auth unless `api_key' is set.

= rule_name
        Name of the security rule.

- rule_type
        Type of security rule (version 6.1 of PanOS and above).
        [Default: universal]
- service
        List of services.
        [Default: application-default]
- source
        List of source addresses.
        [Default: any]
- source_user
        Use users to enforce policy for individual users or a group of users.
        [Default: any]
- spyware
        Name of the already defined spyware profile.
        [Default: None]
- tag
        Administrative tags that can be added to the rule. Note, tags must be already defined.
        [Default: None]
- to_zone
        List of destination zones.
        [Default: any]
- url_filtering
        Name of the already defined url_filtering profile.
        [Default: None]
- username
        Username credentials to use for auth unless `api_key' is set.
        [Default: admin]
- vulnerability
        Name of the already defined vulnerability profile.
        [Default: None]
- wildfire_analysis
        Name of the already defined wildfire_analysis profile.
        [Default: None]
Notes:
  * Checkmode is not supported.
  * Panorama is supported
Requirements:  pan-python can be obtained from PyPi https://pypi.python.org/pypi/pan-python, pandevice can be obtained
        from PyPi https://pypi.python.org/pypi/pandevice

EXAMPLES:
- name: permit ssh to 1.1.1.1
  panos_security_policy:
    ip_address: '10.5.172.91'
    username: 'admin'
    password: 'paloalto'
    rule_name: 'SSH permit'
    description: 'SSH rule test'
    from_zone: ['public']
    to_zone: ['private']
    source: ['any']
    source_user: ['any']
    destination: ['1.1.1.1']
    category: ['any']
    application: ['ssh']
    service: ['application-default']
    hip_profiles: ['any']
    action: 'allow'
    commit: false

- name: Allow HTTP multimedia only from CDNs
  panos_security_policy:
    ip_address: '10.5.172.91'
    username: 'admin'
    password: 'paloalto'
    rule_name: 'HTTP Multimedia'
    description: 'Allow HTTP multimedia only to host at 1.1.1.1'
    from_zone: ['public']
    to_zone: ['private']
    source: ['any']
    source_user: ['any']
    destination: ['1.1.1.1']
    category: ['content-delivery-networks']
    application: ['http-video', 'http-audio']
    service: ['service-http', 'service-https']
    hip_profiles: ['any']
    action: 'allow'
    commit: false

- name: more complex fictitious rule that uses profiles
  panos_security_policy:
    ip_address: '10.5.172.91'
    username: 'admin'
    password: 'paloalto'
    rule_name: 'Allow HTTP w profile'
    log_start: false
    log_end: true
    action: 'allow'
    antivirus: 'default'
    vulnerability: 'default'
    spyware: 'default'
    url_filtering: 'default'
    wildfire_analysis: 'default'
    commit: false

- name: deny all
  panos_security_policy:
    ip_address: '10.5.172.91'
    username: 'admin'
    password: 'paloalto'
    rule_name: 'DenyAll'
    log_start: true
    log_end: true
    action: 'deny'
    rule_type: 'interzone'
    commit: false

# permit ssh to 1.1.1.1 using panorama and pushing the configuration to firewalls
# that are defined in 'DeviceGroupA' device group
- name: permit ssh to 1.1.1.1 through Panorama
  panos_security_policy:
    ip_address: '10.5.172.92'
    password: 'paloalto'
    rule_name: 'SSH permit'
    description: 'SSH rule test'
    from_zone: ['public']
    to_zone: ['private']
    source: ['any']
    source_user: ['any']
    destination: ['1.1.1.1']
    category: ['any']
    application: ['ssh']
    service: ['application-default']
    hip_profiles: ['any']
    action: 'allow'
    devicegroup: 'DeviceGroupA'

RETURN VALUES:
# Default return values


MAINTAINERS: Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PANOS_SERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/network/panos/panos_service.py)

  Create a service object. Service objects are fundamental representation of the applications given src/dst ports and
  protocol

Options (= is mandatory):

- commit
        commit if changed
        [Default: True]
= ip_address
        IP address (or hostname) of PAN-OS device

= password
        password for authentication

= port
        destination port

= protocol
        protocol for the service, should be tcp or udp

= service_name
        name of the service

- source_port
        source port
        [Default: None]
- username
        username for authentication
        [Default: admin]
Requirements:  pan-python

EXAMPLES:
# Creates service for port 22
  - name: create SSH service
    panos_service:
      ip_address: "192.168.1.1"
      password: "admin"
      service_name: "service-tcp-22"
      protocol: "tcp"
      port: "22"

RETURN VALUES:
# Default return values


MAINTAINERS: Luigi Mori (@jtschichold), Ivan Bojer (@ivanbojer)

METADATA:
	Status: ['preview']
	Supported_by: community
> PARTED    (/usr/lib/python2.7/site-packages/ansible/modules/system/parted.py)

  This module allows configuring block device partition using the `parted' command line tool. For a full description of
  the fields and the options check the GNU parted manual.

Options (= is mandatory):

- align
        Set alignment for newly created partitions.
        (Choices: none, cylinder, minimal, optimal)[Default: optimal]
= device
        The block device (disk) where to operate.

- flags
        A list of the flags that has to be set on the partition.
        [Default: (null)]
- label
        Creates a new disk label.
        (Choices: aix, amiga, bsd, dvh, gpt, loop, mac, msdos, pc98, sun, )[Default: msdos]
- name
        Sets the name for the partition number (GPT, Mac, MIPS and PC98 only).
        [Default: (null)]
- number
        The number of the partition to work with or the number of the partition that will be created. Required when
        performing any action on the disk, except fetching information.
        [Default: (null)]
- part_end
        Where the partition will end as offset from the beginning of the disk, that is, the "distance" from the start of
        the disk. The distance can be specified with all the units supported by parted (except compat) and it is case
        sensitive. E.g. `10GiB', `15%'.
        [Default: 100%]
- part_start
        Where the partition will start as offset from the beginning of the disk, that is, the "distance" from the start
        of the disk. The distance can be specified with all the units supported by parted (except compat) and it is case
        sensitive. E.g. `10GiB', `15%'.
        [Default: 0%]
- part_type
        Is one of 'primary', 'extended' or 'logical' and may be specified only with 'msdos' or 'dvh' partition tables. A
        name must be specified for a 'gpt' partition table. Neither part-type nor name may be used with a 'sun' partition
        table.
        (Choices: primary, extended, logical)[Default: (null)]
- state
        If to create or delete a partition. If set to `info' the module will only return the device information.
        (Choices: present, absent, info)[Default: info]
- unit
        Selects the current default unit that Parted will use to display locations and capacities on the disk and to
        interpret those given by the user if they are not suffixed by an unit. When fetching information about a disk, it
        is always recommended to specify a unit.
        (Choices: s, B, KB, KiB, MB, MiB, GB, GiB, TB, TiB, %, cyl, chs, compact)[Default: KiB]
Notes:
  * When fetching information about a new disk and when the version of parted installed on the system is before
        version 3.1, the module queries the kernel through `/sys/' to obtain disk information. In this case the
        units CHS and CYL are not supported.
Requirements:  This module requires parted version 1.8.3 and above., If the version of parted is below 3.1, it
        requires a Linux version running the sysfs file system `/sys/'.

EXAMPLES:
# Create a new primary partition
- parted:
    device: /dev/sdb
    number: 1
    state: present

# Remove partition number 1
- parted:
    device: /dev/sdb
    number: 1
    state: absent

# Create a new primary partition with a size of 1GiB
- parted:
    device: /dev/sdb
    number: 1
    state: present
    part_end: 1GiB

# Create a new primary partition for LVM
- parted:
    device: /dev/sdb
    number: 2
    flags: [ lvm ]
    state: present
    part_start: 1GiB

# Read device information (always use unit when probing)
- parted: device=/dev/sdb unit=MiB
  register: sdb_info

# Remove all partitions from disk
- parted:
    device: /dev/sdb
    number: "{{ item.num }}"
    state: absent
  with_items:
   - "{{ sdb_info.partitions }}"

RETURN VALUES:
partition_info:
  description: Current partition information
  returned: success
  type: dict
  contains:
    device:
      description: Generic device information.
      type: dict
    partitions:
      description: List of device partitions.
      type: list
    sample: >
      {
        "disk": {
          "dev": "/dev/sdb",
          "logical_block": 512,
          "model": "VMware Virtual disk",
          "physical_block": 512,
          "size": 5.0,
          "table": "msdos",
          "unit": "gib"
        },
        "partitions": [{
          "begin": 0.0,
          "end": 1.0,
          "flags": ["boot", "lvm"],
          "fstype": null,
          "num": 1,
          "size": 1.0
        }, {
          "begin": 1.0,
          "end": 5.0,
          "flags": [],
          "fstype": null,
          "num": 2,
          "size": 4.0
        }]
      }


MAINTAINERS: Fabrizio Colonna (@ColOfAbRiX)

METADATA:
	Status: ['preview']
	Supported_by: community
> PATCH    (/usr/lib/python2.7/site-packages/ansible/modules/files/patch.py)

  Apply patch files using the GNU patch tool.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- backup
        passes --backup --version-control=numbered to patch, producing numbered backup copies
        (Choices: yes, no)[Default: no]
- basedir
        Path of a base directory in which the patch file will be applied. May be omitted when `dest' option is specified,
        otherwise required.
        [Default: (null)]
- binary
        Setting to `yes' will disable patch's heuristic for transforming CRLF line endings into LF. Line endings of src
        and dest must match. If set to `no', patch will replace CRLF in src files on POSIX.
        [Default: no]
- dest
        Path of the file on the remote machine to be patched.
        The names of the files to be patched are usually taken from the patch file, but if there's just one file to be
        patched it can specified with this option.
        [Default: (null)]
- remote_src
        If `no', it will search for src at originating/master machine, if `yes' it will go to the remote/target machine
        for the src. Default is `no'.
        (Choices: yes, no)[Default: no]
= src
        Path of the patch file as accepted by the GNU patch tool. If `remote_src' is 'no', the patch source file is
        looked up from the module's "files" directory.

- strip
        Number that indicates the smallest prefix containing leading slashes that will be stripped from each file name
        found in the patch file. For more information see the strip parameter of the GNU patch tool.
        [Default: 0]
Notes:
  * This module requires GNU `patch' utility to be installed on the remote host.
EXAMPLES:
- name: apply patch to one file
  patch:
    src: /tmp/index.html.patch
    dest: /var/www/index.html

- name: apply patch to multiple files under basedir
  patch:
    src: /tmp/customize.patch
    basedir: /var/www
    strip: 1


MAINTAINERS: Luis Alberto Perez Lazaro (@luisperlaz), Jakub Jirutka (@jirutka)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PAUSE    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/pause.py)

  Pauses playbook execution for a set amount of time, or until a prompt is acknowledged. All parameters are optional. The
  default behavior is to pause with a prompt. You can use `ctrl+c' if you wish to advance a pause earlier than it is set
  to expire or if you need to abort a playbook run entirely. To continue early: press `ctrl+c' and then `c'. To abort a
  playbook: press `ctrl+c' and then `a'. The pause module integrates into async/parallelized playbooks without any
  special considerations (see also: Rolling Updates). When using pauses with the `serial' playbook parameter (as in
  rolling updates) you are only prompted once for the current group of hosts.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- minutes
        A positive number of minutes to pause for.
        [Default: None]
- prompt
        Optional text to use for the prompt message.
        [Default: None]
- seconds
        A positive number of seconds to pause for.
        [Default: None]
Notes:
  * Starting in 2.2,  if you specify 0 or negative for minutes or seconds, it will wait for 1 second, previously it
        would wait indefinitely.
EXAMPLES:
# Pause for 5 minutes to build app cache.
- pause:
    minutes: 5

# Pause until you can verify updates to an application were successful.
- pause:

# A helpful reminder of what to look out for post-update.
- pause:
    prompt: "Make sure org.foo.FooOverload exception is not present"

RETURN VALUES:
user_input:
  description: User input from interactive console
  returned: if no waiting time set
  type: string
  sample: Example user input
start:
  description: Time when started pausing
  returned: always
  type: string
  sample: 2017-02-23 14:35:07.298862
stop:
  description: Time when ended pausing
  returned: always
  type: string
  sample: 2017-02-23 14:35:09.552594
delta:
  description: Time paused in seconds
  returned: always
  type: string
  sample: 2
stdout:
  description: Output of pause module
  returned: always
  type: string
  sample: Paused for 0.04 minutes


MAINTAINERS: Tim Bielawa (@tbielawa)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> PEAR    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/pear.py)

  Manage PHP packages with the pear package manager.

Options (= is mandatory):

= name
        Name of the package to install, upgrade, or remove.

- state
        Desired state of the package.
        (Choices: present, absent, latest)[Default: present]
EXAMPLES:
# Install pear package
- pear:
    name: Net_URL2
    state: present

# Install pecl package
- pear:
    name: pecl/json_post
    state: present

# Upgrade package
- pear:
    name: Net_URL2
    state: latest

# Remove packages
- pear:
    name: Net_URL2,pecl/json_post
    state: absent


MAINTAINERS: 'jonathan.lestrelin' <jonathan.lestrelin@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> PING    (/usr/lib/python2.7/site-packages/ansible/modules/system/ping.py)

  A trivial test module, this module always returns `pong' on successful contact. It does not make sense in playbooks,
  but it is useful from `/usr/bin/ansible' to verify the ability to login and that a usable python is configured. This is
  NOT ICMP ping, this is just a trivial test module.

EXAMPLES:
# Test we can logon to 'webservers' and execute python with json lib.
ansible webservers -m ping


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> PINGDOM    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/pingdom.py)

  This module will let you pause/unpause Pingdom alerts

Options (= is mandatory):

= checkid
        Pingdom ID of the check.
        (Choices: )[Default: None]
= key
        Pingdom API key.
        (Choices: )[Default: None]
= passwd
        Pingdom user password.
        (Choices: )[Default: None]
= state
        Define whether or not the check should be running or paused.
        (Choices: running, paused)[Default: None]
= uid
        Pingdom user ID.
        (Choices: )[Default: None]
Notes:
  * This module does not yet have support to add/remove checks.
Requirements:  This pingdom python library: https://github.com/mbabineau/pingdom-python

EXAMPLES:
# Pause the check with the ID of 12345.
- pingdom:
    uid: example@example.com
    passwd: password123
    key: apipassword123
    checkid: 12345
    state: paused

# Unpause the check with the ID of 12345.
- pingdom:
    uid: example@example.com
    passwd: password123
    key: apipassword123
    checkid: 12345
    state: running


MAINTAINERS: Justin Johns, Dylan Silva (@thaumos)

METADATA:
	Status: ['preview']
	Supported_by: community
> PIP    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/language/pip.py)

  Manage Python library dependencies. To use this module, one of the following keys is required: `name' or
  `requirements'.

Options (= is mandatory):

- chdir
        cd into this directory before running the command
        [Default: None]
- editable
        Pass the editable flag for versioning URLs.
        [Default: True]
- executable
        The explicit executable or a pathname to the executable to be used to run pip for a specific version of Python
        installed in the system. For example `pip-3.3', if there are both Python 2.7 and 3.3 installations in the system
        and you want to run pip for the Python 3.3 installation. It cannot be specified together with the 'virtualenv'
        parameter (added in 2.1). By default, it will take the appropriate version for the python interpreter use by
        ansible, e.g. pip3 on python 3, and pip2 or pip on python 2.
        [Default: None]
- extra_args
        Extra arguments passed to pip.
        [Default: None]
- name
        The name of a Python library to install or the url of the remote package.
        As of 2.2 you can supply a list of names.
        [Default: None]
- requirements
        The path to a pip requirements file, which should be local to the remote system. File can be specified as a
        relative path if using the chdir option.
        [Default: None]
- state
        The state of module
        The 'forcereinstall' option is only available in Ansible 2.1 and above.
        (Choices: present, absent, latest, forcereinstall)[Default: present]
- umask
        The system umask to apply before installing the pip package. This is useful, for example, when installing on
        systems that have a very restrictive umask by default (e.g., 0077) and you want to pip install packages which are
        to be used by all users. Note that this requires you to specify desired umask mode in octal, with a leading 0
        (e.g., 0077).
        [Default: None]
- version
        The version number to install of the Python library specified in the `name' parameter
        [Default: None]
- virtualenv
        An optional path to a `virtualenv' directory to install into. It cannot be specified together with the
        'executable' parameter (added in 2.1). If the virtualenv does not exist, it will be created before installing
        packages. The optional virtualenv_site_packages, virtualenv_command, and virtualenv_python options affect the
        creation of the virtualenv.
        [Default: None]
- virtualenv_command
        The command or a pathname to the command to create the virtual environment with. For example `pyvenv',
        `virtualenv', `virtualenv2', `~/bin/virtualenv', `/usr/local/bin/virtualenv'.
        [Default: virtualenv]
- virtualenv_python
        The Python executable used for creating the virtual environment. For example `python3.5', `python2.7'. When not
        specified, the Python version used to run the ansible module is used.
        [Default: None]
- virtualenv_site_packages
        Whether the virtual environment will inherit packages from the global site-packages directory.  Note that if this
        setting is changed on an already existing virtual environment it will not have any effect, the environment must
        be deleted and newly created.
        (Choices: yes, no)[Default: no]
Notes:
  * Please note that virtualenv (http://www.virtualenv.org/) must be installed on the remote host if the virtualenv
        parameter is specified and the virtualenv needs to be created.
  * By default, this module will use the appropriate version of pip for the interpreter used by ansible (e.g. pip3
        when using python 3, pip2 otherwise)
Requirements:  virtualenv, pip

EXAMPLES:
# Install (Bottle) python package.
- pip:
    name: bottle

# Install (Bottle) python package on version 0.11.
- pip:
    name: bottle
    version: 0.11

# Install (MyApp) using one of the remote protocols (bzr+,hg+,git+,svn+). You do not have to supply '-e' option in extra_args.
- pip:
    name: svn+http://myrepo/svn/MyApp#egg=MyApp

# Install MyApp using one of the remote protocols (bzr+,hg+,git+) in a non editable way.
- pip:
    name: git+http://myrepo/app/MyApp
    editable: false

# Install (MyApp) from local tarball
- pip:
    name: file:///path/to/MyApp.tar.gz

# Install (Bottle) into the specified (virtualenv), inheriting none of the globally installed modules
- pip:
    name: bottle
    virtualenv: /my_app/venv

# Install (Bottle) into the specified (virtualenv), inheriting globally installed modules
- pip:
    name: bottle
    virtualenv: /my_app/venv
    virtualenv_site_packages: yes

# Install (Bottle) into the specified (virtualenv), using Python 2.7
- pip:
    name: bottle
    virtualenv: /my_app/venv
    virtualenv_command: virtualenv-2.7

# Install specified python requirements.
- pip:
    requirements: /my_app/requirements.txt

# Install specified python requirements in indicated (virtualenv).
- pip:
    requirements: /my_app/requirements.txt
    virtualenv: /my_app/venv

# Install specified python requirements and custom Index URL.
- pip:
    requirements: /my_app/requirements.txt
    extra_args: -i https://example.com/pypi/simple

# Install (Bottle) for Python 3.3 specifically,using the 'pip-3.3' executable.
- pip:
    name: bottle
    executable: pip-3.3

# Install (Bottle), forcing reinstallation if it's already installed
- pip:
    name: bottle
    state: forcereinstall

# Install (Bottle) while ensuring the umask is 0022 (to ensure other users can use it)
- pip:
    name: bottle
    umask: 0022
  become: True


MAINTAINERS: Matt Wright (@mattupstate)

METADATA:
	Status: ['preview']
	Supported_by: curated
> PKG5    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/pkg5.py)

  IPS packages are the native packages in Solaris 11 and higher.

Options (= is mandatory):

- accept_licenses
        Accept any licences.
        (Choices: True, False)[Default: False]
= name
        An FRMI of the package(s) to be installed/removed/updated.
        Multiple packages may be specified, separated by `,'.

- state
        Whether to install (`present', `latest'), or remove (`absent') a package.
        (Choices: present, latest, absent)[Default: present]
Notes:
  * The naming of IPS packages is explained at http://www.oracle.com/technetwork/articles/servers-storage-admin
        /ips-package-versioning-2232906.html.
EXAMPLES:
# Install Vim:
- pkg5:
    name: editor/vim

# Remove finger daemon:
- pkg5:
    name: service/network/finger
    state: absent

# Install several packages at once:
- pkg5:
    name:
      - /file/gnu-findutils
      - /text/gnu-grep


MAINTAINERS: Peter Oliver (@mavit)

METADATA:
	Status: ['preview']
	Supported_by: community
> PKG5_PUBLISHER    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/pkg5_publisher.py)

  IPS packages are the native packages in Solaris 11 and higher. This modules will configure which publishers a client
  will download IPS packages from.

Options (= is mandatory):

- enabled
        Is the repository enabled or disabled?
        (Choices: True, False)[Default: None]
- mirror
        A path or URL to the repository mirror.
        Multiple values may be provided.
        [Default: None]
= name
        The publisher's name.

- origin
        A path or URL to the repository.
        Multiple values may be provided.
        [Default: None]
- state
        Whether to ensure that a publisher is present or absent.
        (Choices: present, absent)[Default: present]
- sticky
        Packages installed from a sticky repository can only receive updates from that repository.
        (Choices: True, False)[Default: None]
EXAMPLES:
# Fetch packages for the solaris publisher direct from Oracle:
- pkg5_publisher:
    name: solaris
    sticky: true
    origin: https://pkg.oracle.com/solaris/support/

# Configure a publisher for locally-produced packages:
- pkg5_publisher:
    name: site
    origin: 'https://pkg.example.com/site/'


MAINTAINERS: Peter Oliver (@mavit)

METADATA:
	Status: ['preview']
	Supported_by: community
> PKGIN    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/pkgin.py)

  The standard package manager for SmartOS, but also usable on NetBSD or any OS that uses `pkgsrc'.  (Home:
  http://pkgin.net/)

Options (= is mandatory):

- clean
        Clean packages cache
        (Choices: yes, no)[Default: False]
- force
        Force package reinstall
        (Choices: yes, no)[Default: False]
- full_upgrade
        Upgrade all packages to their newer versions
        (Choices: yes, no)[Default: False]
- name
        Name of package to install/remove;
        multiple names may be given, separated by commas
        [Default: None]
- state
        Intended state of the package
        (Choices: present, absent)[Default: present]
- update_cache
        Update repository database. Can be run with other steps or on it's own.
        (Choices: yes, no)[Default: False]
- upgrade
        Upgrade main packages to their newer versions
        (Choices: yes, no)[Default: False]
Notes:
  * Known bug with pkgin < 0.8.0: if a package is removed and another package depends on it, the other package will
        be silently removed as well.  New to Ansible 1.9: check-mode support.
EXAMPLES:
# install package foo
- pkgin:
    name: foo
    state: present

# Update database and install "foo" package
- pkgin:
    name: foo
    update_cache: yes

# remove package foo
- pkgin:
    name: foo
    state: absent

# remove packages foo and bar
- pkgin:
    name: foo,bar
    state: absent

# Update repositories as a separate step
- pkgin:
    update_cache: yes

# Upgrade main packages (equivalent to C(pkgin upgrade))
- pkgin:
    upgrade: yes

# Upgrade all packages (equivalent to C(pkgin full-upgrade))
- pkgin:
    full_upgrade: yes

# Force-upgrade all packages (equivalent to C(pkgin -F full-upgrade))
- pkgin:
    full_upgrade: yes
    force: yes

# clean packages cache (equivalent to C(pkgin clean))
- pkgin:
    clean: yes


MAINTAINERS: Shaun Zinck (@szinck), Larry Gilbert (L2G), Jasper Lievisse Adriaanse (@jasperla)

METADATA:
	Status: ['preview']
	Supported_by: community
> PKGNG    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/pkgng.py)

  Manage binary packages for FreeBSD using 'pkgng' which is available in versions after 9.0.

Options (= is mandatory):

- annotation
        A comma-separated list of keyvalue-pairs of the form `<+/-/:><key>[=<value>]'. A `+' denotes adding an
        annotation, a `-' denotes removing an annotation, and `:' denotes modifying an annotation. If setting or
        modifying annotations, a value must be provided.
        [Default: (null)]
- autoremove
        Remove automatically installed packages which are no longer needed.
        (Choices: yes, no)[Default: False]
- cached
        Use local package base instead of fetching an updated one.
        (Choices: yes, no)[Default: False]
- chroot
        Pkg will chroot in the specified environment.
        Can not be used together with `rootdir' option.
        [Default: (null)]
= name
        Name of package to install/remove.

- pkgsite
        For pkgng versions before 1.1.4, specify packagesite to use for downloading packages. If not specified, use
        settings from `/usr/local/etc/pkg.conf'.
        For newer pkgng versions, specify a the name of a repository configured in `/usr/local/etc/pkg/repos'.
        [Default: (null)]
- rootdir
        For pkgng versions 1.5 and later, pkg will install all packages within the specified root directory.
        Can not be used together with `chroot' option.
        [Default: (null)]
- state
        State of the package.
        (Choices: present, absent)[Default: present]
Notes:
  * When using pkgsite, be careful that already in cache packages won't be downloaded again.
EXAMPLES:
# Install package foo
- pkgng:
    name: foo
    state: present

# Annotate package foo and bar
- pkgng:
    name: foo,bar
    annotation: '+test1=baz,-test2,:test3=foobar'

# Remove packages foo and bar
- pkgng:
    name: foo,bar
    state: absent


MAINTAINERS: bleader (@bleader)

METADATA:
	Status: ['preview']
	Supported_by: community
> PKGUTIL    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/pkgutil.py)

  Manages CSW packages (SVR4 format) on Solaris 10 and 11. These were the native packages on Solaris <= 10 and are
  available as a legacy feature in Solaris 11. Pkgutil is an advanced packaging system, which resolves dependency on
  installation. It is designed for CSW packages.

Options (= is mandatory):

= name
        Package name, e.g. (`CSWnrpe')

- site
        Specifies the repository path to install the package from.
        Its global definition is done in `/etc/opt/csw/pkgutil.conf'.
        [Default: (null)]
= state
        Whether to install (`present'), or remove (`absent') a package.
        The upgrade (`latest') operation will update/install the package to the latest version available.
        Note: The module has a limitation that (`latest') only works for one package, not lists of them.
        (Choices: present, absent, latest)
- update_catalog
        If you want to refresh your catalog from the mirror, set this to (`yes').
        [Default: False]
EXAMPLES:
# Install a package
- pkgutil:
    name: CSWcommon
    state: present

# Install a package from a specific repository
- pkgutil:
    name: CSWnrpe
    site: 'ftp://myinternal.repo/opencsw/kiel'
    state: latest


MAINTAINERS: Alexander Winkler (@dermute)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PN_CLUSTER    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_cluster.py)

  Execute cluster-create or cluster-delete command. A cluster allows two switches to cooperate in high-availability (HA)
  deployments. The nodes that form the cluster must be members of the same fabric. Clusters are typically used in
  conjunction with a virtual link aggregation group (VLAG) that allows links physically connected to two separate
  switches appear as a single trunk to a third device. The third device can be a switch,server, or any Ethernet device.

Options (= is mandatory):

- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch to run the cli on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
- pn_cluster_node1
        Specify the name of the first switch in the cluster.
        Required for 'cluster-create'.
        [Default: (null)]
- pn_cluster_node2
        Specify the name of the second switch in the cluster.
        Required for 'cluster-create'.
        [Default: (null)]
= pn_name
        Specify the name of the cluster.

- pn_validate
        Validate the inter-switch links and state of switches in the cluster.
        (Choices: validate, no-validate)[Default: (null)]
= state
        Specify action to perform. Use 'present' to create cluster and 'absent' to delete cluster.
        (Choices: present, absent)
EXAMPLES:
- name: create spine cluster
  pn_cluster:
    state: 'present'
    pn_name: 'spine-cluster'
    pn_cluster_node1: 'spine01'
    pn_cluster_node2: 'spine02'
    pn_validate: validate
    pn_quiet: True

- name: delete spine cluster
  pn_cluster:
    state: 'absent'
    pn_name: 'spine-cluster'
    pn_quiet: True

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the cluster command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the cluster command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_OSPF    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_ospf.py)

  Execute vrouter-ospf-add, vrouter-ospf-remove command. This command adds/removes Open Shortest Path First(OSPF) routing
  protocol to a virtual router(vRouter) service.

Options (= is mandatory):

- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch to run the CLI on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
= pn_network_ip
        Specify the network IP (IPv4 or IPv6) address.

- pn_ospf_area
        Stub area number for the configuration. Required for vrouter-ospf-add.
        [Default: (null)]
= pn_vrouter_name
        Specify the name of the vRouter.

= state
        Assert the state of the ospf. Use 'present' to add ospf and 'absent' to remove ospf.
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: "Add OSPF to vrouter"
  pn_ospf:
    state: present
    pn_vrouter_name: name-string
    pn_network_ip: 192.168.11.2/24
    pn_ospf_area: 1.0.0.0

- name: "Remove OSPF from vrouter"
  pn_ospf:
    state: absent
    pn_vrouter_name: name-string

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the ospf command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the ospf command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_OSPFAREA    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_ospfarea.py)

  Execute vrouter-ospf-add, vrouter-ospf-remove command. This command adds/removes Open Shortest Path First(OSPF) area
  to/from a virtual router(vRouter) service.

Options (= is mandatory):

= pn_clipassword
        Login password.

- pn_cliswitch
        Target switch(es) to run the CLI on.
        [Default: (null)]
= pn_cliusername
        Login username.

= pn_ospf_area
        Specify the OSPF area number.

- pn_prefix_listin
        OSPF prefix list for filtering incoming packets.
        [Default: (null)]
- pn_prefix_listout
        OSPF prefix list for filtering outgoing packets.
        [Default: (null)]
- pn_quiet
        Enable/disable system information.
        [Default: True]
- pn_stub_type
        Specify the OSPF stub type.
        (Choices: none, stub, stub-no-summary, nssa, nssa-no-summary)[Default: (null)]
= pn_vrouter_name
        Specify the name of the vRouter.

= state
        State the action to perform. Use 'present' to add ospf-area, 'absent' to remove ospf-area and 'update' to modify
        ospf-area.
        (Choices: present, absent, update)
EXAMPLES:
- name: "Add OSPF area to vrouter"
  pn_ospfarea:
    state: present
    pn_cliusername: admin
    pn_clipassword: admin
    pn_ospf_area: 1.0.0.0
    pn_stub_type: stub

- name: "Remove OSPF from vrouter"
  pn_ospf:
    state: absent
    pn_cliusername: admin
    pn_clipassword: admin
    pn_vrouter_name: name-string
    pn_ospf_area: 1.0.0.0

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the ospf command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the ospf command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_SHOW    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_show.py)

  Execute show command in the nodes and returns the results read from the device.

Options (= is mandatory):

- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch(es) to run the cli on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
= pn_command
        The `pn_command' takes a CLI show command as value.

- pn_options
        Specify formatting options.
        [Default: (null)]
- pn_parameters
        Display output using a specific parameter. Use 'all' to display possible output. List of comma separated
        parameters.
        [Default: (null)]
EXAMPLES:
- name: run the vlan-show command
  pn_show:
    pn_command: 'vlan-show'
    pn_parameters: id,scope,ports
    pn_options: 'layout vertical'

- name: run the vlag-show command
  pn_show:
    pn_command: 'vlag-show'
    pn_parameters: 'id,name,cluster,mode'
    pn_options: 'no-show-headers'

- name: run the cluster-show command
  pn_show:
    pn_command: 'cluster-show'

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the show command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the show command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused any change on the target.
  returned: always(False)
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_TRUNK    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_trunk.py)

  Execute trunk-create or trunk-delete command. Trunks can be used to aggregate network links at Layer 2 on the local
  switch. Use this command to create a new trunk.

Options (= is mandatory):

- pn_broadcast_level
        Specify a broadcast level in percent. The default value is 100%.
        [Default: (null)]
- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch(es) to run the cli on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
- pn_description
        Specify a description for the trunk configuration.
        [Default: (null)]
- pn_edge_switch
        Specify if the switch is an edge switch.
        [Default: (null)]
- pn_egress_rate_limit
        Specify an egress port data rate limit for the configuration.
        [Default: (null)]
- pn_host
        Host facing port control setting.
        [Default: (null)]
- pn_jumbo
        Specify if the port can receive jumbo frames.
        [Default: (null)]
- pn_lacp_fallback
        Specify the LACP fallback mode as bundles or individual.
        (Choices: bundle, individual)[Default: (null)]
- pn_lacp_fallback_timeout
        Specify the LACP fallback timeout in seconds. The range is between 30 and 60 seconds with a default value of 50
        seconds.
        [Default: (null)]
- pn_lacp_mode
        Specify the LACP mode for the configuration.
        (Choices: off, passive, active)[Default: (null)]
- pn_lacp_priority
        Specify the LACP priority. This is a number between 1 and 65535 with a default value of 32768.
        [Default: (null)]
- pn_lacp_timeout
        Specify the LACP time out as slow (30 seconds) or fast (4seconds). The default value is slow.
        (Choices: slow, fast)[Default: (null)]
- pn_loopback
        Specify loopback if you want to use loopback.
        [Default: (null)]
- pn_loopvlans
        Specify a list of looping vlans.
        [Default: (null)]
- pn_mirror_receive
        Specify if the configuration receives mirrored traffic.
        [Default: (null)]
= pn_name
        Specify the name for the trunk configuration.

- pn_pause
        Specify if pause frames are sent.
        [Default: (null)]
- pn_port_macaddr
        Specify the MAC address of the port.
        [Default: (null)]
- pn_ports
        Specify the port number(s) for the link(s) to aggregate into the trunk.
        Required for trunk-create.
        [Default: (null)]
- pn_routing
        Specify if the port participates in routing on the network.
        [Default: (null)]
- pn_speed
        Specify the port speed or disable the port.
        (Choices: disable, 10m, 100m, 1g, 2.5g, 10g, 40g)[Default: (null)]
- pn_unknown_mcast_level
        Specify an unknown multicast level in percent. The default value is 100%.
        [Default: (null)]
- pn_unknown_ucast_level
        Specify an unknown unicast level in percent. The default value is 100%.
        [Default: (null)]
= state
        State the action to perform. Use 'present' to create trunk, 'absent' to delete trunk and 'update' to modify
        trunk.
        (Choices: present, absent, update)
EXAMPLES:
- name: create trunk
  pn_trunk:
    state: 'present'
    pn_name: 'spine-to-leaf'
    pn_ports: '11,12,13,14'

- name: delete trunk
  pn_trunk:
    state: 'absent'
    pn_name: 'spine-to-leaf'

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the trunk command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the trunk command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_VLAG    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_vlag.py)

  Execute vlag-create/vlag-delete/vlag-modify command. A virtual link aggregation group (VLAG) allows links that are
  physically connected to two different Pluribus Networks devices to appear as a single trunk to a third device. The
  third device can be a switch, server, or any Ethernet device. A VLAG can provide Layer 2 multipathing, which allows you
  to create redundancy by increasing bandwidth, enabling multiple parallel paths between nodes and loadbalancing traffic
  where alternative paths exist.

Options (= is mandatory):

- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch(es) to run this command on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
- pn_failover_action
        Specify the failover action as move or ignore.
        (Choices: move, ignore)[Default: (null)]
- pn_lacp_fallback
        Specify the LACP fallback mode as bundles or individual.
        (Choices: bundle, individual)[Default: (null)]
- pn_lacp_fallback_timeout
        Specify the LACP fallback timeout in seconds. The range is between 30 and 60 seconds with a default value of 50
        seconds.
        [Default: (null)]
- pn_lacp_mode
        Specify the LACP mode.
        (Choices: off, passive, active)[Default: (null)]
- pn_lacp_timeout
        Specify the LACP timeout as slow(30 seconds) or fast(4 seconds).
        (Choices: slow, fast)[Default: (null)]
- pn_mode
        Specify the mode for the VLAG. Active-standby indicates one side is active and the other side is in standby mode.
        Active-active indicates that both sides of the vlag are up by default.
        (Choices: active-active, active-standby)[Default: (null)]
= pn_name
        The `pn_name' takes a valid name for vlag configuration.

- pn_peer_port
        Specify the peer VLAG port.
        Required for vlag-create.
        [Default: (null)]
- pn_peer_switch
        Specify the fabric-name of the peer switch.
        [Default: (null)]
- pn_port
        Specify the local VLAG port.
        Required for vlag-create.
        [Default: (null)]
= state
        State the action to perform. Use 'present' to create vlag, 'absent' to delete vlag and 'update' to modify vlag.
        (Choices: present, absent, update)
EXAMPLES:
- name: create a VLAG
  pn_vlag:
    state: 'present'
    pn_name: spine-to-leaf
    pn_port: 'spine01-to-leaf'
    pn_peer_port: 'spine02-to-leaf'
    pn_peer_switch: spine02
    pn_mode: 'active-active'

- name: delete VLAGs
  pn_vlag:
    state: 'absent'
    pn_name: spine-to-leaf

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the vlag command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the vlag command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_VLAN    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_vlan.py)

  Execute vlan-create or vlan-delete command. VLANs are used to isolate network traffic at Layer 2.The VLAN identifiers 0
  and 4095 are reserved and cannot be used per the IEEE 802.1Q standard. The range of configurable VLAN identifiers is 2
  through 4092.

Options (= is mandatory):

- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch(es) to run the cli on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
- pn_description
        Specify a description for the VLAN.
        [Default: (null)]
- pn_ports
        Specifies the switch network data port number, list of ports, or range of ports. Port numbers must ne in the
        range of 1 to 64.
        [Default: (null)]
- pn_scope
        Specify a scope for the VLAN.
        Required for vlan-create.
        (Choices: fabric, local)[Default: (null)]
- pn_stats
        Specify if you want to collect statistics for a VLAN. Statistic collection is enabled by default.
        [Default: (null)]
- pn_untagged_ports
        Specifies the ports that should have untagged packets mapped to the VLAN. Untagged packets are packets that do
        not contain IEEE 802.1Q VLAN tags.
        [Default: (null)]
= pn_vlanid
        Specify a VLAN identifier for the VLAN. This is a value between 2 and 4092.

= state
        State the action to perform. Use 'present' to create vlan and 'absent' to delete vlan.
        (Choices: present, absent)
EXAMPLES:
- name: create a VLAN
  pn_vlan:
    state: 'present'
    pn_vlanid: 1854
    pn_scope: fabric

- name: delete VLANs
  pn_vlan:
    state: 'absent'
    pn_vlanid: 1854

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the vlan command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the vlan command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_VROUTER    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_vrouter.py)

  Execute vrouter-create, vrouter-delete, vrouter-modify command. Each fabric, cluster, standalone switch, or virtual
  network (VNET) can provide its tenants with a virtual router (vRouter) service that forwards traffic between networks
  and implements Layer 3 protocols. `vrouter-create' creates a new vRouter service. `vrouter-delete' deletes a vRouter
  service. `vrouter-modify' modifies a vRouter service.

Options (= is mandatory):

- pn_bgp_as
        Specify the Autonomous System Number(ASN) if the vRouter runs Border Gateway Protocol(BGP).
        [Default: (null)]
- pn_bgp_max_paths
        Specify the maximum number of paths for BGP. This is a number between 1 and 255 or 0 to unset.
        [Default: (null)]
- pn_bgp_options
        Specify other BGP options as a whitespaces separated string within single quotes ''.
        [Default: (null)]
- pn_bgp_redistribute
        Specify how BGP routes are redistributed.
        (Choices: static, connected, rip, ospf)[Default: (null)]
- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch(es) to run the CLI on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
- pn_hw_vrrp_id
        Specifies the VRRP ID for a hardware vrouter.
        [Default: (null)]
= pn_name
        Specify the name of the vRouter.

- pn_ospf_options
        Specify other OSPF options as a whitespaces separated string within single quotes ''.
        [Default: (null)]
- pn_ospf_redistribute
        Specify how OSPF routes are redistributed.
        (Choices: static, connected, bgp, rip)[Default: (null)]
- pn_rip_redistribute
        Specify how RIP routes are redistributed.
        (Choices: static, connected, ospf, bgp)[Default: (null)]
- pn_router_id
        Specify the vRouter IP address.
        [Default: (null)]
- pn_router_type
        Specify if the vRouter uses software or hardware.
        Note that if you specify hardware as router type, you cannot assign IP addresses using DHCP. You must specify a
        static IP address.
        (Choices: hardware, software)[Default: (null)]
- pn_service_state
        Specify to enable or disable vRouter service.
        (Choices: enable, disable)[Default: (null)]
- pn_service_type
        Specify if the vRouter is a dedicated or shared VNET service.
        (Choices: dedicated, shared)[Default: (null)]
- pn_vnet
        Specify the name of the VNET.
        Required for vrouter-create.
        [Default: (null)]
= state
        State the action to perform. Use 'present' to create vrouter, 'absent' to delete vrouter and 'update' to modify
        vrouter.
        (Choices: present, absent, update)
EXAMPLES:
- name: create vrouter
  pn_vrouter:
    state: 'present'
    pn_name: 'ansible-vrouter'
    pn_vnet: 'ansible-fab-global'
    pn_router_id: 208.74.182.1

- name: delete vrouter
  pn_vrouter:
    state: 'absent'
    pn_name: 'ansible-vrouter'

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the vrouter command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the vrouter command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_VROUTERBGP    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_vrouterbgp.py)

  Execute vrouter-bgp-add, vrouter-bgp-remove, vrouter-bgp-modify command. Each fabric, cluster, standalone switch, or
  virtual network (VNET) can provide its tenants with a vRouter service that forwards traffic between networks and
  implements Layer 4 protocols.

Options (= is mandatory):

- pn_bfd
        Specify if you want BFD protocol support for fault detection.
        [Default: (null)]
- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch(es) to run the cli on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
- pn_default_originate
        Specify if you want announce default routes to the neighbor or not.
        [Default: (null)]
- pn_ebgp
        Specify a value for external BGP to accept or attempt BGP connections to external peers, not directly connected,
        on the network. This is a value between 1 and 255.
        [Default: (null)]
- pn_holdtime
        Specify BGP neighbor holdtime in seconds.
        [Default: (null)]
- pn_keepalive
        Specify BGP neighbor keepalive interval in seconds.
        [Default: (null)]
- pn_max_prefix
        Specify the maximum number of prefixes.
        [Default: (null)]
- pn_max_prefix_warn
        Specify if you want a warning message when the maximum number of prefixes is exceeded.
        [Default: (null)]
- pn_multiprotocol
        Specify a multi-protocol for BGP.
        (Choices: ipv4-unicast, ipv6-unicast)[Default: (null)]
- pn_neighbor
        Specify a neighbor IP address to use for BGP.
        Required for vrouter-bgp-add.
        [Default: (null)]
- pn_next_hop_self
        Specify if the next-hop is the same router or not.
        [Default: (null)]
- pn_override_capability
        Specify if you want to override capability.
        [Default: (null)]
- pn_password
        Specify a password, if desired.
        [Default: (null)]
- pn_prefix_listin
        Specify the prefix list to filter traffic inbound.
        [Default: (null)]
- pn_prefix_listout
        Specify the prefix list to filter traffic outbound.
        [Default: (null)]
- pn_remote_as
        Specify the remote Autonomous System(AS) number. This value is between 1 and 4294967295.
        Required for vrouter-bgp-add.
        [Default: (null)]
- pn_route_mapin
        Specify inbound route map for neighbor.
        [Default: (null)]
- pn_route_mapout
        Specify outbound route map for neighbor.
        [Default: (null)]
- pn_route_reflector
        Specify if a route reflector client is used.
        [Default: (null)]
- pn_soft_reconfig
        Specify if you want a soft reconfiguration of inbound traffic.
        [Default: (null)]
= pn_vrouter_name
        Specify a name for the vRouter service.

- pn_weight
        Specify a default weight value between 0 and 65535 for the neighbor routes.
        [Default: (null)]
= state
        State the action to perform. Use 'present' to add bgp, 'absent' to remove bgp and 'update' to modify bgp.
        (Choices: present, absent, update)
EXAMPLES:
- name: add vrouter-bgp
  pn_vrouterbgp:
    state: 'present'
    pn_vrouter_name: 'ansible-vrouter'
    pn_neighbor: 104.104.104.1
    pn_remote_as: 1800

- name: remove vrouter-bgp
  pn_vrouterbgp:
    state: 'absent'
    pn_name: 'ansible-vrouter'

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the vrouterbpg command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the vrouterbgp command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_VROUTERIF    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_vrouterif.py)

  Execute vrouter-interface-add, vrouter-interface-remove, vrouter-interface-modify command. You configure interfaces to
  vRouter services on a fabric, cluster, standalone switch or virtual network(VNET).

Options (= is mandatory):

- pn_alias
        Specify an alias for the interface.
        [Default: (null)]
- pn_assignment
        Specify the DHCP method for IP address assignment.
        (Choices: none, dhcp, dhcpv6, autov6)[Default: (null)]
- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch to run the cli on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
- pn_exclusive
        Specify if the interface is exclusive to the configuration. Exclusive means that other configurations cannot use
        the interface. Exclusive is specified when you configure the interface as span interface and allows higher
        throughput through the interface.
        [Default: (null)]
- pn_interface
        Specify if the interface is management, data or span interface.
        (Choices: mgmt, data, span)[Default: (null)]
- pn_interface_ip
        Specify the IP address of the interface in x.x.x.x/n format.
        [Default: (null)]
- pn_l3port
        Specify a Layer 3 port for the interface.
        [Default: (null)]
- pn_nic_enable
        Specify if the NIC is enabled or not
        [Default: (null)]
- pn_nic_str
        Specify the type of NIC. Used for vrouter-interface remove/modify.
        [Default: (null)]
- pn_secondary_macs
        Specify a secondary MAC address for the interface.
        [Default: (null)]
- pn_vlan
        Specify the VLAN identifier. This is a value between 1 and 4092.
        [Default: (null)]
= pn_vrouter_name
        Specify the name of the vRouter interface.

- pn_vrrp_adv_int
        Specify a VRRP advertisement interval in milliseconds. The range is from 30 to 40950 with a default value of
        1000.
        [Default: (null)]
- pn_vrrp_id
        Specify the ID for the VRRP interface. The IDs on both vRouters must be the same IS number.
        [Default: (null)]
- pn_vrrp_priority
        Specify the priority for the VRRP interface. This is a value between 1 (lowest) and 255 (highest).
        [Default: (null)]
- pn_vxlan
        Specify the VXLAN identifier. This is a value between 1 and 16777215.
        [Default: (null)]
= state
        State the action to perform. Use 'present' to add vrouter interface, 'absent' to remove vrouter interface and
        'update' to modify vrouter interface.
        (Choices: present, absent, update)
EXAMPLES:
- name: Add vrouter-interface
  pn_vrouterif:
    pn_cliusername: admin
    pn_clipassword: admin
    state: 'present'
    pn_vrouter_name: 'ansible-vrouter'
    pn_interface_ip: 101.101.101.2/24
    pn_vlan: 101

- name: Add VRRP..
  pn_vrouterif:
    pn_cliusername: admin
    pn_clipassword: admin
    state: 'present'
    pn_vrouter_name: 'ansible-vrouter'
    pn_interface_ip: 101.101.101.2/24
    pn_vrrp_ip: 101.101.101.1/24
    pn_vrrp_priority: 100
    pn_vlan: 101

- name: Remove vrouter-interface
  pn_vrouterif:
    pn_cliusername: admin
    pn_clipassword: admin
    state: 'absent'
    pn_vrouter_name: 'ansible-vrouter'
    pn_interface_ip: 101.101.101.2/24

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the vrouterif command.
  returned: on success
  type: list
stderr:
  description: The set of error responses from the vrouterif command.
  returned: on error
  type: str
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PN_VROUTERLBIF    (/usr/lib/python2.7/site-packages/ansible/modules/network/netvisor/pn_vrouterlbif.py)

  Execute vrouter-loopback-interface-add, vrouter-loopback-interface-remove commands. Each fabric, cluster, standalone
  switch, or virtual network (VNET) can provide its tenants with a virtual router (vRouter) service that forwards traffic
  between networks and implements Layer 3 protocols.

Options (= is mandatory):

- pn_clipassword
        Provide login password if user is not root.
        [Default: (null)]
- pn_cliswitch
        Target switch(es) to run the cli on.
        [Default: (null)]
- pn_cliusername
        Provide login username if user is not root.
        [Default: (null)]
- pn_index
        Specify the interface index from 1 to 255.
        [Default: (null)]
= pn_interface_ip
        Specify the IP address.

= pn_vrouter_name
        Specify the name of the vRouter.

= state
        State the action to perform. Use 'present' to add vrouter loopback interface and 'absent' to remove vrouter
        loopback interface.
        (Choices: present, absent)
EXAMPLES:
- name: add vrouter-loopback-interface
  pn_vrouterlbif:
    state: 'present'
    pn_vrouter_name: 'ansible-vrouter'
    pn_interface_ip: '104.104.104.1'

- name: remove vrouter-loopback-interface
  pn_vrouterlbif:
    state: 'absent'
    pn_vrouter_name: 'ansible-vrouter'
    pn_interface_ip: '104.104.104.1'

RETURN VALUES:
command:
  description: The CLI command run on the target node(s).
  returned: always
  type: str
stdout:
  description: The set of responses from the vrouterlb command.
  returned: always
  type: list
stderr:
  description: The set of error responses from the vrouterlb command.
  returned: on error
  type: list
changed:
  description: Indicates whether the CLI caused changes on the target.
  returned: always
  type: bool


MAINTAINERS: Pluribus Networks (@amitsi)

METADATA:
	Status: ['preview']
	Supported_by: community
> PORTAGE    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/portage.py)

  Manages Gentoo packages

Options (= is mandatory):

- changed_use
        Include installed packages where USE flags have changed, except when
        flags that the user has not enabled are added or removed
        (--changed-use)
        (Choices: yes, no)[Default: False]
- deep
        Consider the entire dependency tree of packages (--deep)
        (Choices: yes, no)[Default: False]
- depclean
        Remove packages not needed by explicitly merged packages (--depclean)
        If no package is specified, clean up the world's dependencies
        Otherwise, --depclean serves as a dependency aware version of --unmerge
        (Choices: yes, no)[Default: False]
- getbinpkg
        Prefer packages specified at PORTAGE_BINHOST in make.conf
        (Choices: yes, no)[Default: False]
- jobs
        Specifies the number of packages to build simultaneously.
        [Default: None]
- keepgoing
        Continue as much as possible after an error.
        (Choices: yes, no)[Default: False]
- loadavg
        Specifies that no new builds should be started if there are
        other builds running and the load average is at least LOAD
        [Default: None]
- newuse
        Include installed packages where USE flags have changed (--newuse)
        (Choices: yes, no)[Default: False]
- nodeps
        Only merge packages but not their dependencies (--nodeps)
        (Choices: yes, no)[Default: False]
- noreplace
        Do not re-emerge installed packages (--noreplace)
        (Choices: yes, no)[Default: False]
- oneshot
        Do not add the packages to the world file (--oneshot)
        (Choices: yes, no)[Default: False]
- onlydeps
        Only merge packages' dependencies but not the packages (--onlydeps)
        (Choices: yes, no)[Default: False]
- package
        Package atom or set, e.g. `sys-apps/foo' or `>foo-2.13' or `@world'
        [Default: None]
- quiet
        Run emerge in quiet mode (--quiet)
        (Choices: yes, no)[Default: False]
- state
        State of the package atom
        (Choices: present, installed, emerged, absent, removed, unmerged, latest)[Default: present]
- sync
        Sync package repositories first
        If yes, perform "emerge --sync"
        If web, perform "emerge-webrsync"
        (Choices: web, yes, no)[Default: None]
- update
        Update packages to the best version available (--update)
        (Choices: yes, no)[Default: False]
- usepkgonly
        Merge only binaries (no compiling). This sets getbinpkg=yes.
        (Choices: yes, no)[Default: False]
- verbose
        Run emerge in verbose mode (--verbose)
        (Choices: yes, no)[Default: False]
Requirements:  gentoolkit

EXAMPLES:
# Make sure package foo is installed
- portage:
    package: foo
    state: present

# Make sure package foo is not installed
- portage:
    package: foo
    state: absent

# Update package foo to the "latest" version ( os specific alternative to latest )
- portage:
    package: foo
    update: yes

# Install package foo using PORTAGE_BINHOST setup
- portage:
    package: foo
    getbinpkg: yes

# Re-install world from binary packages only and do not allow any compiling
- portage:
    package: '@world'
    usepkgonly: yes

# Sync repositories and update world
- portage:
    package: '@world'
    update: yes
    deep: yes
    sync: yes

# Remove unneeded packages
- portage:
    depclean: yes

# Remove package foo if it is not explicitly needed
- portage:
    package: foo
    state: absent
    depclean: yes


MAINTAINERS: Yap Sok Ann (@sayap), William L Thomson Jr (@wltjr), Andrew Udvare

METADATA:
	Status: ['preview']
	Supported_by: community
> PORTINSTALL    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/portinstall.py)

  Manage packages for FreeBSD using 'portinstall'.

Options (= is mandatory):

= name
        name of package to install/remove

- state
        state of the package
        (Choices: present, absent)[Default: present]
- use_packages
        use packages instead of ports whenever available
        (Choices: yes, no)[Default: True]
EXAMPLES:
# Install package foo
- portinstall:
    name: foo
    state: present

# Install package security/cyrus-sasl2-saslauthd
- portinstall:
    name: security/cyrus-sasl2-saslauthd
    state: present

# Remove packages foo and bar
- portinstall:
    name: foo,bar
    state: absent


MAINTAINERS: berenddeboer (@berenddeboer)

METADATA:
	Status: ['preview']
	Supported_by: community
> POSTGRESQL_DB    (/usr/lib/python2.7/site-packages/ansible/modules/database/postgresql/postgresql_db.py)

  Add or remove PostgreSQL databases from a remote host.

Options (= is mandatory):

- encoding
        Encoding of the database
        [Default: None]
- lc_collate
        Collation order (LC_COLLATE) to use in the database. Must match collation order of template database unless
        `template0' is used as template.
        [Default: None]
- lc_ctype
        Character classification (LC_CTYPE) to use in the database (e.g. lower, upper, ...) Must match LC_CTYPE of
        template database unless `template0' is used as template.
        [Default: None]
- login_host
        Host running the database
        [Default: None]
- login_password
        The password used to authenticate with
        [Default: None]
- login_unix_socket
        Path to a Unix domain socket for local connections
        [Default: None]
- login_user
        The username used to authenticate with
        [Default: postgres]
= name
        name of the database to add or remove
        [Default: None]
- owner
        Name of the role to set as owner of the database
        [Default: None]
- port
        Database port to connect to.
        [Default: 5432]
- ssl_mode
        Determines whether or with what priority a secure SSL TCP/IP connection will be negotiated with the server.
        See https://www.postgresql.org/docs/current/static/libpq-ssl.html for more information on the modes.
        Default of `prefer' matches libpq default.
        (Choices: disable, allow, prefer, require, verify-ca, verify-full)[Default: prefer]
- ssl_rootcert
        Specifies the name of a file containing SSL certificate authority (CA) certificate(s).
        If the file exists, the server's certificate will be verified to be signed by one of these authorities.
        [Default: None]
- state
        The database state
        (Choices: present, absent)[Default: present]
- template
        Template used to create the database
        [Default: None]
Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the `postgres' account on
        the host.
  * This module uses `psycopg2', a Python PostgreSQL database adapter. You must ensure that psycopg2 is installed
        on the host before using this module. If the remote host is the PostgreSQL server (which is the default
        case), then PostgreSQL must also be installed on the remote host. For Ubuntu-based systems, install the
        `postgresql', `libpq-dev', and `python-psycopg2' packages on the remote host before using this module.
  * The ssl_rootcert parameter requires at least Postgres version 8.4 and `psycopg2' version 2.4.3.
Requirements:  psycopg2

EXAMPLES:
# Create a new database with name "acme"
- postgresql_db:
    name: acme

# Create a new database with name "acme" and specific encoding and locale
# settings. If a template different from "template0" is specified, encoding
# and locale settings must match those of the template.
- postgresql_db:
    name: acme
    encoding: UTF-8
    lc_collate: de_DE.UTF-8
    lc_ctype: de_DE.UTF-8
    template: template0


MAINTAINERS: Ansible Core Team

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> POSTGRESQL_EXT    (/usr/lib/python2.7/site-packages/ansible/modules/database/postgresql/postgresql_ext.py)

  Add or remove PostgreSQL extensions from a database.

Options (= is mandatory):

= db
        name of the database to add or remove the extension to/from
        [Default: None]
- login_host
        Host running the database
        [Default: localhost]
- login_password
        The password used to authenticate with
        [Default: None]
- login_user
        The username used to authenticate with
        [Default: None]
= name
        name of the extension to add or remove
        [Default: None]
- port
        Database port to connect to.
        [Default: 5432]
- state
        The database extension state
        (Choices: present, absent)[Default: present]
Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the `postgres' account on
        the host.
  * This module uses `psycopg2', a Python PostgreSQL database adapter. You must ensure that psycopg2 is installed
        on the host before using this module. If the remote host is the PostgreSQL server (which is the default
        case), then PostgreSQL must also be installed on the remote host. For Ubuntu-based systems, install the
        `postgresql', `libpq-dev', and `python-psycopg2' packages on the remote host before using this module.
Requirements:  psycopg2

EXAMPLES:
# Adds postgis to the database "acme"
- postgresql_ext:
    name: postgis
    db: acme


MAINTAINERS: Daniel Schep (@dschep)

METADATA:
	Status: ['preview']
	Supported_by: community
> POSTGRESQL_LANG    (/usr/lib/python2.7/site-packages/ansible/modules/database/postgresql/postgresql_lang.py)

  Adds, removes or changes procedural languages with a PostgreSQL database. This module allows you to add a language,
  remote a language or change the trust relationship with a PostgreSQL database. The module can be used on the machine
  where executed or on a remote host. When removing a language from a database, it is possible that dependencies prevent
  the database from being removed. In that case, you can specify casade to automatically drop objects that depend on the
  language (such as functions in the language). In case the language can't be deleted because it is required by the
  database system, you can specify fail_on_drop=no to ignore the error. Be carefull when marking a language as trusted
  since this could be a potential security breach. Untrusted languages allow only users with the PostgreSQL superuser
  privilege to use this language to create new functions.

Options (= is mandatory):

- cascade
        when dropping a language, also delete object that depend on this language.
        only used when `state=absent'.
        (Choices: yes, no)[Default: False]
- db
        name of database where the language will be added, removed or changed
        [Default: None]
- fail_on_drop
        if `yes', fail when removing a language. Otherwise just log and continue
        in some cases, it is not possible to remove a language (used by the db-system). When         dependencies block
        the removal, consider using `cascade'.
        (Choices: yes, no)[Default: yes]
- force_trust
        marks the language as trusted, even if it's marked as untrusted in pg_pltemplate.
        use with care!
        (Choices: yes, no)[Default: False]
= lang
        name of the procedural language to add, remove or change
        [Default: None]
- login_host
        Host running PostgreSQL where you want to execute the actions.
        [Default: localhost]
- login_password
        Password used to authenticate with PostgreSQL (must match `login_user')
        [Default: None]
- login_user
        User used to authenticate with PostgreSQL
        [Default: postgres]
- port
        Database port to connect to.
        [Default: 5432]
- state
        The state of the language for the selected database
        (Choices: present, absent)[Default: present]
- trust
        make this language trusted for the selected db
        (Choices: yes, no)[Default: False]
Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the postgres account on the
        host.
  * This module uses psycopg2, a Python PostgreSQL database adapter. You must ensure that psycopg2 is installed on
        the host before using this module. If the remote host is the PostgreSQL server (which is the default case),
        then PostgreSQL must also be installed on the remote host. For Ubuntu-based systems, install the
        postgresql, libpq-dev, and python-psycopg2 packages on the remote host before using this module.
Requirements:  psycopg2

EXAMPLES:
# Add language pltclu to database testdb if it doesn't exist:
- postgresql_lang db=testdb lang=pltclu state=present

# Add language pltclu to database testdb if it doesn't exist and mark it as trusted:
# Marks the language as trusted if it exists but isn't trusted yet
# force_trust makes sure that the language will be marked as trusted
- postgresql_lang:
    db: testdb
    lang: pltclu
    state: present
    trust: yes
    force_trust: yes

# Remove language pltclu from database testdb:
- postgresql_lang:
    db: testdb
    lang: pltclu
    state: absent

# Remove language pltclu from database testdb and remove all dependencies:
- postgresql_lang:
    db: testdb
    lang: pltclu
    state: absent
    cascade: yes

# Remove language c from database testdb but ignore errors if something prevents the removal:
- postgresql_lang:
    db: testdb
    lang: pltclu
    state: absent
    fail_on_drop: no


MAINTAINERS: Jens Depuydt (@jensdepuydt)

METADATA:
	Status: ['preview']
	Supported_by: community
> POSTGRESQL_PRIVS    (/usr/lib/python2.7/site-packages/ansible/modules/database/postgresql/postgresql_privs.py)

  Grant or revoke privileges on PostgreSQL database objects. This module is basically a wrapper around most of the
  functionality of PostgreSQL's GRANT and REVOKE statements with detection of changes (GRANT/REVOKE `privs' ON `type'
  `objs' TO/FROM `roles')

Options (= is mandatory):

= database
        Name of database to connect to.
        Alias: `db'

- grant_option
        Whether `role' may grant/revoke the specified privileges/group memberships to others.
        Set to `no' to revoke GRANT OPTION, leave unspecified to make no changes.
        `grant_option' only has an effect if `state' is `present'.
        Alias: `admin_option'
        (Choices: yes, no)[Default: (null)]
- host
        Database host address. If unspecified, connect via Unix socket.
        Alias: `login_host'
        [Default: None]
- login
        The username to authenticate with.
        Alias: `login_user'
        [Default: postgres]
- objs
        Comma separated list of database objects to set privileges on.
        If `type' is `table' or `sequence', the special value `ALL_IN_SCHEMA' can be provided instead to specify all
        database objects of type `type' in the schema specified via `schema'. (This also works with PostgreSQL < 9.0.)
        If `type' is `database', this parameter can be omitted, in which case privileges are set for the database
        specified via `database'.
        If `type' is `function', colons (":") in object names will be replaced with commas (needed to specify function
        signatures, see examples)
        Alias: `obj'
        [Default: (null)]
- password
        The password to authenticate with.
        Alias: `login_password')
        [Default: None]
- port
        Database port to connect to.
        [Default: 5432]
- privs
        Comma separated list of privileges to grant/revoke.
        Alias: `priv'
        [Default: (null)]
= roles
        Comma separated list of role (user/group) names to set permissions for.
        The special value `PUBLIC' can be provided instead to set permissions for the implicitly defined PUBLIC group.
        Alias: `role'

- schema
        Schema that contains the database objects specified via `objs'.
        May only be provided if `type' is `table', `sequence' or `function'. Defaults to  `public' in these cases.
        [Default: (null)]
- ssl_mode
        Determines whether or with what priority a secure SSL TCP/IP connection will be negotiated with the server.
        See https://www.postgresql.org/docs/current/static/libpq-ssl.html for more information on the modes.
        Default of `prefer' matches libpq default.
        (Choices: disable, allow, prefer, require, verify-ca, verify-full)[Default: prefer]
- ssl_rootcert
        Specifies the name of a file containing SSL certificate authority (CA) certificate(s). If the file exists, the
        server's certificate will be verified to be signed by one of these authorities.
        [Default: None]
- state
        If `present', the specified privileges are granted, if `absent' they are revoked.
        (Choices: present, absent)[Default: present]
- type
        Type of database object to set privileges on.
        (Choices: table, sequence, function, database, schema, language, tablespace, group)[Default: table]
- unix_socket
        Path to a Unix domain socket for local connections.
        Alias: `login_unix_socket'
        [Default: None]
Notes:
  * Default authentication assumes that postgresql_privs is run by the `postgres' user on the remote host.
        (Ansible's `user' or `sudo-user').
  * This module requires Python package `psycopg2' to be installed on the remote host. In the default case of the
        remote host also being the PostgreSQL server, PostgreSQL has to be installed there as well, obviously. For
        Debian/Ubuntu-based systems, install packages `postgresql' and `python-psycopg2'.
  * Parameters that accept comma separated lists (`privs', `objs', `roles') have singular alias names (`priv',
        `obj', `role').
  * To revoke only `GRANT OPTION' for a specific object, set `state' to `present' and `grant_option' to `no' (see
        examples).
  * Note that when revoking privileges from a role R, this role  may still have access via privileges granted to
        any role R is a member of including `PUBLIC'.
  * Note that when revoking privileges from a role R, you do so as the user specified via `login'. If R has been
        granted the same privileges by another user also, R can still access database objects via these privileges.
  * When revoking privileges, `RESTRICT' is assumed (see PostgreSQL docs).
  * The ssl_rootcert parameter requires at least Postgres version 8.4 and `psycopg2' version 2.4.3.
Requirements:  psycopg2

EXAMPLES:
# On database "library":
# GRANT SELECT, INSERT, UPDATE ON TABLE public.books, public.authors
# TO librarian, reader WITH GRANT OPTION
- postgresql_privs:
    database: library
    state: present
    privs: SELECT,INSERT,UPDATE
    type: table
    objs: books,authors
    schema: public
    roles: librarian,reader
    grant_option: yes

# Same as above leveraging default values:
- postgresql_privs:
    db: library
    privs: SELECT,INSERT,UPDATE
    objs: books,authors
    roles: librarian,reader
    grant_option: yes

# REVOKE GRANT OPTION FOR INSERT ON TABLE books FROM reader
# Note that role "reader" will be *granted* INSERT privilege itself if this
# isn't already the case (since state: present).
- postgresql_privs:
    db: library
    state: present
    priv: INSERT
    obj: books
    role: reader
    grant_option: no

# REVOKE INSERT, UPDATE ON ALL TABLES IN SCHEMA public FROM reader
# "public" is the default schema. This also works for PostgreSQL 8.x.
- postgresql_privs:
    db: library
    state: absent
    privs: INSERT,UPDATE
    objs: ALL_IN_SCHEMA
    role: reader

# GRANT ALL PRIVILEGES ON SCHEMA public, math TO librarian
- postgresql_privs:
    db: library
    privs: ALL
    type: schema
    objs: public,math
    role: librarian

# GRANT ALL PRIVILEGES ON FUNCTION math.add(int, int) TO librarian, reader
# Note the separation of arguments with colons.
- postgresql_privs:
    db: library
    privs: ALL
    type: function
    obj: add(int:int)
    schema: math
    roles: librarian,reader

# GRANT librarian, reader TO alice, bob WITH ADMIN OPTION
# Note that group role memberships apply cluster-wide and therefore are not
# restricted to database "library" here.
- postgresql_privs:
    db: library
    type: group
    objs: librarian,reader
    roles: alice,bob
    admin_option: yes

# GRANT ALL PRIVILEGES ON DATABASE library TO librarian
# Note that here "db: postgres" specifies the database to connect to, not the
# database to grant privileges on (which is specified via the "objs" param)
- postgresql_privs:
    db: postgres
    privs: ALL
    type: database
    obj: library
    role: librarian

# GRANT ALL PRIVILEGES ON DATABASE library TO librarian
# If objs is omitted for type "database", it defaults to the database
# to which the connection is established
- postgresql_privs:
    db: library
    privs: ALL
    type: database
    role: librarian


MAINTAINERS: Bernhard Weitzhofer (@b6d)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> POSTGRESQL_SCHEMA    (/usr/lib/python2.7/site-packages/ansible/modules/database/postgresql/postgresql_schema.py)

  Add or remove PostgreSQL schema from a remote host.

Options (= is mandatory):

- database
        Name of the database to connect to.
        [Default: postgres]
- login_host
        Host running the database.
        [Default: localhost]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_unix_socket
        Path to a Unix domain socket for local connections.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: None]
= name
        Name of the schema to add or remove.
        [Default: None]
- owner
        Name of the role to set as owner of the schema.
        [Default: None]
- port
        Database port to connect to.
        [Default: 5432]
- state
        The schema state.
        (Choices: present, absent)[Default: present]
Notes:
  * This module uses `psycopg2', a Python PostgreSQL database adapter. You must ensure that psycopg2 is installed
        on the host before using this module. If the remote host is the PostgreSQL server (which is the default
        case), then PostgreSQL must also be installed on the remote host. For Ubuntu-based systems, install the
        `postgresql', `libpq-dev', and `python-psycopg2' packages on the remote host before using this module.
Requirements:  psycopg2

EXAMPLES:
# Create a new schema with name "acme"
- postgresql_schema:
    name: acme

# Create a new schema "acme" with a user "bob" who will own it
- postgresql_schema:
    name: acme
    owner: bob


RETURN VALUES:
schema:
    description: Name of the schema
    returned: success, changed
    type: string
    sample: "acme"


MAINTAINERS: Flavien Chantelot <contact@flavien.io>

METADATA:
	Status: ['preview']
	Supported_by: community
> POSTGRESQL_USER    (/usr/lib/python2.7/site-packages/ansible/modules/database/postgresql/postgresql_user.py)

  Add or remove PostgreSQL users (roles) from a remote host and, optionally, grant the users access to an existing
  database or tables. The fundamental function of the module is to create, or delete, roles from a PostgreSQL cluster.
  Privilege assignment, or removal, is an optional step, which works on one database at a time. This allows for the
  module to be called several times in the same module to modify the permissions on different databases, or to grant
  permissions to already existing users. A user cannot be removed until all the privileges have been stripped from the
  user. In such situation, if the module tries to remove the user it will fail. To avoid this from happening the
  fail_on_user option signals the module to try to remove the user, but if not possible keep going; the module will
  report if changes happened and separately if the user was removed or not.

Options (= is mandatory):

- db
        name of database where permissions will be granted
        [Default: None]
- encrypted
        whether the password is stored hashed in the database. boolean. Passwords can be passed already hashed or
        unhashed, and postgresql ensures the stored password is hashed when encrypted is set.
        [Default: False]
- expires
        sets the user's password expiration.
        [Default: None]
- fail_on_user
        if `yes', fail when user can't be removed. Otherwise just log and continue
        (Choices: yes, no)[Default: yes]
- login_host
        Host running PostgreSQL.
        [Default: localhost]
- login_password
        Password used to authenticate with PostgreSQL
        [Default: None]
- login_unix_socket
        Path to a Unix domain socket for local connections
        [Default: None]
- login_user
        User (role) used to authenticate with PostgreSQL
        [Default: postgres]
= name
        name of the user (role) to add or remove
        [Default: None]
- no_password_changes
        if `yes', don't inspect database for password changes. Effective when `pg_authid' is not accessible (such as AWS
        RDS). Otherwise, make password changes as necessary.
        (Choices: yes, no)[Default: no]
- password
        set the user's password, before 1.4 this was required.
        When passing an encrypted password, the encrypted parameter must also be true, and it must be generated with the
        format `'str["md5"] + md5[ password + username ]'', resulting in a total of 35 characters.  An easy way to do
        this is: `echo "md5`echo -n "verysecretpasswordJOE" | md5`"'. Note that if encrypted is set, the stored password
        will be hashed whether or not it is pre-encrypted.
        [Default: None]
- port
        Database port to connect to.
        [Default: 5432]
- priv
        PostgreSQL privileges string in the format: `table:priv1,priv2'
        [Default: None]
- role_attr_flags
        PostgreSQL role attributes string in the format: CREATEDB,CREATEROLE,SUPERUSER
        (Choices: [NO]SUPERUSER, [NO]CREATEROLE, [NO]CREATEUSER, [NO]CREATEDB, [NO]INHERIT, [NO]LOGIN,
        [NO]REPLICATION)[Default: ]
- ssl_mode
        Determines whether or with what priority a secure SSL TCP/IP connection will be negotiated with the server.
        See https://www.postgresql.org/docs/current/static/libpq-ssl.html for more information on the modes.
        Default of `prefer' matches libpq default.
        (Choices: disable, allow, prefer, require, verify-ca, verify-full)[Default: prefer]
- ssl_rootcert
        Specifies the name of a file containing SSL certificate authority (CA) certificate(s). If the file exists, the
        server's certificate will be verified to be signed by one of these authorities.
        [Default: None]
- state
        The user (role) state
        (Choices: present, absent)[Default: present]
Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the postgres account on the
        host.
  * This module uses psycopg2, a Python PostgreSQL database adapter. You must ensure that psycopg2 is installed on
        the host before using this module. If the remote host is the PostgreSQL server (which is the default case),
        then PostgreSQL must also be installed on the remote host. For Ubuntu-based systems, install the
        postgresql, libpq-dev, and python-psycopg2 packages on the remote host before using this module.
  * If the passlib library is installed, then passwords that are encrypted in the DB but not encrypted when passed
        as arguments can be checked for changes. If the passlib library is not installed, unencrypted passwords
        stored in the DB encrypted will be assumed to have changed.
  * If you specify PUBLIC as the user, then the privilege changes will apply to all users. You may not specify
        password or role_attr_flags when the PUBLIC user is specified.
  * The ssl_rootcert parameter requires at least Postgres version 8.4 and `psycopg2' version 2.4.3.
Requirements:  psycopg2

EXAMPLES:
# Create django user and grant access to database and products table
- postgresql_user:
    db: acme
    name: django
    password: ceec4eif7ya
    priv: "CONNECT/products:ALL"

# Create rails user, grant privilege to create other databases and demote rails from super user status
- postgresql_user:
    name: rails
    password: secret
    role_attr_flags: CREATEDB,NOSUPERUSER

# Remove test user privileges from acme
- postgresql_user:
    db: acme
    name: test
    priv: "ALL/products:ALL"
    state: absent
    fail_on_user: no

# Remove test user from test database and the cluster
- postgresql_user:
    db: test
    name: test
    priv: ALL
    state: absent

# Example privileges string format
# INSERT,UPDATE/table:SELECT/anothertable:ALL

# Remove an existing user's password
- postgresql_user:
    db: test
    user: test
    password: NULL


MAINTAINERS: Ansible Core Team

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PROFITBRICKS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/profitbricks/profitbricks.py)

  Create, destroy, update, start, stop, and reboot a ProfitBricks virtual machine. When the virtual machine is created it
  can optionally wait for it to be 'running' before returning. This module has a dependency on profitbricks >= 1.0.0

Options (= is mandatory):

- assign_public_ip
        This will assign the machine to the public LAN. If no LAN exists with public Internet access it is created.
        [Default: False]
- auto_increment
        Whether or not to increment a single number in the name for created virtual machines.
        (Choices: yes, no)[Default: True]
- bus
        The bus type for the volume.
        (Choices: IDE, VIRTIO)[Default: VIRTIO]
- cores
        The number of CPU cores to allocate to the virtual machine.
        [Default: 2]
- count
        The number of virtual machines to create.
        [Default: 1]
- cpu_family
        The CPU family type to allocate to the virtual machine.
        (Choices: AMD_OPTERON, INTEL_XEON)[Default: AMD_OPTERON]
- datacenter
        The datacenter to provision this virtual machine.
        [Default: None]
= image
        The system image ID for creating the virtual machine, e.g. a3eae284-a2fe-11e4-b187-5f1f641608c8.

- image_password
        Password set for the administrative user.
        [Default: (null)]
- instance_ids
        list of instance ids, currently only used when state='absent' to remove instances.
        [Default: (null)]
- lan
        The ID of the LAN you wish to add the servers to.
        [Default: 1]
- location
        The datacenter location. Use only if you want to create the Datacenter or else this value is ignored.
        (Choices: us/las, de/fra, de/fkb)[Default: us/las]
= name
        The name of the virtual machine.

- ram
        The amount of memory to allocate to the virtual machine.
        [Default: 2048]
- remove_boot_volume
        remove the bootVolume of the virtual machine you're destroying.
        (Choices: yes, no)[Default: yes]
- ssh_keys
        Public SSH keys allowing access to the virtual machine.
        [Default: (null)]
- state
        create or terminate instances
        (Choices: running, stopped, absent, present)[Default: present]
- subscription_password
        THe ProfitBricks password. Overrides the PB_PASSWORD environment variable.
        [Default: None]
- subscription_user
        The ProfitBricks username. Overrides the PB_SUBSCRIPTION_ID environment variable.
        [Default: None]
- volume_size
        The size in GB of the boot volume.
        [Default: 10]
- wait
        wait for the instance to be in state 'running' before returning
        (Choices: yes, no)[Default: yes]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 600]
Requirements:  profitbricks, python >= 2.6

EXAMPLES:

# Note: These examples do not set authentication details, see the AWS Guide for details.

# Provisioning example. This will create three servers and enumerate their names.

- profitbricks:
    datacenter: Tardis One
    name: web%02d.stackpointcloud.com
    cores: 4
    ram: 2048
    volume_size: 50
    cpu_family: INTEL_XEON
    image: a3eae284-a2fe-11e4-b187-5f1f641608c8
    location: us/las
    count: 3
    assign_public_ip: true

# Removing Virtual machines

- profitbricks:
    datacenter: Tardis One
    instance_ids:
      - 'web001.stackpointcloud.com'
      - 'web002.stackpointcloud.com'
      - 'web003.stackpointcloud.com'
    wait_timeout: 500
    state: absent

# Starting Virtual Machines.

- profitbricks:
    datacenter: Tardis One
    instance_ids:
      - 'web001.stackpointcloud.com'
      - 'web002.stackpointcloud.com'
      - 'web003.stackpointcloud.com'
    wait_timeout: 500
    state: running

# Stopping Virtual Machines

- profitbricks:
    datacenter: Tardis One
    instance_ids:
      - 'web001.stackpointcloud.com'
      - 'web002.stackpointcloud.com'
      - 'web003.stackpointcloud.com'
    wait_timeout: 500
    state: stopped



MAINTAINERS: Matt Baldwin (baldwin@stackpointcloud.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> PROFITBRICKS_DATACENTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/profitbricks/profitbricks_datacenter.py)

  This is a simple module that supports creating or removing vDCs. A vDC is required before you can create servers. This
  module has a dependency on profitbricks >= 1.0.0

Options (= is mandatory):

- description
        The description of the virtual datacenter.
        [Default: (null)]
- location
        The datacenter location.
        (Choices: us/las, de/fra, de/fkb)[Default: us/las]
= name
        The name of the virtual datacenter.

- state
        create or terminate datacenters
        (Choices: present, absent)[Default: present]
- subscription_password
        THe ProfitBricks password. Overrides the PB_PASSWORD environment variable.
        [Default: (null)]
- subscription_user
        The ProfitBricks username. Overrides the PB_SUBSCRIPTION_ID environment variable.
        [Default: (null)]
- wait
        wait for the datacenter to be created before returning
        (Choices: yes, no)[Default: yes]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 600]
Requirements:  profitbricks

EXAMPLES:

# Create a Datacenter
- profitbricks_datacenter:
    datacenter: Tardis One
    wait_timeout: 500

# Destroy a Datacenter. This will remove all servers, volumes, and other objects in the datacenter.
- profitbricks_datacenter:
    datacenter: Tardis One
    wait_timeout: 500
    state: absent



MAINTAINERS: Matt Baldwin (baldwin@stackpointcloud.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> PROFITBRICKS_NIC    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/profitbricks/profitbricks_nic.py)

  This module allows you to create or restore a volume snapshot. This module has a dependency on profitbricks >= 1.0.0

Options (= is mandatory):

= datacenter
        The datacenter in which to operate.

= lan
        The LAN to place the NIC on. You can pass a LAN that doesn't exist and it will be created. Required on create.

= name
        The name or ID of the NIC. This is only required on deletes, but not on create.

= server
        The server name or ID.

- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- subscription_password
        THe ProfitBricks password. Overrides the PB_PASSWORD environment variable.
        [Default: (null)]
- subscription_user
        The ProfitBricks username. Overrides the PB_SUBSCRIPTION_ID environment variable.
        [Default: (null)]
- wait
        wait for the operation to complete before returning
        (Choices: yes, no)[Default: yes]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 600]
Requirements:  profitbricks

EXAMPLES:

# Create a NIC
- profitbricks_nic:
    datacenter: Tardis One
    server: node002
    lan: 2
    wait_timeout: 500
    state: present

# Remove a NIC
- profitbricks_nic:
    datacenter: Tardis One
    server: node002
    name: 7341c2454f
    wait_timeout: 500
    state: absent



MAINTAINERS: Matt Baldwin (baldwin@stackpointcloud.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> PROFITBRICKS_VOLUME    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/profitbricks/profitbricks_volume.py)

  Allows you to create or remove a volume from a ProfitBricks datacenter. This module has a dependency on profitbricks >=
  1.0.0

Options (= is mandatory):

- auto_increment
        Whether or not to increment a single number in the name for created virtual machines.
        (Choices: yes, no)[Default: True]
- bus
        The bus type.
        (Choices: IDE, VIRTIO)[Default: VIRTIO]
- count
        The number of volumes you wish to create.
        [Default: 1]
= datacenter
        The datacenter in which to create the volumes.

- disk_type
        The disk type of the volume.
        (Choices: HDD, SSD)[Default: HDD]
= image
        The system image ID for the volume, e.g. a3eae284-a2fe-11e4-b187-5f1f641608c8. This can also be a snapshot image
        ID.

- image_password
        Password set for the administrative user.
        [Default: (null)]
- instance_ids
        list of instance ids, currently only used when state='absent' to remove instances.
        [Default: (null)]
- licence_type
        The licence type for the volume. This is used when the image is non-standard.
        (Choices: LINUX, WINDOWS, UNKNOWN, OTHER)[Default: UNKNOWN]
= name
        The name of the volumes. You can enumerate the names using auto_increment.

- size
        The size of the volume.
        [Default: 10]
- ssh_keys
        Public SSH keys allowing access to the virtual machine.
        [Default: (null)]
- state
        create or terminate datacenters
        (Choices: present, absent)[Default: present]
- subscription_password
        THe ProfitBricks password. Overrides the PB_PASSWORD environment variable.
        [Default: (null)]
- subscription_user
        The ProfitBricks username. Overrides the PB_SUBSCRIPTION_ID environment variable.
        [Default: (null)]
- wait
        wait for the datacenter to be created before returning
        (Choices: yes, no)[Default: yes]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 600]
Requirements:  profitbricks

EXAMPLES:

# Create Multiple Volumes

- profitbricks_volume:
    datacenter: Tardis One
    name: vol%02d
    count: 5
    auto_increment: yes
    wait_timeout: 500
    state: present

# Remove Volumes

- profitbricks_volume:
    datacenter: Tardis One
    instance_ids:
      - 'vol01'
      - 'vol02'
    wait_timeout: 500
    state: absent



MAINTAINERS: Matt Baldwin (baldwin@stackpointcloud.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> PROFITBRICKS_VOLUME_ATTACHMENTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/profitbricks/profitbricks_volume_attachments.py)

  Allows you to attach or detach a volume from a ProfitBricks server. This module has a dependency on profitbricks >=
  1.0.0

Options (= is mandatory):

= datacenter
        The datacenter in which to operate.

= server
        The name of the server you wish to detach or attach the volume.

- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- subscription_password
        THe ProfitBricks password. Overrides the PB_PASSWORD environment variable.
        [Default: (null)]
- subscription_user
        The ProfitBricks username. Overrides the PB_SUBSCRIPTION_ID environment variable.
        [Default: (null)]
= volume
        The volume name or ID.

- wait
        wait for the operation to complete before returning
        (Choices: yes, no)[Default: yes]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 600]
Requirements:  profitbricks

EXAMPLES:

# Attach a Volume

- profitbricks_volume_attachments:
    datacenter: Tardis One
    server: node002
    volume: vol01
    wait_timeout: 500
    state: present

# Detach a Volume

- profitbricks_volume_attachments:
    datacenter: Tardis One
    server: node002
    volume: vol01
    wait_timeout: 500
    state: absent



MAINTAINERS: Matt Baldwin (baldwin@stackpointcloud.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> PROXMOX    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/proxmox.py)

  allows you to create/delete/stop instances in Proxmox VE cluster Starting in Ansible 2.1, it automatically detects
  containerization type (lxc for PVE 4, openvz for older)

Options (= is mandatory):

= api_host
        the host of the Proxmox VE cluster

- api_password
        the password to authenticate with
        you can use PROXMOX_PASSWORD environment variable
        [Default: None]
= api_user
        the user to authenticate with

- cpus
        numbers of allocated cpus for instance
        [Default: 1]
- cpuunits
        CPU weight for a VM
        [Default: 1000]
- disk
        hard disk size in GB for instance
        [Default: 3]
- force
        forcing operations
        can be used only with states `present', `stopped', `restarted'
        with `state=present' force option allow to overwrite existing container
        with states `stopped' , `restarted' allow to force stop instance
        [Default: False]
- hostname
        the instance hostname
        required only for `state=present'
        must be unique if vmid is not passed
        [Default: None]
- ip_address
        specifies the address the container will be assigned
        [Default: None]
- memory
        memory size in MB for instance
        [Default: 512]
- mounts
        specifies additional mounts (separate disks) for the container. As a hash/dictionary defining mount points
        [Default: None]
- nameserver
        sets DNS server IP address for a container
        [Default: None]
- netif
        specifies network interfaces for the container. As a hash/dictionary defining interfaces.
        [Default: None]
- node
        Proxmox VE node, when new VM will be created
        required only for `state=present'
        for another states will be autodiscovered
        [Default: None]
- onboot
        specifies whether a VM will be started during system bootup
        [Default: False]
- ostemplate
        the template for VM creating
        required only for `state=present'
        [Default: None]
- password
        the instance root password
        required only for `state=present'
        [Default: None]
- pool
        Proxmox VE resource pool
        [Default: None]
- pubkey
        Public key to add to /root/.ssh/authorized_keys. This was added on Proxmox 4.2, it is ignored for earlier
        versions
        [Default: None]
- searchdomain
        sets DNS search domain for a container
        [Default: None]
- state
        Indicate desired state of the instance
        (Choices: present, started, absent, stopped, restarted)[Default: present]
- storage
        target storage
        [Default: local]
- swap
        swap memory size in MB for instance
        [Default: 0]
- timeout
        timeout for operations
        [Default: 30]
- unprivileged
        Indicate if the container should be unprivileged
        [Default: False]
- validate_certs
        enable / disable https certificate verification
        [Default: False]
- vmid
        the instance id
        if not set, the next available VM ID will be fetched from ProxmoxAPI.
        if not set, will be fetched from PromoxAPI based on the hostname
        [Default: None]
Notes:
  * Requires proxmoxer and requests modules on host. This modules can be installed with pip.
Requirements:  proxmoxer, python >= 2.7, requests

EXAMPLES:
# Create new container with minimal options
- proxmox:
    vmid: 100
    node: uk-mc02
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    password: 123456
    hostname: example.org
    ostemplate: 'local:vztmpl/ubuntu-14.04-x86_64.tar.gz'

# Create new container automatically selecting the next available vmid.
- proxmox: node='uk-mc02' api_user='root@pam' api_password='1q2w3e' api_host='node1' password='123456' hostname='example.org' ostemplate='local:vztmpl/ubuntu-14.04-x86_64.tar.gz'

# Create new container with minimal options with force(it will rewrite existing container)
- proxmox:
    vmid: 100
    node: uk-mc02
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    password: 123456
    hostname: example.org
    ostemplate: 'local:vztmpl/ubuntu-14.04-x86_64.tar.gz'
    force: yes

# Create new container with minimal options use environment PROXMOX_PASSWORD variable(you should export it before)
- proxmox:
    vmid: 100
    node: uk-mc02
    api_user: root@pam
    api_host: node1
    password: 123456
    hostname: example.org
    ostemplate: 'local:vztmpl/ubuntu-14.04-x86_64.tar.gz'

# Create new container with minimal options defining network interface with dhcp
- proxmox:
    vmid: 100
    node: uk-mc02
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    password: 123456
    hostname: example.org
    ostemplate: 'local:vztmpl/ubuntu-14.04-x86_64.tar.gz'
    netif: '{"net0":"name=eth0,ip=dhcp,ip6=dhcp,bridge=vmbr0"}'

# Create new container with minimal options defining network interface with static ip
- proxmox:
    vmid: 100
    node: uk-mc02
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    password: 123456
    hostname: example.org
    ostemplate: 'local:vztmpl/ubuntu-14.04-x86_64.tar.gz'
    netif: '{"net0":"name=eth0,gw=192.168.0.1,ip=192.168.0.2/24,bridge=vmbr0"}'

# Create new container with minimal options defining a mount
- proxmox:
    vmid: 100
    node: uk-mc02
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    password: 123456
    hostname: example.org
    ostemplate: local:vztmpl/ubuntu-14.04-x86_64.tar.gz'
    mounts: '{"mp0":"local:8,mp=/mnt/test/"}'

# Start container
- proxmox:
    vmid: 100
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    state: started

# Stop container
- proxmox:
    vmid: 100
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    state: stopped

# Stop container with force
- proxmox:
    vmid: 100
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    force: yes
    state: stopped

# Restart container(stopped or mounted container you can't restart)
- proxmox:
    vmid: 100
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    state: stopped

# Remove container
- proxmox:
    vmid: 100
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    state: absent


MAINTAINERS: Sergei Antipov @UnderGreen

METADATA:
	Status: ['preview']
	Supported_by: community
> PROXMOX_KVM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/proxmox_kvm.py)

  Allows you to create/delete/stop Qemu(KVM) Virtual Machines in Proxmox VE cluster.

Options (= is mandatory):

- acpi
        Specify if ACPI should be enables/disabled.
        (Choices: yes, no)[Default: yes]
- agent
        Specify if the QEMU GuestAgent should be enabled/disabled.
        (Choices: yes, no)[Default: None]
= api_host
        Specify the target host of the Proxmox VE cluster.

- api_password
        Specify the password to authenticate with.
        You can use `PROXMOX_PASSWORD' environment variable.
        [Default: None]
= api_user
        Specify the user to authenticate with.

- args
        Pass arbitrary arguments to kvm.
        This option is for experts only!
        [Default: -serial unix:/var/run/qemu-server/VMID.serial,server,nowait]
- autostart
        Specify, if the VM should be automatically restarted after crash (currently ignored in PVE API).
        (Choices: yes, no)[Default: no]
- balloon
        Specify the amount of RAM for the VM in MB.
        Using zero disables the balloon driver.
        [Default: 0]
- bios
        Specify the BIOS implementation.
        (Choices: seabios, ovmf)[Default: None]
- boot
        Specify the boot order -> boot on floppy `a', hard disk `c', CD-ROM `d', or network `n'.
        You can combine to set order.
        [Default: cnd]
- bootdisk
        Enable booting from specified disk. `(ide|sata|scsi|virtio'\d+)
        [Default: None]
- clone
        Name of VM to be cloned. If `vmid' is setted, `clone' can take arbitrary value but required for intiating the
        clone.
        [Default: None]
- cores
        Specify number of cores per socket.
        [Default: 1]
- cpu
        Specify emulated CPU type.
        [Default: kvm64]
- cpulimit
        Specify if CPU usage will be limited. Value 0 indicates no CPU limit.
        If the computer has 2 CPUs, it has total of '2' CPU time
        [Default: None]
- cpuunits
        Specify CPU weight for a VM.
        You can disable fair-scheduler configuration by setting this to 0
        [Default: 1000]
- delete
        Specify a list of settings you want to delete.
        [Default: None]
- description
        Specify the description for the VM. Only used on the configuration web interface.
        This is saved as comment inside the configuration file.
        [Default: None]
- digest
        Specify if to prevent changes if current configuration file has different SHA1 digest.
        This can be used to prevent concurrent modifications.
        [Default: None]
- force
        Allow to force stop VM.
        Can be used only with states `stopped', `restarted'.
        (Choices: yes, no)[Default: None]
- format
        Target drive’s backing file’s data format.
        Used only with clone
        (Choices: cloop, cow, qcow, qcow2, qed, raw, vmdk)[Default: qcow2]
- freeze
        Specify if PVE should freeze CPU at startup (use 'c' monitor command to start execution).
        (Choices: yes, no)[Default: None]
- full
        Create a full copy of all disk. This is always done when you clone a normal VM.
        For VM templates, we try to create a linked clone by default.
        Used only with clone
        (Choices: yes, no)[Default: True]
- hostpci
        Specify a hash/dictionary of map host pci devices into guest. `hostpci='{"key":"value", "key":"value"}''.
        Keys allowed are - `hostpci[n]' where 0 ≤ n ≤ N.
        Values allowed are -  `"host="HOSTPCIID[;HOSTPCIID2...]",pcie="1|0",rombar="1|0",x-vga="1|0""'.
        The `host' parameter is Host PCI device pass through. HOSTPCIID syntax is `bus:dev.func' (hexadecimal numbers).
        `pcie=boolean' `default=0' Choose the PCI-express bus (needs the q35 machine model).
        `rombar=boolean' `default=1' Specify whether or not the device’s ROM will be visible in the guest’s memory map.
        `x-vga=boolean' `default=0' Enable vfio-vga device support.
        /!\ This option allows direct access to host hardware. So it is no longer possible to migrate such machines - use
        with special care.
        [Default: None]
- hotplug
        Selectively enable hotplug features.
        This is a comma separated list of hotplug features `'network', 'disk', 'cpu', 'memory' and 'usb''.
        Value 0 disables hotplug completely and value 1 is an alias for the default `'network,disk,usb''.
        [Default: None]
- hugepages
        Enable/disable hugepages memory.
        (Choices: any, 2, 1024)[Default: None]
- ide
        A hash/dictionary of volume used as IDE hard disk or CD-ROM. `ide='{"key":"value", "key":"value"}''.
        Keys allowed are - `ide[n]' where 0 ≤ n ≤ 3.
        Values allowed are - `"storage:size,format=value"'.
        `storage' is the storage identifier where to create the disk.
        `size' is the size of the disk in GB.
        `format' is the drive’s backing file’s data format. `qcow2|raw|subvol'.
        [Default: None]
- keyboard
        Sets the keyboard layout for VNC server.
        [Default: None]
- kvm
        Enable/disable KVM hardware virtualization.
        (Choices: yes, no)[Default: yes]
- localtime
        Sets the real time clock to local time.
        This is enabled by default if ostype indicates a Microsoft OS.
        (Choices: yes, no)[Default: None]
- lock
        Lock/unlock the VM.
        (Choices: migrate, backup, snapshot, rollback)[Default: None]
- machine
        Specifies the Qemu machine type.
        type => `(pc|pc(-i440fx'?-\d+\.\d+(\.pxe)?|q35|pc-q35-\d+\.\d+(\.pxe)?))
        [Default: None]
- memory
        Memory size in MB for instance.
        [Default: 512]
- migrate_downtime
        Sets maximum tolerated downtime (in seconds) for migrations.
        [Default: None]
- migrate_speed
        Sets maximum speed (in MB/s) for migrations.
        A value of 0 is no limit.
        [Default: None]
- name
        Specifies the VM name. Only used on the configuration web interface.
        Required only for `state=present'.
        [Default: None]
- net
        A hash/dictionary of network interfaces for the VM. `net='{"key":"value", "key":"value"}''.
        Keys allowed are - `net[n]' where 0 ≤ n ≤ N.
        Values allowed are -
        `"model="XX:XX:XX:XX:XX:XX",brigde="value",rate="value",tag="value",firewall="1|0",trunks="vlanid""'.
        Model is one of `e1000 e1000-82540em e1000-82544gc e1000-82545em i82551 i82557b i82559er ne2k_isa ne2k_pci pcnet
        rtl8139 virtio vmxnet3'.
        `XX:XX:XX:XX:XX:XX' should be an unique MAC address. This is automatically generated if not specified.
        The `bridge' parameter can be used to automatically add the interface to a bridge device. The Proxmox VE standard
        bridge is called 'vmbr0'.
        Option `rate' is used to limit traffic bandwidth from and to this interface. It is specified as floating point
        number, unit is 'Megabytes per second'.
        If you specify no bridge, we create a kvm 'user' (NATed) network device, which provides DHCP and DNS services.
        [Default: None]
- newid
        VMID for the clone. Used only with clone.
        If newid is not set, the next available VM ID will be fetched from ProxmoxAPI.
        [Default: None]
- node
        Proxmox VE node, where the new VM will be created.
        Only required for `state=present'.
        For other states, it will be autodiscovered.
        [Default: None]
- numa
        A hash/dictionaries of NUMA topology. `numa='{"key":"value", "key":"value"}''.
        Keys allowed are - `numa[n]' where 0 ≤ n ≤ N.
        Values allowed are -
        `"cpu="<id[-id];...>",hostnodes="<id[-id];...>",memory="number",policy="(bind|interleave|preferred'"").
        `cpus' CPUs accessing this NUMA node.
        `hostnodes' Host NUMA nodes to use.
        `memory' Amount of memory this NUMA node provides.
        `policy' NUMA allocation policy.
        [Default: None]
- onboot
        Specifies whether a VM will be started during system bootup.
        (Choices: yes, no)[Default: yes]
- ostype
        Specifies guest operating system. This is used to enable special optimization/features for specific operating
        systems.
        The l26 is Linux 2.6/3.X Kernel.
        (Choices: other, wxp, w2k, w2k3, w2k8, wvista, win7, win8, l24, l26, solaris)[Default: l26]
- parallel
        A hash/dictionary of map host parallel devices. `parallel='{"key":"value", "key":"value"}''.
        Keys allowed are - (parallel[n]) where 0 ≤ n ≤ 2.
        Values allowed are - `"/dev/parport\d+|/dev/usb/lp\d+"'.
        [Default: None]
- pool
        Add the new VM to the specified pool.
        [Default: None]
- protection
        Enable/disable the protection flag of the VM. This will enable/disable the remove VM and remove disk operations.
        (Choices: yes, no)[Default: None]
- reboot
        Allow reboot. If set to yes, the VM exit on reboot.
        (Choices: yes, no)[Default: None]
- revert
        Revert a pending change.
        [Default: None]
- sata
        A hash/dictionary of volume used as sata hard disk or CD-ROM. `sata='{"key":"value", "key":"value"}''.
        Keys allowed are - `sata[n]' where 0 ≤ n ≤ 5.
        Values allowed are -  `"storage:size,format=value"'.
        `storage' is the storage identifier where to create the disk.
        `size' is the size of the disk in GB.
        `format' is the drive’s backing file’s data format. `qcow2|raw|subvol'.
        [Default: None]
- scsi
        A hash/dictionary of volume used as SCSI hard disk or CD-ROM. `scsi='{"key":"value", "key":"value"}''.
        Keys allowed are - `sata[n]' where 0 ≤ n ≤ 13.
        Values allowed are -  `"storage:size,format=value"'.
        `storage' is the storage identifier where to create the disk.
        `size' is the size of the disk in GB.
        `format' is the drive’s backing file’s data format. `qcow2|raw|subvol'.
        [Default: None]
- scsihw
        Specifies the SCSI controller model.
        (Choices: lsi, lsi53c810, virtio-scsi-pci, virtio-scsi-single, megasas, pvscsi)[Default: None]
- serial
        A hash/dictionary of serial device to create inside the VM. `'{"key":"value", "key":"value"}''.
        Keys allowed are - serial[n](str; required) where 0 ≤ n ≤ 3.
        Values allowed are - `(/dev/.+|socket').
        /!\ If you pass through a host serial device, it is no longer possible to migrate such machines - use with
        special care.
        [Default: None]
- shares
        Rets amount of memory shares for auto-ballooning. (0 - 50000).
        The larger the number is, the more memory this VM gets.
        The number is relative to weights of all other running VMs.
        Using 0 disables auto-ballooning, this means no limit.
        [Default: None]
- skiplock
        Ignore locks
        Only root is allowed to use this option.
        [Default: None]
- smbios
        Specifies SMBIOS type 1 fields.
        [Default: None]
- snapname
        The name of the snapshot. Used only with clone.
        [Default: None]
- sockets
        Sets the number of CPU sockets. (1 - N).
        [Default: 1]
- startdate
        Sets the initial date of the real time clock.
        Valid format for date are `'now'' or `'2016-09-25T16:01:21'' or `'2016-09-25''.
        [Default: None]
- startup
        Startup and shutdown behavior. `[[order=]\d+] [,up=\d+] [,down=\d+]'.
        Order is a non-negative number defining the general startup order.
        Shutdown in done with reverse ordering.
        [Default: None]
- state
        Indicates desired state of the instance.
        If `current', the current state of the VM will be fecthed. You can access it with `results.status'
        (Choices: present, started, absent, stopped, restarted, current)[Default: present]
- storage
        Target storage for full clone.
        [Default: None]
- tablet
        Enables/disables the USB tablet device.
        (Choices: yes, no)[Default: no]
- target
        Target node. Only allowed if the original VM is on shared storage.
        Used only with clone
        [Default: None]
- tdf
        Enables/disables time drift fix.
        (Choices: yes, no)[Default: None]
- template
        Enables/disables the template.
        (Choices: yes, no)[Default: no]
- timeout
        Timeout for operations.
        [Default: 30]
- update
        If `yes', the VM will be update with new value.
        Cause of the operations of the API and security reasons, I have disabled the update of the following parameters
        `net, virtio, ide, sata, scsi'. Per example updating `net' update the MAC address and `virtio' create always new
        disk...
        (Choices: yes, no)[Default: no]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: no]
- vcpus
        Sets number of hotplugged vcpus.
        [Default: None]
- vga
        Select VGA type. If you want to use high resolution modes (>= 1280x1024x16) then you should use option 'std' or
        'vmware'.
        (Choices: std, cirrus, vmware, qxl, serial0, serial1, serial2, serial3, qxl2, qxl3, qxl4)[Default: std]
- virtio
        A hash/dictionary of volume used as VIRTIO hard disk. `virtio='{"key":"value", "key":"value"}''.
        Keys allowed are - `virto[n]' where 0 ≤ n ≤ 15.
        Values allowed are -  `"storage:size,format=value"'.
        `storage' is the storage identifier where to create the disk.
        `size' is the size of the disk in GB.
        `format' is the drive’s backing file’s data format. `qcow2|raw|subvol'.
        [Default: None]
- vmid
        Specifies the VM ID. Instead use `name' parameter.
        If vmid is not set, the next available VM ID will be fetched from ProxmoxAPI.
        [Default: None]
- watchdog
        Creates a virtual hardware watchdog device.
        [Default: None]
Requirements:  proxmoxer, requests

EXAMPLES:
# Create new VM with minimal options
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf

# Create new VM with minimal options and given vmid
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    vmid        : 100

# Create new VM with two network interface options.
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    net         : '{"net0":"virtio,bridge=vmbr1,rate=200", "net1":"e1000,bridge=vmbr2,"}'

# Create new VM with one network interface, three virto hard disk, 4 cores, and 2 vcpus.
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    net         : '{"net0":"virtio,bridge=vmbr1,rate=200"}'
    virtio      : '{"virtio0":"VMs_LVM:10", "virtio1":"VMs:2,format=qcow2", "virtio2":"VMs:5,format=raw"}'
    cores       : 4
    vcpus       : 2

# Clone VM with only source VM name
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    clone       : spynal   # The VM source
    name        : zavala  # The target VM name
    node        : sabrewulf
    storage     : VMs
    format      : qcow2
    timeout     : 500  # Note: The task can take a while. Adapt

# Clone VM with source vmid and target newid and raw format
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    clone       : arbitrary_name
    vmid        : 108
    newid       : 152
    name        : zavala  # The target VM name
    node        : sabrewulf
    storage     : LVM_STO
    format      : raw
    timeout     : 300  # Note: The task can take a while. Adapt

# Create new VM and lock it for snapashot.
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    lock        : snapshot

# Create new VM and set protection to disable the remove VM and remove disk operations
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    protection  : yes

# Start VM
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    state       : started

# Stop VM
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    state       : stopped

# Stop VM with force
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    state       : stopped
    force       : yes

# Restart VM
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    state       : restarted

# Remove VM
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    state       : absent

# Get VM current state
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    state       : current

# Update VM configuration
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    cpu         : 8
    memory      : 16384
    update      : yes

# Delete QEMU parameters
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    delete      : 'args,template,cpulimit'

# Revert a pending change
- proxmox_kvm:
    api_user    : root@pam
    api_password: secret
    api_host    : helldorado
    name        : spynal
    node        : sabrewulf
    revert      : 'template,cpulimit'

RETURN VALUES:
devices:
    description: The list of devices created or used.
    returned: success
    type: dict
    sample: '
      {
        "ide0": "VMS_LVM:vm-115-disk-1",
        "ide1": "VMs:115/vm-115-disk-3.raw",
        "virtio0": "VMS_LVM:vm-115-disk-2",
        "virtio1": "VMs:115/vm-115-disk-1.qcow2",
        "virtio2": "VMs:115/vm-115-disk-2.raw"
      }'
mac:
    description: List of mac address created and net[n] attached. Useful when you want to use provision systems like Foreman via PXE.
    returned: success
    type: dict
    sample: '
      {
        "net0": "3E:6E:97:D2:31:9F",
        "net1": "B6:A1:FC:EF:78:A4"
      }'
vmid:
    description: The VM vmid.
    returned: success
    type: int
    sample: 115
status:
    description:
      - The current virtual machine status.
      - Returned only when C(state=current)
    returned: success
    type: dict
    sample: '{
      "changed": false,
      "msg": "VM kropta with vmid = 110 is running",
      "status": "running"
    }'


MAINTAINERS: Abdoul Bah (@helldorado) <bahabdoul at gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> PROXMOX_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/proxmox_template.py)

  allows you to upload/delete templates in Proxmox VE cluster

Options (= is mandatory):

= api_host
        the host of the Proxmox VE cluster

- api_password
        the password to authenticate with
        you can use PROXMOX_PASSWORD environment variable
        [Default: None]
= api_user
        the user to authenticate with

- content_type
        content type
        required only for `state=present'
        (Choices: vztmpl, iso)[Default: vztmpl]
- force
        can be used only with `state=present', exists template will be overwritten
        [Default: False]
= node
        Proxmox VE node, when you will operate with template
        [Default: None]
- src
        path to uploaded file
        required only for `state=present'
        [Default: None]
- state
        Indicate desired state of the template
        (Choices: present, absent)[Default: present]
- storage
        target storage
        [Default: local]
- template
        the template name
        required only for states `absent', `info'
        [Default: None]
- timeout
        timeout for operations
        [Default: 30]
- validate_certs
        enable / disable https certificate verification
        [Default: False]
Notes:
  * Requires proxmoxer and requests modules on host. This modules can be installed with pip.
Requirements:  proxmoxer, requests

EXAMPLES:
# Upload new openvz template with minimal options
- proxmox_template:
    node: uk-mc02
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    src: ~/ubuntu-14.04-x86_64.tar.gz

# Upload new openvz template with minimal options use environment PROXMOX_PASSWORD variable(you should export it before)
- proxmox_template:
    node: uk-mc02
    api_user: root@pam
    api_host: node1
    src: ~/ubuntu-14.04-x86_64.tar.gz

# Upload new openvz template with all options and force overwrite
- proxmox_template:
    node: uk-mc02
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    storage: local
    content_type: vztmpl
    src: ~/ubuntu-14.04-x86_64.tar.gz
    force: yes

# Delete template with minimal options
- proxmox_template:
    node: uk-mc02
    api_user: root@pam
    api_password: 1q2w3e
    api_host: node1
    template: ubuntu-14.04-x86_64.tar.gz
    state: absent


MAINTAINERS: Sergei Antipov @UnderGreen

METADATA:
	Status: ['preview']
	Supported_by: community
> PROXYSQL_BACKEND_SERVERS    (/usr/lib/python2.7/site-packages/ansible/modules/database/proxysql/proxysql_backend_servers.py)

  The [proxysql_backend_servers] module adds or removes mysql hosts using the proxysql admin interface.

Options (= is mandatory):

- comment
        Text field that can be used for any purposed defined by the user. Could be a description of what the host stores,
        a reminder of when the host was added or disabled, or a JSON processed by some checker script.
        [Default: ]
- compression
        If the value of `compression' is greater than 0, new connections to that server will use compression. If omitted
        the proxysql database default for `compression' is 0.
        [Default: (null)]
- config_file
        Specify a config file from which login_user and login_password are to be read.
        [Default: ]
- hostgroup_id
        The hostgroup in which this mysqld instance is included. An instance can be part of one or more hostgroups.
        [Default: 0]
= hostname
        The ip address at which the mysqld instance can be contacted.

- load_to_runtime
        Dynamically load mysql host config to runtime memory.
        [Default: True]
- login_host
        The host used to connect to ProxySQL admin interface.
        [Default: 127.0.0.1]
- login_password
        The password used to authenticate to ProxySQL admin interface.
        [Default: None]
- login_port
        The port used to connect to ProxySQL admin interface.
        [Default: 6032]
- login_user
        The username used to authenticate to ProxySQL admin interface.
        [Default: None]
- max_connections
        The maximum number of connections ProxySQL will open to this backend server. If omitted the proxysql database
        default for `max_connections' is 1000.
        [Default: (null)]
- max_latency_ms
        Ping time is monitored regularly. If a host has a ping time greater than `max_latency_ms' it is excluded from the
        connection pool (although the server stays ONLINE). If omitted the proxysql database default for `max_latency_ms'
        is 0.
        [Default: (null)]
- max_replication_lag
        If greater than 0, ProxySQL will reguarly monitor replication lag. If replication lag goes above
        `max_replication_lag', proxysql will temporarily shun the server until replication catches up. If omitted the
        proxysql database default for `max_replication_lag' is 0.
        [Default: (null)]
- port
        The port at which the mysqld instance can be contacted.
        [Default: 3306]
- save_to_disk
        Save mysql host config to sqlite db on disk to persist the configuration.
        [Default: True]
- state
        When `present' - adds the host, when `absent' - removes the host.
        (Choices: present, absent)[Default: present]
- status
        ONLINE - Backend server is fully operational. OFFLINE_SOFT - When a server is put into `OFFLINE_SOFT' mode,
        connections are kept in use until the current transaction is completed. This allows to gracefully detach a
        backend. OFFLINE_HARD - When a server is put into `OFFLINE_HARD' mode, the existing connections are dropped,
        while new incoming connections aren't accepted either. If omitted the proxysql database default for `status' is
        `ONLINE'.
        (Choices: ONLINE, OFFLINE_SOFT, OFFLINE_HARD)[Default: (null)]
- use_ssl
        If `use_ssl' is set to `True', connections to this server will be made using SSL connections. If omitted the
        proxysql database default for `use_ssl' is `False'.
        [Default: (null)]
- weight
        The bigger the weight of a server relative to other weights, the higher the probability of the server being
        chosen from the hostgroup. If omitted the proxysql database default for `weight' is 1.
        [Default: (null)]
EXAMPLES:
---
# This example adds a server, it saves the mysql server config to disk, but
# avoids loading the mysql server config to runtime (this might be because
# several servers are being added and the user wants to push the config to
# runtime in a single batch using the M(proxysql_manage_config) module).  It
# uses supplied credentials to connect to the proxysql admin interface.

- proxysql_backend_servers:
    login_user: 'admin'
    login_password: 'admin'
    hostname: 'mysql01'
    state: present
    load_to_runtime: False

# This example removes a server, saves the mysql server config to disk, and
# dynamically loads the mysql server config to runtime.  It uses credentials
# in a supplied config file to connect to the proxysql admin interface.

- proxysql_backend_servers:
    config_file: '~/proxysql.cnf'
    hostname: 'mysql02'
    state: absent

RETURN VALUES:
stdout:
    description: The mysql host modified or removed from proxysql
    returned: On create/update will return the newly modified host, on delete
              it will return the deleted record.
    type: dict
    "sample": {
        "changed": true,
        "hostname": "192.168.52.1",
        "msg": "Added server to mysql_hosts",
        "server": {
            "comment": "",
            "compression": "0",
            "hostgroup_id": "1",
            "hostname": "192.168.52.1",
            "max_connections": "1000",
            "max_latency_ms": "0",
            "max_replication_lag": "0",
            "port": "3306",
            "status": "ONLINE",
            "use_ssl": "0",
            "weight": "1"
        },
        "state": "present"
    }


MAINTAINERS: Ben Mildren (@bmildren)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PROXYSQL_GLOBAL_VARIABLES    (/usr/lib/python2.7/site-packages/ansible/modules/database/proxysql/proxysql_global_variables.py)

  The [proxysql_global_variables] module gets or sets the proxysql global variables.

Options (= is mandatory):

- config_file
        Specify a config file from which login_user and login_password are to be read.
        [Default: ]
- load_to_runtime
        Dynamically load mysql host config to runtime memory.
        [Default: True]
- login_host
        The host used to connect to ProxySQL admin interface.
        [Default: 127.0.0.1]
- login_password
        The password used to authenticate to ProxySQL admin interface.
        [Default: None]
- login_port
        The port used to connect to ProxySQL admin interface.
        [Default: 6032]
- login_user
        The username used to authenticate to ProxySQL admin interface.
        [Default: None]
- save_to_disk
        Save mysql host config to sqlite db on disk to persist the configuration.
        [Default: True]
- value
        Defines a value the variable specified using `variable' should be set to.
        [Default: (null)]
= variable
        Defines which variable should be returned, or if `value' is specified which variable should be updated.

EXAMPLES:
---
# This example sets the value of a variable, saves the mysql admin variables
# config to disk, and dynamically loads the mysql admin variables config to
# runtime. It uses supplied credentials to connect to the proxysql admin
# interface.

- proxysql_global_variables:
    login_user: 'admin'
    login_password: 'admin'
    variable: 'mysql-max_connections'
    value: 4096

# This example gets the value of a variable.  It uses credentials in a
# supplied config file to connect to the proxysql admin interface.

- proxysql_global_variables:
    config_file: '~/proxysql.cnf'
    variable: 'mysql-default_query_delay'

RETURN VALUES:
stdout:
    description: Returns the mysql variable supplied with it's associted value.
    returned: Returns the current variable and value, or the newly set value
              for the variable supplied..
    type: dict
    "sample": {
        "changed": false,
        "msg": "The variable is already been set to the supplied value",
        "var": {
            "variable_name": "mysql-poll_timeout",
            "variable_value": "3000"
        }
    }


MAINTAINERS: Ben Mildren (@bmildren)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PROXYSQL_MANAGE_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/database/proxysql/proxysql_manage_config.py)

  The [proxysql_global_variables] module writes the proxysql configuration settings between layers. Currently this module
  will always report a changed state, so should typically be used with WHEN however this will change in a future version
  when the CHECKSUM table commands are available for all tables in proxysql.

Options (= is mandatory):

= action
        The supplied `action' combines with the supplied `direction' to provide the semantics of how we want to move the
        `config_settings' between the `config_layers'.
        (Choices: LOAD, SAVE)
- config_file
        Specify a config file from which login_user and login_password are to be read.
        [Default: ]
= config_layer
        RUNTIME - represents the in-memory data structures of ProxySQL used by the threads that are handling the
        requests. MEMORY - (sometimes also referred as main) represents the in-memory SQLite3 database. DISK - represents
        the on-disk SQLite3 database. CONFIG - is the classical config file. You can only LOAD FROM the config file.
        (Choices: MEMORY, DISK, RUNTIME, CONFIG)
= config_settings
        The `config_settings' specifies which configuration we're writing.
        (Choices: MYSQL USERS, MYSQL SERVERS, MYSQL QUERY RULES, MYSQL VARIABLES, ADMIN VARIABLES, SCHEDULER)
= direction
        FROM - denotes we're reading values FROM the supplied `config_layer' and writing to the next layer. TO - denotes
        we're reading from the previous layer and writing TO the supplied `config_layer'."
        (Choices: FROM, TO)
- login_host
        The host used to connect to ProxySQL admin interface.
        [Default: 127.0.0.1]
- login_password
        The password used to authenticate to ProxySQL admin interface.
        [Default: None]
- login_port
        The port used to connect to ProxySQL admin interface.
        [Default: 6032]
- login_user
        The username used to authenticate to ProxySQL admin interface.
        [Default: None]
EXAMPLES:
---
# This example saves the mysql users config from memory to disk. It uses
# supplied credentials to connect to the proxysql admin interface.

- proxysql_global_variables:
    login_user: 'admin'
    login_password: 'admin'
    action: "SAVE"
    config_settings: "MYSQL USERS"
    direction: "FROM"
    config_layer: "MEMORY"

# This example loads the mysql query rules config from memory to to runtime. It
# uses supplied credentials to connect to the proxysql admin interface.

- proxysql_global_variables:
    config_file: '~/proxysql.cnf'
    action: "LOAD"
    config_settings: "MYSQL QUERY RULES"
    direction: "TO"
    config_layer: "RUNTIME"

RETURN VALUES:
stdout:
    description: Simply reports whether the action reported a change.
    returned: Currently the returned value with always be changed=True.
    type: dict
    "sample": {
        "changed": true
    }


MAINTAINERS: Ben Mildren (@bmildren)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PROXYSQL_MYSQL_USERS    (/usr/lib/python2.7/site-packages/ansible/modules/database/proxysql/proxysql_mysql_users.py)

  The [proxysql_mysql_users] module adds or removes mysql users using the proxysql admin interface.

Options (= is mandatory):

- active
        A user with `active' set to `False' will be tracked in the database, but will be never loaded in the in-memory
        data structures. If omitted the proxysql database default for `active' is `True'.
        [Default: (null)]
- backend
        If `backend' is set to `True', this (username, password) pair is used for authenticating to the ProxySQL
        instance.
        [Default: True]
- config_file
        Specify a config file from which login_user and login_password are to be read.
        [Default: ]
- default_hostgroup
        If there is no matching rule for the queries sent by this user, the traffic it generates is sent to the specified
        hostgroup. If omitted the proxysql database default for `use_ssl' is 0.
        [Default: (null)]
- default_schema
        The schema to which the connection should change to by default.
        [Default: (null)]
- fast_forward
        If `fast_forward' is set to `True', `fast_forward' will bypass the query processing layer (rewriting, caching)
        and pass through the query directly as is to the backend server. If omitted the proxysql database default for
        `fast_forward' is `False'.
        [Default: (null)]
- frontend
        If `frontend' is set to `True', this (username, password) pair is used for authenticating to the mysqld servers
        against any hostgroup.
        [Default: True]
- load_to_runtime
        Dynamically load mysql host config to runtime memory.
        [Default: True]
- login_host
        The host used to connect to ProxySQL admin interface.
        [Default: 127.0.0.1]
- login_password
        The password used to authenticate to ProxySQL admin interface.
        [Default: None]
- login_port
        The port used to connect to ProxySQL admin interface.
        [Default: 6032]
- login_user
        The username used to authenticate to ProxySQL admin interface.
        [Default: None]
- max_connections
        The maximum number of connections ProxySQL will open to the backend for this user. If omitted the proxysql
        database default for `max_connections' is 10000.
        [Default: (null)]
- password
        Password of the user connecting to the mysqld or ProxySQL instance.
        [Default: (null)]
- save_to_disk
        Save mysql host config to sqlite db on disk to persist the configuration.
        [Default: True]
- state
        When `present' - adds the user, when `absent' - removes the user.
        (Choices: present, absent)[Default: present]
- transaction_persistent
        If this is set for the user with which the MySQL client is connecting to ProxySQL (thus a "frontend" user),
        transactions started within a hostgroup will remain within that hostgroup regardless of any other rules. If
        omitted the proxysql database default for `transaction_persistent' is `False'.
        [Default: (null)]
- use_ssl
        If `use_ssl' is set to `True', connections by this user will be made using SSL connections. If omitted the
        proxysql database default for `use_ssl' is `False'.
        [Default: (null)]
= username
        Name of the user connecting to the mysqld or ProxySQL instance.

EXAMPLES:
---
# This example adds a user, it saves the mysql user config to disk, but
# avoids loading the mysql user config to runtime (this might be because
# several users are being added and the user wants to push the config to
# runtime in a single batch using the M(proxysql_manage_config) module).  It
# uses supplied credentials to connect to the proxysql admin interface.

- proxysql_mysql_users:
    login_user: 'admin'
    login_password: 'admin'
    username: 'productiondba'
    state: present
    load_to_runtime: False

# This example removes a user, saves the mysql user config to disk, and
# dynamically loads the mysql user config to runtime.  It uses credentials
# in a supplied config file to connect to the proxysql admin interface.

- proxysql_mysql_users:
    config_file: '~/proxysql.cnf'
    username: 'mysqlboy'
    state: absent

RETURN VALUES:
stdout:
    description: The mysql user modified or removed from proxysql
    returned: On create/update will return the newly modified user, on delete
              it will return the deleted record.
    type: dict
    sample": {
        "changed": true,
        "msg": "Added user to mysql_users",
        "state": "present",
        "user": {
            "active": "1",
            "backend": "1",
            "default_hostgroup": "1",
            "default_schema": null,
            "fast_forward": "0",
            "frontend": "1",
            "max_connections": "10000",
            "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER",
            "schema_locked": "0",
            "transaction_persistent": "0",
            "use_ssl": "0",
            "username": "guest_ro"
        },
        "username": "guest_ro"
    }


MAINTAINERS: Ben Mildren (@bmildren)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PROXYSQL_QUERY_RULES    (/usr/lib/python2.7/site-packages/ansible/modules/database/proxysql/proxysql_query_rules.py)

  The [proxysql_query_rules] module modifies query rules using the proxysql admin interface.

Options (= is mandatory):

- active
        A rule with `active' set to `False' will be tracked in the database, but will be never loaded in the in-memory
        data structures.
        [Default: (null)]
- apply
        Used in combination with `flagIN' and `flagOUT' to create chains of rules. Setting apply to True signifies the
        last rule to be applied.
        [Default: (null)]
- cache_ttl
        The number of milliseconds for which to cache the result of the query. Note in ProxySQL 1.1 `cache_ttl' was in
        seconds.
        [Default: (null)]
- client_addr
        Match traffic from a specific source.
        [Default: (null)]
- comment
        Free form text field, usable for a descriptive comment of the query rule.
        [Default: (null)]
- config_file
        Specify a config file from which login_user and login_password are to be read.
        [Default: ]
- delay
        Number of milliseconds to delay the execution of the query. This is essentially a throttling mechanism and QoS,
        and allows a way to give priority to queries over others. This value is added to the mysql-default_query_delay
        global variable that applies to all queries.
        [Default: (null)]
- destination_hostgroup
        Route matched queries to this hostgroup. This happens unless there is a started transaction and the logged in
        user has `transaction_persistent' set to `True' (see [proxysql_mysql_users]).
        [Default: (null)]
- digest
        Match queries with a specific digest, as returned by stats_mysql_query_digest.digest.
        [Default: (null)]
- error_msg
        Query will be blocked, and the specified error_msg will be returned to the client.
        [Default: (null)]
- flagIN
        Used in combination with `flagOUT' and `apply' to create chains of rules.
        [Default: (null)]
- flagOUT
        Used in combination with `flagIN' and apply to create chains of rules. When set, `flagOUT' signifies the `flagIN'
        to be used in the next chain of rules.
        [Default: (null)]
- force_delete
        By default we avoid deleting more than one schedule in a single batch, however if you need this behaviour and
        you're not concerned about the schedules deleted, you can set `force_delete' to `True'.
        [Default: False]
- load_to_runtime
        Dynamically load mysql host config to runtime memory.
        [Default: True]
- log
        Query will be logged.
        [Default: (null)]
- login_host
        The host used to connect to ProxySQL admin interface.
        [Default: 127.0.0.1]
- login_password
        The password used to authenticate to ProxySQL admin interface.
        [Default: None]
- login_port
        The port used to connect to ProxySQL admin interface.
        [Default: 6032]
- login_user
        The username used to authenticate to ProxySQL admin interface.
        [Default: None]
- match_digest
        Regular expression that matches the query digest. The dialect of regular expressions used is that of re2 -
        https://github.com/google/re2
        [Default: (null)]
- match_pattern
        Regular expression that matches the query text. The dialect of regular expressions used is that of re2 -
        https://github.com/google/re2
        [Default: (null)]
- mirror_flagOUT
        Enables query mirroring. If set `mirror_flagOUT' can be used to evaluates the mirrored query against the
        specified chain of rules.
        [Default: (null)]
- mirror_hostgroup
        Enables query mirroring. If set `mirror_hostgroup' can be used to mirror queries to the same or different
        hostgroup.
        [Default: (null)]
- negate_match_pattern
        If `negate_match_pattern' is set to `True', only queries not matching the query text will be considered as a
        match. This acts as a NOT operator in front of the regular expression matching against match_pattern.
        [Default: (null)]
- proxy_addr
        Match incoming traffic on a specific local IP.
        [Default: (null)]
- proxy_port
        Match incoming traffic on a specific local port.
        [Default: (null)]
- replace_pattern
        This is the pattern with which to replace the matched pattern. Note that this is optional, and when omitted, the
        query processor will only cache, route, or set other parameters without rewriting.
        [Default: (null)]
- retries
        The maximum number of times a query needs to be re-executed in case of detected failure during the execution of
        the query. If retries is not specified, the global variable mysql-query_retries_on_failure applies.
        [Default: (null)]
- rule_id
        The unique id of the rule. Rules are processed in rule_id order.
        [Default: (null)]
- save_to_disk
        Save mysql host config to sqlite db on disk to persist the configuration.
        [Default: True]
- schemaname
        Filtering criteria matching schemaname. If `schemaname' is non-NULL, a query will match only if the connection
        uses schemaname as its default schema.
        [Default: (null)]
- state
        When `present' - adds the rule, when `absent' - removes the rule.
        (Choices: present, absent)[Default: present]
- timeout
        The maximum timeout in milliseconds with which the matched or rewritten query should be executed. If a query run
        for longer than the specific threshold, the query is automatically killed. If timeout is not specified, the
        global variable mysql-default_query_timeout applies.
        [Default: (null)]
- username
        Filtering criteria matching username.  If `username' is non-NULL, a query will match only if the connection is
        made with the correct username.
        [Default: (null)]
EXAMPLES:
---
# This example adds a rule to redirect queries from a specific user to another
# hostgroup, it saves the mysql query rule config to disk, but avoids loading
# the mysql query config config to runtime (this might be because several
# rules are being added and the user wants to push the config to runtime in a
# single batch using the M(proxysql_manage_config) module). It uses supplied
# credentials to connect to the proxysql admin interface.

- proxysql_backend_servers:
    login_user: admin
    login_password: admin
    username: 'guest_ro'
    destination_hostgroup: 1
    active: 1
    retries: 3
    state: present
    load_to_runtime: False

# This example removes all rules that use the username 'guest_ro', saves the
# mysql query rule config to disk, and dynamically loads the mysql query rule
# config to runtime.  It uses credentials in a supplied config file to connect
# to the proxysql admin interface.

- proxysql_backend_servers:
    config_file: '~/proxysql.cnf'
    username: 'guest_ro'
    state: absent
    force_delete: true

RETURN VALUES:
stdout:
    description: The mysql user modified or removed from proxysql
    returned: On create/update will return the newly modified rule, in all
              other cases will return a list of rules that match the supplied
              criteria.
    type: dict
    "sample": {
        "changed": true,
        "msg": "Added rule to mysql_query_rules",
        "rules": [
            {
                "active": "0",
                "apply": "0",
                "cache_ttl": null,
                "client_addr": null,
                "comment": null,
                "delay": null,
                "destination_hostgroup": 1,
                "digest": null,
                "error_msg": null,
                "flagIN": "0",
                "flagOUT": null,
                "log": null,
                "match_digest": null,
                "match_pattern": null,
                "mirror_flagOUT": null,
                "mirror_hostgroup": null,
                "negate_match_pattern": "0",
                "proxy_addr": null,
                "proxy_port": null,
                "reconnect": null,
                "replace_pattern": null,
                "retries": null,
                "rule_id": "1",
                "schemaname": null,
                "timeout": null,
                "username": "guest_ro"
            }
        ],
        "state": "present"
    }


MAINTAINERS: Ben Mildren (@bmildren)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PROXYSQL_REPLICATION_HOSTGROUPS    (/usr/lib/python2.7/site-packages/ansible/modules/database/proxysql/proxysql_replication_hostgroups.py)

  Each row in mysql_replication_hostgroups represent a pair of writer_hostgroup and reader_hostgroup. ProxySQL will
  monitor the value of read_only for all the servers in specified hostgroups, and based on the value of read_only will
  assign the server to the writer or reader hostgroups.

Options (= is mandatory):

- comment
        Text field that can be used for any purposed defined by the user.
        [Default: (null)]
- config_file
        Specify a config file from which login_user and login_password are to be read.
        [Default: ]
- load_to_runtime
        Dynamically load mysql host config to runtime memory.
        [Default: True]
- login_host
        The host used to connect to ProxySQL admin interface.
        [Default: 127.0.0.1]
- login_password
        The password used to authenticate to ProxySQL admin interface.
        [Default: None]
- login_port
        The port used to connect to ProxySQL admin interface.
        [Default: 6032]
- login_user
        The username used to authenticate to ProxySQL admin interface.
        [Default: None]
= reader_hostgroup
        Id of the reader hostgroup.

- save_to_disk
        Save mysql host config to sqlite db on disk to persist the configuration.
        [Default: True]
- state
        When `present' - adds the replication hostgroup, when `absent' - removes the replication hostgroup.
        (Choices: present, absent)[Default: present]
= writer_hostgroup
        Id of the writer hostgroup.

EXAMPLES:
---
# This example adds a replication hostgroup, it saves the mysql server config
# to disk, but avoids loading the mysql server config to runtime (this might be
# because several replication hostgroup are being added and the user wants to
# push the config to runtime in a single batch using the
# M(proxysql_manage_config) module).  It uses supplied credentials to connect
# to the proxysql admin interface.

- proxysql_replication_hostgroups:
    login_user: 'admin'
    login_password: 'admin'
    writer_hostgroup: 1
    reader_hostgroup: 2
    state: present
    load_to_runtime: False

# This example removes a replication hostgroup, saves the mysql server config
# to disk, and dynamically loads the mysql server config to runtime.  It uses
# credentials in a supplied config file to connect to the proxysql admin
# interface.

- proxysql_replication_hostgroups:
    config_file: '~/proxysql.cnf'
    writer_hostgroup: 3
    reader_hostgroup: 4
    state: absent

RETURN VALUES:
stdout:
    description: The replication hostgroup modified or removed from proxysql
    returned: On create/update will return the newly modified group, on delete
              it will return the deleted record.
    type: dict
    "sample": {
        "changed": true,
        "msg": "Added server to mysql_hosts",
        "repl_group": {
            "comment": "",
            "reader_hostgroup": "1",
            "writer_hostgroup": "2"
        },
        "state": "present"
    }


MAINTAINERS: Ben Mildren (@bmildren)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PROXYSQL_SCHEDULER    (/usr/lib/python2.7/site-packages/ansible/modules/database/proxysql/proxysql_scheduler.py)

  The [proxysql_scheduler] module adds or removes schedules using the proxysql admin interface.

Options (= is mandatory):

- active
        A schedule with `active' set to `False' will be tracked in the database, but will be never loaded in the in-
        memory data structures.
        [Default: True]
- arg1
        Argument that can be passed to the job.
        [Default: (null)]
- arg2
        Argument that can be passed to the job.
        [Default: (null)]
- arg3
        Argument that can be passed to the job.
        [Default: (null)]
- arg4
        Argument that can be passed to the job.
        [Default: (null)]
- arg5
        Argument that can be passed to the job.
        [Default: (null)]
- comment
        Text field that can be used for any purposed defined by the user.
        [Default: (null)]
- config_file
        Specify a config file from which login_user and login_password are to be read.
        [Default: ]
= filename
        Full path of the executable to be executed.

- force_delete
        By default we avoid deleting more than one schedule in a single batch, however if you need this behaviour and
        you're not concerned about the schedules deleted, you can set `force_delete' to `True'.
        [Default: False]
- interval_ms
        How often (in millisecond) the job will be started. The minimum value for `interval_ms' is 100 milliseconds.
        [Default: 10000]
- load_to_runtime
        Dynamically load mysql host config to runtime memory.
        [Default: True]
- login_host
        The host used to connect to ProxySQL admin interface.
        [Default: 127.0.0.1]
- login_password
        The password used to authenticate to ProxySQL admin interface.
        [Default: None]
- login_port
        The port used to connect to ProxySQL admin interface.
        [Default: 6032]
- login_user
        The username used to authenticate to ProxySQL admin interface.
        [Default: None]
- save_to_disk
        Save mysql host config to sqlite db on disk to persist the configuration.
        [Default: True]
- state
        When `present' - adds the schedule, when `absent' - removes the schedule.
        (Choices: present, absent)[Default: present]
EXAMPLES:
---
# This example adds a schedule, it saves the scheduler config to disk, but
# avoids loading the scheduler config to runtime (this might be because
# several servers are being added and the user wants to push the config to
# runtime in a single batch using the M(proxysql_manage_config) module).  It
# uses supplied credentials to connect to the proxysql admin interface.

- proxysql_scheduler:
    login_user: 'admin'
    login_password: 'admin'
    interval_ms: 1000
    filename: "/opt/maintenance.py"
    state: present
    load_to_runtime: False

# This example removes a schedule, saves the scheduler config to disk, and
# dynamically loads the scheduler config to runtime.  It uses credentials
# in a supplied config file to connect to the proxysql admin interface.

- proxysql_scheduler:
    config_file: '~/proxysql.cnf'
    filename: "/opt/old_script.py"
    state: absent

RETURN VALUES:
stdout:
    description: The schedule modified or removed from proxysql
    returned: On create/update will return the newly modified schedule, on
              delete it will return the deleted record.
    type: dict
    "sample": {
        "changed": true,
        "filename": "/opt/test.py",
        "msg": "Added schedule to scheduler",
        "schedules": [
            {
                "active": "1",
                "arg1": null,
                "arg2": null,
                "arg3": null,
                "arg4": null,
                "arg5": null,
                "comment": "",
                "filename": "/opt/test.py",
                "id": "1",
                "interval_ms": "10000"
            }
        ],
        "state": "present"
    }


MAINTAINERS: Ben Mildren (@bmildren)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PUBNUB_BLOCKS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/pubnub/pubnub_blocks.py)

  This module allows Ansible to interface with the PubNub BLOCKS infrastructure by providing the following operations:
  create / remove, start / stop and rename for blocks and create / modify / remove for event handlers

Options (= is mandatory):

= application
        Name of target PubNub application for which blocks configuration on specific `keyset' will be done.

- cache
        In case if single play use blocks management module few times it is preferred to enabled 'caching' by making
        previous module to share gathered artifacts and pass them to this parameter.
        [Default: {}]
- changes
        List of fields which should be changed by block itself (doesn't affect any event handlers).
        Possible options for change is: `name'.
        [Default: {}]
- description
        Short block description which will be later visible on admin.pubnub.com. Used only if block doesn't exists and
        won't change description for existing block.
        [Default: New block]
- email
        Email from account for which new session should be started.
        Not required if `cache' contains result of previous module call (in same play).
        [Default: (null)]
- event_handlers
        List of event handlers which should be updated for specified block `name'.
        Each entry for new event handler should contain: `name', `src', `channels', `event'. `name' used as event handler
        name which can be used later to make changes to it.
        `src' is full path to file with event handler code.
        `channels' is name of channel from which event handler is waiting for events.
        `event' is type of event which is able to trigger event handler: `js-before-publish', `js-after-publish', `js-
        after-presence'.
        Each entry for existing handlers should contain `name' (so target handler can be identified). Rest parameters
        (`src', `channels' and `event') can be added if changes required for them.
        It is possible to rename event handler by adding `changes' key to event handler payload and pass dictionary,
        which will contain single key `name', where new name should be passed.
        To remove particular event handler it is possible to set `state' for it to `absent' and it will be removed.
        [Default: []]
= keyset
        Name of application's keys set which is bound to managed blocks.

= name
        Name of managed block which will be later visible on admin.pubnub.com.

- password
        Password which match to account to which specified `email' belong.
        Not required if `cache' contains result of previous module call (in same play).
        [Default: (null)]
- state
        Intended block state after event handlers creation / update process will be completed.
        (Choices: started, stopped, present, absent)[Default: started]
- validate_certs
        This key allow to try skip certificates check when performing REST API calls. Sometimes host may have issues with
        certificates on it and this will cause problems to call PubNub REST API.
        If check should be ignored `False' should be passed to this parameter.
        [Default: True]
Requirements:  python >= 2.7, pubnub_blocks_client >= 1.0

EXAMPLES:
# Event handler create example.
- name: Create single event handler
  pubnub_blocks:
    email: '{{ email }}'
    password: '{{ password }}'
    application: '{{ app_name }}'
    keyset: '{{ keyset_name }}'
    name: '{{ block_name }}'
    event_handlers:
      -
        src: '{{ path_to_handler_source }}'
        name: '{{ handler_name }}'
        event: 'js-before-publish'
        channels: '{{ handler_channel }}'

# Change event handler trigger event type.
- name: Change event handler 'event'
  pubnub_blocks:
    email: '{{ email }}'
    password: '{{ password }}'
    application: '{{ app_name }}'
    keyset: '{{ keyset_name }}'
    name: '{{ block_name }}'
    event_handlers:
      -
        name: '{{ handler_name }}'
        event: 'js-after-publish'

# Stop block and event handlers.
- name: Stopping block
  pubnub_blocks:
    email: '{{ email }}'
    password: '{{ password }}'
    application: '{{ app_name }}'
    keyset: '{{ keyset_name }}'
    name: '{{ block_name }}'
    state: stop

# Multiple module calls with cached result passing
- name: Create '{{ block_name }}' block
  register: module_cache
  pubnub_blocks:
    email: '{{ email }}'
    password: '{{ password }}'
    application: '{{ app_name }}'
    keyset: '{{ keyset_name }}'
    name: '{{ block_name }}'
    state: present
- name: Add '{{ event_handler_1_name }}' handler to '{{ block_name }}'
  register: module_cache
  pubnub_blocks:
    cache: '{{ module_cache }}'
    application: '{{ app_name }}'
    keyset: '{{ keyset_name }}'
    name: '{{ block_name }}'
    state: present
    event_handlers:
      -
        src: '{{ path_to_handler_1_source }}'
        name: '{{ event_handler_1_name }}'
        channels: '{{ event_handler_1_channel }}'
        event: 'js-before-publish'
- name: Add '{{ event_handler_2_name }}' handler to '{{ block_name }}'
  register: module_cache
  pubnub_blocks:
    cache: '{{ module_cache }}'
    application: '{{ app_name }}'
    keyset: '{{ keyset_name }}'
    name: '{{ block_name }}'
    state: present
    event_handlers:
      -
        src: '{{ path_to_handler_2_source }}'
        name: '{{ event_handler_2_name }}'
        channels: '{{ event_handler_2_channel }}'
        event: 'js-before-publish'
- name: Start '{{ block_name }}' block
  register: module_cache
  pubnub_blocks:
    cache: '{{ module_cache }}'
    application: '{{ app_name }}'
    keyset: '{{ keyset_name }}'
    name: '{{ block_name }}'
    state: started

RETURN VALUES:
module_cache:
  description: "Cached account information. In case if with single play module
  used few times it is better to pass cached data to next module calls to speed
  up process."
  type: dict


MAINTAINERS: PubNub <support@pubnub.com> (@pubnub), Sergey Mamontov <sergey@pubnub.com> (@parfeon)

METADATA:
	Status: ['preview']
	Supported_by: community
> PULP_REPO    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/pulp_repo.py)

  Add or remove Pulp repos from a remote host.

Options (= is mandatory):

- add_export_distributor
        Whether or not to add the export distributor to new `rpm' repositories.
        [Default: False]
- feed
        Upstream feed URL to receive updates from.
        [Default: None]
- force_basic_auth
        httplib2, the library used by the [uri] module only sends authentication information when a webservice responds
        to an initial request with a 401 status. Since some basic auth services do not properly send a 401, logins will
        fail. This option forces the sending of the Basic authentication header upon initial request.
        (Choices: yes, no)[Default: no]
- importer_ssl_ca_cert
        CA certificate string used to validate the feed source SSL certificate. This can be the file content or the path
        to the file.
        [Default: None]
- importer_ssl_client_cert
        Certificate used as the client certificate when synchronizing the repository. This is used to communicate
        authentication information to the feed source. The value to this option must be the full path to the certificate.
        The specified file may be the certificate itself or a single file containing both the certificate and private
        key. This can be the file content or the path to the file.
        [Default: None]
- importer_ssl_client_key
        Private key to the certificate specified in `importer_ssl_client_cert', assuming it is not included in the
        certificate file itself. This can be the file content or the path to the file.
        [Default: None]
= name
        Name of the repo to add or remove. This correlates to repo-id in Pulp.

- proxy_host
        Proxy url setting for the pulp repository importer. This is in the format scheme://host.
        [Default: None]
- proxy_port
        Proxy port setting for the pulp repository importer.
        [Default: None]
- publish_distributor
        Distributor to use when state is `publish'. The default is to publish all distributors.
        [Default: (null)]
- pulp_host
        URL of the pulp server to connect to.
        [Default: http://127.0.0.1]
= relative_url
        Relative URL for the local repository.
        [Default: None]
- repo_type
        Repo plugin type to use (i.e. `rpm', `docker').
        [Default: rpm]
- serve_http
        Make the repo available over HTTP.
        [Default: False]
- serve_https
        Make the repo available over HTTPS.
        [Default: True]
- state
        The repo state. A state of `sync' will queue a sync of the repo. This is asynchronous but not delayed like a
        scheduled sync. A state of `publish' will use the repository's distributor to publish the content.
        (Choices: present, absent, sync, publish)[Default: present]
- url_password
        The password for use in HTTP basic authentication to the pulp API. If the `url_username' parameter is not
        specified, the `url_password' parameter will not be used.
        [Default: (null)]
- url_username
        The username for use in HTTP basic authentication to the pulp API.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
- wait_for_completion
        Wait for asynchronous tasks to complete before returning.
        (Choices: yes, no)[Default: no]
Notes:
  * This module can currently only create distributors and importers on rpm repositories. Contributions to support
        other repo types are welcome.
EXAMPLES:
- name: Create a new repo with name 'my_repo'
  pulp_repo:
    name: my_repo
    relative_url: my/repo
    state: present

- name: Create a repo with a feed and a relative URL
  pulp_repo:
    name: my_centos_updates
    repo_type: rpm
    feed: http://mirror.centos.org/centos/6/updates/x86_64/
    relative_url: centos/6/updates
    url_username: admin
    url_password: admin
    force_basic_auth: yes
    state: present

- name: Remove a repo from the pulp server
  pulp_repo:
    name: my_old_repo
    repo_type: rpm
    state: absent

RETURN VALUES:
repo:
  description: Name of the repo that the action was performed on.
  returned: success
  type: string
  sample: my_repo


MAINTAINERS: Joe Adams (@sysadmind)

METADATA:
	Status: ['preview']
	Supported_by: community
> PUPPET    (/usr/lib/python2.7/site-packages/ansible/modules/system/puppet.py)

  Runs `puppet' agent or apply in a reliable manner

Options (= is mandatory):

- certname
        The name to use when handling certificates.
        [Default: None]
- environment
        Puppet environment to be used.
        [Default: None]
- execute
        Execute a specific piece of Puppet code. It has no effect with a puppetmaster.
        [Default: None]
- facter_basename
        Basename of the facter output file
        [Default: ansible]
- facts
        A dict of values to pass in as persistent external facter facts
        [Default: None]
- logdest
        Where the puppet logs should go, if puppet apply is being used
        (Choices: stdout, syslog)[Default: stdout]
- manifest
        Path to the manifest file to run puppet apply on.
        [Default: None]
- puppetmaster
        The hostname of the puppetmaster to contact.
        [Default: None]
- tags
        A comma-separated list of puppet tags to be used.
        [Default: None]
- timeout
        How long to wait for `puppet' to finish.
        [Default: 30m]
Requirements:  puppet

EXAMPLES:
# Run puppet agent and fail if anything goes wrong
- puppet

# Run puppet and timeout in 5 minutes
- puppet:
    timeout: 5m

# Run puppet using a different environment
- puppet:
    environment: testing

# Run puppet using a specific certname
- puppet:
    certname: agent01.example.com

# Run puppet using a specific piece of Puppet code. Has no effect with a
# puppetmaster.
- puppet:
    execute: 'include ::mymodule'

# Run puppet using a specific tags
- puppet:
    tags: update,nginx


MAINTAINERS: Monty Taylor (@emonty)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> PUSHBULLET    (/usr/lib/python2.7/site-packages/ansible/modules/notification/pushbullet.py)

  This module sends push notifications via Pushbullet to channels or devices.

Options (= is mandatory):

= api_key
        Push bullet API token

- body
        Body of the notification, e.g. Details of the fault you're alerting.
        [Default: (null)]
- channel
        The channel TAG you wish to broadcast a push notification, as seen on the "My Channels" > "Edit your channel" at
        Pushbullet page.
        [Default: None]
- device
        The device NAME you wish to send a push notification, as seen on the Pushbullet main page.
        [Default: None]
- push_type
        Thing you wish to push.
        (Choices: note, link)[Default: note]
= title
        Title of the notification.

Notes:
  * Requires pushbullet.py Python package on the remote host. You can install it via pip with ($ pip install
        pushbullet.py). See https://github.com/randomchars/pushbullet.py
Requirements:  pushbullet.py

EXAMPLES:
# Sends a push notification to a device
- pushbullet:
    api_key: "ABC123abc123ABC123abc123ABC123ab"
    device: "Chrome"
    title: "You may see this on Google Chrome"

# Sends a link to a device
- pushbullet:
    api_key: ABC123abc123ABC123abc123ABC123ab
    device: Chrome
    push_type: link
    title: Ansible Documentation
    body: http://docs.ansible.com/

# Sends a push notification to a channel
- pushbullet:
    api_key: ABC123abc123ABC123abc123ABC123ab
    channel: my-awesome-channel
    title: Broadcasting a message to the #my-awesome-channel folks

# Sends a push notification with title and body to a channel
- pushbullet:
    api_key: ABC123abc123ABC123abc123ABC123ab
    channel: my-awesome-channel
    title: ALERT! Signup service is down
    body: Error rate on signup service is over 90% for more than 2 minutes


MAINTAINERS: Willy Barro (@willybarro)

METADATA:
	Status: ['preview']
	Supported_by: community
> PUSHOVER    (/usr/lib/python2.7/site-packages/ansible/modules/notification/pushover.py)

  Send notifications via pushover, to subscriber list of devices, and email addresses. Requires pushover app on devices.

Options (= is mandatory):

= app_token
        Pushover issued token identifying your pushover app.

= msg
        What message you wish to send.

- pri
        Message priority (see https://pushover.net for details.)
        [Default: (null)]
= user_key
        Pushover issued authentication key for your user.

Notes:
  * You will require a pushover.net account to use this module. But no account is required to receive messages.
EXAMPLES:
- pushover:
    msg: '{{ inventory_hostname }} has exploded in flames, It is now time to panic'
    app_token: wxfdksl
    user_key: baa5fe97f2c5ab3ca8f0bb59
  delegate_to: localhost


MAINTAINERS: Jim Richardson (@weaselkeeper)

METADATA:
	Status: ['preview']
	Supported_by: community
> QUANTUM_FLOATING_IP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_quantum_floating_ip.py)

  Add or Remove a floating IP to an instance

DEPRECATED: 
Deprecated in 2.0. Use M(os_floating_ip) instead.

Options (= is mandatory):

- auth_url
        The keystone url for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
= instance_name
        The name of the instance to which the IP address should be assigned
        [Default: None]
- internal_network_name
        The name of the network of the port to associate with the floating ip. Necessary when VM multiple networks.
        [Default: None]
= login_password
        Password of login user
        [Default: yes]
= login_tenant_name
        The tenant name of the login user
        [Default: yes]
= login_username
        login username to authenticate to keystone
        [Default: admin]
= network_name
        Name of the network from which IP has to be assigned to VM. Please make sure the network is an external network
        [Default: None]
- region_name
        Name of the region
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
Requirements:  python >= 2.6, python-novaclient, python-neutronclient or python-quantumclient, python-keystoneclient

EXAMPLES:
- name: Assign a floating ip to the instance from an external network
  quantum_floating_ip:
    state: present
    login_username: admin
    login_password: admin
    login_tenant_name: admin
    network_name: external_network
    instance_name: vm1
    internal_network_name: internal_network


MAINTAINERS: Benno Joy (@bennojoy), Brad P. Crochet (@bcrochet)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> QUANTUM_FLOATING_IP_ASSOCIATE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_quantum_floating_ip_associate.py)

  Associates or disassociates a specific floating IP with a particular instance

DEPRECATED: 
Deprecated in 2.0. Use M(os_floating_ip) instead.

Options (= is mandatory):

- auth_url
        the keystone url for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
= instance_name
        name of the instance to which the public IP should be assigned
        [Default: None]
= ip_address
        floating ip that should be assigned to the instance
        [Default: None]
= login_password
        password of login user
        [Default: yes]
= login_tenant_name
        the tenant name of the login user
        [Default: True]
= login_username
        login username to authenticate to keystone
        [Default: admin]
- region_name
        name of the region
        [Default: None]
- state
        indicates the desired state of the resource
        (Choices: present, absent)[Default: present]
Requirements:  python >= 2.6, python-novaclient, python-neutronclient or python-quantumclient, python-keystoneclient

EXAMPLES:
- name: Associate a specific floating IP with an Instance
  quantum_floating_ip_associate:
    state: present
    login_username: admin
    login_password: admin
    login_tenant_name: admin
    ip_address: 1.1.1.1
    instance_name: vm1


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> QUANTUM_NETWORK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_quantum_network.py)

  Add or Remove network from OpenStack.

DEPRECATED: 
Deprecated in 2.0. Use M(os_network) instead.

Options (= is mandatory):

- admin_state_up
        Whether the state should be marked as up or down
        [Default: True]
- auth_url
        The keystone url for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
= login_password
        Password of login user
        [Default: yes]
= login_tenant_name
        The tenant name of the login user
        [Default: yes]
= login_username
        login username to authenticate to keystone
        [Default: admin]
= name
        Name to be assigned to the network
        [Default: None]
- provider_network_type
        The type of the network to be created, gre, vlan, local. Available types depend on the plugin. The Quantum
        service decides if not specified.
        [Default: None]
- provider_physical_network
        The physical network which would realize the virtual network for flat and vlan networks.
        [Default: None]
- provider_segmentation_id
        The id that has to be assigned to the network, in case of vlan networks that would be vlan id and for gre the
        tunnel id
        [Default: None]
- region_name
        Name of the region
        [Default: None]
- router_external
        If 'yes', specifies that the virtual network is a external network (public).
        [Default: False]
- shared
        Whether this network is shared or not
        [Default: False]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_name
        The name of the tenant for whom the network is created
        [Default: None]
Requirements:  python >= 2.6, python-neutronclient or python-quantumclient, python-keystoneclient

EXAMPLES:
- name: Create a GRE backed Quantum network with tunnel id 1 for tenant1
  quantum_network:
    name: t1network
    tenant_name: tenant1
    state: present
    provider_network_type: gre
    provider_segmentation_id: 1
    login_username: admin
    login_password: admin
    login_tenant_name: admin

- name: Create an external network
  quantum_network:
    name: external_network
    state: present
    provider_network_type: local
    router_external: yes
    login_username: admin
    login_password: admin
    login_tenant_name: admin


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> QUANTUM_ROUTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_quantum_router.py)

  Create or Delete routers from OpenStack

DEPRECATED: 
Deprecated in 2.0. Use M(os_router) instead.

Options (= is mandatory):

- admin_state_up
        desired admin state of the created router .
        [Default: True]
- auth_url
        The keystone url for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
= login_password
        Password of login user
        [Default: yes]
= login_tenant_name
        The tenant name of the login user
        [Default: yes]
= login_username
        login username to authenticate to keystone
        [Default: admin]
= name
        Name to be give to the router
        [Default: None]
- region_name
        Name of the region
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_name
        Name of the tenant for which the router has to be created, if none router would be created for the login tenant.
        [Default: None]
Requirements:  python >= 2.6, python-neutronclient or python-quantumclient, python-keystoneclient

EXAMPLES:
- name: Create a router for tenant admin
  quantum_router:
    state: present
    login_username: admin
    login_password: admin
    login_tenant_name: admin
    name: router1


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> QUANTUM_ROUTER_GATEWAY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_quantum_router_gateway.py)

  Creates/Removes a gateway interface from the router, used to associate a external network with a router to route
  external traffic.

DEPRECATED: 
Deprecated in 2.0. Use M(os_router) instead.

Options (= is mandatory):

- auth_url
        The keystone URL for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
= login_password
        Password of login user
        [Default: yes]
= login_tenant_name
        The tenant name of the login user
        [Default: yes]
= login_username
        login username to authenticate to keystone
        [Default: admin]
= network_name
        Name of the external network which should be attached to the router.
        [Default: None]
- region_name
        Name of the region
        [Default: None]
= router_name
        Name of the router to which the gateway should be attached.
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
Requirements:  python >= 2.6, python-neutronclient or python-quantumclient, python-keystoneclient

EXAMPLES:
- name: Attach an external network with a router to allow flow of external traffic
  quantum_router_gateway:
    state: present
    login_username: admin
    login_password: admin
    login_tenant_name: admin
    router_name: external_router
    network_name: external_network


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> QUANTUM_ROUTER_INTERFACE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_quantum_router_interface.py)

  Attach/Detach a subnet interface to a router, to provide a gateway for the subnet.

DEPRECATED: 
Deprecated in 2.0. Use M(os_router) instead.

Options (= is mandatory):

- auth_url
        The keystone URL for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
= login_password
        Password of login user
        [Default: yes]
= login_tenant_name
        The tenant name of the login user
        [Default: yes]
= login_username
        login username to authenticate to keystone
        [Default: admin]
- region_name
        Name of the region
        [Default: None]
= router_name
        Name of the router to which the subnet's interface should be attached.
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
= subnet_name
        Name of the subnet to whose interface should be attached to the router.
        [Default: None]
- tenant_name
        Name of the tenant whose subnet has to be attached.
        [Default: None]
Requirements:  python >= 2.6, python-neutronclient or python-quantumclient, python-keystoneclient

EXAMPLES:
- name: "Attach tenant1's subnet to the external router"
  quantum_router_interface:
    state: present
    login_username: admin
    login_password: admin
    login_tenant_name: admin
    tenant_name: tenant1
    router_name: external_route
    subnet_name: t1subnet


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> QUANTUM_SUBNET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/openstack/_quantum_subnet.py)

  Add/remove subnet from a network

DEPRECATED: 
Deprecated in 2.0. Use M(os_subnet) instead.

Options (= is mandatory):

- allocation_pool_end
        From the subnet pool the last IP that should be assigned to the virtual machines
        [Default: None]
- allocation_pool_start
        From the subnet pool the starting address from which the IP should be allocated
        [Default: None]
- auth_url
        The keystone URL for authentication
        [Default: http://127.0.0.1:35357/v2.0/]
= cidr
        The CIDR representation of the subnet that should be assigned to the subnet
        [Default: None]
- dns_nameservers
        DNS nameservers for this subnet, comma-separated
        [Default: None]
- enable_dhcp
        Whether DHCP should be enabled for this subnet.
        [Default: True]
- gateway_ip
        The ip that would be assigned to the gateway for this subnet
        [Default: None]
- ip_version
        The IP version of the subnet 4 or 6
        [Default: 4]
= login_password
        Password of login user
        [Default: True]
= login_tenant_name
        The tenant name of the login user
        [Default: True]
= login_username
        login username to authenticate to keystone
        [Default: admin]
= name
        The name of the subnet that should be created
        [Default: None]
= network_name
        Name of the network to which the subnet should be attached
        [Default: None]
- region_name
        Name of the region
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_name
        The name of the tenant for whom the subnet should be created
        [Default: None]
Requirements:  python >= 2.6, python-neutronclient or python-quantumclient, python-keystoneclient

EXAMPLES:
- name: Create a subnet for a tenant with the specified subnet
  quantum_subnet:
    state: present
    login_username: admin
    login_password: admin
    login_tenant_name: admin
    tenant_name: tenant1
    network_name: network1
    name: net1subnet
    cidr: 192.168.0.0/24


MAINTAINERS: Benno Joy (@bennojoy)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> RABBITMQ_BINDING    (/usr/lib/python2.7/site-packages/ansible/modules/messaging/rabbitmq_binding.py)

  This module uses rabbitMQ Rest API to create/delete bindings

Options (= is mandatory):

- arguments
        extra arguments for exchange. If defined this argument is a key/value dictionary
        [Default: {}]
= destination
        destination exchange or queue for the binding

= destination_type
        Either queue or exchange
        (Choices: queue, exchange)
- login_host
        rabbitMQ host for connection
        [Default: localhost]
- login_password
        rabbitMQ password for connection
        [Default: False]
- login_port
        rabbitMQ management api port
        [Default: 15672]
- login_user
        rabbitMQ user for connection
        [Default: guest]
= name
        source exchange to create binding on

- routing_key
        routing key for the binding
        default is
        [Default: #]
- state
        Whether the exchange should be present or absent
        Only present implemented atm
        (Choices: present, absent)[Default: present]
- vhost
        rabbitMQ virtual host
        default vhost is /
        [Default: /]
Requirements:  requests >= 1.0.0

EXAMPLES:
# Bind myQueue to directExchange with routing key info
- rabbitmq_binding:
    name: directExchange
    destination: myQueue
    type: queue
    routing_key: info

# Bind directExchange to topicExchange with routing key *.info
- rabbitmq_binding:
    name: topicExchange
    destination: topicExchange
    type: exchange
    routing_key: '*.info'


MAINTAINERS: Manuel Sousa (@manuel-sousa)

METADATA:
	Status: ['preview']
	Supported_by: community
> RABBITMQ_EXCHANGE    (/usr/lib/python2.7/site-packages/ansible/modules/messaging/rabbitmq_exchange.py)

  This module uses rabbitMQ Rest API to create/delete exchanges

Options (= is mandatory):

- arguments
        extra arguments for exchange. If defined this argument is a key/value dictionary
        [Default: {}]
- auto_delete
        if the exchange should delete itself after all queues/exchanges unbound from it
        (Choices: yes, no)[Default: False]
- durable
        whether exchange is durable or not
        (Choices: yes, no)[Default: True]
- exchange_type
        type for the exchange
        (Choices: fanout, direct, headers, topic)[Default: direct]
- internal
        exchange is available only for other exchanges
        (Choices: yes, no)[Default: False]
- login_host
        rabbitMQ host for connection
        [Default: localhost]
- login_password
        rabbitMQ password for connection
        [Default: False]
- login_port
        rabbitMQ management api port
        [Default: 15672]
- login_user
        rabbitMQ user for connection
        [Default: guest]
= name
        Name of the exchange to create

- state
        Whether the exchange should be present or absent
        Only present implemented atm
        (Choices: present, absent)[Default: present]
- vhost
        rabbitMQ virtual host
        [Default: /]
Requirements:  requests >= 1.0.0

EXAMPLES:
# Create direct exchange
- rabbitmq_exchange:
    name: directExchange

# Create topic exchange on vhost
- rabbitmq_exchange:
    name: topicExchange
    type: topic
    vhost: myVhost


MAINTAINERS: Manuel Sousa (@manuel-sousa)

METADATA:
	Status: ['preview']
	Supported_by: community
> RABBITMQ_PARAMETER    (/usr/lib/python2.7/site-packages/ansible/modules/messaging/rabbitmq_parameter.py)

  Manage dynamic, cluster-wide parameters for RabbitMQ

Options (= is mandatory):

= component
        Name of the component of which the parameter is being set
        [Default: None]
= name
        Name of the parameter being set
        [Default: None]
- node
        erlang node name of the rabbit we wish to configure
        [Default: rabbit]
- state
        Specify if user is to be added or removed
        (Choices: present, absent)[Default: present]
- value
        Value of the parameter, as a JSON term
        [Default: None]
- vhost
        vhost to apply access privileges.
        [Default: /]
EXAMPLES:
# Set the federation parameter 'local_username' to a value of 'guest' (in quotes)
- rabbitmq_parameter:
    component: federation
    name: local-username
    value: '"guest"'
    state: present


MAINTAINERS: "Chris Hoffman (@chrishoffman)"

METADATA:
	Status: ['preview']
	Supported_by: community
> RABBITMQ_PLUGIN    (/usr/lib/python2.7/site-packages/ansible/modules/messaging/rabbitmq_plugin.py)

  Enables or disables RabbitMQ plugins

Options (= is mandatory):

= names
        Comma-separated list of plugin names
        [Default: None]
- new_only
        Only enable missing plugins
        Does not disable plugins that are not in the names list
        (Choices: yes, no)[Default: no]
- prefix
        Specify a custom install prefix to a Rabbit
        [Default: None]
- state
        Specify if plugins are to be enabled or disabled
        (Choices: enabled, disabled)[Default: enabled]
EXAMPLES:
# Enables the rabbitmq_management plugin
- rabbitmq_plugin:
    names: rabbitmq_management
    state: enabled


MAINTAINERS: "Chris Hoffman (@chrishoffman)"

METADATA:
	Status: ['preview']
	Supported_by: community
> RABBITMQ_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/messaging/rabbitmq_policy.py)

  Manage the state of a virtual host in RabbitMQ.

Options (= is mandatory):

- apply_to
        What the policy applies to. Requires RabbitMQ 3.2.0 or later.
        (Choices: all, exchanges, queues)[Default: all]
= name
        The name of the policy to manage.
        [Default: None]
- node
        Erlang node name of the rabbit we wish to configure.
        [Default: rabbit]
= pattern
        A regex of queues to apply the policy to.
        [Default: None]
- priority
        The priority of the policy.
        [Default: 0]
- state
        The state of the policy.
        (Choices: present, absent)[Default: present]
= tags
        A dict or string describing the policy.
        [Default: None]
- vhost
        The name of the vhost to apply to.
        [Default: /]
EXAMPLES:
- name: ensure the default vhost contains the HA policy via a dict
  rabbitmq_policy:
    name: HA
    pattern: .*
  args:
    tags:
      ha-mode: all

- name: ensure the default vhost contains the HA policy
  rabbitmq_policy:
    name: HA
    pattern: .*
    tags:
      ha-mode: all


MAINTAINERS: John Dewey (@retr0h)

METADATA:
	Status: ['preview']
	Supported_by: community
> RABBITMQ_QUEUE    (/usr/lib/python2.7/site-packages/ansible/modules/messaging/rabbitmq_queue.py)

  This module uses rabbitMQ Rest API to create/delete queues

Options (= is mandatory):

- arguments
        extra arguments for queue. If defined this argument is a key/value dictionary
        [Default: {}]
- auto_delete
        if the queue should delete itself after all queues/queues unbound from it
        (Choices: yes, no)[Default: False]
- auto_expires
        How long a queue can be unused before it is automatically deleted (milliseconds)
        [Default: forever]
- dead_letter_exchange
        Optional name of an exchange to which messages will be republished if they
        are rejected or expire
        [Default: None]
- dead_letter_routing_key
        Optional replacement routing key to use when a message is dead-lettered.
        Original routing key will be used if unset
        [Default: None]
- durable
        whether queue is durable or not
        (Choices: yes, no)[Default: True]
- login_host
        rabbitMQ host for connection
        [Default: localhost]
- login_password
        rabbitMQ password for connection
        [Default: False]
- login_port
        rabbitMQ management api port
        [Default: 15672]
- login_user
        rabbitMQ user for connection
        [Default: guest]
- max_length
        How many messages can the queue contain before it starts rejecting
        [Default: no limit]
- message_ttl
        How long a message can live in queue before it is discarded (milliseconds)
        [Default: forever]
= name
        Name of the queue to create

- state
        Whether the queue should be present or absent
        Only present implemented atm
        (Choices: present, absent)[Default: present]
- vhost
        rabbitMQ virtual host
        [Default: /]
Requirements:  requests >= 1.0.0

EXAMPLES:
# Create a queue
- rabbitmq_queue:
    name: myQueue

# Create a queue on remote host
- rabbitmq_queue:
    name: myRemoteQueue
    login_user: user
    login_password: secret
    login_host: remote.example.org


MAINTAINERS: Manuel Sousa (@manuel-sousa)

METADATA:
	Status: ['preview']
	Supported_by: community
> RABBITMQ_USER    (/usr/lib/python2.7/site-packages/ansible/modules/messaging/rabbitmq_user.py)

  Add or remove users to RabbitMQ and assign permissions

Options (= is mandatory):

- configure_priv
        Regular expression to restrict configure actions on a resource for the specified vhost.
        By default all actions are restricted.
        This option will be ignored when permissions option is used.
        [Default: ^$]
- force
        Deletes and recreates the user.
        (Choices: yes, no)[Default: no]
- node
        erlang node name of the rabbit we wish to configure
        [Default: rabbit]
- password
        Password of user to add.
        To change the password of an existing user, you must also specify `force=yes'.
        [Default: None]
- permissions
        a list of dicts, each dict contains vhost, configure_priv, write_priv, and read_priv, and represents a permission
        rule for that vhost.
        This option should be preferable when you care about all permissions of the user.
        You should use vhost, configure_priv, write_priv, and read_priv options instead if you care about permissions for
        just some vhosts.
        [Default: []]
- read_priv
        Regular expression to restrict configure actions on a resource for the specified vhost.
        By default all actions are restricted.
        This option will be ignored when permissions option is used.
        [Default: ^$]
- state
        Specify if user is to be added or removed
        (Choices: present, absent)[Default: present]
- tags
        User tags specified as comma delimited
        [Default: None]
= user
        Name of user to add
        [Default: None]
- vhost
        vhost to apply access privileges.
        This option will be ignored when permissions option is used.
        [Default: /]
- write_priv
        Regular expression to restrict configure actions on a resource for the specified vhost.
        By default all actions are restricted.
        This option will be ignored when permissions option is used.
        [Default: ^$]
EXAMPLES:
# Add user to server and assign full access control on / vhost.
# The user might have permission rules for other vhost but you don't care.
- rabbitmq_user:
    user: joe
    password: changeme
    vhost: /
    configure_priv: .*
    read_priv: .*
    write_priv: .*
    state: present

# Add user to server and assign full access control on / vhost.
# The user doesn't have permission rules for other vhosts
- rabbitmq_user:
    user: joe
    password: changeme
    permissions:
      - vhost: /
        configure_priv: .*
        read_priv: .*
        write_priv: .*
    state: present


MAINTAINERS: "Chris Hoffman (@chrishoffman)"

METADATA:
	Status: ['preview']
	Supported_by: community
> RABBITMQ_VHOST    (/usr/lib/python2.7/site-packages/ansible/modules/messaging/rabbitmq_vhost.py)

  Manage the state of a virtual host in RabbitMQ

Options (= is mandatory):

= name
        The name of the vhost to manage
        [Default: None]
- node
        erlang node name of the rabbit we wish to configure
        [Default: rabbit]
- state
        The state of vhost
        (Choices: present, absent)[Default: present]
- tracing
        Enable/disable tracing for a vhost
        (Choices: yes, no)[Default: no]
EXAMPLES:
# Ensure that the vhost /test exists.
- rabbitmq_vhost:
    name: /test
    state: present


MAINTAINERS: "Chris Hoffman (@choffman)"

METADATA:
	Status: ['preview']
	Supported_by: community
> RAW    (/usr/lib/python2.7/site-packages/ansible/modules/commands/raw.py)

  Executes a low-down and dirty SSH command, not going through the module subsystem. This is useful and should only be
  done in two cases. The first case is installing `python-simplejson' on older (Python 2.4 and before) hosts that need it
  as a dependency to run modules, since nearly all core modules require it. Another is speaking to any devices such as
  routers that do not have any Python installed. In any other case, using the [shell] or [command] module is much more
  appropriate. Arguments given to `raw' are run directly through the configured remote shell. Standard output, error
  output and return code are returned when available. There is no change handler support for this module. This module
  does not require python on the remote system, much like the [script] module.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- executable
        change the shell used to execute the command. Should be an absolute path to the executable.
        when using privilege escalation (`become'), a default shell will be assigned if one is not provided as privilege
        escalation requires a shell.
        [Default: (null)]
= free_form
        the raw module takes a free form command to run. There is no parameter actually named 'free form'; see the
        examples!

Notes:
  * If using raw from a playbook, you may need to disable fact gathering using `gather_facts: no' if you're using
        `raw' to bootstrap python onto the machine.
  * If you want to execute a command securely and predictably, it may be better to use the [command] or [shell]
        modules instead.
  * the `environment' keyword does not work with raw normally, it requires a shell which means it only works if
        `executable' is set or using the module with privilege escalation (`become').
EXAMPLES:
- name: Bootstrap a legacy python 2.4 host
  raw: yum -y install python-simplejson

- name: Bootstrap a host without python2 installed
  raw: dnf install -y python2 python2-dnf libselinux-python

- name: Run a command that uses non-posix shell-isms (in this example /bin/sh doesn't handle redirection and wildcards together but bash does)
  raw: cat < /tmp/*txt
  args:
    executable: /bin/bash

- name: safely use templated variables. Always use quote filter to avoid injection issues.
  raw: "{{package_mgr|quote}} {{pkg_flags|quote}} install {{python_simplejson|quote}}"


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> RAX    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax.py)

  creates / deletes a Rackspace Public Cloud instance and optionally waits for it to be 'running'.

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- auto_increment
        Whether or not to increment a single number with the name of the created servers. Only applicable when used with
        the `group' attribute or meta key.
        (Choices: yes, no)[Default: True]
- boot_from_volume
        Whether or not to boot the instance from a Cloud Block Storage volume. If `yes' and `image' is specified a new
        volume will be created at boot time. `boot_volume_size' is required with `image' to create a new volume at boot
        time.
        (Choices: yes, no)[Default: no]
- boot_volume
        Cloud Block Storage ID or Name to use as the boot volume of the instance
        [Default: (null)]
- boot_volume_size
        Size of the volume to create in Gigabytes. This is only required with `image' and `boot_from_volume'.
        [Default: 100]
- boot_volume_terminate
        Whether the `boot_volume' or newly created volume from `image' will be terminated when the server is terminated
        [Default: False]
- config_drive
        Attach read-only configuration drive to server as label config-2
        (Choices: yes, no)[Default: False]
- count
        number of instances to launch
        [Default: 1]
- count_offset
        number count to start at
        [Default: 1]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- disk_config
        Disk partitioning strategy
        (Choices: auto, manual)[Default: auto]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- exact_count
        Explicitly ensure an exact count of instances, used with state=active/present. If specified as `yes' and `count'
        is less than the servers matched, servers will be deleted to match the count. If the number of matched servers is
        fewer than specified in `count' additional servers will be added.
        (Choices: yes, no)[Default: False]
- extra_client_args
        A hash of key/value pairs to be used when creating the cloudservers client. This is considered an advanced
        option, use it wisely and with caution.
        [Default: (null)]
- extra_create_args
        A hash of key/value pairs to be used when creating a new server. This is considered an advanced option, use it
        wisely and with caution.
        [Default: (null)]
- files
        Files to insert into the instance. remotefilename:localcontent
        [Default: None]
- flavor
        flavor to use for the instance
        [Default: None]
- group
        host group to assign to server, is also used for idempotent operations to ensure a specific number of instances
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
- image
        image to use for the instance. Can be an `id', `human_id' or `name'. With `boot_from_volume', a Cloud Block
        Storage volume will be created with this image
        [Default: None]
- instance_ids
        list of instance ids, currently only used when state='absent' to remove instances
        [Default: (null)]
- key_name
        key pair to use on the instance
        [Default: None]
- meta
        A hash of metadata to associate with the instance
        [Default: None]
- name
        Name to give the instance
        [Default: None]
- networks
        The network to attach to the instances. If specified, you must include ALL networks including the public and
        private interfaces. Can be `id' or `label'.
        [Default: [u'public', u'private']]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- user_data
        Data to be uploaded to the servers config drive. This option implies `config_drive'. Can be a file path or a
        string
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
- wait
        wait for the instance to be in state 'running' before returning
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
Notes:
  * `exact_count' can be "destructive" if the number of running servers in the `group' is larger than that
        specified in `count'. In such a case, the `state' is effectively set to `absent' and the extra servers are
        deleted. In the case of deletion, the returned data structure will have `action' set to `delete', and the
        oldest servers in the group will be deleted.
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Build a Cloud Server
  gather_facts: False
  tasks:
    - name: Server build request
      local_action:
        module: rax
        credentials: ~/.raxpub
        name: rax-test1
        flavor: 5
        image: b11d9567-e412-4255-96b9-bd63ab23bcfe
        key_name: my_rackspace_key
        files:
          /root/test.txt: /home/localuser/test.txt
        wait: yes
        state: present
        networks:
          - private
          - public
      register: rax

- name: Build an exact count of cloud servers with incremented names
  hosts: local
  gather_facts: False
  tasks:
    - name: Server build requests
      local_action:
        module: rax
        credentials: ~/.raxpub
        name: test%03d.example.org
        flavor: performance1-1
        image: ubuntu-1204-lts-precise-pangolin
        state: present
        count: 10
        count_offset: 10
        exact_count: yes
        group: test
        wait: yes
      register: rax


MAINTAINERS: Jesse Keating (@j2sol), Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_CBS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_cbs.py)

  Manipulate Rackspace Cloud Block Storage Volumes

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- description
        Description to give the volume being created
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
- image
        image to use for bootable volumes. Can be an `id', `human_id' or `name'. This option requires `pyrax>=1.9.3'
        [Default: None]
- meta
        A hash of metadata to associate with the volume
        [Default: None]
= name
        Name to give the volume being created
        [Default: None]
- region
        Region to create an instance in.
        [Default: DFW]
= size
        Size of the volume to create in Gigabytes
        [Default: 100]
- snapshot_id
        The id of the snapshot to create the volume from
        [Default: None]
= state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
= volume_type
        Type of the volume being created
        (Choices: SATA, SSD)[Default: SATA]
- wait
        wait for the volume to be in state 'available' before returning
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Build a Block Storage Volume
  gather_facts: False
  hosts: local
  connection: local
  tasks:
    - name: Storage volume create request
      local_action:
        module: rax_cbs
        credentials: ~/.raxpub
        name: my-volume
        description: My Volume
        volume_type: SSD
        size: 150
        region: DFW
        wait: yes
        state: present
        meta:
          app: my-cool-app
      register: my_volume


MAINTAINERS: Christopher H. Laco (@claco), Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_CBS_ATTACHMENTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_cbs_attachments.py)

  Manipulate Rackspace Cloud Block Storage Volume Attachments

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
= device
        The device path to attach the volume to, e.g. /dev/xvde
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
- region
        Region to create an instance in.
        [Default: DFW]
= server
        Name or id of the server to attach/detach
        [Default: None]
= state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
= volume
        Name or id of the volume to attach/detach
        [Default: None]
- wait
        wait for the volume to be in 'in-use'/'available' state before returning
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Attach a Block Storage Volume
  gather_facts: False
  hosts: local
  connection: local
  tasks:
    - name: Storage volume attach request
      local_action:
        module: rax_cbs_attachments
        credentials: ~/.raxpub
        volume: my-volume
        server: my-server
        device: /dev/xvdd
        region: DFW
        wait: yes
        state: present
      register: my_volume


MAINTAINERS: Christopher H. Laco (@claco), Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_CDB    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_cdb.py)

  creates / deletes or resize a Rackspace Cloud Databases instance and optionally waits for it to be 'running'. The name
  option needs to be unique since it's used to identify the instance.

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- cdb_type
        type of instance (i.e. MySQL, MariaDB, Percona)
        [Default: MySQL]
- cdb_version
        version of database (MySQL supports 5.1 and 5.6, MariaDB supports 10, Percona supports 5.6)
        (Choices: 5.1, 5.6, 10)[Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- flavor
        flavor to use for the instance 1 to 6 (i.e. 512MB to 16GB)
        [Default: 1]
- name
        Name of the databases server instance
        [Default: None]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
- volume
        Volume size of the database 1-150GB
        [Default: 2]
- wait
        wait for the instance to be in state 'running' before returning
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Build a Cloud Databases
  gather_facts: False
  tasks:
    - name: Server build request
      local_action:
        module: rax_cdb
        credentials: ~/.raxpub
        region: IAD
        name: db-server1
        flavor: 1
        volume: 2
        cdb_type: MySQL
        cdb_version: 5.6
        wait: yes
        state: present
      register: rax_db_server


MAINTAINERS: Simon JAILLET (@jails)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_CDB_DATABASE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_cdb_database.py)

  create / delete a database in the Cloud Databases.

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- cdb_id
        The databases server UUID
        [Default: None]
- character_set
        Set of symbols and encodings
        [Default: utf8]
- collate
        Set of rules for comparing characters in a character set
        [Default: utf8_general_ci]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- name
        Name to give to the database
        [Default: None]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Build a database in Cloud Databases
  tasks:
    - name: Database build request
      local_action:
        module: rax_cdb_database
        credentials: ~/.raxpub
        region: IAD
        cdb_id: 323e7ce0-9cb0-11e3-a5e2-0800200c9a66
        name: db1
        state: present
      register: rax_db_database


MAINTAINERS: Simon JAILLET (@jails)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_CDB_USER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_cdb_user.py)

  create / delete a database in the Cloud Databases.

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- cdb_id
        The databases server UUID
        [Default: None]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- databases
        Name of the databases that the user can access
        [Default: []]
- db_password
        Database user password
        [Default: None]
- db_username
        Name of the database user
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- host
        Specifies the host from which a user is allowed to connect to the database. Possible values are a string
        containing an IPv4 address or "%" to allow connecting from any host
        [Default: %]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Build a user in Cloud Databases
  tasks:
    - name: User build request
      local_action:
        module: rax_cdb_user
        credentials: ~/.raxpub
        region: IAD
        cdb_id: 323e7ce0-9cb0-11e3-a5e2-0800200c9a66
        db_username: user1
        db_password: user1
        databases: ['db1']
        state: present
      register: rax_db_user


MAINTAINERS: Simon JAILLET (@jails)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_CLB    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_clb.py)

  creates / deletes a Rackspace Public Cloud load balancer.

Options (= is mandatory):

- algorithm
        algorithm for the balancer being created
        (Choices: RANDOM, LEAST_CONNECTIONS, ROUND_ROBIN, WEIGHTED_LEAST_CONNECTIONS, WEIGHTED_ROUND_ROBIN)[Default:
        LEAST_CONNECTIONS]
- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- meta
        A hash of metadata to associate with the instance
        [Default: None]
- name
        Name to give the load balancer
        [Default: None]
- port
        Port for the balancer being created
        [Default: 80]
- protocol
        Protocol for the balancer being created
        (Choices: DNS_TCP, DNS_UDP, FTP, HTTP, HTTPS, IMAPS, IMAPv4, LDAP, LDAPS, MYSQL, POP3, POP3S, SMTP, TCP,
        TCP_CLIENT_FIRST, UDP, UDP_STREAM, SFTP)[Default: HTTP]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- timeout
        timeout for communication between the balancer and the node
        [Default: 30]
- type
        type of interface for the balancer being created
        (Choices: PUBLIC, SERVICENET)[Default: PUBLIC]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
- vip_id
        Virtual IP ID to use when creating the load balancer for purposes of sharing an IP with another load balancer of
        another protocol
        [Default: (null)]
- wait
        wait for the balancer to be in state 'running' before returning
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Build a Load Balancer
  gather_facts: False
  hosts: local
  connection: local
  tasks:
    - name: Load Balancer create request
      local_action:
        module: rax_clb
        credentials: ~/.raxpub
        name: my-lb
        port: 8080
        protocol: HTTP
        type: SERVICENET
        timeout: 30
        region: DFW
        wait: yes
        state: present
        meta:
          app: my-cool-app
      register: my_lb


MAINTAINERS: Christopher H. Laco (@claco), Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_CLB_NODES    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_clb_nodes.py)

  Adds, modifies and removes nodes from a Rackspace Cloud Load Balancer

Options (= is mandatory):

- address
        IP address or domain name of the node
        [Default: (null)]
- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- condition
        Condition for the node, which determines its role within the load balancer
        (Choices: enabled, disabled, draining)[Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
= load_balancer_id
        Load balancer id

- node_id
        Node id
        [Default: (null)]
- port
        Port number of the load balanced service on the node
        [Default: (null)]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the node
        (Choices: present, absent)[Default: present]
- type
        Type of node
        (Choices: primary, secondary)[Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
- wait
        Wait for the load balancer to become active before returning
        (Choices: yes, no)[Default: no]
- wait_timeout
        How long to wait before giving up and returning an error
        [Default: 30]
- weight
        Weight of node
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
# Add a new node to the load balancer
- local_action:
    module: rax_clb_nodes
    load_balancer_id: 71
    address: 10.2.2.3
    port: 80
    condition: enabled
    type: primary
    wait: yes
    credentials: /path/to/credentials

# Drain connections from a node
- local_action:
    module: rax_clb_nodes
    load_balancer_id: 71
    node_id: 410
    condition: draining
    wait: yes
    credentials: /path/to/credentials

# Remove a node from the load balancer
- local_action:
    module: rax_clb_nodes
    load_balancer_id: 71
    node_id: 410
    state: absent
    wait: yes
    credentials: /path/to/credentials


MAINTAINERS: Lukasz Kawczynski (@neuroid)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_CLB_SSL    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_clb_ssl.py)

  Set up, reconfigure, or remove SSL termination for an existing load balancer.

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- certificate
        The public SSL certificates as a string in PEM format.
        [Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- enabled
        If set to "false", temporarily disable SSL termination without discarding
        existing credentials.
        [Default: True]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- https_redirect
        If "true", the load balancer will redirect HTTP traffic to HTTPS.
        Requires "secure_traffic_only" to be true. Incurs an implicit wait if SSL
        termination is also applied or removed.
        [Default: (null)]
- intermediate_certificate
        One or more intermediate certificate authorities as a string in PEM
        format, concatenated into a single string.
        [Default: (null)]
= loadbalancer
        Name or ID of the load balancer on which to manage SSL termination.

- private_key
        The private SSL key as a string in PEM format.
        [Default: (null)]
- region
        Region to create an instance in.
        [Default: DFW]
- secure_port
        The port to listen for secure traffic.
        [Default: 443]
- secure_traffic_only
        If "true", the load balancer will *only* accept secure traffic.
        [Default: False]
- state
        If set to "present", SSL termination will be added to this load balancer.
        If "absent", SSL termination will be removed instead.
        (Choices: present, absent)[Default: present]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
- wait
        Wait for the balancer to be in state "running" before turning.
        [Default: False]
- wait_timeout
        How long before "wait" gives up, in seconds.
        [Default: 300]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Enable SSL termination on a load balancer
  rax_clb_ssl:
    loadbalancer: the_loadbalancer
    state: present
    private_key: "{{ lookup('file', 'credentials/server.key' ) }}"
    certificate: "{{ lookup('file', 'credentials/server.crt' ) }}"
    intermediate_certificate: "{{ lookup('file', 'credentials/trust-chain.crt') }}"
    secure_traffic_only: true
    wait: true

- name: Disable SSL termination
  rax_clb_ssl:
    loadbalancer: "{{ registered_lb.balancer.id }}"
    state: absent
    wait: true


MAINTAINERS: Ash Wilson

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_DNS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_dns.py)

  Manage domains on Rackspace Cloud DNS

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- comment
        Brief description of the domain. Maximum length of 160 characters
        [Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- email
        Email address of the domain administrator
        [Default: (null)]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- name
        Domain name to create
        [Default: (null)]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- ttl
        Time to live of domain in seconds
        [Default: 3600]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * It is recommended that plays utilizing this module be run with `serial: 1' to avoid exceeding the API request
        limit imposed by the Rackspace CloudDNS API
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Create domain
  hosts: all
  gather_facts: False
  tasks:
    - name: Domain create request
      local_action:
        module: rax_dns
        credentials: ~/.raxpub
        name: example.org
        email: admin@example.org
      register: rax_dns


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_DNS_RECORD    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_dns_record.py)

  Manage DNS records on Rackspace Cloud DNS

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- comment
        Brief description of the domain. Maximum length of 160 characters
        [Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
= data
        IP address for A/AAAA record, FQDN for CNAME/MX/NS, or text data for SRV/TXT

- domain
        Domain name to create the record in. This is an invalid option when type=PTR
        [Default: (null)]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- loadbalancer
        Load Balancer ID to create a PTR record for. Only used with type=PTR
        [Default: (null)]
= name
        FQDN record name to create

- overwrite
        Add new records if data doesn't match, instead of updating existing record with matching name. If there are
        already multiple records with matching name and overwrite=true, this module will fail.
        [Default: True]
- priority
        Required for MX and SRV records, but forbidden for other record types. If specified, must be an integer from 0 to
        65535.
        [Default: (null)]
- region
        Region to create an instance in.
        [Default: DFW]
- server
        Server ID to create a PTR record for. Only used with type=PTR
        [Default: (null)]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- ttl
        Time to live of record in seconds
        [Default: 3600]
= type
        DNS record type
        (Choices: A, AAAA, CNAME, MX, NS, SRV, TXT, PTR)
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * It is recommended that plays utilizing this module be run with `serial: 1' to avoid exceeding the API request
        limit imposed by the Rackspace CloudDNS API
  * To manipulate a `PTR' record either `loadbalancer' or `server' must be supplied
  * As of version 1.7, the `type' field is required and no longer defaults to an `A' record.
  * `PTR' record support was added in version 1.7
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Create DNS Records
  hosts: all
  gather_facts: False
  tasks:
    - name: Create A record
      local_action:
        module: rax_dns_record
        credentials: ~/.raxpub
        domain: example.org
        name: www.example.org
        data: "{{ rax_accessipv4 }}"
        type: A
      register: a_record

    - name: Create PTR record
      local_action:
        module: rax_dns_record
        credentials: ~/.raxpub
        server: "{{ rax_id }}"
        name: "{{ inventory_hostname }}"
        region: DFW
      register: ptr_record


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_facts.py)

  Gather facts for Rackspace Cloud Servers.

Options (= is mandatory):

- address
        Server IP address to retrieve facts for, will match any IP assigned to the server
        [Default: (null)]
- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- id
        Server ID to retrieve facts for
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
- name
        Server name to retrieve facts for
        [Default: None]
- region
        Region to create an instance in.
        [Default: DFW]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Gather info about servers
  hosts: all
  gather_facts: False
  tasks:
    - name: Get facts about servers
      local_action:
        module: rax_facts
        credentials: ~/.raxpub
        name: "{{ inventory_hostname }}"
        region: DFW
    - name: Map some facts
      set_fact:
        ansible_ssh_host: "{{ rax_accessipv4 }}"


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_FILES    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_files.py)

  Manipulate Rackspace Cloud Files Containers

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- clear_meta
        Optionally clear existing metadata when applying metadata to existing containers. Selecting this option is only
        appropriate when setting type=meta
        (Choices: yes, no)[Default: no]
= container
        The container to use for container or metadata operations.

- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- meta
        A hash of items to set as metadata values on a container
        [Default: (null)]
- private
        Used to set a container as private, removing it from the CDN.  *Warning!* Private containers, if previously made
        public, can have live objects available until the TTL on cached objects expires
        [Default: (null)]
- public
        Used to set a container as public, available via the Cloud Files CDN
        [Default: (null)]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- ttl
        In seconds, set a container-wide TTL for all objects cached on CDN edge nodes. Setting a TTL is only appropriate
        for containers that are public
        [Default: (null)]
- type
        Type of object to do work on, i.e. metadata object or a container object
        (Choices: file, meta)[Default: file]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
- web_error
        Sets an object to be presented as the HTTP error page when accessed by the CDN URL
        [Default: (null)]
- web_index
        Sets an object to be presented as the HTTP index page when accessed by the CDN URL
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: "Test Cloud Files Containers"
  hosts: local
  gather_facts: no
  tasks:
    - name: "List all containers"
      rax_files:
        state: list

    - name: "Create container called 'mycontainer'"
      rax_files:
        container: mycontainer

    - name: "Create container 'mycontainer2' with metadata"
      rax_files:
        container: mycontainer2
        meta:
          key: value
          file_for: someuser@example.com

    - name: "Set a container's web index page"
      rax_files:
        container: mycontainer
        web_index: index.html

    - name: "Set a container's web error page"
      rax_files:
        container: mycontainer
        web_error: error.html

    - name: "Make container public"
      rax_files:
        container: mycontainer
        public: yes

    - name: "Make container public with a 24 hour TTL"
      rax_files:
        container: mycontainer
        public: yes
        ttl: 86400

    - name: "Make container private"
      rax_files:
        container: mycontainer
        private: yes

- name: "Test Cloud Files Containers Metadata Storage"
  hosts: local
  gather_facts: no
  tasks:
    - name: "Get mycontainer2 metadata"
      rax_files:
        container: mycontainer2
        type: meta

    - name: "Set mycontainer2 metadata"
      rax_files:
        container: mycontainer2
        type: meta
        meta:
          uploaded_by: someuser@example.com

    - name: "Remove mycontainer2 metadata"
      rax_files:
        container: "mycontainer2"
        type: meta
        state: absent
        meta:
          key: ""
          file_for: ""


MAINTAINERS: Paul Durivage (@angstwad)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_FILES_OBJECTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_files_objects.py)

  Upload, download, and delete objects in Rackspace Cloud Files

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- clear_meta
        Optionally clear existing metadata when applying metadata to existing objects. Selecting this option is only
        appropriate when setting type=meta
        (Choices: yes, no)[Default: no]
= container
        The container to use for file object operations.
        [Default: None]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- dest
        The destination of a "get" operation; i.e. a local directory, "/home/user/myfolder". Used to specify the
        destination of an operation on a remote object; i.e. a file name, "file1", or a comma-separated list of remote
        objects, "file1,file2,file17"
        [Default: (null)]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- expires
        Used to set an expiration on a file or folder uploaded to Cloud Files. Requires an integer, specifying expiration
        in seconds
        [Default: None]
- meta
        A hash of items to set as metadata values on an uploaded file or folder
        [Default: None]
- method
        The method of operation to be performed.  For example, put to upload files to Cloud Files, get to download files
        from Cloud Files or delete to delete remote objects in Cloud Files
        (Choices: get, put, delete)[Default: get]
- region
        Region to create an instance in.
        [Default: DFW]
- src
        Source from which to upload files.  Used to specify a remote object as a source for an operation, i.e. a file
        name, "file1", or a comma-separated list of remote objects, "file1,file2,file17".  src and dest are mutually
        exclusive on remote-only object operations
        [Default: None]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- structure
        Used to specify whether to maintain nested directory structure when downloading objects from Cloud Files.
        Setting to false downloads the contents of a container to a single, flat directory
        (Choices: True, no)[Default: yes]
- type
        Type of object to do work on
        Metadata object or a file object
        (Choices: file, meta)[Default: file]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: "Test Cloud Files Objects"
  hosts: local
  gather_facts: False
  tasks:
    - name: "Get objects from test container"
      rax_files_objects:
        container: testcont
        dest: ~/Downloads/testcont

    - name: "Get single object from test container"
      rax_files_objects:
        container: testcont
        src: file1
        dest: ~/Downloads/testcont

    - name: "Get several objects from test container"
      rax_files_objects:
        container: testcont
        src: file1,file2,file3
        dest: ~/Downloads/testcont

    - name: "Delete one object in test container"
      rax_files_objects:
        container: testcont
        method: delete
        dest: file1

    - name: "Delete several objects in test container"
      rax_files_objects:
        container: testcont
        method: delete
        dest: file2,file3,file4

    - name: "Delete all objects in test container"
      rax_files_objects:
        container: testcont
        method: delete

    - name: "Upload all files to test container"
      rax_files_objects:
        container: testcont
        method: put
        src: ~/Downloads/onehundred

    - name: "Upload one file to test container"
      rax_files_objects:
        container: testcont
        method: put
        src: ~/Downloads/testcont/file1

    - name: "Upload one file to test container with metadata"
      rax_files_objects:
        container: testcont
        src: ~/Downloads/testcont/file2
        method: put
        meta:
          testkey: testdata
          who_uploaded_this: someuser@example.com

    - name: "Upload one file to test container with TTL of 60 seconds"
      rax_files_objects:
        container: testcont
        method: put
        src: ~/Downloads/testcont/file3
        expires: 60

    - name: "Attempt to get remote object that does not exist"
      rax_files_objects:
        container: testcont
        method: get
        src: FileThatDoesNotExist.jpg
        dest: ~/Downloads/testcont
      ignore_errors: yes

    - name: "Attempt to delete remote object that does not exist"
      rax_files_objects:
        container: testcont
        method: delete
        dest: FileThatDoesNotExist.jpg
      ignore_errors: yes

- name: "Test Cloud Files Objects Metadata"
  hosts: local
  gather_facts: false
  tasks:
    - name: "Get metadata on one object"
      rax_files_objects:
        container: testcont
        type: meta
        dest: file2

    - name: "Get metadata on several objects"
      rax_files_objects:
        container: testcont
        type: meta
        src: file2,file1

    - name: "Set metadata on an object"
      rax_files_objects:
        container: testcont
        type: meta
        dest: file17
        method: put
        meta:
          key1: value1
          key2: value2
        clear_meta: true

    - name: "Verify metadata is set"
      rax_files_objects:
        container: testcont
        type: meta
        src: file17

    - name: "Delete metadata"
      rax_files_objects:
        container: testcont
        type: meta
        dest: file17
        method: delete
        meta:
          key1: ''
          key2: ''

    - name: "Get metadata on all objects"
      rax_files_objects:
        container: testcont
        type: meta


MAINTAINERS: Paul Durivage (@angstwad)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_IDENTITY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_identity.py)

  Verifies Rackspace Cloud credentials and returns identity information

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Load Rackspace Cloud Identity
  gather_facts: False
  hosts: local
  connection: local
  tasks:
    - name: Load Identity
      local_action:
        module: rax_identity
        credentials: ~/.raxpub
        region: DFW
      register: rackspace_identity


MAINTAINERS: Christopher H. Laco (@claco), Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_KEYPAIR    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_keypair.py)

  Create a keypair for use with Rackspace Cloud Servers

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
= name
        Name of keypair

- public_key
        Public Key string to upload. Can be a file path or string
        [Default: None]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * Keypairs cannot be manipulated, only created and deleted. To "update" a keypair you must first delete and then
        recreate.
  * The ability to specify a file path for the public key was added in 1.7
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Create a keypair
  hosts: localhost
  gather_facts: False
  tasks:
    - name: keypair request
      local_action:
        module: rax_keypair
        credentials: ~/.raxpub
        name: my_keypair
        region: DFW
      register: keypair
    - name: Create local public key
      local_action:
        module: copy
        content: "{{ keypair.keypair.public_key }}"
        dest: "{{ inventory_dir }}/{{ keypair.keypair.name }}.pub"
    - name: Create local private key
      local_action:
        module: copy
        content: "{{ keypair.keypair.private_key }}"
        dest: "{{ inventory_dir }}/{{ keypair.keypair.name }}"

- name: Create a keypair
  hosts: localhost
  gather_facts: False
  tasks:
    - name: keypair request
      local_action:
        module: rax_keypair
        credentials: ~/.raxpub
        name: my_keypair
        public_key: "{{ lookup('file', 'authorized_keys/id_rsa.pub') }}"
        region: DFW
      register: keypair


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_META    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_meta.py)

  Manipulate metadata for Rackspace Cloud Servers

Options (= is mandatory):

- address
        Server IP address to modify metadata for, will match any IP assigned to the server
        [Default: (null)]
- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- id
        Server ID to modify metadata for
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
- meta
        A hash of metadata to associate with the instance
        [Default: None]
- name
        Server name to modify metadata for
        [Default: None]
- region
        Region to create an instance in.
        [Default: DFW]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Set metadata for a server
  hosts: all
  gather_facts: False
  tasks:
    - name: Set metadata
      local_action:
        module: rax_meta
        credentials: ~/.raxpub
        name: "{{ inventory_hostname }}"
        region: DFW
        meta:
          group: primary_group
          groups:
            - group_two
            - group_three
          app: my_app

    - name: Clear metadata
      local_action:
        module: rax_meta
        credentials: ~/.raxpub
        name: "{{ inventory_hostname }}"
        region: DFW


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_MON_ALARM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_mon_alarm.py)

  Create or delete a Rackspace Cloud Monitoring alarm that associates an existing rax_mon_entity, rax_mon_check, and
  rax_mon_notification_plan with criteria that specify what conditions will trigger which levels of notifications.
  Rackspace monitoring module flow | rax_mon_entity -> rax_mon_check -> rax_mon_notification -> rax_mon_notification_plan
  -> *rax_mon_alarm*

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
= check_id
        ID of the check that should be alerted on. May be acquired by registering the value of a rax_mon_check task.

- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- criteria
        Alarm DSL that describes alerting conditions and their output states. Must be between 1 and 16384 characters
        long. See http://docs.rackspace.com/cm/api/v1.0/cm-devguide/content/alerts-language.html for a reference on the
        alerting language.
        [Default: (null)]
- disabled
        If yes, create this alarm, but leave it in an inactive state. Defaults to no.
        (Choices: yes, no)[Default: (null)]
= entity_id
        ID of the entity this alarm is attached to. May be acquired by registering the value of a rax_mon_entity task.

- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
= label
        Friendly name for this alarm, used to achieve idempotence. Must be a String between 1 and 255 characters long.

- metadata
        Arbitrary key/value pairs to accompany the alarm. Must be a hash of String keys and values between 1 and 255
        characters long.
        [Default: (null)]
= notification_plan_id
        ID of the notification plan to trigger if this alarm fires. May be acquired by registering the value of a
        rax_mon_notification_plan task.

- region
        Region to create an instance in.
        [Default: DFW]
- state
        Ensure that the alarm with this `label' exists or does not exist.
        (Choices: present, absent)[Default: present]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Alarm example
  gather_facts: False
  hosts: local
  connection: local
  tasks:
  - name: Ensure that a specific alarm exists.
    rax_mon_alarm:
      credentials: ~/.rax_pub
      state: present
      label: uhoh
      entity_id: "{{ the_entity['entity']['id'] }}"
      check_id: "{{ the_check['check']['id'] }}"
      notification_plan_id: "{{ defcon1['notification_plan']['id'] }}"
      criteria: >
        if (rate(metric['average']) > 10) {
          return new AlarmStatus(WARNING);
        }
        return new AlarmStatus(OK);
    register: the_alarm


MAINTAINERS: Ash Wilson

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_MON_CHECK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_mon_check.py)

  Create or delete a Rackspace Cloud Monitoring check associated with an existing rax_mon_entity. A check is a specific
  test or measurement that is performed, possibly from different monitoring zones, on the systems you monitor. Rackspace
  monitoring module flow | rax_mon_entity -> *rax_mon_check* -> rax_mon_notification -> rax_mon_notification_plan ->
  rax_mon_alarm

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
= check_type
        The type of check to create. `remote.' checks may be created on any rax_mon_entity. `agent.' checks may only be
        created on rax_mon_entities that have a non-null `agent_id'.
        (Choices: remote.dns, remote.ftp-banner, remote.http, remote.imap-banner, remote.mssql-banner, remote.mysql-
        banner, remote.ping, remote.pop3-banner, remote.postgresql-banner, remote.smtp-banner, remote.smtp, remote.ssh,
        remote.tcp, remote.telnet-banner, agent.filesystem, agent.memory, agent.load_average, agent.cpu, agent.disk,
        agent.network, agent.plugin)
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- details
        Additional details specific to the check type. Must be a hash of strings between 1 and 255 characters long, or an
        array or object containing 0 to 256 items.
        [Default: (null)]
- disabled
        If "yes", ensure the check is created, but don't actually use it yet.
        (Choices: yes, no)[Default: (null)]
= entity_id
        ID of the rax_mon_entity to target with this check.

- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
= label
        Defines a label for this check, between 1 and 64 characters long.

- metadata
        Hash of arbitrary key-value pairs to accompany this check if it fires. Keys and values must be strings between 1
        and 255 characters long.
        [Default: (null)]
- monitoring_zones_poll
        Comma-separated list of the names of the monitoring zones the check should run from. Available monitoring zones
        include mzdfw, mzhkg, mziad, mzlon, mzord and mzsyd. Required for remote.* checks; prohibited for agent.* checks.
        [Default: (null)]
- period
        The number of seconds between each time the check is performed. Must be greater than the minimum period set on
        your account.
        [Default: (null)]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Ensure that a check with this `label' exists or does not exist.
        (Choices: present, absent)[Default: (null)]
- target_alias
        One of `target_alias` and `target_hostname` is required for remote.* checks, but prohibited for agent.* checks.
        Use the corresponding key in the entity's `ip_addresses` hash to resolve an IP address to target.
        [Default: (null)]
- target_hostname
        One of `target_hostname` and `target_alias` is required for remote.* checks, but prohibited for agent.* checks.
        The hostname this check should target. Must be a valid IPv4, IPv6, or FQDN.
        [Default: (null)]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- timeout
        The number of seconds this check will wait when attempting to collect results. Must be less than the period.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Create a monitoring check
  gather_facts: False
  hosts: local
  connection: local
  tasks:
  - name: Associate a check with an existing entity.
    rax_mon_check:
      credentials: ~/.rax_pub
      state: present
      entity_id: "{{ the_entity['entity']['id'] }}"
      label: the_check
      check_type: remote.ping
      monitoring_zones_poll: mziad,mzord,mzdfw
      details:
        count: 10
      meta:
        hurf: durf
    register: the_check


MAINTAINERS: Ash Wilson

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_MON_ENTITY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_mon_entity.py)

  Create or delete a Rackspace Cloud Monitoring entity, which represents a device to monitor. Entities associate checks
  and alarms with a target system and provide a convenient, centralized place to store IP addresses. Rackspace monitoring
  module flow | *rax_mon_entity* -> rax_mon_check -> rax_mon_notification -> rax_mon_notification_plan -> rax_mon_alarm

Options (= is mandatory):

- agent_id
        Rackspace monitoring agent on the target device to which this entity is bound. Necessary to collect `agent.'
        rax_mon_checks against this entity.
        [Default: (null)]
- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
= label
        Defines a name for this entity. Must be a non-empty string between 1 and 255 characters long.

- metadata
        Hash of arbitrary `name', `value' pairs that are passed to associated rax_mon_alarms. Names and values must all
        be between 1 and 255 characters long.
        [Default: (null)]
- named_ip_addresses
        Hash of IP addresses that may be referenced by name by rax_mon_checks added to this entity. Must be a dictionary
        of with keys that are names between 1 and 64 characters long, and values that are valid IPv4 or IPv6 addresses.
        [Default: (null)]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Ensure that an entity with this `name' exists or does not exist.
        (Choices: present, absent)[Default: (null)]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Entity example
  gather_facts: False
  hosts: local
  connection: local
  tasks:
  - name: Ensure an entity exists
    rax_mon_entity:
      credentials: ~/.rax_pub
      state: present
      label: my_entity
      named_ip_addresses:
        web_box: 192.0.2.4
        db_box: 192.0.2.5
      meta:
        hurf: durf
    register: the_entity


MAINTAINERS: Ash Wilson

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_MON_NOTIFICATION    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_mon_notification.py)

  Create or delete a Rackspace Cloud Monitoring notification that specifies a channel that can be used to communicate
  alarms, such as email, webhooks, or PagerDuty. Rackspace monitoring module flow | rax_mon_entity -> rax_mon_check ->
  *rax_mon_notification* -> rax_mon_notification_plan -> rax_mon_alarm

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
= details
        Dictionary of key-value pairs used to initialize the notification. Required keys and meanings vary with
        notification type. See http://docs.rackspace.com/cm/api/v1.0/cm-devguide/content/ service-notification-types-
        crud.html for details.

- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
= label
        Defines a friendly name for this notification. String between 1 and 255 characters long.

= notification_type
        A supported notification type.
        (Choices: webhook, email, pagerduty)
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Ensure that the notification with this `label' exists or does not exist.
        (Choices: present, absent)[Default: (null)]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Monitoring notification example
  gather_facts: False
  hosts: local
  connection: local
  tasks:
  - name: Email me when something goes wrong.
    rax_mon_entity:
      credentials: ~/.rax_pub
      label: omg
      type: email
      details:
        address: me@mailhost.com
    register: the_notification


MAINTAINERS: Ash Wilson

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_MON_NOTIFICATION_PLAN    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_mon_notification_plan.py)

  Create or delete a Rackspace Cloud Monitoring notification plan by associating existing rax_mon_notifications with
  severity levels. Rackspace monitoring module flow | rax_mon_entity -> rax_mon_check -> rax_mon_notification ->
  *rax_mon_notification_plan* -> rax_mon_alarm

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- critical_state
        Notification list to use when the alarm state is CRITICAL. Must be an array of valid rax_mon_notification ids.
        [Default: (null)]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
= label
        Defines a friendly name for this notification plan. String between 1 and 255 characters long.

- ok_state
        Notification list to use when the alarm state is OK. Must be an array of valid rax_mon_notification ids.
        [Default: (null)]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Ensure that the notification plan with this `label' exists or does not exist.
        (Choices: present, absent)[Default: (null)]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
- warning_state
        Notification list to use when the alarm state is WARNING. Must be an array of valid rax_mon_notification ids.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Example notification plan
  gather_facts: False
  hosts: local
  connection: local
  tasks:
  - name: Establish who gets called when.
    rax_mon_notification_plan:
      credentials: ~/.rax_pub
      state: present
      label: defcon1
      critical_state:
      - "{{ everyone['notification']['id'] }}"
      warning_state:
      - "{{ opsfloor['notification']['id'] }}"
    register: defcon1


MAINTAINERS: Ash Wilson

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_NETWORK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_network.py)

  creates / deletes a Rackspace Public Cloud isolated network.

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- auth_endpoint
        The URI of the authentication service.
        [Default: https://identity.api.rackspacecloud.com/v2.0/]
- cidr
        cidr of the network being created
        [Default: None]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- identity_type
        Authentication mechanism to use, such as rackspace or keystone.
        [Default: rackspace]
- label
        Label (name) to give the network
        [Default: None]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- tenant_id
        The tenant ID used for authentication.
        [Default: (null)]
- tenant_name
        The tenant name used for authentication.
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Build an Isolated Network
  gather_facts: False

  tasks:
    - name: Network create request
      local_action:
        module: rax_network
        credentials: ~/.raxpub
        label: my-net
        cidr: 192.168.3.0/24
        state: present


MAINTAINERS: Christopher H. Laco (@claco), Jesse Keating (@j2sol)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_QUEUE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_queue.py)

  creates / deletes a Rackspace Public Cloud queue.

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- name
        Name to give the queue
        [Default: None]
- region
        Region to create an instance in.
        [Default: DFW]
- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
- name: Build a Queue
  gather_facts: False
  hosts: local
  connection: local
  tasks:
    - name: Queue create request
      local_action:
        module: rax_queue
        credentials: ~/.raxpub
        name: my-queue
        region: DFW
        state: present
      register: my_queue


MAINTAINERS: Christopher H. Laco (@claco), Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_SCALING_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_scaling_group.py)

  Manipulate Rackspace Cloud Autoscale Groups

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- config_drive
        Attach read-only configuration drive to server as label config-2
        (Choices: yes, no)[Default: False]
- cooldown
        The period of time, in seconds, that must pass before any scaling can occur after the previous scaling. Must be
        an integer between 0 and 86400 (24 hrs).
        [Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- disk_config
        Disk partitioning strategy
        (Choices: auto, manual)[Default: auto]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- files
        Files to insert into the instance. Hash of `remotepath: localpath'
        [Default: None]
= flavor
        flavor to use for the instance

= image
        image to use for the instance. Can be an `id', `human_id' or `name'

- key_name
        key pair to use on the instance
        [Default: None]
- loadbalancers
        List of load balancer `id' and `port' hashes
        [Default: (null)]
= max_entities
        The maximum number of entities that are allowed in the scaling group. Must be an integer between 0 and 1000.

- meta
        A hash of metadata to associate with the instance
        [Default: None]
= min_entities
        The minimum number of entities that are allowed in the scaling group. Must be an integer between 0 and 1000.

= name
        Name to give the scaling group

- networks
        The network to attach to the instances. If specified, you must include ALL networks including the public and
        private interfaces. Can be `id' or `label'.
        [Default: [u'public', u'private']]
- region
        Region to create an instance in.
        [Default: DFW]
= server_name
        The base name for servers created by Autoscale

- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- user_data
        Data to be uploaded to the servers config drive. This option implies `config_drive'. Can be a file path or a
        string
        [Default: (null)]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
- wait
        wait for the scaling group to finish provisioning the minimum amount of servers
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
---
- hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    - rax_scaling_group:
        credentials: ~/.raxpub
        region: ORD
        cooldown: 300
        flavor: performance1-1
        image: bb02b1a3-bc77-4d17-ab5b-421d89850fca
        min_entities: 5
        max_entities: 10
        name: ASG Test
        server_name: asgtest
        loadbalancers:
            - id: 228385
              port: 80
      register: asg


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RAX_SCALING_POLICY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/rackspace/rax_scaling_policy.py)

  Manipulate Rackspace Cloud Autoscale Scaling Policy

Options (= is mandatory):

- api_key
        Rackspace API key, overrides `credentials'.
        [Default: (null)]
- at
        The UTC time when this policy will be executed. The time must be formatted according to `yyyy-MM-
        dd'T'HH:mm:ss.SSS' such as `2013-05-19T08:07:08Z'
        [Default: (null)]
- change
        The change, either as a number of servers or as a percentage, to make in the scaling group. If this is a
        percentage, you must set `is_percent' to `true' also.
        [Default: (null)]
- cooldown
        The period of time, in seconds, that must pass before any scaling can occur after the previous scaling. Must be
        an integer between 0 and 86400 (24 hrs).
        [Default: (null)]
- credentials
        File to find the Rackspace credentials in. Ignored if `api_key' and `username' are provided.
        [Default: None]
- cron
        The time when the policy will be executed, as a cron entry. For example, if this is parameter is set to `1 0 * *
        *'
        [Default: (null)]
- desired_capacity
        The desired server capacity of the scaling the group; that is, how many servers should be in the scaling group.
        [Default: (null)]
- env
        Environment as configured in `~/.pyrax.cfg', see
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#pyrax-configuration.
        [Default: (null)]
- is_percent
        Whether the value in `change' is a percent value
        [Default: False]
= name
        Name to give the policy

= policy_type
        The type of policy that will be executed for the current release.
        (Choices: webhook, schedule)
- region
        Region to create an instance in.
        [Default: DFW]
= scaling_group
        Name of the scaling group that this policy will be added to

- state
        Indicate desired state of the resource
        (Choices: present, absent)[Default: present]
- username
        Rackspace username, overrides `credentials'.
        [Default: (null)]
- verify_ssl
        Whether or not to require SSL validation of API endpoints.
        [Default: (null)]
Notes:
  * The following environment variables can be used, `RAX_USERNAME', `RAX_API_KEY', `RAX_CREDS_FILE',
        `RAX_CREDENTIALS', `RAX_REGION'.
  * `RAX_CREDENTIALS' and `RAX_CREDS_FILE' points to a credentials file appropriate for pyrax. See
        https://github.com/rackspace/pyrax/blob/master/docs/getting_started.md#authenticating
  * `RAX_USERNAME' and `RAX_API_KEY' obviate the use of a credentials file
  * `RAX_REGION' defines a Rackspace Public Cloud region (DFW, ORD, LON, ...)
Requirements:  python >= 2.6, pyrax

EXAMPLES:
---
- hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    - rax_scaling_policy:
        credentials: ~/.raxpub
        region: ORD
        at: '2013-05-19T08:07:08Z'
        change: 25
        cooldown: 300
        is_percent: true
        name: ASG Test Policy - at
        policy_type: schedule
        scaling_group: ASG Test
      register: asps_at

    - rax_scaling_policy:
        credentials: ~/.raxpub
        region: ORD
        cron: '1 0 * * *'
        change: 25
        cooldown: 300
        is_percent: true
        name: ASG Test Policy - cron
        policy_type: schedule
        scaling_group: ASG Test
      register: asp_cron

    - rax_scaling_policy:
        credentials: ~/.raxpub
        region: ORD
        cooldown: 300
        desired_capacity: 5
        name: ASG Test Policy - webhook
        policy_type: webhook
        scaling_group: ASG Test
      register: asp_webhook


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['preview']
	Supported_by: community
> RDS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/rds.py)

  Creates, deletes, or modifies rds instances.  When creating an instance it can be either a new instance or a read-only
  replica of an existing instance. This module has a dependency on python-boto >= 2.5. The 'promote' command requires
  boto >= 2.18.0. Certain features such as tags rely on boto.rds2 (boto >= 2.26.0)

Options (= is mandatory):

- apply_immediately
        Used only when command=modify.  If enabled, the modifications will be applied as soon as possible rather than
        waiting for the next preferred maintenance window.
        (Choices: yes, no)[Default: False]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- backup_retention
        Number of days backups are retained.  Set to 0 to disable backups.  Default is 1 day.  Valid range: 0-35. Used
        only when command=create or command=modify.
        [Default: None]
- backup_window
        Backup window in format of hh24:mi-hh24:mi.  If not specified then a random backup window is assigned. Used only
        when command=create or command=modify.
        [Default: None]
- character_set_name
        Associate the DB instance with a specified character set. Used with command=create.
        [Default: None]
= command
        Specifies the action to take. The 'reboot' option is available starting at version 2.0
        (Choices: create, replicate, delete, facts, modify, promote, snapshot, reboot, restore)
- db_engine
        The type of database.  Used only when command=create.
        mariadb was added in version 2.2
        (Choices: mariadb, MySQL, oracle-se1, oracle-se, oracle-ee, sqlserver-ee, sqlserver-se, sqlserver-ex, sqlserver-
        web, postgres, aurora)[Default: None]
- db_name
        Name of a database to create within the instance.  If not specified then no database is created. Used only when
        command=create.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- engine_version
        Version number of the database engine to use. Used only when command=create. If not specified then the current
        Amazon RDS default engine version is used.
        [Default: None]
- force_failover
        Used only when command=reboot.  If enabled, the reboot is done using a MultiAZ failover.
        (Choices: yes, no)[Default: no]
- instance_name
        Database instance identifier. Required except when using command=facts or command=delete on just a snapshot
        [Default: None]
- instance_type
        The instance type of the database.  Must be specified when command=create. Optional when command=replicate,
        command=modify or command=restore. If not specified then the replica inherits the same instance type as the
        source instance.
        [Default: None]
- iops
        Specifies the number of IOPS for the instance.  Used only when command=create or command=modify. Must be an
        integer greater than 1000.
        [Default: None]
- license_model
        The license model for this DB instance. Used only when command=create or command=restore.
        (Choices: license-included, bring-your-own-license, general-public-license, postgresql-license)[Default: None]
- maint_window
        Maintenance window in format of ddd:hh24:mi-ddd:hh24:mi.  (Example: Mon:22:00-Mon:23:15) If not specified then a
        random maintenance window is assigned. Used only when command=create or command=modify.
        [Default: None]
- multi_zone
        Specifies if this is a Multi-availability-zone deployment. Can not be used in conjunction with zone parameter.
        Used only when command=create or command=modify.
        (Choices: yes, no)[Default: None]
- new_instance_name
        Name to rename an instance to. Used only when command=modify.
        [Default: None]
- option_group
        The name of the option group to use.  If not specified then the default option group is used. Used only when
        command=create.
        [Default: None]
- parameter_group
        Name of the DB parameter group to associate with this instance.  If omitted then the RDS default DBParameterGroup
        will be used. Used only when command=create or command=modify.
        [Default: None]
- password
        Password for the master database username. Used only when command=create or command=modify.
        [Default: None]
- port
        Port number that the DB instance uses for connections. Used only when command=create or command=replicate.
        Prior to 2.0 it always defaults to null and the API would use 3306, it had to be set to other DB default values
        when not using MySql. Starting at 2.0 it automatically defaults to what is expected for each c(db_engine).
        [Default: 3306 for mysql, 1521 for Oracle, 1433 for SQL Server, 5432 for PostgreSQL.]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- publicly_accessible
        explicitly set whether the resource should be publicly accessible or not. Used with command=create,
        command=replicate. Requires boto >= 2.26.0
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_groups
        Comma separated list of one or more security groups.  Used only when command=create or command=modify.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- size
        Size in gigabytes of the initial storage for the DB instance. Used only when command=create or command=modify.
        [Default: None]
- snapshot
        Name of snapshot to take. When command=delete, if no snapshot name is provided then no snapshot is taken. If used
        with command=delete with no instance_name, the snapshot is deleted. Used with command=facts, command=delete or
        command=snapshot.
        [Default: None]
- source_instance
        Name of the database to replicate. Used only when command=replicate.
        [Default: None]
- subnet
        VPC subnet group.  If specified then a VPC instance is created. Used only when command=create.
        [Default: None]
- tags
        tags dict to apply to a resource. Used with command=create, command=replicate, command=restore. Requires boto >=
        2.26.0
        [Default: None]
- upgrade
        Indicates that minor version upgrades should be applied automatically. Used only when command=create or
        command=replicate.
        (Choices: yes, no)[Default: False]
- username
        Master database username. Used only when command=create.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_security_groups
        Comma separated list of one or more vpc security group ids. Also requires `subnet` to be specified. Used only
        when command=create or command=modify.
        [Default: None]
- wait
        When command=create, replicate, modify or restore then wait for the database to enter the 'available' state.
        When command=delete wait for the database to be terminated.
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
- zone
        availability zone in which to launch the instance. Used only when command=create, command=replicate or
        command=restore.
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, python >= 2.6

EXAMPLES:
# Basic mysql provisioning example
- rds:
    command: create
    instance_name: new-database
    db_engine: MySQL
    size: 10
    instance_type: db.m1.small
    username: mysql_admin
    password: 1nsecure
    tags:
      Environment: testing
      Application: cms

# Create a read-only replica and wait for it to become available
- rds:
    command: replicate
    instance_name: new-database-replica
    source_instance: new_database
    wait: yes
    wait_timeout: 600

# Delete an instance, but create a snapshot before doing so
- rds:
    command: delete
    instance_name: new-database
    snapshot: new_database_snapshot

# Get facts about an instance
- rds:
    command: facts
    instance_name: new-database
  register: new_database_facts

# Rename an instance and wait for the change to take effect
- rds:
    command: modify
    instance_name: new-database
    new_instance_name: renamed-database
    wait: yes

# Reboot an instance and wait for it to become available again
- rds:
    command: reboot
    instance_name: database
    wait: yes

# Restore a Postgres db instance from a snapshot, wait for it to become available again, and
#  then modify it to add your security group. Also, display the new endpoint.
#  Note that the "publicly_accessible" option is allowed here just as it is in the AWS CLI
- local_action:
     module: rds
     command: restore
     snapshot: mypostgres-snapshot
     instance_name: MyNewInstanceName
     region: us-west-2
     zone: us-west-2b
     subnet: default-vpc-xx441xxx
     publicly_accessible: yes
     wait: yes
     wait_timeout: 600
     tags:
         Name: pg1_test_name_tag
  register: rds

- local_action:
     module: rds
     command: modify
     instance_name: MyNewInstanceName
     region: us-west-2
     vpc_security_groups: sg-xxx945xx

- debug:
    msg: "The new db endpoint is {{ rds.instance.endpoint }}"


MAINTAINERS: Will Thames (@willthames), Bruce Pennypacker (@bpennypacker)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> RDS_PARAM_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/rds_param_group.py)

  Creates, modifies, and deletes RDS parameter groups. This module has a dependency on python-boto >= 2.5.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- description
        Database parameter group description. Only set when a new group is added.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- engine
        The type of database for this group. Required for state=present.
        (Choices: aurora5.6, mariadb10.0, mariadb10.1, mysql5.1, mysql5.5, mysql5.6, mysql5.7, oracle-ee-11.2, oracle-
        ee-12.1, oracle-se-11.2, oracle-se-12.1, oracle-se1-11.2, oracle-se1-12.1, postgres9.3, postgres9.4, postgres9.5,
        postgres9.6, sqlserver-ee-10.5', sqlserver-ee-11.0, sqlserver-ex-10.5, sqlserver-ex-11.0, sqlserver-ex-12.0,
        sqlserver-se-10.5, sqlserver-se-11.0, sqlserver-se-12.0, sqlserver-web-10.5, sqlserver-web-11.0, sqlserver-
        web-12.0)[Default: None]
- immediate
        Whether to apply the changes immediately, or after the next reboot of any associated instances.
        [Default: None]
= name
        Database parameter group identifier.
        [Default: None]
- params
        Map of parameter names and values. Numeric values may be represented as K for kilo (1024), M for mega (1024^2), G
        for giga (1024^3), or T for tera (1024^4), and these values will be expanded into the appropriate number before
        being set in the parameter group.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Specifies whether the group should be present or absent.
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Add or change a parameter group, in this case setting auto_increment_increment to 42 * 1024
- rds_param_group:
      state: present
      name: norwegian_blue
      description: 'My Fancy Ex Parrot Group'
      engine: 'mysql5.6'
      params:
          auto_increment_increment: "42K"

# Remove a parameter group
- rds_param_group:
      state: absent
      name: norwegian_blue


MAINTAINERS: Scott Anderson (@tastychutney)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> RDS_SUBNET_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/rds_subnet_group.py)

  Creates, modifies, and deletes RDS database subnet groups. This module has a dependency on python-boto >= 2.5.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- description
        Database subnet group description. Only set when a new group is added.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= name
        Database subnet group identifier.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Specifies whether the subnet should be present or absent.
        (Choices: present, absent)[Default: present]
- subnets
        List of subnet IDs that make up the database subnet group.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Add or change a subnet group
- rds_subnet_group:
    state: present
    name: norwegian-blue
    description: My Fancy Ex Parrot Subnet Group
    subnets:
      - subnet-aaaaaaaa
      - subnet-bbbbbbbb

# Remove a subnet group
- rds_subnet_group:
    state: absent
    name: norwegian-blue


MAINTAINERS: Scott Anderson (@tastychutney)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> REDHAT_SUBSCRIPTION    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/redhat_subscription.py)

  Manage registration and subscription to the Red Hat Subscription Management entitlement platform using the
  `subscription-manager' command

Options (= is mandatory):

- activationkey
        supply an activation key for use with registration
        [Default: None]
- autosubscribe
        Upon successful registration, auto-consume available subscriptions
        [Default: False]
- consumer_id
        References an existing consumer ID to resume using a previous registration for this system. If the  system's
        identity certificate is lost or corrupted, this option allows it to resume using its previous identity and
        subscriptions. The default is to not specify a consumer ID so a new ID is created.
        [Default: None]
- consumer_name
        Name of the system to register, defaults to the hostname
        [Default: None]
- consumer_type
        The type of unit to register, defaults to system
        [Default: None]
- environment
        Register with a specific environment in the destination org. Used with Red Hat Satellite 6.x or Katello
        [Default: None]
- force_register
        Register the system even if it is already registered
        [Default: False]
- org_id
        Organization ID to use in conjunction with activationkey
        [Default: None]
- password
        access.redhat.com or Sat6 password
        [Default: None]
- pool
        Specify a subscription pool name to consume.  Regular expressions accepted.
        [Default: ^$]
- rhsm_baseurl
        Specify CDN baseurl
        [Default: Current value from `/etc/rhsm/rhsm.conf' is the default]
- server_hostname
        Specify an alternative Red Hat Subscription Management or Sat6 server
        [Default: Current value from `/etc/rhsm/rhsm.conf' is the default]
- server_insecure
        Enable or disable https server certificate verification when connecting to `server_hostname'
        [Default: Current value from `/etc/rhsm/rhsm.conf' is the default]
- state
        whether to register and subscribe (`present'), or unregister (`absent') a system
        (Choices: present, absent)[Default: present]
- username
        access.redhat.com or Sat6  username
        [Default: None]
Notes:
  * In order to register a system, subscription-manager requires either a username and password, or an
        activationkey and an Organization ID.
Requirements:  subscription-manager

EXAMPLES:
# Register as user (joe_user) with password (somepass) and auto-subscribe to available content.
- redhat_subscription:
    state: present
    username: joe_user
    password: somepass
    autosubscribe: true

# Same as above but with pulling existing system data.
- redhat_subscription:
    state: present
    username: joe_user
    password: somepass
    consumer_id: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx

# Register with activationkey (1-222333444) and consume subscriptions matching
# the names (Red hat Enterprise Server) and (Red Hat Virtualization)
- redhat_subscription:
    state: present
    activationkey: 1-222333444
    org_id: 222333444
    pool: '^(Red Hat Enterprise Server|Red Hat Virtualization)$'

# Update the consumed subscriptions from the previous example (remove the Red
# Hat Virtualization subscription)
- redhat_subscription:
    state: present
    activationkey: 1-222333444
    org_id: 222333444
    pool: '^Red Hat Enterprise Server$'

# Register as user credentials into given environment (against Red Hat
# Satellite 6.x), and auto-subscribe to available content.
- redhat_subscription:
    state: present
    username: joe_user
    password: somepass
    environment: Library
    autosubscribe: yes


MAINTAINERS: Barnaby Court (@barnabycourt)

METADATA:
	Status: ['preview']
	Supported_by: community
> REDIS    (/usr/lib/python2.7/site-packages/ansible/modules/database/misc/redis.py)

  Unified utility to interact with redis instances. 'slave' sets a redis instance in slave or master mode. 'flush'
  flushes all the instance or a specified db. 'config' (new in 1.6), ensures a configuration setting on an instance.

Options (= is mandatory):

= command
        The selected redis command
        (Choices: slave, flush, config)[Default: None]
- db
        The database to flush (used in db mode) [flush command]
        [Default: None]
- flush_mode
        Type of flush (all the dbs in a redis instance or a specific one) [flush command]
        (Choices: all, db)[Default: all]
- login_host
        The host running the database
        [Default: localhost]
- login_password
        The password used to authenticate with (usually not used)
        [Default: None]
- login_port
        The port to connect to
        [Default: 6379]
- master_host
        The host of the master instance [slave command]
        [Default: None]
- master_port
        The port of the master instance [slave command]
        [Default: None]
- name
        A redis config key.
        [Default: None]
- slave_mode
        the mode of the redis instance [slave command]
        (Choices: master, slave)[Default: slave]
- value
        A redis config value.
        [Default: None]
Notes:
  * Requires the redis-py Python package on the remote host. You can install it with pip (pip install redis) or
        with a package manager. https://github.com/andymccurdy/redis-py
  * If the redis master instance we are making slave of is password protected this needs to be in the redis.conf in
        the masterauth variable
Requirements:  redis

EXAMPLES:
# Set local redis instance to be slave of melee.island on port 6377
- redis:
    command: slave
    master_host: melee.island
    master_port: 6377

# Deactivate slave mode
- redis:
    command: slave
    slave_mode: master

# Flush all the redis db
- redis:
    command: flush
    flush_mode: all

# Flush only one db in a redis instance
- redis:
    command: flush
    db: 1
    flush_mode: db

# Configure local redis to have 10000 max clients
- redis:
    command: config
    name: maxclients
    value: 10000

# Configure local redis to have lua time limit of 100 ms
- redis:
    command: config
    name: lua-time-limit
    value: 100


MAINTAINERS: Xabier Larrakoetxea (@slok)

METADATA:
	Status: ['preview']
	Supported_by: community
> REDSHIFT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/redshift.py)

  Creates, deletes, or modifies amazon Redshift cluster instances.

Options (= is mandatory):

- allow_version_upgrade
        flag to determinate if upgrade of version is possible
        [Default: True]
- automated_snapshot_retention_period
        period when the snapshot take place
        [Default: None]
- availability_zone
        availability zone in which to launch cluster
        [Default: (null)]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- cluster_parameter_group_name
        name of the cluster parameter group
        [Default: None]
- cluster_security_groups
        in which security group the cluster belongs
        [Default: None]
- cluster_subnet_group_name
        which subnet to place the cluster
        [Default: (null)]
- cluster_type
        The type of cluster.
        (Choices: multi-node, single-node)[Default: single-node]
- cluster_version
        which version the cluster should have
        (Choices: 1.0)[Default: None]
= command
        Specifies the action to take.
        (Choices: create, facts, delete, modify)
- db_name
        Name of the database.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- elastic_ip
        if the cluster has an elastic IP or not
        [Default: None]
- encrypted
        if the cluster is encrypted or not
        [Default: False]
= identifier
        Redshift cluster identifier.

- new_cluster_identifier
        Only used when command=modify.
        [Default: None]
- node_type
        The node type of the cluster. Must be specified when command=create.
        (Choices: ds1.xlarge, ds1.8xlarge, ds2.xlarge, ds2.8xlarge, dc1.large, dc1.8xlarge, dw1.xlarge, dw1.8xlarge,
        dw2.large, dw2.8xlarge)[Default: (null)]
- number_of_nodes
        Number of nodes. Only used when cluster_type=multi-node.
        [Default: None]
- password
        Master database password. Used only when command=create.
        [Default: (null)]
- port
        which port the cluster is listining
        [Default: None]
- preferred_maintenance_window
        maintenance window
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- publicly_accessible
        if the cluster is accessible publicly or not
        [Default: False]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- username
        Master database username. Used only when command=create.
        [Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_security_group_ids
        VPC security group
        [Default: None]
- wait
        When command=create, modify or restore then wait for the database to enter the 'available' state. When
        command=delete wait for the database to be terminated.
        (Choices: yes, no)[Default: no]
- wait_timeout
        how long before wait gives up, in seconds
        [Default: 300]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, python >= 2.6

EXAMPLES:
# Basic cluster provisioning example
- redshift: >
    command=create
    node_type=ds1.xlarge
    identifier=new_cluster
    username=cluster_admin
    password=1nsecure

RETURN VALUES:
cluster:
    description: dictionary containing all the cluster information
    returned: success
    type: dictionary
    contains:
        identifier:
            description: Id of the cluster.
            returned: success
            type: string
            sample: "new_redshift_cluster"
        create_time:
            description: Time of the cluster creation as timestamp.
            returned: success
            type: float
            sample: 1430158536.308
        status:
            description: Stutus of the cluster.
            returned: success
            type: string
            sample: "available"
        db_name:
            description: Name of the database.
            returned: success
            type: string
            sample: "new_db_name"
        availability_zone:
            description: Amazon availability zone where the cluster is located.
            returned: success
            type: string
            sample: "us-east-1b"
        maintenance_window:
            description: Time frame when maintenance/upgrade are done.
            returned: success
            type: string
            sample: "sun:09:30-sun:10:00"
        private_ip_address:
            description: Private IP address of the main node.
            returned: success
            type: string
            sample: "10.10.10.10"
        public_ip_address:
            description: Public IP address of the main node.
            returned: success
            type: string
            sample: "0.0.0.0"
        port:
            description: Port of the cluster.
            returned: success
            type: int
            sample: 5439
        url:
            description: FQDN of the main cluster node.
            returned: success
            type: string
            sample: "new-redshift_cluster.jfkdjfdkj.us-east-1.redshift.amazonaws.com"


MAINTAINERS: Jens Carl (@j-carl), Hothead Games Inc.

METADATA:
	Status: ['preview']
	Supported_by: community
> REDSHIFT_SUBNET_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/redshift_subnet_group.py)

  Create, modifies, and deletes Redshift cluster subnet groups.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- group_description
        Database subnet group description.
        [Default: None]
= group_name
        Cluster subnet group name.

- group_subnets
        List of subnet IDs that make up the cluster subnet group.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Specifies whether the subnet should be present or absent.
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, python >= 2.6

EXAMPLES:
# Create a Redshift subnet group
- local_action:
    module: redshift_subnet_group
    state: present
    group_name: redshift-subnet
    group_description: Redshift subnet
    group_subnets:
        - 'subnet-aaaaa'
        - 'subnet-bbbbb'

# Remove subnet group
- redshift_subnet_group:
    state: absent
    group_name: redshift-subnet

RETURN VALUES:
group:
    description: dictionary containing all Redshift subnet group information
    returned: success
    type: dictionary
    contains:
        name:
            description: name of the Redshift subnet group
            returned: success
            type: string
            sample: "redshift_subnet_group_name"
        vpc_id:
            description: Id of the VPC where the subnet is located
            returned: success
            type: string
            sample: "vpc-aabb1122"


MAINTAINERS: Jens Carl (@j-carl), Hothead Games Inc.

METADATA:
	Status: ['preview']
	Supported_by: community
> REPLACE    (/usr/lib/python2.7/site-packages/ansible/modules/files/replace.py)

  This module will replace all instances of a pattern within a file. It is up to the user to maintain idempotence by
  ensuring that the same pattern would never match any replacements made.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- follow
        This flag indicates that filesystem links, if they exist, should be followed.
        (Choices: yes, no)[Default: no]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- others
        All arguments accepted by the [file] module also work here.
        [Default: (null)]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
= path
        The file to modify.
        Before 2.3 this option was only usable as `dest', `destfile' and `name'.

= regexp
        The regular expression to look for in the contents of the file. Uses Python regular expressions; see
        http://docs.python.org/2/library/re.html. Uses multiline mode, which means `^' and `$' match the beginning and
        end respectively of `each line' of the file.

- replace
        The string to replace regexp matches. May contain backreferences that will get expanded with the regexp capture
        groups if the regexp matches. If not set, matches are removed entirely.
        [Default: (null)]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- validate
        The validation command to run before copying into place. The path to the file to validate is passed in via '%s'
        which must be present as in the example below. The command is passed securely so shell features like expansion
        and pipes won't work.
        [Default: None]
Notes:
  * As of Ansible 2.3, the `dest' option has been changed to `path' as default, but `dest' still works as well.
EXAMPLES:
# Before 2.3, option 'dest', 'destfile' or 'name' was used instead of 'path'
- replace:
    path: /etc/hosts
    regexp: '(\s+)old\.host\.name(\s+.*)?$'
    replace: '\1new.host.name\2'
    backup: yes

- replace:
    path: /home/jdoe/.ssh/known_hosts
    regexp: '^old\.host\.name[^\n]*\n'
    owner: jdoe
    group: jdoe
    mode: 0644

- replace:
    path: /etc/apache/ports
    regexp: '^(NameVirtualHost|Listen)\s+80\s*$'
    replace: '\1 127.0.0.1:8080'
    validate: '/usr/sbin/apache2ctl -f %s -t'


MAINTAINERS: Evan Kaufman (@EvanK)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> RHEVM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/rhevm.py)

  This module only supports oVirt/RHEV version 3. A newer module [ovirt_vms] supports oVirt/RHV version 4. Allows you to
  create/remove/update or powermanage virtual machines on a RHEV/oVirt platform.

Options (= is mandatory):

- boot_order
        This option uses complex arguments and is a list of items that specify the bootorder.
        [Default: [u'network', u'hd']]
- cd_drive
        The CD you wish to have mounted on the VM when `state = 'CD''.
        [Default: None]
- cluster
        The rhev/ovirt cluster in which you want you VM to start.
        [Default: (null)]
- cpu_share
        This parameter is used to configure the cpu share.
        [Default: 0]
- datacenter
        The rhev/ovirt datacenter in which you want you VM to start.
        [Default: Default]
- del_prot
        This option sets the delete protection checkbox.
        [Default: True]
- disks
        This option uses complex arguments and is a list of disks with the options name, size and domain.
        [Default: (null)]
- ifaces
        This option uses complex arguments and is a list of interfaces with the options name and vlan.
        [Default: (null)]
- image
        The template to use for the VM.
        [Default: None]
- insecure_api
        A boolean switch to make a secure or insecure connection to the server.
        [Default: False]
- mempol
        The minimum amount of memory you wish to reserve for this system.
        [Default: 1]
- name
        The name of the VM.
        [Default: (null)]
- osver
        The operationsystem option in RHEV/oVirt.
        [Default: rhel_6x64]
- port
        The port on which the API is reacheable.
        [Default: 443]
- server
        The name/ip of your RHEV-m/oVirt instance.
        [Default: 127.0.0.1]
- state
        This serves to create/remove/update or powermanage your VM.
        (Choices: ping, present, absent, up, down, restarted, cd, info)[Default: present]
- timeout
        The timeout you wish to define for power actions.
        When `state = 'up''
        When `state = 'down''
        When `state = 'restarted''
        [Default: None]
- type
        To define if the VM is a server or desktop.
        (Choices: server, desktop, host)[Default: server]
- user
        The user to authenticate with.
        [Default: admin@internal]
- vm_ha
        To make your VM High Available.
        [Default: True]
- vmcpu
        The number of CPUs you want in your VM.
        [Default: 2]
- vmhost
        The host you wish your VM to run on.
        [Default: (null)]
- vmmem
        The amount of memory you want your VM to use (in GB).
        [Default: 1]
Requirements:  ovirtsdk

EXAMPLES:
# basic get info from VM
  - rhevm:
      name: "demo"
      user: "{{ rhev.admin.name }}"
      password: "{{ rhev.admin.pass }}"
      server: "rhevm01"
      state: "info"

# basic create example from image
  - rhevm:
      name: "demo"
      user: "{{ rhev.admin.name }}"
      password: "{{ rhev.admin.pass }}"
      server: "rhevm01"
      state: "present"
      image: "centos7_x64"
      cluster: "centos"

# power management
  - rhevm:
      name: "uptime_server"
      user: "{{ rhev.admin.name }}"
      password: "{{ rhev.admin.pass }}"
      server: "rhevm01"
      cluster: "RH"
      state: "down"
      image: "centos7_x64"
      cluster: "centos"

# multi disk, multi nic create example
  - rhevm:
      name: "server007"
      user: "{{ rhev.admin.name }}"
      password: "{{ rhev.admin.pass }}"
      server: "rhevm01"
      cluster: "RH"
      state: "present"
      type: "server"
      vmcpu: 4
      vmmem: 2
      ifaces:
        - name: "eth0"
          vlan: "vlan2202"
        - name: "eth1"
          vlan: "vlan36"
        - name: "eth2"
          vlan: "vlan38"
        - name: "eth3"
          vlan: "vlan2202"
      disks:
        - name: "root"
          size: 10
          domain: "ssd-san"
        - name: "swap"
          size: 10
          domain: "15kiscsi-san"
        - name: "opt"
          size: 10
          domain: "15kiscsi-san"
        - name: "var"
          size: 10
          domain: "10kiscsi-san"
        - name: "home"
          size: 10
          domain: "sata-san"
      boot_order:
        - "network"
        - "hd"

# add a CD to the disk cd_drive
  - rhevm:
      name: 'server007'
      user: "{{ rhev.admin.name }}"
      password: "{{ rhev.admin.pass }}"
      state: 'cd'
      cd_drive: 'rhev-tools-setup.iso'

# new host deployment + host network configuration
  - rhevm:
      name: "ovirt_node007"
      password: "{{ rhevm.admin.pass }}"
      type: "host"
      state: present
      cluster: "rhevm01"
      ifaces:
        - name: em1
        - name: em2
        - name: p3p1
          ip: '172.31.224.200'
          netmask: '255.255.254.0'
        - name: p3p2
          ip: '172.31.225.200'
          netmask: '255.255.254.0'
        - name: bond0
          bond:
            - em1
            - em2
          network: 'rhevm'
          ip: '172.31.222.200'
          netmask: '255.255.255.0'
          management: True
        - name: bond0.36
          network: 'vlan36'
          ip: '10.2.36.200'
          netmask: '255.255.254.0'
          gateway: '10.2.36.254'
        - name: bond0.2202
          network: 'vlan2202'
        - name: bond0.38
          network: 'vlan38'

RETURN VALUES:
vm:
    description: Returns all of the VMs variables and execution.
    returned: always
    type: dict
    sample: '{
        "boot_order": [
            "hd",
            "network"
        ],
        "changed": true,
        "changes": [
            "Delete Protection"
        ],
        "cluster": "C1",
        "cpu_share": "0",
        "created": false,
        "datacenter": "Default",
        "del_prot": true,
        "disks": [
            {
                "domain": "ssd-san",
                "name": "OS",
                "size": 40
            }
        ],
        "eth0": "00:00:5E:00:53:00",
        "eth1": "00:00:5E:00:53:01",
        "eth2": "00:00:5E:00:53:02",
        "exists": true,
        "failed": false,
        "ifaces": [
            {
                "name": "eth0",
                "vlan": "Management"
            },
            {
                "name": "eth1",
                "vlan": "Internal"
            },
            {
                "name": "eth2",
                "vlan": "External"
            }
        ],
        "image": false,
        "mempol": "0",
        "msg": [
            "VM exists",
            "cpu_share was already set to 0",
            "VM high availability was already set to True",
            "The boot order has already been set",
            "VM delete protection has been set to True",
            "Disk web2_Disk0_OS already exists",
            "The VM starting host was already set to host416"
        ],
        "name": "web2",
        "type": "server",
        "uuid": "4ba5a1be-e60b-4368-9533-920f156c817b",
        "vm_ha": true,
        "vmcpu": "4",
        "vmhost": "host416",
        "vmmem": "16"
    }'


MAINTAINERS: Timothy Vandenbrande

METADATA:
	Status: ['preview']
	Supported_by: community
> RHN_CHANNEL    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/rhn_channel.py)

  Adds or removes Red Hat software channels

Options (= is mandatory):

= name
        name of the software channel
        [Default: None]
= password
        the user's password

- state
        whether the channel should be present or not
        [Default: present]
= sysname
        name of the system as it is known in RHN/Satellite
        [Default: None]
= url
        The full url to the RHN/Satellite api

= user
        RHN/Satellite user

Notes:
  * this module fetches the system id from RHN.
Requirements:  none

EXAMPLES:
- rhn_channel:
    name: rhel-x86_64-server-v2vwin-6
    sysname: server01
    url: https://rhn.redhat.com/rpc/api
    user: rhnuser
    password: guessme


MAINTAINERS: Vincent Van der Kussen (@vincentvdk)

METADATA:
	Status: ['preview']
	Supported_by: core
> RHN_REGISTER    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/rhn_register.py)

  Manage registration to the Red Hat Network.

Options (= is mandatory):

- activationkey
        supply an activation key for use with registration
        [Default: None]
- channels
        Optionally specify a list of comma-separated channels to subscribe to upon successful registration.
        [Default: []]
- enable_eus
        If true, extended update support will be requested.
        [Default: False]
- password
        Red Hat Network password
        [Default: None]
- profilename
        supply an profilename for use with registration
        [Default: None]
- server_url
        Specify an alternative Red Hat Network server URL
        [Default: Current value of `serverURL' from `/etc/sysconfig/rhn/up2date' is the default]
- sslcacert
        supply a custom ssl CA certificate file for use with registration
        [Default: None]
- state
        whether to register (`present'), or unregister (`absent') a system
        (Choices: present, absent)[Default: present]
- systemorgid
        supply an organizational id for use with registration
        [Default: None]
- username
        Red Hat Network username
        [Default: None]
Notes:
  * In order to register a system, rhnreg_ks requires either a username and password, or an activationkey.
Requirements:  rhnreg_ks

EXAMPLES:
# Unregister system from RHN.
- rhn_register:
    state: absent
    username: joe_user
    password: somepass

# Register as user (joe_user) with password (somepass) and auto-subscribe to available content.
- rhn_register:
    state: present
    username: joe_user
    password: somepass

# Register with activationkey (1-222333444) and enable extended update support.
- rhn_register:
    state: present
    activationkey: 1-222333444
    enable_eus: true

# Register with activationkey (1-222333444) and set a profilename which may differ from the hostname.
- rhn_register:
    state: present
    activationkey: 1-222333444
    profilename: host.example.com.custom

# Register as user (joe_user) with password (somepass) against a satellite
# server specified by (server_url).
- rhn_register:
    state: present
    username: joe_user
    password: somepass'
    server_url: https://xmlrpc.my.satellite/XMLRPC

# Register as user (joe_user) with password (somepass) and enable
# channels (rhel-x86_64-server-6-foo-1) and (rhel-x86_64-server-6-bar-1).
- rhn_register:
    state: present
    username: joe_user
    password: somepass
    channels: rhel-x86_64-server-6-foo-1,rhel-x86_64-server-6-bar-1


MAINTAINERS: James Laska

METADATA:
	Status: ['preview']
	Supported_by: core
> RIAK    (/usr/lib/python2.7/site-packages/ansible/modules/database/misc/riak.py)

  This module can be used to join nodes to a cluster, check the status of the cluster.

Options (= is mandatory):

- command
        The command you would like to perform against the cluster.
        (Choices: ping, kv_test, join, plan, commit)[Default: None]
- config_dir
        The path to the riak configuration directory
        [Default: /etc/riak]
- http_conn
        The ip address and port that is listening for Riak HTTP queries
        [Default: 127.0.0.1:8098]
- target_node
        The target node for certain operations (join, ping)
        [Default: riak@127.0.0.1]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
- wait_for_handoffs
        Number of seconds to wait for handoffs to complete.
        [Default: None]
- wait_for_ring
        Number of seconds to wait for all nodes to agree on the ring.
        [Default: None]
- wait_for_service
        Waits for a riak service to come online before continuing.
        (Choices: kv)[Default: None]
EXAMPLES:
# Join's a Riak node to another node
- riak:
    command: join
    target_node: riak@10.1.1.1

# Wait for handoffs to finish.  Use with async and poll.
- riak:
    wait_for_handoffs: yes

# Wait for riak_kv service to startup
- riak:
    wait_for_service: kv


MAINTAINERS: James Martin (@jsmartin), Drew Kerrigan (@drewkerrigan)

METADATA:
	Status: ['preview']
	Supported_by: community
> ROCKETCHAT    (/usr/lib/python2.7/site-packages/ansible/modules/notification/rocketchat.py)

  The `rocketchat' module sends notifications to Rocket Chat via the Incoming WebHook integration

Options (= is mandatory):

- attachments
        Define a list of attachments.
        [Default: None]
- channel
        Channel to send the message to. If absent, the message goes to the channel selected for the `token' specifed
        during the creation of webhook.
        [Default: None]
- color
        Allow text to use default colors - use the default of 'normal' to not send a custom color bar at the start of the
        message
        (Choices: normal, good, warning, danger)[Default: normal]
= domain
        The domain for your environment without protocol. (i.e. `example.com' or `chat.example.com')

- icon_emoji
        Emoji for the message sender. The representation for the available emojis can be got from Rocket Chat. (for
        example :thumbsup:) (if `icon_emoji' is set, `icon_url' will not be used)
        [Default: None]
- icon_url
        URL for the message sender's icon.
        [Default: https://www.ansible.com/favicon.ico]
- link_names
        Automatically create links for channels and usernames in `msg'.
        (Choices: 1, 0)[Default: 1]
- msg
        Message to be sent.
        [Default: None]
- protocol
        Specify the protocol used to send notification messages before the webhook url. (i.e. http or https)
        (Choices: http, https)[Default: https]
= token
        Rocket Chat Incoming Webhook integration token.  This provides authentication to Rocket Chat's Incoming webhook
        for posting messages.

- username
        This is the sender of the message.
        [Default: Ansible]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- name: Send notification message via Rocket Chat
  rocketchat:
    token: thetoken/generatedby/rocketchat
    domain: chat.example.com
    msg: '{{ inventory_hostname }} completed'
  delegate_to: localhost

- name: Send notification message via Rocket Chat all options
  rocketchat:
    domain: chat.example.com
    token: thetoken/generatedby/rocketchat
    msg: '{{ inventory_hostname }} completed'
    channel: #ansible
    username: 'Ansible on {{ inventory_hostname }}'
    icon_url: http://www.example.com/some-image-file.png
    link_names: 0
  delegate_to: localhost

- name: insert a color bar in front of the message for visibility purposes and use the default webhook icon and name configured in rocketchat
  rocketchat:
    token: thetoken/generatedby/rocketchat
    domain: chat.example.com
    msg: '{{ inventory_hostname }} is alive!'
    color: good
    username: ''
    icon_url: ''
  delegate_to: localhost

- name: Use the attachments API
  rocketchat:
    token: thetoken/generatedby/rocketchat
    domain: chat.example.com
    attachments:
      - text: Display my system load on host A and B
        color: #ff00dd
        title: System load
        fields:
          - title: System A
            value: 'load average: 0,74, 0,66, 0,63'
            short: True
          - title: System B
            value: 'load average: 5,16, 4,64, 2,43'
            short: True
  delegate_to: localhost

RETURN VALUES:
changed:
    description: A flag indicating if any change was made or not.
    returned: success
    type: boolean
    sample: false


MAINTAINERS: Ramon de la Fuente (@ramondelafuente)

METADATA:
	Status: ['preview']
	Supported_by: community
> ROLLBAR_DEPLOYMENT    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/rollbar_deployment.py)

  Notify Rollbar about app deployments (see https://rollbar.com/docs/deploys_other/)

Options (= is mandatory):

- comment
        Deploy comment (e.g. what is being deployed).
        [Default: (null)]
= environment
        Name of the environment being deployed, e.g. 'production'.

= revision
        Revision number/sha being deployed.

- rollbar_user
        Rollbar username of the user who deployed.
        [Default: (null)]
= token
        Your project access token.

- url
        Optional URL to submit the notification to.
        [Default: https://api.rollbar.com/api/1/deploy/]
- user
        User who deployed.
        [Default: (null)]
- validate_certs
        If `no', SSL certificates for the target url will not be validated. This should only be used on personally
        controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- rollbar_deployment:
    token: AAAAAA
    environment: staging
    user: ansible
    revision: '4.2'
    rollbar_user: admin
    comment: Test Deploy


MAINTAINERS: Max Riveiro (@kavu)

METADATA:
	Status: ['preview']
	Supported_by: community
> ROUTE53    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/route53.py)

  Creates and deletes DNS records in Amazons Route53 service

Options (= is mandatory):

- alias
        Indicates if this is an alias record.
        (Choices: True, False)[Default: False]
- alias_evaluate_target_health
        Whether or not to evaluate an alias target health. Useful for aliases to Elastic Load Balancers.
        [Default: False]
- alias_hosted_zone_id
        The hosted zone identifier.
        [Default: None]
- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
= command
        Specifies the action to take.
        (Choices: get, create, delete)
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- failover
        Failover resource record sets only. Whether this is the primary or secondary resource record set. Allowed values
        are PRIMARY and SECONDARY
        [Default: None]
- health_check
        Health check to associate with this record
        [Default: None]
- hosted_zone_id
        The Hosted Zone ID of the DNS zone to modify
        [Default: None]
- identifier
        Have to be specified for Weighted, latency-based and failover resource record sets only. An identifier that
        differentiates among multiple resource record sets that have the same combination of DNS name and type.
        [Default: None]
- overwrite
        Whether an existing record should be overwritten on create if values do not match
        [Default: None]
- private_zone
        If set to true, the private zone matching the requested name within the domain will be used if there are both
        public and private zones. The default is to use the public zone.
        [Default: False]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
= record
        The full DNS record to create or delete

- region
        Latency-based resource record sets only Among resource record sets that have the same combination of DNS name and
        type, a value that determines which region this should be associated with for the latency-based routing
        [Default: None]
- retry_interval
        In the case that route53 is still servicing a prior request, this module will wait and try again after this many
        seconds. If you have many domain names, the default of 500 seconds may be too long.
        [Default: 500]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- ttl
        The TTL to give the new record
        [Default: 3600 (one hour)]
= type
        The type of DNS record to create
        (Choices: A, CNAME, MX, AAAA, TXT, PTR, SRV, SPF, NS, SOA)
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- value
        The new value when creating a DNS record.  Multiple comma-spaced values are allowed for non-alias records.  When
        deleting a record all values for the record must be specified or Route53 will not delete it.
        [Default: None]
- vpc_id
        When used in conjunction with private_zone: true, this will only modify records in the private hosted zone
        attached to this VPC.
        This allows you to have multiple private hosted zones, all with the same name, attached to different VPCs.
        [Default: None]
- wait
        Wait until the changes have been replicated to all Amazon Route 53 DNS servers.
        [Default: False]
- wait_timeout
        How long to wait for the changes to be replicated, in seconds.
        [Default: 300]
- weight
        Weighted resource record sets only. Among resource record sets that have the same combination of DNS name and
        type, a value that determines what portion of traffic for the current resource record set is routed to the
        associated location.
        [Default: None]
= zone
        The DNS zone to modify

Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Add new.foo.com as an A record with 3 IPs and wait until the changes have been replicated
- route53:
      command: create
      zone: foo.com
      record: new.foo.com
      type: A
      ttl: 7200
      value: 1.1.1.1,2.2.2.2,3.3.3.3
      wait: yes

# Retrieve the details for new.foo.com
- route53:
      command: get
      zone: foo.com
      record: new.foo.com
      type: A
  register: rec

# Delete new.foo.com A record using the results from the get command
- route53:
      command: delete
      zone: foo.com
      record: "{{ rec.set.record }}"
      ttl: "{{ rec.set.ttl }}"
      type: "{{ rec.set.type }}"
      value: "{{ rec.set.value }}"

# Add an AAAA record.  Note that because there are colons in the value
# that the entire parameter list must be quoted:
- route53:
      command: "create"
      zone: "foo.com"
      record: "localhost.foo.com"
      type: "AAAA"
      ttl: "7200"
      value: "::1"

# Add a SRV record with multiple fields for a service on port 22222
# For more information on SRV records see:
# https://en.wikipedia.org/wiki/SRV_record
- route53:
      command: "create"
      "zone": "foo.com"
      "record": "_example-service._tcp.foo.com"
      "type": "SRV"
      "value": "0 0 22222 host1.foo.com,0 0 22222 host2.foo.com"

# Add a TXT record. Note that TXT and SPF records must be surrounded
# by quotes when sent to Route 53:
- route53:
      command: "create"
      zone: "foo.com"
      record: "localhost.foo.com"
      type: "TXT"
      ttl: "7200"
      value: '"bar"'

# Add an alias record that points to an Amazon ELB:
- route53:
    command: create
    zone: foo.com
    record: elb.foo.com
    type: A
    value: "{{ elb_dns_name }}"
    alias: True
    alias_hosted_zone_id: "{{ elb_zone_id }}"

# Retrieve the details for elb.foo.com
- route53:
      command: get
      zone: foo.com
      record: elb.foo.com
      type: A
  register: rec

# Delete an alias record using the results from the get command
- route53:
      command: delete
      zone: foo.com
      record: "{{ rec.set.record }}"
      ttl: "{{ rec.set.ttl }}"
      type: "{{ rec.set.type }}"
      value: "{{ rec.set.value }}"
      alias: True
      alias_hosted_zone_id: "{{ rec.set.alias_hosted_zone_id }}"

# Add an alias record that points to an Amazon ELB and evaluates it health:
- route53:
    command: create
    zone: foo.com
    record: elb.foo.com
    type: A
    value: "{{ elb_dns_name }}"
    alias: True
    alias_hosted_zone_id: "{{ elb_zone_id }}"
    alias_evaluate_target_health: True

# Add an AAAA record with Hosted Zone ID.  Note that because there are colons in the value
# that the entire parameter list must be quoted:
- route53:
      command: "create"
      zone: "foo.com"
      hosted_zone_id: "Z2AABBCCDDEEFF"
      record: "localhost.foo.com"
      type: "AAAA"
      ttl: "7200"
      value: "::1"

# Add an AAAA record with Hosted Zone ID.  Note that because there are colons in the value
# that the entire parameter list must be quoted:
- route53:
      command: "create"
      zone: "foo.com"
      hosted_zone_id: "Z2AABBCCDDEEFF"
      record: "localhost.foo.com"
      type: "AAAA"
      ttl: "7200"
      value: "::1"

# Use a routing policy to distribute traffic:
- route53:
      command: "create"
      zone: "foo.com"
      record: "www.foo.com"
      type: "CNAME"
      value: "host1.foo.com"
      ttl: 30
      # Routing policy
      identifier: "host1@www"
      weight: 100
      health_check: "d994b780-3150-49fd-9205-356abdd42e75"



MAINTAINERS: Mike Buzzetti <mike.buzzetti@gmail.com>, Bruce Pennypacker (@bpennypacker)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> ROUTE53_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/route53_facts.py)

  Gets various details related to Route53 zone, record set or health check details

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- change_id
        The ID of the change batch request. The value that you specify here is the value that ChangeResourceRecordSets
        returned in the Id element when you submitted the request.
        [Default: (null)]
- delegation_set_id
        The DNS Zone delegation set ID
        [Default: (null)]
- dns_name
        The first name in the lexicographic ordering of domain names that you want the list_command to start listing from
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- health_check_id
        The ID of the health check
        [Default: (null)]
- health_check_method
        This is used in conjunction with query: health_check. It allows for listing details, counts or tags of various
        health check details.
        (Choices: list, details, status, failure_reason, count, tags)[Default: list]
- hosted_zone_id
        The Hosted Zone ID of the DNS zone
        [Default: (null)]
- hosted_zone_method
        This is used in conjunction with query: hosted_zone. It allows for listing details, counts or tags of various
        hosted zone details.
        (Choices: details, list, list_by_name, count, tags)[Default: list]
- max_items
        Maximum number of items to return for various get/list requests
        [Default: (null)]
- next_marker
        Some requests such as list_command: hosted_zones will return a maximum number of entries - EG 100. If the number
        of entries exceeds this maximum another request can be sent using the NextMarker entry from the first response to
        get the next page of results
        [Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
= query
        specifies the query action to take
        (Choices: change, checker_ip_range, health_check, hosted_zone, record_sets, reusable_delegation_set)
- resource_id
        The ID/s of the specified resource/s
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- start_record_name
        The first name in the lexicographic ordering of domain names that you want the list_command: record_sets to start
        listing from
        [Default: (null)]
- type
        The type of DNS record
        (Choices: A, CNAME, MX, AAAA, TXT, PTR, SRV, SPF, NS)[Default: (null)]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Simple example of listing all hosted zones
- name: List all hosted zones
  route53_facts:
    query: hosted_zone
  register: hosted_zones

# Getting a count of hosted zones
- name: Return a count of all hosted zones
  route53_facts:
    query: hosted_zone
    hosted_zone_method: count
  register: hosted_zone_count

- name: List the first 20 resource record sets in a given hosted zone
  route53_facts:
    profile: account_name
    query: record_sets
    hosted_zone_id: ZZZ1111112222
    max_items: 20
  register: record_sets

- name: List first 20 health checks
  route53_facts:
    query: health_check
    health_check_method: list
    max_items: 20
  register: health_checks

- name: Get health check last failure_reason
  route53_facts:
    query: health_check
    health_check_method: failure_reason
    health_check_id: 00000000-1111-2222-3333-12345678abcd
  register: health_check_failure_reason

- name: Retrieve reusable delegation set details
  route53_facts:
    query: reusable_delegation_set
    delegation_set_id: delegation id
  register: delegation_sets



MAINTAINERS: Karen Cheng(@Etherdaemon)

METADATA:
	Status: ['preview']
	Supported_by: community
> ROUTE53_HEALTH_CHECK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/route53_health_check.py)

  Creates and deletes DNS Health checks in Amazons Route53 service Only the port, resource_path, string_match and
  request_interval are considered when updating existing health-checks.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= failure_threshold
        The number of consecutive health checks that an endpoint must pass or fail for Amazon Route 53 to change the
        current status of the endpoint from unhealthy to healthy or vice versa.
        (Choices: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)[Default: 3]
- fqdn
        Domain name of the endpoint to check. Either this or `ip_address` has to be provided. When both are given the
        `fqdn` is used in the `Host:` header of the HTTP request.
        [Default: (null)]
- ip_address
        IP address of the end-point to check. Either this or `fqdn` has to be provided.
        [Default: None]
- port
        The port on the endpoint on which you want Amazon Route 53 to perform health checks. Required for TCP checks.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
= request_interval
        The number of seconds between the time that Amazon Route 53 gets a response from your endpoint and the time that
        it sends the next health-check request.
        (Choices: 10, 30)[Default: 30]
- resource_path
        The path that you want Amazon Route 53 to request when performing health checks. The path can be any value for
        which your endpoint will return an HTTP status code of 2xx or 3xx when the endpoint is healthy, for example the
        file /docs/route53-health-check.html.
        Required for all checks except TCP.
        The path must begin with a /
        Maximum 255 characters.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
= state
        Specifies the action to take.
        (Choices: present, absent)
- string_match
        If the check type is HTTP_STR_MATCH or HTTP_STR_MATCH, the string that you want Amazon Route 53 to search for in
        the response body from the specified resource. If the string appears in the first 5120 bytes of the response
        body, Amazon Route 53 considers the resource healthy.
        [Default: None]
= type
        The type of health check that you want to create, which indicates how Amazon Route 53 determines whether an
        endpoint is healthy.
        (Choices: HTTP, HTTPS, HTTP_STR_MATCH, HTTPS_STR_MATCH, TCP)
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Create a health-check for host1.example.com and use it in record
- route53_health_check:
    state: present
    fqdn: host1.example.com
    type: HTTP_STR_MATCH
    resource_path: /
    string_match: "Hello"
    request_interval: 10
    failure_threshold: 2
  register: my_health_check

- route53:
    action: create
    zone: "example.com"
    type: CNAME
    record: "www.example.com"
    value: host1.example.com
    ttl: 30
    # Routing policy
    identifier: "host1@www"
    weight: 100
    health_check: "{{ my_health_check.health_check.id }}"

# Delete health-check
- route53_health_check:
    state: absent
    fqdn: host1.example.com



MAINTAINERS: zimbatm (@zimbatm)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> ROUTE53_ZONE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/route53_zone.py)

  Creates and deletes Route53 private and public zones

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- comment
        Comment associated with the zone
        [Default: ]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        whether or not the zone should exist or not
        (Choices: present, absent)[Default: True]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- vpc_id
        The VPC ID the zone should be a part of (if this is going to be a private zone)
        [Default: None]
- vpc_region
        The VPC Region the zone should be a part of (if this is going to be a private zone)
        [Default: None]
= zone
        The DNS zone record (eg: foo.com.)

Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# create a public zone
- route53_zone:
    zone: example.com
    state: present
    comment: this is an example

# delete a public zone
- route53_zone:
    zone: example.com
    state: absent

- name: private zone for devel
  route53_zone:
    zone: devel.example.com
    state: present
    vpc_id: '{{ myvpc_id }}'
    comment: developer domain

# more complex example
- name: register output after creating zone in parameterized region
  route53_zone:
    vpc_id: '{{ vpc.vpc_id }}'
    vpc_region: '{{ ec2_region }}'
    zone: '{{ vpc_dns_zone }}'
    state: present
  register: zone_out

- debug:
    var: zone_out

RETURN VALUES:
comment:
    description: optional hosted zone comment
    returned: when hosted zone exists
    type: string
    sample: "Private zone"
name:
    description: hosted zone name
    returned: when hosted zone exists
    type: string
    sample: "private.local."
private_zone:
    description: whether hosted zone is private or public
    returned: when hosted zone exists
    type: bool
    sample: true
vpc_id:
    description: id of vpc attached to private hosted zone
    returned: for private hosted zone
    type: string
    sample: "vpc-1d36c84f"
vpc_region:
    description: region of vpc attached to private hosted zone
    returned: for private hosted zone
    type: string
    sample: "eu-west-1"
zone_id:
    description: hosted zone id
    returned: when hosted zone exists
    type: string
    sample: "Z6JQG9820BEFMW"


MAINTAINERS: Christopher Troup (@minichate)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> RPM_KEY    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/rpm_key.py)

  Adds or removes (rpm --import) a gpg key to your rpm database.

Options (= is mandatory):

= key
        Key that will be modified. Can be a url, a file, or a keyid if the key already exists in the database.
        [Default: None]
- state
        If the key will be imported or removed from the rpm db.
        (Choices: present, absent)[Default: present]
- validate_certs
        If `no' and the `key' is a url starting with https, SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
# Example action to import a key from a url
- rpm_key:
    state: present
    key: http://apt.sw.be/RPM-GPG-KEY.dag.txt

# Example action to import a key from a file
- rpm_key:
    state: present
    key: /path/to/key.gpg

# Example action to ensure a key is not present in the db
- rpm_key:
    state: absent
    key: DEADB33F


MAINTAINERS: Hector Acosta (@hacosta) <hector.acosta@gazzang.com>

METADATA:
	Status: ['preview']
	Supported_by: core
> RUNIT    (/usr/lib/python2.7/site-packages/ansible/modules/system/runit.py)

  Controls runit services on remote hosts using the sv utility.

Options (= is mandatory):

- enabled
        Wheater the service is enabled or not, if disabled it also implies stopped.
        (Choices: yes, no)[Default: (null)]
= name
        Name of the service to manage.

- service_dir
        directory runsv watches for services
        [Default: /var/service]
- service_src
        directory where services are defined, the source of symlinks to service_dir.
        [Default: /etc/sv]
- state
        `started'/`stopped' are idempotent actions that will not run commands unless necessary.  `restarted' will always
        bounce the service (sv restart) and `killed' will always bounce the service (sv force-stop). `reloaded' will send
        a HUP (sv reload). `once' will run a normally downed sv once (sv once), not really an idempotent operation.
        (Choices: started, stopped, restarted, killed, reloaded, once)[Default: (null)]
EXAMPLES:
# Example action to start sv dnscache, if not running
 - sv:
    name: dnscache
    state: started

# Example action to stop sv dnscache, if running
 - sv:
    name: dnscache
    state: stopped

# Example action to kill sv dnscache, in all cases
 - sv:
    name: dnscache
    state: killed

# Example action to restart sv dnscache, in all cases
 - sv:
    name: dnscache
    state: restarted

# Example action to reload sv dnscache, in all cases
 - sv:
    name: dnscache
    state: reloaded

# Example using alt sv directory location
 - sv:
    name: dnscache
    state: reloaded
    service_dir: /run/service


MAINTAINERS: James Sumners (@jsumners)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> S3    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/s3.py)

  This module allows the user to manage S3 buckets and the objects within them. Includes support for creating and
  deleting both objects and buckets, retrieving objects as files or strings and generating download links. This module
  has a dependency on python-boto.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
= bucket
        Bucket name.
        [Default: None]
- dest
        The destination file path when downloading an object/key with a GET operation.
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- encrypt
        When set for PUT mode, asks for server-side encryption
        [Default: False]
- expiration
        Time limit (in seconds) for the URL generated and returned by S3/Walrus when performing a mode=put or mode=geturl
        operation.
        [Default: 600]
- headers
        Custom headers for PUT operation, as a dictionary of 'key=value' and 'key=value,key=value'.
        [Default: None]
- ignore_nonexistent_bucket
        Overrides initial bucket lookups in case bucket or iam policies are restrictive. Example: a user may have the
        GetObject permission but no other permissions. In this case using the option mode: get will fail without
        specifying ignore_nonexistent_bucket: True.
        [Default: False]
- marker
        Specifies the key to start with when using list mode. Object keys are returned in alphabetical order, starting
        with key after the marker in order.
        [Default: None]
- max_keys
        Max number of results to return in list mode, set this if you want to retrieve fewer than the default 1000 keys.
        [Default: 1000]
- metadata
        Metadata for PUT operation, as a dictionary of 'key=value' and 'key=value,key=value'.
        [Default: None]
= mode
        Switches the module behaviour between put (upload), get (download), geturl (return download url, Ansible 1.3+),
        getstr (download object as string (1.3+)), list (list keys, Ansible 2.0+), create (bucket), delete (bucket), and
        delobj (delete object, Ansible 2.0+).
        (Choices: get, put, delete, create, geturl, getstr, delobj, list)
- object
        Keyname of the object inside the bucket. Can be used to create "virtual directories", see examples.
        [Default: None]
- overwrite
        Force overwrite either locally on the filesystem or remotely with the object/key. Used with PUT and GET
        operations. Boolean or one of [always, never, different], true is equal to 'always' and false is equal to
        'never', new in 2.0
        [Default: always]
- permission
        This option lets the user set the canned permissions on the object/bucket that are created. The permissions that
        can be set are 'private', 'public-read', 'public-read-write', 'authenticated-read'. Multiple permissions can be
        specified as a list.
        [Default: private]
- prefix
        Limits the response to keys that begin with the specified prefix for list mode
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        AWS region to create the bucket in. If not set then the value of the AWS_REGION and EC2_REGION environment
        variables are checked, followed by the aws_region and ec2_region settings in the Boto config file.  If none of
        those are set the region defaults to the S3 Location: US Standard.  Prior to ansible 1.8 this parameter could be
        specified but had no effect.
        [Default: None]
- retries
        On recoverable failure, how many times to retry before actually failing.
        [Default: 0]
- rgw
        Enable Ceph RGW S3 support. This option requires an explicit url via s3_url.
        [Default: False]
- s3_url
        S3 URL endpoint for usage with Ceph, Eucalypus, fakes3, etc.  Otherwise assumes AWS
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- src
        The source file path when performing a PUT operation.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- version
        Version ID of the object inside the bucket. Can be used to get a specific version of a file if versioning is
        enabled in the target bucket.
        [Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, python >= 2.6

EXAMPLES:
- name: Simple PUT operation
  s3:
    bucket: mybucket
    object: /my/desired/key.txt
    src: /usr/local/myfile.txt
    mode: put

- name: Simple PUT operation in Ceph RGW S3
  s3:
    bucket: mybucket
    object: /my/desired/key.txt
    src: /usr/local/myfile.txt
    mode: put
    rgw: true
    s3_url: "http://localhost:8000"

- name: Simple GET operation
  s3:
    bucket: mybucket
    object: /my/desired/key.txt
    dest: /usr/local/myfile.txt
    mode: get

- name: Get a specific version of an object.
  s3:
    bucket: mybucket
    object: /my/desired/key.txt
    version: 48c9ee5131af7a716edc22df9772aa6f
    dest: /usr/local/myfile.txt
    mode: get

- name: PUT/upload with metadata
  s3:
    bucket: mybucket
    object: /my/desired/key.txt
    src: /usr/local/myfile.txt
    mode: put
    metadata: 'Content-Encoding=gzip,Cache-Control=no-cache'

- name: PUT/upload with custom headers
  s3:
    bucket: mybucket
    object: /my/desired/key.txt
    src: /usr/local/myfile.txt
    mode: put
    headers: 'x-amz-grant-full-control=emailAddress=owner@example.com'

- name: List keys simple
  s3:
    bucket: mybucket
    mode: list

- name: List keys all options
  s3:
    bucket: mybucket
    mode: list
    prefix: /my/desired/
    marker: /my/desired/0023.txt
    max_keys: 472

- name: Create an empty bucket
  s3:
    bucket: mybucket
    mode: create
    permission: public-read

- name: Create a bucket with key as directory, in the EU region
  s3:
    bucket: mybucket
    object: /my/directory/path
    mode: create
    region: eu-west-1

- name: Delete a bucket and all contents
  s3:
    bucket: mybucket
    mode: delete

- name: GET an object but dont download if the file checksums match. New in 2.0
  s3:
    bucket: mybucket
    object: /my/desired/key.txt
    dest: /usr/local/myfile.txt
    mode: get
    overwrite: different

- name: Delete an object from a bucket
  s3:
    bucket: mybucket
    object: /my/desired/key.txt
    mode: delobj


MAINTAINERS: Lester Wade (@lwade)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> S3_BUCKET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/s3_bucket.py)

  Manage S3 buckets in AWS, Ceph, Walrus and FakeS3

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ceph
        Enable API compatibility with Ceph. It takes into account the S3 API subset working with Ceph in order to provide
        the same module behaviour where possible.
        [Default: (null)]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- force
        When trying to delete a bucket, delete all keys in the bucket first (an s3 bucket must be empty for a successful
        deletion)
        (Choices: yes, no)[Default: False]
= name
        Name of the s3 bucket
        [Default: None]
- policy
        The JSON policy as a string.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- requester_pays
        With Requester Pays buckets, the requester instead of the bucket owner pays the cost of the request and the data
        download from the bucket.
        (Choices: yes, no)[Default: False]
- s3_url
        S3 URL endpoint for usage with Ceph, Eucalypus, fakes3, etc. Otherwise assumes AWS
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or remove the s3 bucket
        (Choices: present, absent)[Default: present]
- tags
        tags dict to apply to bucket
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
- versioning
        Whether versioning is enabled or disabled (note that once versioning is enabled, it can only be suspended)
        (Choices: yes, no)[Default: None]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Create a simple s3 bucket
- s3_bucket:
    name: mys3bucket

# Create a simple s3 bucket on Ceph Rados Gateway
- s3_bucket:
    name: mys3bucket
    s3_url: http://your-ceph-rados-gateway-server.xxx
    ceph: true

# Remove an s3 bucket and any keys it contains
- s3_bucket:
    name: mys3bucket
    state: absent
    force: yes

# Create a bucket, add a policy from a file, enable requester pays, enable versioning and tag
- s3_bucket:
    name: mys3bucket
    policy: "{{ lookup('file','policy.json') }}"
    requester_pays: yes
    versioning: yes
    tags:
      example: tag1
      another: tag2



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> S3_LIFECYCLE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/s3_lifecycle.py)

  Manage s3 bucket lifecycle rules in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- expiration_date
        Indicates the lifetime of the objects that are subject to the rule by the date they will expire. The value must
        be ISO-8601 format, the time must be midnight and a GMT timezone must be specified.
        [Default: None]
- expiration_days
        Indicates the lifetime, in days, of the objects that are subject to the rule. The value must be a non-zero
        positive integer.
        [Default: None]
= name
        Name of the s3 bucket

- prefix
        Prefix identifying one or more objects to which the rule applies.  If no prefix is specified, the rule will apply
        to the whole bucket.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- rule_id
        Unique identifier for the rule. The value cannot be longer than 255 characters. A unique value for the rule will
        be generated if no value is provided.
        [Default: None]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or remove the lifecycle rule
        (Choices: present, absent)[Default: present]
- status
        If 'enabled', the rule is currently being applied. If 'disabled', the rule is not currently being applied.
        (Choices: enabled, disabled)[Default: enabled]
- storage_class
        The storage class to transition to. Currently there are two supported values - 'glacier' or 'standard_ia'.
        The 'standard_ia' class is only being available from Ansible version 2.2.
        (Choices: glacier, standard_ia)[Default: glacier]
- transition_date
        Indicates the lifetime of the objects that are subject to the rule by the date they will transition to a
        different storage class. The value must be ISO-8601 format, the time must be midnight and a GMT timezone must be
        specified. If transition_days is not specified, this parameter is required.
        [Default: None]
- transition_days
        Indicates when, in days, an object transitions to a different storage class. If transition_date is not specified,
        this parameter is required.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If specifying expiration time as days then transition time must also be specified in days
  * If specifying expiration time as a date then transition time must also be specified as a date
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, python >= 2.6, python-dateutil

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Configure a lifecycle rule on a bucket to expire (delete) items with a prefix of /logs/ after 30 days
- s3_lifecycle:
    name: mybucket
    expiration_days: 30
    prefix: /logs/
    status: enabled
    state: present

# Configure a lifecycle rule to transition all items with a prefix of /logs/ to glacier after 7 days and then delete after 90 days
- s3_lifecycle:
    name: mybucket
    transition_days: 7
    expiration_days: 90
    prefix: /logs/
    status: enabled
    state: present

# Configure a lifecycle rule to transition all items with a prefix of /logs/ to glacier on 31 Dec 2020 and then delete on 31 Dec 2030. Note that midnight GMT must be specified.
# Be sure to quote your date strings
- s3_lifecycle:
    name: mybucket
    transition_date: "2020-12-30T00:00:00.000Z"
    expiration_date: "2030-12-30T00:00:00.000Z"
    prefix: /logs/
    status: enabled
    state: present

# Disable the rule created above
- s3_lifecycle:
    name: mybucket
    prefix: /logs/
    status: disabled
    state: present

# Delete the lifecycle rule created above
- s3_lifecycle:
    name: mybucket
    prefix: /logs/
    state: absent

# Configure a lifecycle rule to transition all backup files older than 31 days in /backups/ to standard infrequent access class.
- s3_lifecycle:
    name: mybucket
    prefix: /backups/
    storage_class: standard_ia
    transition_days: 31
    state: present
    status: enabled



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> S3_LOGGING    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/s3_logging.py)

  Manage logging facility of an s3 bucket in AWS

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= name
        Name of the s3 bucket.

- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Enable or disable logging.
        (Choices: present, absent)[Default: present]
- target_bucket
        The bucket to log to. Required when state=present.
        [Default: None]
- target_prefix
        The prefix that should be prepended to the generated log files written to the target_bucket.
        [Default: ]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

- name: Enable logging of s3 bucket mywebsite.com to s3 bucket mylogs
  s3_logging:
    name: mywebsite.com
    target_bucket: mylogs
    target_prefix: logs/mywebsite.com
    state: present

- name: Remove logging on an s3 bucket
  s3_logging:
    name: mywebsite.com
    state: absent



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> S3_SYNC    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/s3_sync.py)

  The S3 module is great, but it is very slow for a large volume of files- even a dozen will be noticeable. In addition
  to speed, it handles globbing, inclusions/exclusions, mime types, expiration mapping, recursion, and smart directory
  mapping.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
= bucket
        Bucket name.

- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- exclude
        Shell pattern-style file matching.
        Used after include to remove files (for instance, skip "*.txt")
        For multiple patterns, comma-separate them.
        [Default: .*]
- file_change_strategy
        Difference determination method to allow changes-only syncing. Unlike rsync, files are not patched- they are
        fully skipped or fully uploaded.
        date_size will upload if file sizes don't match or if local file modified date is newer than s3's version
        checksum will compare etag values based on s3's implementation of chunked md5s.
        force will always upload all files.
        (Choices: force, checksum, date_size)[Default: date_size]
= file_root
        File/directory path for synchronization. This is a local path.
        This root path is scrubbed from the key name, so subdirectories will remain as keys.

- include
        Shell pattern-style file matching.
        Used before exclude to determine eligible files (for instance, only "*.gif")
        For multiple patterns, comma-separate them.
        [Default: *]
- key_prefix
        In addition to file path, prepend s3 path with this prefix. Module will add slash at end of prefix if necessary.
        [Default: (null)]
- mime_map
        Dict entry from extension to MIME type. This will override any default/sniffed MIME type. For example `{".txt":
        "application/text", ".yml": "appication/text"}'
        [Default: (null)]
= mode
        sync direction.
        (Choices: push)[Default: push]
- permission
        Canned ACL to apply to synced files.
        Changing this ACL only changes newly synced files, it does not trigger a full reupload.
        (Choices: , private, public-read, public-read-write, authenticated-read, aws-exec-read, bucket-owner-read,
        bucket-owner-full-control)[Default: (null)]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
- name: basic upload
  s3_sync:
    bucket: tedder
    file_root: roles/s3/files/

- name: all the options
  s3_sync:
    bucket: tedder
    file_root: roles/s3/files
    mime_map:
      .yml: application/text
      .json: application/text
    key_prefix: config_files/web
    file_change_strategy: force
    permission: public-read
    include: "*"
    exclude: "*.txt,.*"

RETURN VALUES:
filelist_initial:
  description: file listing (dicts) from inital globbing
  returned: always
  type: list
  sample: [{
                "bytes": 151,
                "chopped_path": "policy.json",
                "fullpath": "roles/cf/files/policy.json",
                "modified_epoch": 1477416706
           }]
filelist_local_etag:
  description: file listing (dicts) including calculated local etag
  returned: always
  type: list
  sample: [{
                "bytes": 151,
                "chopped_path": "policy.json",
                "fullpath": "roles/cf/files/policy.json",
                "mime_type": "application/json",
                "modified_epoch": 1477416706,
                "s3_path": "s3sync/policy.json"
           }]
filelist_s3:
  description: file listing (dicts) including information about previously-uploaded versions
  returned: always
  type: list
  sample: [{
                "bytes": 151,
                "chopped_path": "policy.json",
                "fullpath": "roles/cf/files/policy.json",
                "mime_type": "application/json",
                "modified_epoch": 1477416706,
                "s3_path": "s3sync/policy.json"
           }]
filelist_typed:
  description: file listing (dicts) with calculated or overridden mime types
  returned: always
  type: list
  sample: [{
                "bytes": 151,
                "chopped_path": "policy.json",
                "fullpath": "roles/cf/files/policy.json",
                "mime_type": "application/json",
                "modified_epoch": 1477416706
           }]
filelist_actionable:
  description: file listing (dicts) of files that will be uploaded after the strategy decision
  returned: always
  type: list
  sample: [{
                "bytes": 151,
                "chopped_path": "policy.json",
                "fullpath": "roles/cf/files/policy.json",
                "mime_type": "application/json",
                "modified_epoch": 1477931256,
                "s3_path": "s3sync/policy.json",
                "whysize": "151 / 151",
                "whytime": "1477931256 / 1477929260"
           }]
uploaded:
  description: file listing (dicts) of files that were actually uploaded
  returned: always
  type: list
  sample: [{
                "bytes": 151,
                "chopped_path": "policy.json",
                "fullpath": "roles/cf/files/policy.json",
                "s3_path": "s3sync/policy.json",
                "whysize": "151 / 151",
                "whytime": "1477931637 / 1477931489"
           }]



MAINTAINERS: tedder

METADATA:
	Status: ['preview']
	Supported_by: community
> S3_WEBSITE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/s3_website.py)

  Configure an s3 bucket as a website

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- error_key
        The object key name to use when a 4XX class error occurs. To remove an error key, set to None.
        [Default: None]
= name
        Name of the s3 bucket
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- redirect_all_requests
        Describes the redirect behavior for every request to this s3 bucket website endpoint
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Add or remove s3 website configuration
        (Choices: present, absent)[Default: present]
- suffix
        Suffix that is appended to a request that is for a directory on the website endpoint (e.g. if the suffix is
        index.html and you make a request to samplebucket/images/ the data that is returned will be for the object with
        the key name images/index.html). The suffix must not include a slash character.
        [Default: index.html]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Configure an s3 bucket to redirect all requests to example.com
- s3_website:
    name: mybucket.com
    redirect_all_requests: example.com
    state: present

# Remove website configuration from an s3 bucket
- s3_website:
    name: mybucket.com
    state: absent

# Configure an s3 bucket as a website with index and error pages
- s3_website:
    name: mybucket.com
    suffix: home.htm
    error_key: errors/404.htm
    state: present


RETURN VALUES:
index_document:
  suffix:
    description: suffix that is appended to a request that is for a directory on the website endpoint
    returned: success
    type: string
    sample: index.html
error_document:
  key:
    description:  object key name to use when a 4XX class error occurs
    returned: when error_document parameter set
    type: string
    sample: error.html
redirect_all_requests_to:
  host_name:
    description: name of the host where requests will be redirected.
    returned: when redirect all requests parameter set
    type: string
    sample: ansible.com
routing_rules:
  routing_rule:
    host_name:
      description: name of the host where requests will be redirected.
      returned: when host name set as part of redirect rule
      type: string
      sample: ansible.com
    condition:
      key_prefix_equals:
        description: object key name prefix when the redirect is applied. For example, to redirect requests for ExamplePage.html, the key prefix will be ExamplePage.html
        returned: when routing rule present
        type: string
        sample: docs/
    redirect:
      replace_key_prefix_with:
        description: object key prefix to use in the redirect request
        returned: when routing rule present
        type: string
        sample: documents/



MAINTAINERS: Rob White (@wimnat)

METADATA:
	Status: ['preview']
	Supported_by: community
> SCRIPT    (/usr/lib/python2.7/site-packages/ansible/modules/commands/script.py)

  The `script' module takes the script name followed by a list of space-delimited arguments.  The local script at path
  will be transferred to the remote node and then executed.  The given script will be processed through the shell
  environment on the remote node.  This module does not require python on the remote system, much like the [raw] module.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- creates
        a filename, when it already exists, this step will *not* be run.
        [Default: None]
= free_form
        path to the local script file followed by optional arguments. There is no parameter actually named 'free form';
        see the examples!
        [Default: None]
- removes
        a filename, when it does not exist, this step will *not* be run.
        [Default: None]
Notes:
  * It is usually preferable to write Ansible modules than pushing scripts. Convert your script to an Ansible
        module for bonus points!
  * The ssh connection plugin will force psuedo-tty allocation via -tt when scripts are executed. psuedo-ttys do
        not have a stderr channel and all stderr is sent to stdout. If you depend on separated stdout and stderr
        result keys, please switch to a copy+command set of tasks instead of using script.
EXAMPLES:
# Example from Ansible Playbooks
- script: /some/local/script.sh --some-arguments 1234

# Run a script that creates a file, but only if the file is not yet created
- script: /some/local/create_file.sh --some-arguments 1234
  args:
    creates: /the/created/file.txt

# Run a script that removes a file, but only if the file is not yet removed
- script: /some/local/remove_file.sh --some-arguments 1234
  args:
    removes: /the/removed/file.txt


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SEBOOLEAN    (/usr/lib/python2.7/site-packages/ansible/modules/system/seboolean.py)

  Toggles SELinux booleans.

Options (= is mandatory):

= name
        Name of the boolean to configure
        [Default: None]
- persistent
        Set to `yes' if the boolean setting should survive a reboot
        (Choices: yes, no)[Default: False]
= state
        Desired boolean value
        (Choices: yes, no)[Default: None]
Notes:
  * Not tested on any debian based system
Requirements:  libselinux-python, libsemanage-python

EXAMPLES:
# Set (httpd_can_network_connect) flag on and keep it persistent across reboots
- seboolean:
    name: httpd_can_network_connect
    state: yes
    persistent: yes


MAINTAINERS: Stephen Fromm (@sfromm)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SEFCONTEXT    (/usr/lib/python2.7/site-packages/ansible/modules/system/sefcontext.py)

  Manages SELinux file context mapping definitions Similar to the `semanage fcontext' command

Options (= is mandatory):

- ftype
        File type.
        [Default: a]
- reload
        Reload SELinux policy after commit.
        [Default: True]
- selevel
        SELinux range for the specified target.
        [Default: None]
= setype
        SELinux type for the specified target.
        [Default: None]
- seuser
        SELinux user for the specified target.
        [Default: None]
- state
        Desired boolean value.
        (Choices: present, absent)[Default: present]
= target
        Target path (expression).
        [Default: None]
Notes:
  * The changes are persistent across reboots
Requirements:  libselinux-python, policycoreutils-python

EXAMPLES:
# Allow apache to modify files in /srv/git_repos
- sefcontext:
    target: '/srv/git_repos(/.*)?'
    setype: httpd_git_rw_content_t
    state: present

RETURN VALUES:
# Default return values


MAINTAINERS: Dag Wieers

METADATA:
	Status: ['preview']
	Supported_by: community
> SELINUX    (/usr/lib/python2.7/site-packages/ansible/modules/system/selinux.py)

  Configures the SELinux mode and policy. A reboot may be required after usage. Ansible will not issue this reboot but
  will let you know when it is required.

Options (= is mandatory):

- conf
        path to the SELinux configuration file, if non-standard
        [Default: /etc/selinux/config]
- policy
        name of the SELinux policy to use (example: `targeted') will be required if state is not `disabled'
        [Default: None]
= state
        The SELinux mode
        (Choices: enforcing, permissive, disabled)[Default: None]
Notes:
  * Not tested on any debian based system
Requirements:  libselinux-python

EXAMPLES:
# Enable SELinux
- selinux:
    policy: targeted
    state: enforcing

# Put SELinux in permissive mode, logging actions that would be blocked.
- selinux:
    policy: targeted
    state: permissive

# Disable SELinux
- selinux:
    state: disabled


MAINTAINERS: Derek Carter (@goozbach) <goozbach@friocorte.com>

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SELINUX_PERMISSIVE    (/usr/lib/python2.7/site-packages/ansible/modules/system/selinux_permissive.py)

  Add and remove domain from the list of permissive domain.

Options (= is mandatory):

= domain
        the domain that will be added or removed from the list of permissive domains

- no_reload
        automatically reload the policy after a change
        default is set to 'false' as that's what most people would want after changing one domain
        Note that this doesn't work on older version of the library (example EL 6), the module will silently ignore it in
        this case
        (Choices: True, False)[Default: False]
= permissive
        indicate if the domain should or should not be set as permissive
        (Choices: True, False)
- store
        name of the SELinux policy store to use
        [Default: None]
Notes:
  * Requires a version of SELinux recent enough ( ie EL 6 or newer )
Requirements:  policycoreutils-python

EXAMPLES:
- selinux_permissive:
    name: httpd_t
    permissive: true


MAINTAINERS: Michael Scherer <misc@zarb.org>

METADATA:
	Status: ['preview']
	Supported_by: community
> SENDGRID    (/usr/lib/python2.7/site-packages/ansible/modules/notification/sendgrid.py)

  Sends an email with a SendGrid account through their API, not through the SMTP service.

Options (= is mandatory):

- api_key
        sendgrid API key to use instead of username/password
        [Default: None]
- attachments
        a list of relative or explicit paths of files you want to attach (7MB limit as per SendGrid docs)
        [Default: None]
- bcc
        a list of email addresses to bcc
        [Default: None]
- cc
        a list of email addresses to cc
        [Default: None]
= from_address
        the address in the "from" field for the email

- from_name
        the name you want to appear in the from field, i.e 'John Doe'
        [Default: None]
- headers
        a dict to pass on as headers
        [Default: None]
- html_body
        whether the body is html content that should be rendered
        [Default: False]
- password
        password that corresponds to the username
        Since 2.2 it is only required if api_key is not supplied.
        [Default: None]
= subject
        the desired subject for the email

= to_addresses
        a list with one or more recipient email addresses

- username
        username for logging into the SendGrid account.
        Since 2.2 it is only required if api_key is not supplied.
        [Default: None]
Notes:
  * This module is non-idempotent because it sends an email through the external API. It is idempotent only in the
        case that the module fails.
  * Like the other notification modules, this one requires an external dependency to work. In this case, you'll
        need an active SendGrid account.
  * In order to use api_key, cc, bcc, attachments, from_name, html_body, headers you must pip install sendgrid
  * since 2.2 username and password are not required if you supply an api_key
Requirements:  sendgrid python library

EXAMPLES:
# send an email to a single recipient that the deployment was successful
- sendgrid:
    username: "{{ sendgrid_username }}"
    password: "{{ sendgrid_password }}"
    from_address: "ansible@mycompany.com"
    to_addresses:
      - "ops@mycompany.com"
    subject: "Deployment success."
    body: "The most recent Ansible deployment was successful."
  delegate_to: localhost

# send an email to more than one recipient that the build failed
- sendgrid:
      username: "{{ sendgrid_username }}"
      password: "{{ sendgrid_password }}"
      from_address: "build@mycompany.com"
      to_addresses:
        - "ops@mycompany.com"
        - "devteam@mycompany.com"
      subject: "Build failure!."
      body: "Unable to pull source repository from Git server."
  delegate_to: localhost


MAINTAINERS: Matt Makai (@makaimc)

METADATA:
	Status: ['preview']
	Supported_by: community
> SENSU_CHECK    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/sensu_check.py)

  Manage the checks that should be run on a machine by `Sensu'. Most options do not have a default and will not be added
  to the check definition unless specified. All defaults except `path', `state', `backup' and `metric' are not managed by
  this module, they are simply specified for your convenience.

Options (= is mandatory):

- aggregate
        Classifies the check as an aggregate check,
        making it available via the aggregate API
        (Choices: yes, no)[Default: False]
- backup
        Create a backup file (if yes), including the timestamp information so
        you can get the original file back if you somehow clobbered it incorrectly.
        (Choices: yes, no)[Default: False]
= command
        Path to the sensu check to run (not required when `state=absent')

- custom
        A hash/dictionary of custom parameters for mixing to the configuration.
        You can't rewrite others module parameters using this
        [Default: {}]
- dependencies
        Other checks this check depends on, if dependencies fail,
        handling of this check will be disabled
        [Default: []]
- handle
        Whether the check should be handled or not
        (Choices: yes, no)[Default: True]
- handlers
        List of handlers to notify when the check fails
        [Default: []]
- high_flap_threshold
        The high threshhold for flap detection
        [Default: None]
- interval
        Check interval in seconds
        [Default: None]
- low_flap_threshold
        The low threshhold for flap detection
        [Default: None]
- metric
        Whether the check is a metric
        (Choices: yes, no)[Default: False]
= name
        The name of the check
        This is the key that is used to determine whether a check exists

- occurrences
        Number of event occurrences before the handler should take action
        [Default: 1]
- path
        Path to the json file of the check to be added/removed.
        Will be created if it does not exist (unless `state=absent').
        The parent folders need to exist when `state=present', otherwise an error will be thrown
        [Default: /etc/sensu/conf.d/checks.json]
- publish
        Whether the check should be scheduled at all.
        You can still issue it via the sensu api
        (Choices: yes, no)[Default: True]
- refresh
        Number of seconds handlers should wait before taking second action
        [Default: None]
- source
        The check source, used to create a JIT Sensu client for an external resource (e.g. a network switch).
        [Default: None]
- standalone
        Whether the check should be scheduled by the sensu client or server
        This option obviates the need for specifying the `subscribers' option
        (Choices: yes, no)[Default: False]
- state
        Whether the check should be present or not
        (Choices: present, absent)[Default: present]
- subdue_begin
        When to disable handling of check failures
        [Default: None]
- subdue_end
        When to enable handling of check failures
        [Default: None]
- subscribers
        List of subscribers/channels this check should run for
        See sensu_subscribers to subscribe a machine to a channel
        [Default: []]
- timeout
        Timeout for the check
        [Default: 10]
EXAMPLES:
# Fetch metrics about the CPU load every 60 seconds,
# the sensu server has a handler called 'relay' which forwards stats to graphite
- name: get cpu metrics
  sensu_check:
    name: cpu_load
    command: /etc/sensu/plugins/system/cpu-mpstat-metrics.rb
    metric: yes
    handlers: relay
    subscribers: common
    interval: 60

# Check whether nginx is running
- name: check nginx process
  sensu_check:
    name: nginx_running
    command: /etc/sensu/plugins/processes/check-procs.rb -f /var/run/nginx.pid
    handlers: default
    subscribers: nginx
    interval: 60

# Stop monitoring the disk capacity.
# Note that the check will still show up in the sensu dashboard,
# to remove it completely you need to issue a DELETE request to the sensu api.
- name: check disk
  sensu_check:
    name: check_disk_capacity
    state: absent


MAINTAINERS: Anders Ingemann (@andsens)

METADATA:
	Status: ['preview']
	Supported_by: community
> SENSU_SUBSCRIPTION    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/sensu_subscription.py)

  Manage which `sensu channels' a machine should subscribe to

Options (= is mandatory):

- backup
        Create a backup file (if yes), including the timestamp information so you
        can get the original file back if you somehow clobbered it incorrectly.
        (Choices: yes, no)[Default: False]
= name
        The name of the channel

- path
        Path to the subscriptions json file
        [Default: /etc/sensu/conf.d/subscriptions.json]
- state
        Whether the machine should subscribe or unsubscribe from the channel
        (Choices: present, absent)[Default: present]
EXAMPLES:
# Subscribe to the nginx channel
- name: subscribe to nginx checks
  sensu_subscription: name=nginx

# Unsubscribe from the common checks channel
- name: unsubscribe from common checks
  sensu_subscription: name=common state=absent

RETURN VALUES:
reasons:
    description: the reasons why the moule changed or did not change something
    returned: success
    type: list
    sample: ["channel subscription was absent and state is `present'"]


MAINTAINERS: Anders Ingemann

METADATA:
	Status: ['preview']
	Supported_by: community
> SEPORT    (/usr/lib/python2.7/site-packages/ansible/modules/system/seport.py)

  Manages SELinux network port type definitions.

Options (= is mandatory):

= ports
        Ports or port ranges, separated by a comma
        [Default: None]
= proto
        Protocol for the specified port.
        (Choices: tcp, udp)[Default: None]
- reload
        Reload SELinux policy after commit.
        [Default: True]
= setype
        SELinux type for the specified port.
        [Default: None]
= state
        Desired boolean value.
        (Choices: present, absent)[Default: present]
Notes:
  * The changes are persistent across reboots
  * Not tested on any debian based system
Requirements:  libselinux-python, policycoreutils-python

EXAMPLES:
# Allow Apache to listen on tcp port 8888
- seport:
    ports: 8888
    proto: tcp
    setype: http_port_t
    state: present

# Allow sshd to listen on tcp port 8991
- seport:
    ports: 8991
    proto: tcp
    setype: ssh_port_t
    state: present

# Allow memcached to listen on tcp ports 10000-10100 and 10112
- seport:
    ports: 10000-10100,10112
    proto: tcp
    setype: memcache_port_t
    state: present


MAINTAINERS: Dan Keder

METADATA:
	Status: ['preview']
	Supported_by: community
> SERVERLESS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/serverless.py)

  Provides support for managing Serverless Framework (https://serverless.com/) project deployments and stacks.

Options (= is mandatory):

- deploy
        Whether or not to deploy artifacts after building them. When this option is `false` all the functions will be
        built, but no stack update will be run to send them out. This is mostly useful for generating artifacts to be
        stored/deployed elsewhere.
        [Default: True]
- functions
        A list of specific functions to deploy. If this is not provided, all functions in the service will be deployed.
        [Default: []]
- region
        AWS region to deploy the service to
        [Default: us-east-1]
= service_path
        The path to the root of the Serverless Service to be operated on.

- state
        Goal state of given stage/project
        (Choices: present, absent)[Default: present]
Notes:
  * Currently, the `serverless` command must be in the path of the node executing the task. In the future this may
        be a flag.
Requirements:  serverless

EXAMPLES:
# Basic deploy of a service
- serverless:
    service_path: '{{ project_dir }}'
    state: present

# Deploy specific functions
- serverless:
    service_path: '{{ project_dir }}'
    functions:
      - my_func_one
      - my_func_two

# deploy a project, then pull its resource list back into Ansible
- serverless:
    stage: dev
    region: us-east-1
    service_path: '{{ project_dir }}'
  register: sls
# The cloudformation stack is always named the same as the full service, so the
# cloudformation_facts module can get a full list of the stack resources, as
# well as stack events and outputs
- cloudformation_facts:
    region: us-east-1
    stack_name: '{{ sls.service_name }}'
    stack_resources: true

RETURN VALUES:
service_name:
  type: string
  description: Most
  returned: always
  sample: my-fancy-service-dev
state:
  type: string
  description: Whether the stack for the serverless project is present/absent.
  returned: always
command:
  type: string
  description: Full `serverless` command run by this module, in case you want to re-run the command outside the module.
  returned: always
  sample: serverless deploy --stage production


MAINTAINERS: Ryan Scott Brown @ryansb

METADATA:
	Status: ['preview']
	Supported_by: community
> SERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/system/service.py)

  Controls services on remote hosts. Supported init systems include BSD init, OpenRC, SysV, Solaris SMF, systemd,
  upstart.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- arguments
        Additional arguments provided on the command line
        [Default: (null)]
- enabled
        Whether the service should start on boot. *At least one of state and enabled are required.*
        (Choices: yes, no)[Default: (null)]
= name
        Name of the service.

- pattern
        If the service does not respond to the status command, name a substring to look for as would be found in the
        output of the `ps' command as a stand-in for a status result.  If the string is found, the service will be
        assumed to be running.
        [Default: (null)]
- runlevel
        For OpenRC init scripts (ex: Gentoo) only.  The runlevel that this service belongs to.
        [Default: default]
- sleep
        If the service is being `restarted' then sleep this many seconds between the stop and start command. This helps
        to workaround badly behaving init scripts that exit immediately after signaling a process to stop.
        [Default: (null)]
- state
        `started'/`stopped' are idempotent actions that will not run commands unless necessary.  `restarted' will always
        bounce the service.  `reloaded' will always reload. *At least one of state and enabled are required.* Note that
        reloaded will start the service if it is not already started, even if your chosen init system wouldn't normally.
        (Choices: started, stopped, restarted, reloaded)[Default: (null)]
- use
        The service module actually uses system specific modules, normally through auto detection, this setting can force
        a specific module.
        Normally it uses the value of the 'ansible_service_mgr' fact and falls back to the old 'service' module when none
        matching is found.
        [Default: auto]
EXAMPLES:
# Example action to start service httpd, if not running
- service:
    name: httpd
    state: started

# Example action to stop service httpd, if running
- service:
    name: httpd
    state: stopped

# Example action to restart service httpd, in all cases
- service:
    name: httpd
    state: restarted

# Example action to reload service httpd, in all cases
- service:
    name: httpd
    state: reloaded

# Example action to enable service httpd, and not touch the running state
- service:
    name: httpd
    enabled: yes

# Example action to start service foo, based on running process /usr/bin/foo
- service:
    name: foo
    pattern: /usr/bin/foo
    state: started

# Example action to restart network service for interface eth0
- service:
    name: network
    state: restarted
    args: eth0



MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SET_FACT    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/set_fact.py)

  This module allows setting new variables.  Variables are set on a host-by-host basis just like facts discovered by the
  setup module. These variables will be available to subsequent plays during an ansible-playbook run, but will not be
  saved across executions even if you use a fact cache. Per the standard Ansible variable precedence rules, many other
  types of variables have a higher priority, so this value may be overridden. See
  http://docs.ansible.com/ansible/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable for more
  information.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

= key_value
        The `set_fact' module takes key=value pairs as variables to set in the playbook scope. Or alternatively, accepts
        complex arguments using the `args:' statement.
        [Default: None]
Notes:
  * The `var=value` notation can only create strings or booleans. If you want to create lists/arrays or
        dictionary/hashes use `var: [val1, val2]`
EXAMPLES:
# Example setting host facts using key=value pairs, note that this always creates strings or booleans
- set_fact: one_fact="something" other_fact="{{ local_var }}"

# Example setting host facts using complex arguments
- set_fact:
     one_fact: something
     other_fact: "{{ local_var * 2 }}"
     another_fact: "{{ some_registered_var.results | map(attribute='ansible_facts.some_fact') | list }}"

# As of 1.8, Ansible will convert boolean strings ('true', 'false', 'yes', 'no')
# to proper boolean values when using the key=value syntax, however it is still
# recommended that booleans be set using the complex argument style:
- set_fact:
    one_fact: true
    other_fact: false



MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SET_STATS    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/set_stats.py)

  This module allows setting/accumulating stats on the current ansible run, either per host of for all hosts in the run.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- aggregate
        boolean that indicates if the provided value is aggregated to the existing stat `yes' or will replace it `no'
        [Default: True]
= data
        A dictionary of which each key represents a stat (or variable) you want to keep track of

- per_host
        boolean that indicates if the stats is per host or for all hosts in the run.
        [Default: False]
EXAMPLES:
# Aggregating packages_installed stat per host
- set_stats:
    data:
      packages_installed: 31

# Aggregating random stats for all hosts using complex arguments
- set_stats:
    data:
      one_stat: 11
      other_stat: "{{ local_var * 2 }}"
      another_stat: "{{ some_registered_var.results | map(attribute='ansible_facts.some_fact') | list }}"
    per_host: no


# setting stats (not aggregating)
- set_stats:
    data:
      the_answer: 42
    aggregate: no


MAINTAINERS: Brian Coca (@bcoca)

METADATA:
	Status: ['preview']
	Supported_by: community
> SETUP    (/usr/lib/python2.7/site-packages/ansible/modules/system/setup.py)

  This module is automatically called by playbooks to gather useful variables about remote hosts that can be used in
  playbooks. It can also be executed directly by `/usr/bin/ansible' to check what variables are available to a host.
  Ansible provides many `facts' about the system, automatically.

Options (= is mandatory):

- fact_path
        path used for local ansible facts (*.fact) - files in this dir will be run (if executable) and their results be
        added to ansible_local facts if a file is not executable it is read. Check notes for Windows options. (from 2.1
        on) File/results format can be json or ini-format
        [Default: /etc/ansible/facts.d]
- filter
        if supplied, only return facts that match this shell-style (fnmatch) wildcard.
        [Default: *]
- gather_subset
        if supplied, restrict the additional facts collected to the given subset. Possible values: all, hardware,
        network, virtual, ohai, and facter Can specify a list of values to specify a larger subset. Values can also be
        used with an initial `!' to specify that that specific subset should not be collected.  For instance: !hardware,
        !network, !virtual, !ohai, !facter.  Note that a few facts are always collected.  Use the filter parameter if you
        do not want to display those.
        [Default: all]
- gather_timeout
        Set the default timeout in seconds for individual fact gathering
        [Default: 10]
Notes:
  * More ansible facts will be added with successive releases. If `facter' or `ohai' are installed, variables from
        these programs will also be snapshotted into the JSON file for usage in templating. These variables are
        prefixed with `facter_' and `ohai_' so it's easy to tell their source. All variables are bubbled up to the
        caller. Using the ansible facts and choosing to not install `facter' and `ohai' means you can avoid Ruby-
        dependencies on your remote systems. (See also [facter] and [ohai].)
  * The filter option filters only the first level subkey below ansible_facts.
  * If the target host is Windows, you will not currently have the ability to use `filter' as this is provided by a
        simpler implementation of the module.
  * If the target host is Windows you can now use `fact_path'. Make sure that this path exists on the target host.
        Files in this path MUST be PowerShell scripts (``*.ps1``) and their output must be formattable in JSON
        (Ansible will take care of this). Test the output of your scripts. This option was added in Ansible 2.1.
EXAMPLES:
# Display facts from all hosts and store them indexed by I(hostname) at C(/tmp/facts).
# ansible all -m setup --tree /tmp/facts

# Display only facts regarding memory found by ansible on all hosts and output them.
# ansible all -m setup -a 'filter=ansible_*_mb'

# Display only facts returned by facter.
# ansible all -m setup -a 'filter=facter_*'

# Display only facts about certain interfaces.
# ansible all -m setup -a 'filter=ansible_eth[0-2]'

# Restrict additional gathered facts to network and virtual.
# ansible all -m setup -a 'gather_subset=network,virtual'

# Do not call puppet facter or ohai even if present.
# ansible all -m setup -a 'gather_subset=!facter,!ohai'

# Only collect the minimum amount of facts:
# ansible all -m setup -a 'gather_subset=!all'

# Display facts from Windows hosts with custom facts stored in C(C:\custom_facts).
# ansible windows -m setup -a "fact_path='c:\custom_facts'"


MAINTAINERS: Ansible Core Team, Michael DeHaan, David O'Brien @david_obrien davidobrien1985

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SF_ACCOUNT_MANAGER    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/sf_account_manager.py)

  Create, destroy, or update accounts on SolidFire

Options (= is mandatory):

- account_id
        The ID of the account to manage or update.
        [Default: None]
- attributes
        List of Name/Value pairs in JSON object format.
        [Default: (null)]
= hostname
        The hostname or IP address of the SolidFire cluster.

- initiator_secret
        CHAP secret to use for the initiator. Should be 12-16 characters long and impenetrable.
        The CHAP initiator secrets must be unique and cannot be the same as the target CHAP secret.
        If not specified, a random secret is created.
        [Default: (null)]
= name
        Unique username for this account. (May be 1 to 64 characters in length).

- new_name
        New name for the user account.
        [Default: None]
= password
        Password for the specified user.

= state
        Whether the specified account should exist or not.
        (Choices: present, absent)
- status
        Status of the account.
        [Default: (null)]
- target_secret
        CHAP secret to use for the target (mutual CHAP authentication).
        Should be 12-16 characters long and impenetrable.
        The CHAP target secrets must be unique and cannot be the same as the initiator CHAP secret.
        If not specified, a random secret is created.
        [Default: (null)]
= username
        Please ensure that the user has the adequate permissions. For more information, please read the official
        documentation https://goo.gl/ddJa4Q.

Notes:
  * The modules prefixed with `sf\_' are built to support the SolidFire storage platform.
Requirements:  solidfire-sdk-python (1.1.0.92)

EXAMPLES:
- name: Create Account
  sf_account_manager:
    hostname: "{{ solidfire_hostname }}"
    username: "{{ solidfire_username }}"
    password: "{{ solidfire_password }}"
    state: present
    name: TenantA

- name: Modify Account
  sf_account_manager:
    hostname: "{{ solidfire_hostname }}"
    username: "{{ solidfire_username }}"
    password: "{{ solidfire_password }}"
    state: present
    name: TenantA
    new_name: TenantA-Renamed

- name: Delete Account
  sf_account_manager:
    hostname: "{{ solidfire_hostname }}"
    username: "{{ solidfire_username }}"
    password: "{{ solidfire_password }}"
    state: absent
    name: TenantA-Renamed

RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> SF_CHECK_CONNECTIONS    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/sf_check_connections.py)

  Used to test the management connection to the cluster. The test pings the MVIP and SVIP, and executes a simple API
  method to verify connectivity.

Options (= is mandatory):

= hostname
        The hostname or IP address of the SolidFire cluster.

- mvip
        Optionally, use to test connection of a different MVIP.
        This is not needed to test the connection to the target cluster.
        [Default: None]
= password
        Password for the specified user.

- skip
        Skip checking connection to SVIP or MVIP.
        (Choices: svip, mvip)[Default: None]
- svip
        Optionally, use to test connection of a different SVIP.
        This is not needed to test the connection to the target cluster.
        [Default: None]
= username
        Please ensure that the user has the adequate permissions. For more information, please read the official
        documentation https://goo.gl/ddJa4Q.

Notes:
  * The modules prefixed with `sf\_' are built to support the SolidFire storage platform.
Requirements:  solidfire-sdk-python (1.1.0.92)

EXAMPLES:
   - name: Check connections to MVIP and SVIP
     sf_check_connections:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"

RETURN VALUES:



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> SF_SNAPSHOT_SCHEDULE_MANAGER    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/sf_snapshot_schedule_manager.py)

  Create, destroy, or update accounts on SolidFire

Options (= is mandatory):

= hostname
        The hostname or IP address of the SolidFire cluster.

= name
        Name for the snapshot schedule.

= password
        Password for the specified user.

- paused
        Pause / Resume a schedule.
        [Default: (null)]
- recurring
        Should the schedule recur?
        [Default: (null)]
- retention
        Retention period for the snapshot.
        Format is 'HH:mm:ss'.
        [Default: (null)]
- schedule_id
        The schedule ID for the schedule that you want to update or delete.
        [Default: (null)]
- snapshot_name
        Name for the created snapshots.
        [Default: (null)]
- starting_date
        Starting date for the schedule.
        Required when `state=present'.
        Please use two '-' in the above format, or you may see an error- TypeError, is not JSON serializable description.
        Format: `2016--12--01T00:00:00Z'
        [Default: (null)]
= state
        Whether the specified schedule should exist or not.
        (Choices: present, absent)
- time_interval_days
        Time interval in days.
        [Default: 1]
- time_interval_hours
        Time interval in hours.
        [Default: 0]
- time_interval_minutes
        Time interval in minutes.
        [Default: 0]
= username
        Please ensure that the user has the adequate permissions. For more information, please read the official
        documentation https://goo.gl/ddJa4Q.

- volumes
        Volume IDs that you want to set the snapshot schedule for.
        At least 1 volume ID is required for creating a new schedule.
        required when `state=present'
        [Default: (null)]
Notes:
  * The modules prefixed with `sf\_' are built to support the SolidFire storage platform.
Requirements:  solidfire-sdk-python (1.1.0.92)

EXAMPLES:
   - name: Create Snapshot schedule
     sf_snapshot_schedule_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: present
       name: Schedule_A
       time_interval_days: 1
       starting_date: 2016--12--01T00:00:00Z
       volumes: 7

   - name: Update Snapshot schedule
     sf_snapshot_schedule_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: present
       schedule_id: 6
       recurring: True
       snapshot_name: AnsibleSnapshots

   - name: Delete Snapshot schedule
     sf_snapshot_schedule_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: absent
       schedule_id: 6

RETURN VALUES:

schedule_id:
    description: Schedule ID of the newly created schedule
    returned: success



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> SF_VOLUME_ACCESS_GROUP_MANAGER    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/sf_volume_access_group_manager.py)

  Create, destroy, or update volume access groups on SolidFire

Options (= is mandatory):

- attributes
        List of Name/Value pairs in JSON object format.
        [Default: None]
= hostname
        The hostname or IP address of the SolidFire cluster.

- initiators
        List of initiators to include in the volume access group. If unspecified, the access group will start out without
        configured initiators.
        [Default: None]
= name
        Name of the volume access group. It is not required to be unique, but recommended.

= password
        Password for the specified user.

= state
        Whether the specified volume access group should exist or not.
        (Choices: present, absent)
= username
        Please ensure that the user has the adequate permissions. For more information, please read the official
        documentation https://goo.gl/ddJa4Q.

- virtual_network_id
        The ID of the SolidFire Virtual Network ID to associate the volume access group with.
        [Default: None]
- virtual_network_tags
        The ID of the VLAN Virtual Network Tag to associate the volume access group with.
        [Default: None]
- volume_access_group_id
        The ID of the volume access group to modify or delete.
        [Default: None]
- volumes
        List of volumes to initially include in the volume access group. If unspecified, the access group will start
        without any volumes.
        [Default: None]
Notes:
  * The modules prefixed with `sf\_' are built to support the SolidFire storage platform.
Requirements:  solidfire-sdk-python (1.1.0.92)

EXAMPLES:
   - name: Create Volume Access Group
     sf_volume_access_group_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: present
       name: AnsibleVolumeAccessGroup
       volumes: [7,8]

   - name: Modify Volume Access Group
     sf_volume_access_group_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: present
       volume_access_group_id: 1
       name: AnsibleVolumeAccessGroup-Renamed
       attributes: {"volumes": [1,2,3], "virtual_network_id": 12345}

   - name: Delete Volume Access Group
     sf_volume_access_group_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: absent
       volume_access_group_id: 1

RETURN VALUES:




MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> SF_VOLUME_MANAGER    (/usr/lib/python2.7/site-packages/ansible/modules/storage/netapp/sf_volume_manager.py)

  Create, destroy, or update volumes on SolidFire

Options (= is mandatory):

- 512emulation
        Should the volume provide 512-byte sector emulation?
        Required when `state=present'
        [Default: (null)]
- access
        Access allowed for the volume.
        readOnly: Only read operations are allowed.
        readWrite: Reads and writes are allowed.
        locked: No reads or writes are allowed.
        replicationTarget: Identify a volume as the target volume for a paired set of volumes. If the volume is not
        paired, the access status is locked.
        If unspecified, the access settings of the clone will be the same as the source.
        (Choices: readOnly, readWrite, locked, replicationTarget)[Default: None]
= account_id
        Account ID for the owner of this volume.

- attributes
        A YAML dictionary of attributes that you would like to apply on this volume.
        [Default: None]
= hostname
        The hostname or IP address of the SolidFire cluster.

= name
        The name of the volume to manage.

= password
        Password for the specified user.

- qos
        Initial quality of service settings for this volume.
        [Default: None]
- size
        The size of the volume in (size_unit).
        Required when `state = present'.
        [Default: (null)]
- size_unit
        The unit used to interpret the size parameter.
        (Choices: bytes, b, kb, mb, gb, tb, pb, eb, zb, yb)[Default: gb]
= state
        Whether the specified volume should exist or not.
        (Choices: present, absent)
= username
        Please ensure that the user has the adequate permissions. For more information, please read the official
        documentation https://goo.gl/ddJa4Q.

- volume_id
        The ID of the volume to manage or update.
        In order to create multiple volumes with the same name, but different volume_ids, please declare the `volume_id'
        parameter with an arbitary value. However, the specified volume_id will not be assigned to the newly created
        volume (since it's an auto-generated property).
        [Default: None]
Notes:
  * The modules prefixed with `sf\_' are built to support the SolidFire storage platform.
Requirements:  solidfire-sdk-python (1.1.0.92)

EXAMPLES:
   - name: Create Volume
     sf_volume_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: present
       name: AnsibleVol
       account_id: 3
       enable512e: False
       size: 1
       size_unit: gb

   - name: Update Volume
     sf_volume_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: present
       name: AnsibleVol
       account_id: 3
       access: readWrite

   - name: Delete Volume
     sf_volume_manager:
       hostname: "{{ solidfire_hostname }}"
       username: "{{ solidfire_username }}"
       password: "{{ solidfire_password }}"
       state: absent
       name: AnsibleVol
       account_id: 2

RETURN VALUES:

msg:
    description: Success message
    returned: success
    type: string



MAINTAINERS: Sumit Kumar (sumit4@netapp.com)

METADATA:
	Status: ['preview']
	Supported_by: community
> SHELL    (/usr/lib/python2.7/site-packages/ansible/modules/commands/shell.py)

  The `shell' module takes the command name followed by a list of space-delimited arguments. It is almost exactly like
  the [command] module but runs the command through a shell (`/bin/sh') on the remote node.

Options (= is mandatory):

- chdir
        cd into this directory before running the command
        [Default: None]
- creates
        a filename, when it already exists, this step will *not* be run.
        [Default: None]
- executable
        change the shell used to execute the command. Should be an absolute path to the executable.
        [Default: None]
= free_form
        The shell module takes a free form command to run, as a string.  There's not an actual option named "free form".
        See the examples!
        [Default: None]
- removes
        a filename, when it does not exist, this step will *not* be run.
        [Default: None]
- warn
        if command warnings are on in ansible.cfg, do not warn about this particular line if set to no/false.
        [Default: True]
Notes:
  * If you want to execute a command securely and predictably, it may be better to use the [command] module
        instead. Best practices when writing playbooks will follow the trend of using [command] unless the `shell'
        module is explicitly required. When running ad-hoc commands, use your best judgement.
  * To sanitize any variables passed to the shell module, you should use "{{ var | quote }}" instead of just "{{
        var }}" to make sure they don't include evil things like semicolons.
EXAMPLES:
- name: Execute the command in remote shell; stdout goes to the specified file on the remote.
  shell: somescript.sh >> somelog.txt

- name: Change the working directory to somedir/ before executing the command.
  shell: somescript.sh >> somelog.txt
  args:
    chdir: somedir/

# You can also use the 'args' form to provide the options.
- name: This command will change the working directory to somedir/ and will only run when somedir/somelog.txt doesn't exist.
  shell: somescript.sh >> somelog.txt
  args:
    chdir: somedir/
    creates: somelog.txt

- name: Run a command that uses non-posix shell-isms (in this example /bin/sh doesn't handle redirection and wildcards together but bash does)
  shell: cat < /tmp/*txt
  args:
    executable: /bin/bash

- name: Run a command using a templated variable (always use quote filter to avoid injection)
  shell: cat {{ myfile|quote }}

# You can use shell to run other executables to perform actions inline
- name: Run expect to wait for a successful PXE boot via out-of-band CIMC
  shell: |
    set timeout 300
    spawn ssh admin@{{ cimc_host }}

    expect "password:"
    send "{{ cimc_password }}\n"

    expect "\n{{ cimc_name }}"
    send "connect host\n"

    expect "pxeboot.n12"
    send "\n"

    exit 0
  args:
    executable: /usr/bin/expect
  delegate_to: localhost

RETURN VALUES:
msg:
    description: changed
    returned: always
    type: boolean
    sample: True
start:
    description: The command execution start time
    returned: always
    type: string
    sample: '2016-02-25 09:18:26.429568'
end:
    description: The command execution end time
    returned: always
    type: string
    sample: '2016-02-25 09:18:26.755339'
delta:
    description: The command execution delta time
    returned: always
    type: string
    sample: '0:00:00.325771'
stdout:
    description: The command standard output
    returned: always
    type: string
    sample: 'Clustering node rabbit@slave1 with rabbit@master ...'
stderr:
    description: The command standard error
    returned: always
    type: string
    sample: 'ls: cannot access foo: No such file or directory'
cmd:
    description: The command executed by the task
    returned: always
    type: string
    sample: 'rabbitmqctl join_cluster rabbit@master'
rc:
    description: The command return code (0 means success)
    returned: always
    type: int
    sample: 0
stdout_lines:
    description: The command standard output split in lines
    returned: always
    type: list of strings
    sample: [u'Clustering node rabbit@slave1 with rabbit@master ...']


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SL_VM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/softlayer/sl_vm.py)

  Creates or cancels SoftLayer instances. When created, optionally waits for it to be 'running'.

Options (= is mandatory):

= cpus
        Count of cpus to be assigned to new virtual instance
        [Default: None]
- datacenter
        Datacenter for the virtual instance to be deployed
        [Default: None]
- dedicated
        Falg to determine if the instance should be deployed in dedicated space
        [Default: False]
= disks
        List of disk sizes to be assigned to new virtual instance
        [Default: [25]]
- domain
        Domain name to be provided to a virtual instance
        [Default: None]
- hostname
        Hostname to be provided to a virtual instance
        [Default: None]
- hourly
        Flag to determine if the instance should be hourly billed
        [Default: True]
- image_id
        Image Template to be used for new virtual instance
        [Default: None]
- instance_id
        Instance Id of the virtual instance to perform action option
        [Default: None]
- local_disk
        Flag to determine if local disk should be used for the new instance
        [Default: True]
= memory
        Amount of memory to be assigned to new virtual instance
        [Default: None]
- nic_speed
        NIC Speed to be assigned to new virtual instance
        [Default: 10]
- os_code
        OS Code to be used for new virtual instance
        [Default: None]
- post_uri
        URL of a post provisioning script to be loaded and executed on virtual instance
        [Default: None]
- private
        Flag to determine if the instance should be private only
        [Default: False]
- private_vlan
        VLAN by its Id to be assigned to the private NIC
        [Default: None]
- public_vlan
        VLAN by its Id to be assigned to the public NIC
        [Default: None]
- ssh_keys
        List of ssh keys by their Id to be assigned to a virtual instance
        [Default: None]
- state
        Create, or cancel a virtual instance. Specify "present" for create, "absent" to cancel.
        [Default: present]
- tags
        Tag or list of tags to be provided to a virtual instance
        [Default: None]
- wait
        Flag used to wait for active status before returning
        [Default: True]
- wait_timeout
        time in seconds before wait returns
        [Default: 600]
Requirements:  python >= 2.6, softlayer >= 4.1.1

EXAMPLES:
- name: Build instance
  hosts: localhost
  gather_facts: False
  tasks:
  - name: Build instance request
    sl_vm:
      hostname: instance-1
      domain: anydomain.com
      datacenter: dal09
      tags: ansible-module-test
      hourly: True
      private: False
      dedicated: False
      local_disk: True
      cpus: 1
      memory: 1024
      disks: [25]
      os_code: UBUNTU_LATEST
      wait: False

- name: Build additional instances
  hosts: localhost
  gather_facts: False
  tasks:
  - name: Build instances request
    sl_vm:
      hostname: "{{ item.hostname }}"
      domain: "{{ item.domain }}"
      datacenter: "{{ item.datacenter }}"
      tags: "{{ item.tags }}"
      hourly: "{{ item.hourly }}"
      private: "{{ item.private }}"
      dedicated: "{{ item.dedicated }}"
      local_disk: "{{ item.local_disk }}"
      cpus: "{{ item.cpus }}"
      memory: "{{ item.memory }}"
      disks: "{{ item.disks }}"
      os_code: "{{ item.os_code }}"
      ssh_keys: "{{ item.ssh_keys }}"
      wait: "{{ item.wait }}"
    with_items:
      - hostname: instance-2
        domain: anydomain.com
        datacenter: dal09
        tags:
          - ansible-module-test
          - ansible-module-test-slaves
        hourly: True
        private: False
        dedicated: False
        local_disk: True
        cpus: 1
        memory: 1024
        disks:
          - 25
          - 100
        os_code: UBUNTU_LATEST
        ssh_keys: []
        wait: True
      - hostname: instance-3
        domain: anydomain.com
        datacenter: dal09
        tags:
          - ansible-module-test
          - ansible-module-test-slaves
        hourly: True
        private: False
        dedicated: False
        local_disk: True
        cpus: 1
        memory: 1024
        disks:
          - 25
          - 100
        os_code: UBUNTU_LATEST
        ssh_keys: []
        wait: True

- name: Cancel instances
  hosts: localhost
  gather_facts: False
  tasks:
  - name: Cancel by tag
    sl_vm:
      state: absent
      tags: ansible-module-test

RETURN VALUES:
 

MAINTAINERS: Matt Colton (@mcltn)

METADATA:
	Status: ['preview']
	Supported_by: community
> SLACK    (/usr/lib/python2.7/site-packages/ansible/modules/notification/slack.py)

  The `slack' module sends notifications to http://slack.com via the Incoming WebHook integration

Options (= is mandatory):

- attachments
        Define a list of attachments. This list mirrors the Slack JSON API. For more information, see
        https://api.slack.com/docs/attachments
        [Default: None]
- channel
        Channel to send the message to. If absent, the message goes to the channel selected for the `token'.
        [Default: None]
- color
        Allow text to use default colors - use the default of 'normal' to not send a custom color bar at the start of the
        message
        (Choices: normal, good, warning, danger)[Default: normal]
- domain
        Slack (sub)domain for your environment without protocol. (i.e. `example.slack.com') In 1.8 and beyond, this is
        deprecated and may be ignored.  See token documentation for information.
        [Default: None]
- icon_emoji
        Emoji for the message sender. See Slack documentation for options. (if `icon_emoji' is set, `icon_url' will not
        be used)
        [Default: None]
- icon_url
        Url for the message sender's icon (default `https://www.ansible.com/favicon.ico')
        [Default: (null)]
- link_names
        Automatically create links for channels and usernames in `msg'.
        (Choices: 1, 0)[Default: 1]
- msg
        Message to send. Note that the module does not handle escaping characters. Plain-text angle brackets and
        ampersands should be converted to HTML entities (e.g. & to &amp;) before sending. See Slack's documentation
        (https://api.slack.com/docs/message-formatting) for more.
        [Default: None]
- parse
        Setting for the message parser at Slack
        (Choices: full, none)[Default: None]
= token
        Slack integration token.  This authenticates you to the slack service. Prior to 1.8, a token looked like
        `3Ffe373sfhRE6y42Fg3rvf4GlK'.  In 1.8 and above, ansible adapts to the new slack API where tokens look like
        `G922VJP24/D921DW937/3Ffe373sfhRE6y42Fg3rvf4GlK'.  If tokens are in the new format then slack will ignore any
        value of domain.  If the token is in the old format the domain is required.  Ansible has no control of when slack
        will get rid of the old API.  When slack does that the old format will stop working.  ** Please keep in mind the
        tokens are not the API tokens but are the webhook tokens.  In slack these are found in the webhook URL which are
        obtained under the apps and integrations. The incoming webhooks can be added in that area.  In some cases this
        may be locked by your Slack admin and you must request access.  It is there that the incoming webhooks can be
        added.  The key is on the end of the URL given to you in that section.

- username
        This is the sender of the message.
        [Default: Ansible]
- validate_certs
        If `no', SSL certificates will not be validated. This should only be used on personally controlled sites using
        self-signed certificates.
        (Choices: yes, no)[Default: yes]
EXAMPLES:
- name: Send notification message via Slack
  slack:
    token: thetoken/generatedby/slack
    msg: '{{ inventory_hostname }} completed'
  delegate_to: localhost

- name: Send notification message via Slack all options
  slack:
    token: thetoken/generatedby/slack
    msg: '{{ inventory_hostname }} completed'
    channel: #ansible
    username: 'Ansible on {{ inventory_hostname }}'
    icon_url: http://www.example.com/some-image-file.png
    link_names: 0
    parse: 'none'
  delegate_to: localhost

- name: insert a color bar in front of the message for visibility purposes and use the default webhook icon and name configured in Slack
  slack:
    token: thetoken/generatedby/slack
    msg: '{{ inventory_hostname }} is alive!'
    color: good
    username: ''
    icon_url: ''

- name: Use the attachments API
  slack:
    token: thetoken/generatedby/slack
    attachments:
      - text: Display my system load on host A and B
        color: #ff00dd
        title: System load
        fields:
          - title: System A
            value: "load average: 0,74, 0,66, 0,63"
            short: True
          - title: System B
            value: 'load average: 5,16, 4,64, 2,43'
            short: True

- name: Send a message with a link using Slack markup
  slack:
    token: thetoken/generatedby/slack
    msg: We sent this message using <https://www.ansible.com|Ansible>!

- name: Send a message with angle brackets and ampersands
  slack:
    token: thetoken/generatedby/slack
    msg: This message has &lt;brackets&gt; &amp; ampersands in plain text.


MAINTAINERS: Ramon de la Fuente (@ramondelafuente)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> SLACKPKG    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/slackpkg.py)

  Manage binary packages for Slackware using 'slackpkg' which is available in versions after 12.2.

Options (= is mandatory):

= name
        name of package to install/remove

- state
        state of the package, you can use "installed" as an alias for `present' and removed as one for c(absent).
        (Choices: present, absent, latest)[Default: present]
- update_cache
        update the package database first
        (Choices: True, False)[Default: False]
Requirements:  Slackware >= 12.2

EXAMPLES:
# Install package foo
- slackpkg:
    name: foo
    state: present

# Remove packages foo and bar
- slackpkg:
    name: foo,bar
    state: absent

# Make sure that it is the most updated package
- slackpkg:
    name: foo
    state: latest


MAINTAINERS: Kim Nørgaard (@KimNorgaard)

METADATA:
	Status: ['preview']
	Supported_by: community
> SLURP    (/usr/lib/python2.7/site-packages/ansible/modules/network/basics/slurp.py)

  This module works like [fetch]. It is used for fetching a base64- encoded blob containing the data in a remote file.

Options (= is mandatory):

= src
        The file on the remote system to fetch. This `must' be a file, not a directory.
        [Default: None]
Notes:
  * This module returns an 'in memory' base64 encoded version of the file, take into account that this will require
        at least twice the RAM as the original file size.
  * See also: [fetch]
EXAMPLES:
# Find out what the remote machine's mounts are:
- slurp:
    src: /proc/mounts
  register: mounts

- debug:
    msg: "{{ mounts['content'] | b64decode }}"

# From the commandline, find the pid of the remote machine's sshd
# $ ansible host -m slurp -a 'src=/var/run/sshd.pid'
# host | SUCCESS => {
#     "changed": false,
#     "content": "MjE3OQo=",
#     "encoding": "base64",
#     "source": "/var/run/sshd.pid"
# }
# $ echo MjE3OQo= | base64 -d
# 2179


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SMARTOS_IMAGE_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/smartos/smartos_image_facts.py)

  Retrieve facts about all installed images on SmartOS. Facts will be inserted to the ansible_facts key.

Options (= is mandatory):

- filters
        Criteria for selecting image. Can be any value from image manifest and 'published_date', 'published', 'source',
        'clones', and 'size'. More informaton can be found at https://smartos.org/man/1m/imgadm under 'imgadm list'.
        [Default: None]
EXAMPLES:
# Return facts about all installed images.
smartos_image_facts:

# Return all private active Linux images.
smartos_image_facts: filters="os=linux state=active public=false"

# Show, how many clones does every image have.
smartos_image_facts:

debug: msg="{{ smartos_images[item]['name'] }}-{{smartos_images[item]['version'] }}
            has {{ smartos_images[item]['clones'] }} VM(s)"
with_items: "{{ smartos_images.keys() }}"

RETURN VALUES:
# this module returns ansible_facts


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> SNMP_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/snmp_facts.py)

  Retrieve facts for a device using SNMP, the facts will be inserted to the ansible_facts key.

Options (= is mandatory):

- authkey
        Authentication key, required if version is v3
        [Default: (null)]
- community
        The SNMP community string, required if version is v2/v2c
        [Default: (null)]
= host
        Set to target snmp server (normally {{inventory_hostname}})

- integrity
        Hashing algorithm, required if version is v3
        (Choices: md5, sha)[Default: (null)]
- level
        Authentication level, required if version is v3
        (Choices: authPriv, authNoPriv)[Default: (null)]
- privacy
        Encryption algorithm, required if level is authPriv
        (Choices: des, aes)[Default: (null)]
- privkey
        Encryption key, required if version is authPriv
        [Default: (null)]
- username
        Username for SNMPv3, required if version is v3
        [Default: (null)]
= version
        SNMP Version to use, v2/v2c or v3
        (Choices: v2, v2c, v3)
Requirements:  pysnmp

EXAMPLES:
# Gather facts with SNMP version 2
- snmp_facts:
    host: '{{ inventory_hostname }}'
    version: 2c
    community: public
  delegate_to: local

# Gather facts using SNMP version 3
- snmp_facts:
    host: '{{ inventory_hostname }}'
    version: v3
    level: authPriv
    integrity: sha
    privacy: aes
    username: snmp-user
    authkey: abc12345
    privkey: def6789
  delegate_to: localhost


MAINTAINERS: Patrick Ogenstad (@ogenstad)

METADATA:
	Status: ['preview']
	Supported_by: community
> SNS    (/usr/lib/python2.7/site-packages/ansible/modules/notification/sns.py)

  The `sns' module sends notifications to a topic on your Amazon SNS account

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY environment variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_KEY environment variable is used.
        [Default: None]
- email
        Message to send to email-only subscription
        [Default: (null)]
- http
        Message to send to HTTP-only subscription
        [Default: (null)]
- https
        Message to send to HTTPS-only subscription
        [Default: (null)]
- message_attributes
        Dictionary of message attributes. These are optional structured data entries to be sent along to the endpoint.
        This is in AWS's distinct Name/Type/Value format; see example below.
        [Default: None]
= message_structure
        The payload format to use for the message.
        This must be 'json' to support non-default messages (`http`, `https`, `email`, `sms`, `sqs`). It must be 'string'
        to support message_attributes.
        (Choices: json, string)[Default: json]
= msg
        Default message to send.

- region
        The AWS region to use. If not specified then the value of the EC2_REGION environment variable, if any, is used.
        [Default: (null)]
- sms
        Message to send to SMS-only subscription
        [Default: (null)]
- sqs
        Message to send to SQS-only subscription
        [Default: (null)]
- subject
        Subject line for email delivery.
        [Default: (null)]
= topic
        The topic you want to publish to.

Requirements:  boto

EXAMPLES:
- name: Send default notification message via SNS
  sns:
    msg: '{{ inventory_hostname }} has completed the play.'
    subject: Deploy complete!
    topic: deploy
  delegate_to: localhost

- name: Send notification messages via SNS with short message for SMS
  sns:
    msg: '{{ inventory_hostname }} has completed the play.'
    sms: deployed!
    subject: Deploy complete!
    topic: deploy
  delegate_to: localhost

- name: Send message with message_attributes
  sns:
    topic: "deploy"
    msg: "message with extra details!"
    message_attributes:
      channel:
        data_type: String
        string_value: "mychannel"
      color:
        data_type: String
        string_value: "green"
  delegate_to: localhost


MAINTAINERS: Michael J. Schultz (@mjschultz)

METADATA:
	Status: ['preview']
	Supported_by: community
> SNS_TOPIC    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/sns_topic.py)

  The `sns_topic' module allows you to create, delete, and manage subscriptions for AWS SNS topics.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- delivery_policy
        Delivery policy to apply to the SNS topic
        [Default: None]
- display_name
        Display name of the topic
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
= name
        The name or ARN of the SNS topic to converge

- policy
        Policy to apply to the SNS topic
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- purge_subscriptions
        Whether to purge any subscriptions not listed here. NOTE: AWS does not allow you to purge any PendingConfirmation
        subscriptions, so if any exist and would be purged, they are silently skipped. This means that somebody could
        come back later and confirm the subscription. Sorry. Blame Amazon.
        [Default: True]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Whether to create or destroy an SNS topic
        (Choices: absent, present)[Default: present]
- subscriptions
        List of subscriptions to apply to the topic. Note that AWS requires subscriptions to be confirmed, so you will
        need to confirm any new subscriptions.
        [Default: []]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, python >= 2.6

EXAMPLES:

- name: Create alarm SNS topic
  sns_topic:
    name: "alarms"
    state: present
    display_name: "alarm SNS topic"
    delivery_policy:
      http:
        defaultHealthyRetryPolicy:
            minDelayTarget: 2
            maxDelayTarget: 4
            numRetries: 3
            numMaxDelayRetries: 5
            backoffFunction: "<linear|arithmetic|geometric|exponential>"
        disableSubscriptionOverrides: True
        defaultThrottlePolicy:
            maxReceivesPerSecond: 10
    subscriptions:
      - endpoint: "my_email_address@example.com"
        protocol: "email"
      - endpoint: "my_mobile_number"
        protocol: "sms"


RETURN VALUES:
sns_arn:
    description: The ARN of the topic you are modifying
    type: string
    sample: "arn:aws:sns:us-east-1:123456789012:my_topic_name"

sns_topic:
    description: Dict of sns topic details
    type: dict
    sample:
      name: sns-topic-name
      state: present
      display_name: default
      policy: {}
      delivery_policy: {}
      subscriptions_new: []
      subscriptions_existing: []
      subscriptions_deleted: []
      subscriptions_added: []
      subscriptions_purge': false
      check_mode: false
      topic_created: false
      topic_deleted: false
      attributes_set: []


MAINTAINERS: Joel Thompson (@joelthompson), Fernando Jose Pando (@nand0p)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> SOLARIS_ZONE    (/usr/lib/python2.7/site-packages/ansible/modules/system/solaris_zone.py)

  Create, start, stop and delete Solaris zones. This module doesn't currently allow changing of options for a zone that's
  already been created.

Options (= is mandatory):

- attach_options
        Extra options to the zoneadm attach command. For example, this can be used to specify whether a minimum or full
        update of packages is required and if any packages need to be deleted. For valid values, see zoneadm(1M)
        [Default: empty string]
- config
        The zonecfg configuration commands for this zone. See zonecfg(1M) for the valid options and syntax. Typically
        this is a list of options separated by semi-colons or new lines, e.g. "set auto-boot=true;add net;set
        physical=bge0;set address=10.1.1.1;end"
        [Default: empty string]
- create_options
        Extra options to the zonecfg(1M) create command.
        [Default: empty string]
- install_options
        Extra options to the zoneadm(1M) install command. To automate Solaris 11 zone creation, use this to specify the
        profile XML file, e.g. install_options="-c sc_profile.xml"
        [Default: empty string]
= name
        Zone name.

- path
        The path where the zone will be created. This is required when the zone is created, but not used otherwise.
        [Default: None]
- root_password
        The password hash for the root account. If not specified, the zone's root account will not have a password.
        [Default: None]
- sparse
        Whether to create a sparse (`true') or whole root (`false') zone.
        [Default: False]
= state
        `present', configure and install the zone.
        `installed', synonym for `present'.
        `running', if the zone already exists, boot it, otherwise, configure and install the zone first, then boot it.
        `started', synonym for `running'.
        `stopped', shutdown a zone.
        `absent', destroy the zone.
        `configured', configure the ready so that it's to be attached.
        `attached', attach a zone, but do not boot it.
        `detached', shutdown and detach a zone
        (Choices: present, installed, started, running, stopped, absent, configured, attached, detached)[Default:
        present]
- timeout
        Timeout, in seconds, for zone to boot.
        [Default: 600]
Requirements:  Solaris 10 or 11

EXAMPLES:
- name: Create and install a zone, but don't boot it
  solaris_zone:
    name: zone1
    state: present
    path: /zones/zone1
    sparse: True
    root_password: Be9oX7OSwWoU.
    config: 'set autoboot=true; add net; set physical=bge0; set address=10.1.1.1; end'

- name: Create and install a zone and boot it
  solaris_zone:
    name: zone1
    state: running
    path: /zones/zone1
    root_password: Be9oX7OSwWoU.
    config: 'set autoboot=true; add net; set physical=bge0; set address=10.1.1.1; end'

- name: Boot an already installed zone
  solaris_zone:
    name: zone1
    state: running

- name: Stop a zone
  solaris_zone:
    name: zone1
    state: stopped

- name: Destroy a zone
  solaris_zone:
    name: zone1
    state: absent

- name: Detach a zone
  solaris_zone:
    name: zone1
    state: detached

- name: Configure a zone, ready to be attached
  solaris_zone:
    name: zone1
    state: configured
    path: /zones/zone1
    root_password: Be9oX7OSwWoU.
    config: 'set autoboot=true; add net; set physical=bge0; set address=10.1.1.1; end'

- name: Attach zone1
  solaris_zone:
    name: zone1
    state: attached
    attach_options: -u


MAINTAINERS: Paul Markham

METADATA:
	Status: ['preview']
	Supported_by: community
> SORCERY    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/sorcery.py)

  Manages "spells" on Source Mage GNU/Linux using `sorcery' toolchain

Options (= is mandatory):

- cache_valid_time
        Time in seconds to invalidate grimoire collection on update
        especially useful for SCM and rsync grimoires
        makes sense only in pair with `update_cache'
        [Default: None]
- depends
        Comma-separated list of _optional_ dependencies to build a spell (or make sure it is built) with; use +/- in
        front of dependency to turn it on/off ('+' is optional though)
        this option is ignored if `name' parameter is equal to '*' or contains more than one spell
        providers must be supplied in the form recognized by Sorcery, e.g. 'openssl(SSL)'
        [Default: None]
- name
        Name of the spell
        multiple names can be given, separated by commas
        special value '*' in conjunction with states `latest' or `rebuild' will update or rebuild the whole system
        respectively
        [Default: None]
- state
        Whether to cast, dispel or rebuild a package
        state `cast' is an equivalent of `present', not `latest'
        state `latest' always triggers `update_cache=yes'
        state `rebuild' implies cast of all specified spells, not only those existed before
        (Choices: present, latest, absent, cast, dispelled, rebuild)[Default: present]
- update
        Whether or not to update sorcery scripts at the very first stage
        (Choices: yes, no)[Default: no]
- update_cache
        Whether or not to update grimoire collection before casting spells
        (Choices: yes, no)[Default: no]
Notes:
  * When all three components are selected, the update goes by the sequence -- Sorcery -> Grimoire(s) -> Spell(s);
        you cannot override it.
  * grimoire handling (i.e. add/remove, including SCM/rsync versions) is not yet supported.
Requirements:  bash

EXAMPLES:
# Make sure spell 'foo' is installed
- sorcery:
    spell: foo
    state: present

# Make sure spells 'foo', 'bar' and 'baz' are removed
- sorcery:
    spell: foo,bar,baz
    state: absent

# Make sure spell 'foo' with dependencies 'bar' and 'baz' is installed
- sorcery:
    spell: foo
    depends: bar,baz
    state: present

# Make sure spell 'foo' with 'bar' and without 'baz' dependencies is installed
- sorcery:
    spell: foo
    depends: +bar,-baz
    state: present

# Make sure spell 'foo' with libressl (providing SSL) dependency is installed
- sorcery:
    spell: foo
    depends: libressl(SSL)
    state: present

# Playbook: make sure spells with/without required dependencies (if any) are installed
- sorcery:
    name: "{{ item.spell }}"
    depends: "{{ item.depends | default(None) }}"
    state: present
  with_items:
    - { spell: 'vifm', depends: '+file,-gtk+2' }
    - { spell: 'fwknop', depends: 'gpgme' }
    - { spell: 'pv,tnftp,tor' }

# Install the latest version of spell 'foo' using regular glossary
- sorcery:
    name: foo
    state: latest

# Rebuild spell 'foo'
- sorcery:
    spell: foo
    state: rebuild

# Rebuild the whole system, but update Sorcery and Codex first
- sorcery:
    spell: '*'
    state: rebuild
    update: yes
    update_cache: yes

# Refresh the grimoire collection if it's 1 day old using native sorcerous alias
- sorcery:
    update_codex: yes
    cache_valid_time: 86400

# Update only Sorcery itself
- sorcery:
    update: yes

RETURN VALUES:


MAINTAINERS: Vlad Glagolev (@vaygr)

METADATA:
	Status: ['preview']
	Supported_by: community
> SQS_QUEUE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/sqs_queue.py)

  Create or delete AWS SQS queues. Update attributes on existing queues.

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- default_visibility_timeout
        The default visibility timeout in seconds.
        [Default: None]
- delivery_delay
        The delivery delay in seconds.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- maximum_message_size
        The maximum message size in bytes.
        [Default: None]
- message_retention_period
        The message retention period in seconds.
        [Default: None]
= name
        Name of the queue.

- policy
        The json dict policy to attach to queue
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- receive_message_wait_time
        The receive message wait time in seconds.
        [Default: None]
- redrive_policy
        json dict with the redrive_policy (see example)
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- state
        Create or delete the queue
        (Choices: present, absent)[Default: present]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto >= 2.33.0, python >= 2.6

EXAMPLES:
# Create SQS queue with redrive policy
- sqs_queue:
    name: my-queue
    region: ap-southeast-2
    default_visibility_timeout: 120
    message_retention_period: 86400
    maximum_message_size: 1024
    delivery_delay: 30
    receive_message_wait_time: 20
    policy: "{{ json_dict }}"
    redrive_policy:
      maxReceiveCount: 5
      deadLetterTargetArn: arn:aws:sqs:eu-west-1:123456789012:my-dead-queue

# Delete SQS queue
- sqs_queue:
    name: my-queue
    region: ap-southeast-2
    state: absent

RETURN VALUES:
default_visibility_timeout:
    description: The default visibility timeout in seconds.
    returned: always
    sample: 30
delivery_delay:
    description: The delivery delay in seconds.
    returned: always
    sample: 0
maximum_message_size:
    description: The maximum message size in bytes.
    returned: always
    sample: 262144
message_retention_period:
    description: The message retention period in seconds.
    returned: always
    sample: 345600
name:
    description: Name of the SQS Queue
    returned: always
    sample: "queuename-987d2de0"
queue_arn:
    description: The queue's Amazon resource name (ARN).
    returned: on successful creation or update of the queue
    sample: 'arn:aws:sqs:us-east-1:199999999999:queuename-987d2de0'
receive_message_wait_time:
    description: The receive message wait time in seconds.
    returned: always
    sample: 0
region:
    description: Region that the queue was created within
    returned: always
    sample: 'us-east-1'


MAINTAINERS: Nadir Lloret (@nadirollo), Alan Loi (@loia), Fernando Jose Pando (@nand0p)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> SROS_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/sros/sros_command.py)

  Sends arbitrary commands to an SR OS node and returns the results read from the device. This module includes an
  argument that will cause the module to wait for a specific condition before returning or timing out if the condition is
  not met. This module does not support running commands in configuration mode. Please use [sros_config] to configure SR
  OS devices.

Options (= is mandatory):

= commands
        List of commands to send to the remote SR OS device over the configured provider. The resulting output from the
        command is returned. If the `wait_for' argument is provided, the module is not returned until the condition is
        satisfied or the number of retries has expired.

- interval
        Configures the interval in seconds to wait between retries of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy.  Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the wait_for must be satisfied.
        If the value is set to `any' then only one of the values must be satisfied.
        (Choices: any, all)[Default: all]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should by tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditions.
        [Default: 10]
- wait_for
        List of conditions to evaluate against the output of the command. The task will wait for each condition to be
        true before moving forward. If the conditional is not true within the configured number of retries, the task
        fails. See examples.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

---
tasks:
  - name: run show version on remote devices
    sros_command:
      commands: show version
      provider: "{{ cli }}"

  - name: run show version and check to see if output contains sros
    sros_command:
      commands: show version
      wait_for: result[0] contains sros
      provider: "{{ cli }}"

  - name: run multiple commands on remote nodes
    sros_command:
      commands:
        - show version
        - show port detail
      provider: "{{ cli }}"

  - name: run multiple commands and evaluate the output
    sros_command:
      commands:
        - show version
        - show port detail
      wait_for:
        - result[0] contains TiMOS-B-14.0.R4
      provider: "{{ cli }}"

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']

stdout_lines:
  description: The value of stdout split into a list
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: [['...', '...'], ['...'], ['...']]

failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> SROS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/sros/sros_config.py)

  Nokia SR OS configurations use a simple block indent file syntax for segmenting configuration into sections.  This
  module provides an implementation for working with SR OS configuration sections in a deterministic way.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- after
        The ordered set of commands to append to the end of the command stack if a change needs to be made.  Just like
        with `before' this allows the playbook designer to append a set of commands to be executed after the command set.
        [Default: None]
- backup
        This argument will cause the module to create a full backup of the current `running-config' from the remote
        device before any changes are made.  The backup file is written to the `backup' folder in the playbook root
        directory.  If the directory does not exist, it is created.
        (Choices: yes, no)[Default: False]
- before
        The ordered set of commands to push on to the command stack if a change needs to be made.  This allows the
        playbook designer the opportunity to perform configuration commands prior to pushing any changes without
        affecting how the set of commands are matched against the system.
        [Default: None]
- config
        The `config' argument allows the playbook designer to supply the base configuration to be used to validate
        configuration changes necessary.  If this argument is provided, the module will not download the running-config
        from the remote node.
        [Default: None]
- defaults
        This argument specifies whether or not to collect all defaults when getting the remote device running config.
        When enabled, the module will get the current config by issuing the command `show running-config all'.
        (Choices: yes, no)[Default: False]
- force
        The force argument instructs the module to not consider the current devices running-config.  When set to true,
        this will cause the module to push the contents of `src' into the device without first checking if already
        configured.
        Note this argument should be considered deprecated.  To achieve the equivalent, set the `match=none' which is
        idempotent.  This argument will be removed in a future release.
        (Choices: true, false)[Default: False]
- lines
        The ordered set of commands that should be configured in the section.  The commands must be the exact same
        commands as found in the device running-config.  Be sure to note the configuration command syntax as some
        commands are automatically modified by the device config parser.
        [Default: None]
- match
        Instructs the module on the way to perform the matching of the set of commands against the current device config.
        If match is set to `line', commands are matched line by line.  If match is set to `strict', command lines are
        matched with respect to position.  If match is set to `exact', command lines must be an equal match.  Finally, if
        match is set to `none', the module will not attempt to compare the source configuration with the running
        configuration on the remote device.
        (Choices: line, strict, exact, none)[Default: line]
- parents
        The ordered set of parents that uniquely identify the section the commands should be checked against.  If the
        parents argument is omitted, the commands are checked against the set of top level or global commands.
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- replace
        Instructs the module on the way to perform the configuration on the device.  If the replace argument is set to
        `line' then the modified lines are pushed to the device in configuration mode.  If the replace argument is set to
        `block' then the entire command block is pushed to the device in configuration mode if any line is not correct.
        (Choices: line, block)[Default: line]
- save
        The `save' argument instructs the module to save the running- config to the startup-config at the conclusion of
        the module running.  If check mode is specified, this argument is ignored.
        (Choices: yes, no)[Default: False]
- src
        Specifies the source path to the file that contains the configuration or configuration template to load.  The
        path to the source file can either be the full path on the Ansible control host or a relative path from the
        playbook or role root directory.  This argument is mutually exclusive with `lines'.
        [Default: None]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

---
- name: enable rollback location
  sros_config:
    lines: configure system rollback rollback-location "cf3:/ansible"
    provider: "{{ cli }}"

- name: set system name to {{ inventory_hostname }} using one line
  sros_config:
    lines:
        - configure system name "{{ inventory_hostname }}"
    provider: "{{ cli }}"

- name: set system name to {{ inventory_hostname }} using parents
  sros_config:
    lines:
        - 'name "{{ inventory_hostname }}"'
    parents:
        - configure
        - system
    provider: "{{ cli }}"
    backup: yes

- name: load config from file
  sros_config:
      src: "{{ inventory_hostname }}.cfg"
      provider: "{{ cli }}"
      save: yes

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['config system name "sros01"']
commands:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['config system name "sros01"']
backup_path:
  description: The full path to the backup file
  returned: when backup is yes
  type: path
  sample: /playbooks/ansible/backup/sros_config.2016-07-16@22:28:34


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> SROS_ROLLBACK    (/usr/lib/python2.7/site-packages/ansible/modules/network/sros/sros_rollback.py)

  Configure the rollback feature on remote Nokia devices running the SR OS operating system.  this module provides a
  stateful implementation for managing the configuration of the rollback feature

Options (= is mandatory):

- local_max_checkpoints
        The `local_max_checkpoints' argument configures the maximum number of rollback files that can be saved on the
        devices local compact flash.  Valid values for this argument are in the range of 1 to 50
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- remote_max_checkpoints
        The `remote_max_checkpoints' argument configures the maximum number of rollback files that can be transferred and
        saved to a remote location.  Valid values for this argument are in the range of 1 to 50
        [Default: None]
- rescue_location
        The `rescue_location' specifies the location of the rescue file.  This argument supports any valid local or
        remote URL as specified in SR OS
        [Default: None]
- rollback_location
        The `rollback_location' specifies the location and filename of the rollback checkpoint files.   This argument
        supports any valid local or remote URL as specified in SR OS
        [Default: None]
- state
        The `state' argument specifies the state of the configuration entries in the devices active configuration.  When
        the state value is set to `true' the configuration is present in the devices active configuration.  When the
        state value is set to `false' the configuration values are removed from the devices active configuration.
        (Choices: present, absent)[Default: present]
EXAMPLES:
# Note: examples below use the following provider dict to handle
#       transport and authentication to the node.
---
vars:
  cli:
    host: "{{ inventory_hostname }}"
    username: admin
    password: admin
    transport: cli

---
- name: configure rollback location
  sros_rollback:
    rollback_location: "cb3:/ansible"
    provider: "{{ cli }}"

- name: remove all rollback configuration
  sros_rollback:
    state: absent
    provider: "{{ cli }}"

RETURN VALUES:
updates:
  description: The set of commands that will be pushed to the remote device
  returned: always
  type: list
  sample: ['...', '...']


MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> STACKDRIVER    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/stackdriver.py)

  Send code deploy and annotation events to Stackdriver

Options (= is mandatory):

- annotated_by
        The person or robot who the annotation should be attributed to.
        [Default: Ansible]
- deployed_by
        The person or robot responsible for deploying the code
        [Default: Ansible]
- deployed_to
        The environment code was deployed to. (ie: development, staging, production)
        [Default: None]
- event
        The type of event to send, either annotation or deploy
        (Choices: annotation, deploy)[Default: None]
- event_epoch
        Unix timestamp of where the event should appear in the timeline, defaults to now. Be careful with this.
        [Default: None]
- instance_id
        id of an EC2 instance that this event should be attached to, which will limit the contexts where this event is
        shown
        [Default: None]
= key
        API key.
        [Default: None]
- level
        one of INFO/WARN/ERROR, defaults to INFO if not supplied.  May affect display.
        (Choices: INFO, WARN, ERROR)[Default: INFO]
- msg
        The contents of the annotation message, in plain text.  Limited to 256 characters. Required for annotation.
        [Default: None]
- repository
        The repository (or project) deployed
        [Default: None]
- revision_id
        The revision of the code that was deployed. Required for deploy events
        [Default: None]
EXAMPLES:
- stackdriver:
    key: AAAAAA
    event: deploy
    deployed_to: production
    deployed_by: leeroyjenkins
    repository: MyWebApp
    revision_id: abcd123

- stackdriver:
    key: AAAAAA
    event: annotation
    msg: Greetings from Ansible
    annotated_by: leeroyjenkins
    level: WARN
    instance_id: i-abcd1234


MAINTAINERS: Ben Whaley (@bwhaley)

METADATA:
	Status: ['preview']
	Supported_by: community
> STACKI_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/stacki/stacki_host.py)

  Use this module to add or remove hosts to a stacki front-end via API https://github.com/StackIQ/stacki

Options (= is mandatory):

- force_install
        Set value to True to force node into install state if it already exists in stacki.
        [Default: (null)]
= name
        Name of the host to be added to Stacki.

- prim_intf
        Name of the primary network interface.
        [Default: (null)]
- prim_intf_ip
        IP Address for the primary network interface.
        [Default: (null)]
- prim_intf_mac
        MAC Address for the primary PXE boot network interface.
        [Default: (null)]
= stacki_endpoint
        URL for the Stacki API Endpoint.

= stacki_password
        Password for authenticating with Stacki API, but if not specified, the environment variable `stacki_password' is
        used instead.

= stacki_user
        Username for authenticating with Stacki API, but if not specified, the environment variable `stacki_user' is used
        instead.

EXAMPLES:
- name: Add a host named test-1
  stacki_host:
    name: test-1
    stacki_user: usr
    stacki_password: pwd
    stacki_endpoint: url
    prim_intf_mac: mac_addr
    prim_intf_ip: x.x.x.x
    prim_intf: eth0

- name: Remove a host named test-1
  stacki_host:
    name: test-1
    stacki_user: usr
    stacki_password: pwd
    stacki_endpoint: url
    state: absent

RETURN VALUES:
changed:
  description: response to whether or not the api call completed successfully
  returned: always
  type: boolean
  sample: true

stdout:
  description: the set of responses from the commands
  returned: always
  type: list
  sample: ['...', '...']

stdout_lines:
  description: the value of stdout split into a list
  returned: always
  type: list
  sample: [['...', '...'], ['...'], ['...']]


MAINTAINERS: Hugh Ma <Hugh.Ma@flextronics.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> STAT    (/usr/lib/python2.7/site-packages/ansible/modules/files/stat.py)

  Retrieves facts for a file similar to the linux/unix 'stat' command.

Options (= is mandatory):

- checksum_algorithm
        Algorithm to determine checksum of file. Will throw an error if the host is unable to use specified algorithm.
        (Choices: sha1, sha224, sha256, sha384, sha512)[Default: sha1]
- follow
        Whether to follow symlinks
        [Default: False]
- get_attributes
        Get file attributes using lsattr tool if present.
        [Default: True]
- get_checksum
        Whether to return a checksum of the file (default sha1)
        [Default: True]
- get_md5
        Whether to return the md5 sum of the file.  Will return None if we're unable to use md5 (Common for FIPS-140
        compliant systems)
        [Default: True]
- get_mime
        Use file magic and return data about the nature of the file. this uses the 'file' utility found on most
        Linux/Unix systems.
        This will add both `mime_type` and 'charset' fields to the return, if possible.
        In 2.3 this option changed from 'mime' to 'get_mime' and the default changed to 'Yes'
        (Choices: True, False)[Default: True]
= path
        The full path of the file/object to get the facts of
        [Default: None]
EXAMPLES:
# Obtain the stats of /etc/foo.conf, and check that the file still belongs
# to 'root'. Fail otherwise.
- stat:
    path: /etc/foo.conf
  register: st
- fail:
    msg: "Whoops! file ownership has changed"
  when: st.stat.pw_name != 'root'

# Determine if a path exists and is a symlink. Note that if the path does
# not exist, and we test sym.stat.islnk, it will fail with an error. So
# therefore, we must test whether it is defined.
# Run this to understand the structure, the skipped ones do not pass the
# check performed by 'when'
- stat:
    path: /path/to/something
  register: sym

- debug:
    msg: "islnk isn't defined (path doesn't exist)"
  when: sym.stat.islnk is not defined

- debug:
    msg: "islnk is defined (path must exist)"
  when: sym.stat.islnk is defined

- debug:
    msg: "Path exists and is a symlink"
  when: sym.stat.islnk is defined and sym.stat.islnk

- debug:
    msg: "Path exists and isn't a symlink"
  when: sym.stat.islnk is defined and sym.stat.islnk == False


# Determine if a path exists and is a directory.  Note that we need to test
# both that p.stat.isdir actually exists, and also that it's set to true.
- stat:
    path: /path/to/something
  register: p
- debug:
    msg: "Path exists and is a directory"
  when: p.stat.isdir is defined and p.stat.isdir

# Don't do md5 checksum
- stat:
    path: /path/to/myhugefile
    get_md5: no

# Use sha256 to calculate checksum
- stat:
    path: /path/to/something
    checksum_algorithm: sha256

RETURN VALUES:
stat:
    description: dictionary containing all the stat data, some platforms might add additional fields
    returned: success
    type: dictionary
    contains:
        exists:
            description: if the destination path actually exists or not
            returned: success
            type: boolean
            sample: True
        path:
            description: The full path of the file/object to get the facts of
            returned: success and if path exists
            type: string
            sample: '/path/to/file'
        mode:
            description: Unix permissions of the file in octal
            returned: success, path exists and user can read stats
            type: octal
            sample: 1755
        isdir:
            description: Tells you if the path is a directory
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        ischr:
            description: Tells you if the path is a character device
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        isblk:
            description: Tells you if the path is a block device
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        isreg:
            description: Tells you if the path is a regular file
            returned: success, path exists and user can read stats
            type: boolean
            sample: True
        isfifo:
            description: Tells you if the path is a named pipe
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        islnk:
            description: Tells you if the path is a symbolic link
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        issock:
            description: Tells you if the path is a unix domain socket
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        uid:
            description: Numeric id representing the file owner
            returned: success, path exists and user can read stats
            type: int
            sample: 1003
        gid:
            description: Numeric id representing the group of the owner
            returned: success, path exists and user can read stats
            type: int
            sample: 1003
        size:
            description: Size in bytes for a plain file, amount of data for some special files
            returned: success, path exists and user can read stats
            type: int
            sample: 203
        inode:
            description: Inode number of the path
            returned: success, path exists and user can read stats
            type: int
            sample: 12758
        dev:
            description: Device the inode resides on
            returned: success, path exists and user can read stats
            type: int
            sample: 33
        nlink:
            description: Number of links to the inode (hard links)
            returned: success, path exists and user can read stats
            type: int
            sample: 1
        atime:
            description: Time of last access
            returned: success, path exists and user can read stats
            type: float
            sample: 1424348972.575
        mtime:
            description: Time of last modification
            returned: success, path exists and user can read stats
            type: float
            sample: 1424348972.575
        ctime:
            description: Time of last metadata update or creation (depends on OS)
            returned: success, path exists and user can read stats
            type: float
            sample: 1424348972.575
        wusr:
            description: Tells you if the owner has write permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: True
        rusr:
            description: Tells you if the owner has read permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: True
        xusr:
            description: Tells you if the owner has execute permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: True
        wgrp:
            description: Tells you if the owner's group has write permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        rgrp:
            description: Tells you if the owner's group has read permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: True
        xgrp:
            description: Tells you if the owner's group has execute permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: True
        woth:
            description: Tells you if others have write permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        roth:
            description: Tells you if others have read permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: True
        xoth:
            description: Tells you if others have execute permission
            returned: success, path exists and user can read stats
            type: boolean
            sample: True
        isuid:
            description: Tells you if the invoking user's id matches the owner's id
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        isgid:
            description: Tells you if the invoking user's group id matches the owner's group id
            returned: success, path exists and user can read stats
            type: boolean
            sample: False
        lnk_source:
            description: Original path
            returned: success, path exists and user can read stats and the path is a symbolic link
            type: string
            sample: /home/foobar/21102015-1445431274-908472971
        md5:
            description: md5 hash of the path
            returned: success, path exists and user can read stats and path
                supports hashing and md5 is supported
            type: string
            sample: f88fa92d8cf2eeecf4c0a50ccc96d0c0
        checksum:
            description: hash of the path
            returned: success, path exists, user can read stats, path supports
                hashing and supplied checksum algorithm is available
            type: string
            sample: 50ba294cdf28c0d5bcde25708df53346825a429f
        pw_name:
            description: User name of owner
            returned: success, path exists and user can read stats and installed python supports it
            type: string
            sample: httpd
        gr_name:
            description: Group name of owner
            returned: success, path exists and user can read stats and installed python supports it
            type: string
            sample: www-data
        mime_type:
            description: file magic data or mime-type
            returned: success, path exists and user can read stats and
                installed python supports it and the `mime` option was true, will
                return 'unknown' on error.
            type: string
            sample: PDF document, version 1.2
        charset:
            description: file character set or encoding
            returned: success, path exists and user can read stats and
                installed python supports it and the `mime` option was true, will
                return 'unknown' on error.
            type: string
            sample: us-ascii
        readable:
            description: Tells you if the invoking user has the right to read the path
            returned: success, path exists and user can read the path
            type: boolean
            sample: False
            version_added: 2.2
        writeable:
            description: Tells you if the invoking user has the right to write the path
            returned: success, path exists and user can write the path
            type: boolean
            sample: False
            version_added: 2.2
        executable:
            description: Tells you if the invoking user has the execute the path
            returned: success, path exists and user can execute the path
            type: boolean
            sample: False
            version_added: 2.2
        attributes:
            description: list of file attributes
            returned: success, path exists and user can execute the path
            type: boolean
            sample: [ immutable, extent ]
            version_added: 2.3


MAINTAINERS: Bruce Pennypacker (@bpennypacker)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> STATUSIO_MAINTENANCE    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/statusio_maintenance.py)

  Creates a maintenance window for status.io Deletes a maintenance window for status.io

Options (= is mandatory):

- all_infrastructure_affected
        If it affects all components and containers
        [Default: False]
= api_id
        Your unique API ID from status.io

= api_key
        Your unique API Key from status.io

- automation
        Automatically start and end the maintenance window
        [Default: False]
- components
        The given name of your component (server name)
        [Default: None]
- containers
        The given name of your container (data center)
        [Default: None]
- desc
        Message describing the maintenance window
        [Default: Created by Ansible]
- maintenance_id
        The maintenance id number when deleting a maintenance window
        [Default: None]
- maintenance_notify_1_hr
        Notify subscribers 1 hour before maintenance start time
        [Default: False]
- maintenance_notify_24_hr
        Notify subscribers 24 hours before maintenance start time
        [Default: False]
- maintenance_notify_72_hr
        Notify subscribers 72 hours before maintenance start time
        [Default: False]
- maintenance_notify_now
        Notify subscribers now
        [Default: False]
- minutes
        The length of time in UTC that the maintenance will run             (starting from playbook runtime)
        [Default: 10]
- start_date
        Date maintenance is expected to start (Month/Day/Year) (UTC)
        End Date is worked out from start_date + minutes
        [Default: None]
- start_time
        Time maintenance is expected to start (Hour:Minutes) (UTC)
        End Time is worked out from start_time + minutes
        [Default: None]
- state
        Desired state of the package.
        (Choices: present, absent)[Default: present]
= statuspage
        Your unique StatusPage ID from status.io

- title
        A descriptive title for the maintenance window
        [Default: A new maintenance window]
- url
        Status.io API URL. A private apiary can be used instead.
        [Default: https://api.status.io]
Notes:
  * You can use the apiary API url (http://docs.statusio.apiary.io/) to capture API traffic
  * Use start_date and start_time with minutes to set future maintenance window
EXAMPLES:
- name: Create a maintenance window for 10 minutes on server1, with automation to stop the maintenance
  statusio_maintenance:
    title: Router Upgrade from ansible
    desc: Performing a Router Upgrade
    components: server1.example.com
    api_id: api_id
    api_key: api_key
    statuspage: statuspage_id
    maintenance_notify_1_hr: True
    automation: True

- name: Create a maintenance window for 60 minutes on server1 and server2
  statusio_maintenance:
    title: Routine maintenance
    desc: Some security updates
    components:
      - server1.example.com
      - server2.example.com
    minutes: 60
    api_id: api_id
    api_key: api_key
    statuspage: statuspage_id
    maintenance_notify_1_hr: True
    automation: True
  delegate_to: localhost

- name: Create a future maintenance window for 24 hours to all hosts inside the Primary Data Center
  statusio_maintenance:
    title: Data center downtime
    desc: Performing a Upgrade to our data center
    components: Primary Data Center
    api_id: api_id
    api_key: api_key
    statuspage: statuspage_id
    start_date: 01/01/2016
    start_time: 12:00
    minutes: 1440

- name: Delete a maintenance window
  statusio_maintenance:
    title: Remove a maintenance window
    maintenance_id: 561f90faf74bc94a4700087b
    statuspage: statuspage_id
    api_id: api_id
    api_key: api_key
    state: absent


RETURN VALUES:
# 

MAINTAINERS: Benjamin Copeland (@bhcopeland) <ben@copeland.me.uk>

METADATA:
	Status: ['preview']
	Supported_by: community
> STS_ASSUME_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/sts_assume_role.py)

  Assume a role using AWS Security Token Service and obtain temporary credentials

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- duration_seconds
        The duration, in seconds, of the role session. The value can range from 900 seconds (15 minutes) to 3600 seconds
        (1 hour). By default, the value is set to 3600 seconds.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- external_id
        A unique identifier that is used by third parties to assume a role in their customers' accounts.
        [Default: None]
- mfa_serial_number
        he identification number of the MFA device that is associated with the user who is making the AssumeRole call.
        [Default: None]
- mfa_token
        The value provided by the MFA device, if the trust policy of the role being assumed requires MFA.
        [Default: None]
- policy
        Supplemental policy to use in addition to assumed role's policies.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
= role_arn
        The Amazon Resource Name (ARN) of the role that the caller is assuming
        (http://docs.aws.amazon.com/IAM/latest/UserGuide/Using_Identifiers.html#Identifiers_ARNs)

= role_session_name
        Name of the role's session - will be used by CloudTrail

- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * In order to use the assumed role in a following playbook task you must pass the access_key, access_secret and
        access_token
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  python >= 2.6, boto

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Assume an existing role (more details: http://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html)
sts_assume_role:
  role_arn: "arn:aws:iam::123456789012:role/someRole"
  role_session_name: "someRoleSession"
register: assumed_role

# Use the assumed role above to tag an instance in account 123456789012
ec2_tag:
  aws_access_key: "{{ assumed_role.sts_creds.access_key }}"
  aws_secret_key: "{{ assumed_role.sts_creds.secret_key }}"
  security_token: "{{ assumed_role.sts_creds.session_token }}"
  resource: i-xyzxyz01
  state: present
  tags:
    MyNewTag: value



MAINTAINERS: Boris Ekelchik (@bekelchik)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> STS_SESSION_TOKEN    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/amazon/sts_session_token.py)

  Obtain a session token from the AWS Security Token Service

Options (= is mandatory):

- aws_access_key
        AWS access key. If not set then the value of the AWS_ACCESS_KEY_ID, AWS_ACCESS_KEY or EC2_ACCESS_KEY environment
        variable is used.
        [Default: None]
- aws_secret_key
        AWS secret key. If not set then the value of the AWS_SECRET_ACCESS_KEY, AWS_SECRET_KEY, or EC2_SECRET_KEY
        environment variable is used.
        [Default: None]
- duration_seconds
        The duration, in seconds, of the session token. See
        http://docs.aws.amazon.com/STS/latest/APIReference/API_GetSessionToken.html#API_GetSessionToken_RequestParameters
        for acceptable and default values.
        [Default: None]
- ec2_url
        Url to use to connect to EC2 or your Eucalyptus cloud (by default the module will use EC2 endpoints). Ignored for
        modules where region is required. Must be specified for all other modules if region is not used. If not set then
        the value of the EC2_URL environment variable, if any, is used.
        [Default: None]
- mfa_serial_number
        The identification number of the MFA device that is associated with the user who is making the GetSessionToken
        call.
        [Default: None]
- mfa_token
        The value provided by the MFA device, if the trust policy of the user requires MFA.
        [Default: None]
- profile
        Uses a boto profile. Only works with boto >= 2.24.0.
        [Default: None]
- region
        The AWS region to use. If not specified then the value of the AWS_REGION or EC2_REGION environment variable, if
        any, is used. See http://docs.aws.amazon.com/general/latest/gr/rande.html#ec2_region
        [Default: (null)]
- security_token
        AWS STS security token. If not set then the value of the AWS_SECURITY_TOKEN or EC2_SECURITY_TOKEN environment
        variable is used.
        [Default: None]
- validate_certs
        When set to "no", SSL certificates will not be validated for boto versions >= 2.6.0.
        (Choices: yes, no)[Default: yes]
Notes:
  * In order to use the session token in a following playbook task you must pass the `access_key', `access_secret'
        and `access_token'.
  * If parameters are not set within the module, the following environment variables can be used in decreasing
        order of precedence `AWS_URL' or `EC2_URL', `AWS_ACCESS_KEY_ID' or `AWS_ACCESS_KEY' or `EC2_ACCESS_KEY',
        `AWS_SECRET_ACCESS_KEY' or `AWS_SECRET_KEY' or `EC2_SECRET_KEY', `AWS_SECURITY_TOKEN' or
        `EC2_SECURITY_TOKEN', `AWS_REGION' or `EC2_REGION'
  * Ansible uses the boto configuration file (typically ~/.boto) if no credentials are provided. See
        http://boto.readthedocs.org/en/latest/boto_config_tut.html
  * `AWS_REGION' or `EC2_REGION' can be typically be used to specify the AWS region, when required, but this can
        also be configured in the boto config file
Requirements:  boto, boto3, botocore, python >= 2.6

EXAMPLES:
# Note: These examples do not set authentication details, see the AWS Guide for details.

# Get a session token (more details: http://docs.aws.amazon.com/STS/latest/APIReference/API_GetSessionToken.html)
sts_session_token:
  duration: 3600
register: session_credentials

# Use the session token obtained above to tag an instance in account 123456789012
ec2_tag:
  aws_access_key: "{{ session_credentials.sts_creds.access_key }}"
  aws_secret_key: "{{ session_credentials.sts_creds.secret_key }}"
  security_token: "{{ session_credentials.sts_creds.session_token }}"
  resource: i-xyzxyz01
  state: present
  tags:
    MyNewTag: value


RETURN VALUES:
sts_creds:
    description: The Credentials object returned by the AWS Security Token Service
    returned: always
    type: list
    sample:
      access_key: ASXXXXXXXXXXXXXXXXXX
      expiration: "2016-04-08T11:59:47+00:00"
      secret_key: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
      session_token: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
changed:
    description: True if obtaining the credentials succeeds
    type: bool
    returned: always


MAINTAINERS: Victor Costan (@pwnall)

METADATA:
	Status: ['stableinterface']
	Supported_by: curated
> SUBVERSION    (/usr/lib/python2.7/site-packages/ansible/modules/source_control/subversion.py)

  Deploy given repository URL / revision to dest. If dest exists, update to the specified revision, otherwise perform a
  checkout.

Options (= is mandatory):

- checkout
        If no, do not check out the repository if it does not exist locally
        (Choices: yes, no)[Default: yes]
= dest
        Absolute path where the repository should be deployed.
        [Default: None]
- executable
        Path to svn executable to use. If not supplied, the normal mechanism for resolving binary paths will be used.
        [Default: None]
- export
        If `yes', do export instead of checkout/update.
        (Choices: yes, no)[Default: no]
- force
        If `yes', modified files will be discarded. If `no', module will fail if it encounters modified files. Prior to
        1.9 the default was `yes`.
        (Choices: yes, no)[Default: no]
- password
        --password parameter passed to svn.
        [Default: None]
= repo
        The subversion URL to the repository.
        [Default: None]
- revision
        Specific revision to checkout.
        [Default: HEAD]
- switch
        If `no', do not call svn switch before update.
        (Choices: yes, no)[Default: yes]
- update
        If no, do not retrieve new revisions from the origin repository
        (Choices: yes, no)[Default: yes]
- username
        --username parameter passed to svn.
        [Default: None]
Notes:
  * Requires `svn' to be installed on the client.
  * This module does not handle externals
EXAMPLES:
# Checkout subversion repository to specified folder.
- subversion:
    repo: svn+ssh://an.example.org/path/to/repo
    dest: /src/checkout

# Export subversion directory to folder
- subversion:
    repo: svn+ssh://an.example.org/path/to/repo
    dest: /src/export

# Example just get information about the repository whether or not it has
# already been cloned locally.
- subversion:
    repo: svn+ssh://an.example.org/path/to/repo
    dest: /srv/checkout
    checkout: no
    update: no


MAINTAINERS: Dane Summers (@dsummersl) <njharman@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: core
> SUPERVISORCTL    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/supervisorctl.py)

  Manage the state of a program or group of programs running via supervisord

Options (= is mandatory):

- config
        The supervisor configuration file path
        [Default: None]
= name
        The name of the supervisord program or group to manage.
        The name will be taken as group name when it ends with a colon `:'
        Group support is only available in Ansible version 1.6 or later.
        [Default: None]
- password
        password to use for authentication
        [Default: None]
- server_url
        URL on which supervisord server is listening
        [Default: None]
= state
        The desired state of program/group.
        (Choices: present, started, stopped, restarted, absent)[Default: None]
- supervisorctl_path
        path to supervisorctl executable
        [Default: None]
- username
        username to use for authentication
        [Default: None]
Notes:
  * When `state' = `present', the module will call `supervisorctl reread' then `supervisorctl add' if the
        program/group does not exist.
  * When `state' = `restarted', the module will call `supervisorctl update' then call `supervisorctl restart'.
Requirements:  supervisorctl

EXAMPLES:
# Manage the state of program to be in 'started' state.
- supervisorctl:
    name: my_app
    state: started

# Manage the state of program group to be in 'started' state.
- supervisorctl:
    name: 'my_apps:'
    state: started

# Restart my_app, reading supervisorctl configuration from a specified file.
- supervisorctl:
    name: my_app
    state: restarted
    config: /var/opt/my_project/supervisord.conf

# Restart my_app, connecting to supervisord with credentials and server URL.
- supervisorctl:
    name: my_app
    state: restarted
    username: test
    password: testpass
    server_url: http://localhost:9001


MAINTAINERS: Matt Wright (@mattupstate), Aaron Wang (@inetfuture) <inetfuture@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> SVC    (/usr/lib/python2.7/site-packages/ansible/modules/system/svc.py)

  Controls daemontools services on remote hosts using the svc utility.

Options (= is mandatory):

- downed
        Should a 'down' file exist or not, if it exists it disables auto startup. defaults to no. Downed does not imply
        stopped.
        (Choices: yes, no)[Default: False]
- enabled
        Wheater the service is enabled or not, if disabled it also implies stopped. Make note that a service can be
        enabled and downed (no auto restart).
        (Choices: yes, no)[Default: (null)]
= name
        Name of the service to manage.

- service_dir
        directory svscan watches for services
        [Default: /service]
- service_src
        directory where services are defined, the source of symlinks to service_dir.
        [Default: (null)]
- state
        `Started'/`stopped' are idempotent actions that will not run commands unless necessary.  `restarted' will always
        bounce the svc (svc -t) and `killed' will always bounce the svc (svc -k). `reloaded' will send a sigusr1 (svc
        -1). `once' will run a normally downed svc once (svc -o), not really an idempotent operation.
        (Choices: started, stopped, restarted, reloaded, once)[Default: (null)]
EXAMPLES:
# Example action to start svc dnscache, if not running
 - svc:
    name: dnscache
    state: started

# Example action to stop svc dnscache, if running
 - svc:
    name: dnscache
    state: stopped

# Example action to kill svc dnscache, in all cases
 - svc:
    name: dnscache
    state: killed

# Example action to restart svc dnscache, in all cases
 - svc:
    name: dnscache
    state: restarted

# Example action to reload svc dnscache, in all cases
 - svc:
    name: dnscache
    state: reloaded

# Example using alt svc directory location
 - svc:
    name: dnscache
    state: reloaded
    service_dir: /var/service


MAINTAINERS: Brian Coca (@bcoca)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> SVR4PKG    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/svr4pkg.py)

  Manages SVR4 packages on Solaris 10 and 11. These were the native packages on Solaris <= 10 and are available as a
  legacy feature in Solaris 11. Note that this is a very basic packaging system. It will not enforce dependencies on
  install or remove.

Options (= is mandatory):

- category
        Install/Remove category instead of a single package.
        (Choices: true, false)[Default: (null)]
= name
        Package name, e.g. `SUNWcsr'

- proxy
        HTTP[s] proxy to be used if `src' is a URL.
        [Default: (null)]
- response_file
        Specifies the location of a response file to be used if package expects input on install. (added in Ansible 1.4)
        [Default: (null)]
- src
        Specifies the location to install the package from. Required when `state=present'.
        Can be any path acceptable to the `pkgadd' command's `-d' option. e.g.: `somefile.pkg', `/dir/with/pkgs',
        `http:/server/mypkgs.pkg'.
        If using a file or directory, they must already be accessible by the host. See the [copy] module for a way to get
        them there.
        [Default: (null)]
= state
        Whether to install (`present'), or remove (`absent') a package.
        If the package is to be installed, then `src' is required.
        The SVR4 package system doesn't provide an upgrade operation. You need to uninstall the old, then install the new
        package.
        (Choices: present, absent)
- zone
        Whether to install the package only in the current zone, or install it into all zones.
        The installation into all zones works only if you are working with the global zone.
        (Choices: current, all)[Default: all]
EXAMPLES:
# Install a package from an already copied file
- svr4pkg:
    name: CSWcommon
    src: /tmp/cswpkgs.pkg
    state: present

# Install a package directly from an http site
- svr4pkg:
    name: CSWpkgutil
    src: 'http://get.opencsw.org/now'
    state: present
    zone: current

# Install a package with a response file
- svr4pkg:
    name: CSWggrep
    src: /tmp/third-party.pkg
    response_file: /tmp/ggrep.response
    state: present

# Ensure that a package is not installed.
- svr4pkg:
    name: SUNWgnome-sound-recorder
    state: absent

# Ensure that a category is not installed.
- svr4pkg:
    name: FIREFOX
    state: absent
    category: true


MAINTAINERS: Boyd Adamson (@brontitall)

METADATA:
	Status: ['preview']
	Supported_by: community
> SWDEPOT    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/swdepot.py)

  Will install, upgrade and remove packages with swdepot package manager (HP-UX)

Options (= is mandatory):

- depot
        The source repository from which install or upgrade a package.
        (Choices: )[Default: None]
= name
        package name.
        (Choices: )[Default: None]
= state
        whether to install (`present', `latest'), or remove (`absent') a package.
        (Choices: present, latest, absent)[Default: None]
EXAMPLES:
- swdepot:
    name: unzip-6.0
    state: installed
    depot: 'repository:/path'

- swdepot:
    name: unzip
    state: latest
    depot: 'repository:/path'

- swdepot:
    name: unzip
    state: absent


MAINTAINERS: Raul Melo (@melodous)

METADATA:
	Status: ['preview']
	Supported_by: community
> SWUPD    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/swupd.py)

  Manages updates and bundles with the swupd bundle manager, which is used by the Clear Linux Project for Intel
  Architecture.

Options (= is mandatory):

- contenturl
        URL pointing to the contents of available bundles. If not specified, the contents are retrieved from
        clearlinux.org.
        [Default: None]
- format
        The format suffix for version file downloads. For example [1,2,3,staging,etc]. If not specified, the default
        format is used.
        [Default: None]
- manifest
        The manifest contains information about the bundles at certaion version of the OS. Specify a Manifest version to
        verify against that version or leave unspecified to verify against the current version.
        [Default: None]
- name
        Name of the (I)bundle to install or remove.
        [Default: None]
- state
        Indicates the desired (I)bundle state. `present' ensures the bundle is installed while `absent' ensures the
        (I)bundle is not installed.
        (Choices: present, absent)[Default: present]
- update
        Updates the OS to the latest version.
        [Default: False]
- url
        Overrides both `contenturl' and `versionurl'.
        [Default: None]
- verify
        Verify content for OS version.
        [Default: None]
- versionurl
        URL for version string download.
        [Default: None]
EXAMPLES:
- name: Update the OS to the latest version
  swupd:
    update: yes

- name: Installs the "foo" bundle
  swupd:
    name: foo
    state: present

- name: Removes the "foo" bundle
  swupd:
    name: foo
    state: absent

- name: Check integrity of filesystem
  swupd:
    verify: yes

- name: Downgrade OS to release 12920
  swupd:
    verify: yes
    manifest: 12920

RETURN VALUES:
stdout:
  description: stdout of swupd
  returned: always
  type: string
stderr:
  description: stderr of swupd
  returned: always
  type: string


MAINTAINERS: Alberto Murillo (@albertomurillo)

METADATA:
	Status: ['preview']
	Supported_by: community
> SYNCHRONIZE    (/usr/lib/python2.7/site-packages/ansible/modules/files/synchronize.py)

  `synchronize' is a wrapper around rsync to make common tasks in your playbooks quick and easy. It is run and originates
  on the local host where Ansible is being run. Of course, you could just use the `command' action to call rsync
  yourself, but you also have to add a fair number of boilerplate options and host facts. `synchronize' is not intended
  to provide access to the full power of rsync, but does make the most common invocations easier to implement. You
  `still` may need to call rsync directly via `command' or `shell' depending on your use case.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- archive
        Mirrors the rsync archive flag, enables recursive, links, perms, times, owner, group flags and -D.
        (Choices: yes, no)[Default: yes]
- checksum
        Skip based on checksum, rather than mod-time & size; Note that that "archive" option is still enabled by default
        - the "checksum" option will not disable it.
        (Choices: yes, no)[Default: no]
- compress
        Compress file data during the transfer. In most cases, leave this enabled unless it causes problems.
        (Choices: yes, no)[Default: yes]
- copy_links
        Copy symlinks as the item that they point to (the referent) is copied, rather than the symlink.
        (Choices: yes, no)[Default: no]
- delete
        Delete files in `dest' that don't exist (after transfer, not before) in the `src' path. This option requires
        `recursive=yes'.
        (Choices: yes, no)[Default: no]
= dest
        Path on the destination host that will be synchronized from the source; The path can be absolute or relative.

- dest_port
        Port number for ssh on the destination host. Prior to ansible 2.0, the ansible_ssh_port inventory var took
        precedence over this value.
        [Default: Value of ansible_ssh_port for this host, remote_port config setting, or the value from ssh client
        configuration if none of those are set]
- dirs
        Transfer directories without recursing
        (Choices: yes, no)[Default: no]
- existing_only
        Skip creating new files on receiver.
        (Choices: yes, no)[Default: no]
- group
        Preserve group
        (Choices: yes, no)[Default: the value of the archive option]
- links
        Copy symlinks as symlinks.
        (Choices: yes, no)[Default: the value of the archive option]
- mode
        Specify the direction of the synchronization. In push mode the localhost or delegate is the source; In pull mode
        the remote host in context is the source.
        (Choices: push, pull)[Default: push]
- owner
        Preserve owner (super user only)
        (Choices: yes, no)[Default: the value of the archive option]
- partial
        Tells rsync to keep the partial file which should make a subsequent transfer of the rest of the file much faster.
        [Default: False]
- perms
        Preserve permissions.
        (Choices: yes, no)[Default: the value of the archive option]
- recursive
        Recurse into directories.
        (Choices: yes, no)[Default: the value of the archive option]
- rsync_opts
        Specify additional rsync options by passing in an array.
        [Default: None]
- rsync_path
        Specify the rsync command to run on the remote host. See `--rsync-path' on the rsync man page.
        [Default: (null)]
- rsync_timeout
        Specify a --timeout for the rsync command in seconds.
        [Default: 0]
- set_remote_user
        put user@ for the remote paths. If you have a custom ssh config to define the remote user for a host that does
        not match the inventory user, you should set this parameter to "no".
        [Default: True]
= src
        Path on the source host that will be synchronized to the destination; The path can be absolute or relative.

- times
        Preserve modification times
        (Choices: yes, no)[Default: the value of the archive option]
- use_ssh_args
        Use the ssh_args specified in ansible.cfg
        (Choices: yes, no)[Default: no]
- verify_host
        Verify destination host key.
        [Default: False]
Notes:
  * rsync must be installed on both the local and remote host.
  * For the `synchronize' module, the "local host" is the host `the synchronize task originates on`, and the
        "destination host" is the host `synchronize is connecting to`.
  * The "local host" can be changed to a different host by using `delegate_to`.  This enables copying between two
        remote hosts or entirely on one remote machine.
  * The user and permissions for the synchronize `src` are those of the user running the Ansible task on the local
        host (or the remote_user for a delegate_to host when delegate_to is used).
  * The user and permissions for the synchronize `dest` are those of the `remote_user` on the destination host or
        the `become_user` if `become=yes` is active.
  * In 2.0.0.0 a bug in the synchronize module made become occur on the "local host".  This was fixed in 2.0.1.
  * Currently, synchronize is limited to elevating permissions via passwordless sudo.  This is because rsync itself
        is connecting to the remote machine and rsync doesn't give us a way to pass sudo credentials in.
  * Currently there are only a few connection types which support synchronize (ssh, paramiko, local, and docker)
        because a sync strategy has been determined for those connection types.  Note that the connection for these
        must not need a password as rsync itself is making the connection and rsync does not provide us a way to
        pass a password to the connection.
  * Expect that dest=~/x will be ~<remote_user>/x even if using sudo.
  * Inspect the verbose output to validate the destination user/host/path are what was expected.
  * To exclude files and directories from being synchronized, you may add `.rsync-filter' files to the source
        directory.
  * rsync daemon must be up and running with correct permission when using rsync protocol in source or destination
        path.
  * The `synchronize' module forces `--delay-updates` to avoid leaving a destination in a broken in-between state
        if the underlying rsync process encounters an error. Those synchronizing large numbers of files that are
        willing to trade safety for performance should call rsync directly.
EXAMPLES:
# Synchronization of src on the control machine to dest on the remote hosts
- synchronize:
    src: some/relative/path
    dest: /some/absolute/path

# Synchronization using rsync protocol (push)
- synchronize:
    src: some/relative/path/
    dest: rsync://somehost.com/path/

# Synchronization using rsync protocol (pull)
- synchronize:
    mode: pull
    src: rsync://somehost.com/path/
    dest: /some/absolute/path/

# Synchronization using rsync protocol on delegate host (push)
- synchronize:
    src: /some/absolute/path/
    dest: rsync://somehost.com/path/
  delegate_to: delegate.host

# Synchronization using rsync protocol on delegate host (pull)
- synchronize:
    mode: pull
    src: rsync://somehost.com/path/
    dest: /some/absolute/path/
  delegate_to: delegate.host

# Synchronization without any --archive options enabled
- synchronize:
    src: some/relative/path
    dest: /some/absolute/path
    archive: no

# Synchronization with --archive options enabled except for --recursive
- synchronize:
    src: some/relative/path
    dest: /some/absolute/path
    recursive: no

# Synchronization with --archive options enabled except for --times, with --checksum option enabled
- synchronize:
    src: some/relative/path
    dest: /some/absolute/path
    checksum: yes
    times: no

# Synchronization without --archive options enabled except use --links
- synchronize:
    src: some/relative/path
    dest: /some/absolute/path
    archive: no
    links: yes

# Synchronization of two paths both on the control machine
- synchronize:
    src: some/relative/path
    dest: /some/absolute/path
  delegate_to: localhost

# Synchronization of src on the inventory host to the dest on the localhost in pull mode
- synchronize:
    mode: pull
    src: some/relative/path
    dest: /some/absolute/path

# Synchronization of src on delegate host to dest on the current inventory host.
- synchronize:
    src: /first/absolute/path
    dest: /second/absolute/path
  delegate_to: delegate.host

# Synchronize two directories on one remote host.
- synchronize:
    src: /first/absolute/path
    dest: /second/absolute/path
  delegate_to: "{{ inventory_hostname }}"

# Synchronize and delete files in dest on the remote host that are not found in src of localhost.
- synchronize:
    src: some/relative/path
    dest: /some/absolute/path
    delete: yes
    recursive: yes

# Synchronize using an alternate rsync command
# This specific command is granted su privileges on the destination
- synchronize:
    src: some/relative/path
    dest: /some/absolute/path
    rsync_path: "su -c rsync"

# Example .rsync-filter file in the source directory
# - var       # exclude any path whose last part is 'var'
# - /var      # exclude any path starting with 'var' starting at the source directory
# + /var/conf # include /var/conf even though it was previously excluded

# Synchronize passing in extra rsync options
- synchronize:
    src: /tmp/helloworld
    dest: /var/www/helloworld
    rsync_opts:
      - "--no-motd"
      - "--exclude=.git"


MAINTAINERS: Timothy Appnel (@tima)

METADATA:
	Status: ['preview']
	Supported_by: core
> SYSCTL    (/usr/lib/python2.7/site-packages/ansible/modules/system/sysctl.py)

  This module manipulates sysctl entries and optionally performs a `/sbin/sysctl -p' after changing them.

Options (= is mandatory):

- ignoreerrors
        Use this option to ignore errors about unknown keys.
        (Choices: yes, no)[Default: False]
= name
        The dot-separated path (aka `key') specifying the sysctl variable.
        [Default: None]
- reload
        If `yes', performs a `/sbin/sysctl -p' if the `sysctl_file' is updated. If `no', does not reload `sysctl' even if
        the `sysctl_file' is updated.
        (Choices: yes, no)[Default: yes]
- state
        Whether the entry should be present or absent in the sysctl file.
        (Choices: present, absent)[Default: present]
- sysctl_file
        Specifies the absolute path to `sysctl.conf', if not `/etc/sysctl.conf'.
        [Default: /etc/sysctl.conf]
- sysctl_set
        Verify token value with the sysctl command and set with -w if necessary
        (Choices: yes, no)[Default: False]
- value
        Desired value of the sysctl key.
        [Default: None]
EXAMPLES:
# Set vm.swappiness to 5 in /etc/sysctl.conf
- sysctl:
    name: vm.swappiness
    value: 5
    state: present

# Remove kernel.panic entry from /etc/sysctl.conf
- sysctl:
    name: kernel.panic
    state: absent
    sysctl_file: /etc/sysctl.conf

# Set kernel.panic to 3 in /tmp/test_sysctl.conf
- sysctl:
    name: kernel.panic
    value: 3
    sysctl_file: /tmp/test_sysctl.conf
    reload: no

# Set ip forwarding on in /proc and do not reload the sysctl file
- sysctl:
    name: net.ipv4.ip_forward
    value: 1
    sysctl_set: yes

# Set ip forwarding on in /proc and in the sysctl file and reload if necessary
- sysctl:
    name: net.ipv4.ip_forward
    value: 1
    sysctl_set: yes
    state: present
    reload: yes


MAINTAINERS: David CHANIAL (@davixx) <david.chanial@gmail.com>

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> SYSTEMD    (/usr/lib/python2.7/site-packages/ansible/modules/system/systemd.py)

  Controls systemd services on remote hosts.

Options (= is mandatory):

- daemon_reload
        run daemon-reload before doing any other operations, to make sure systemd has read any changes.
        (Choices: yes, no)[Default: False]
- enabled
        Whether the service should start on boot. *At least one of state and enabled are required.*
        (Choices: yes, no)[Default: None]
- masked
        Whether the unit should be masked or not, a masked unit is impossible to start.
        (Choices: yes, no)[Default: None]
= name
        Name of the service. When using in a chroot environment you always need to specify the full name i.e.
        (crond.service).

- no_block
        Do not synchronously wait for the requested operation to finish. Enqueued job will continue without Ansible
        blocking on its completion.
        (Choices: yes, no)[Default: False]
- state
        `started'/`stopped' are idempotent actions that will not run commands unless necessary. `restarted' will always
        bounce the service. `reloaded' will always reload.
        (Choices: started, stopped, restarted, reloaded)[Default: None]
- user
        run systemctl talking to the service manager of the calling user, rather than the service manager of the system.
        (Choices: yes, no)[Default: False]
Notes:
  * One option other than name is required.
Requirements:  A system managed by systemd

EXAMPLES:
# Example action to start service httpd, if not running
- systemd: state=started name=httpd

# Example action to stop service cron on debian, if running
- systemd: name=cron state=stopped

# Example action to restart service cron on centos, in all cases, also issue daemon-reload to pick up config changes
- systemd:
    state: restarted
    daemon_reload: yes
    name: crond

# Example action to reload service httpd, in all cases
- systemd:
    name: httpd
    state: reloaded

# Example action to enable service httpd and ensure it is not masked
- systemd:
    name: httpd
    enabled: yes
    masked: no

# Example action to enable a timer for dnf-automatic
- systemd:
    name: dnf-automatic.timer
    state: started
    enabled: True

RETURN VALUES:
status:
    description: A dictionary with the key=value pairs returned from `systemctl show`
    returned: success
    type: complex
    sample: {
            "ActiveEnterTimestamp": "Sun 2016-05-15 18:28:49 EDT",
            "ActiveEnterTimestampMonotonic": "8135942",
            "ActiveExitTimestampMonotonic": "0",
            "ActiveState": "active",
            "After": "auditd.service systemd-user-sessions.service time-sync.target systemd-journald.socket basic.target system.slice",
            "AllowIsolate": "no",
            "Before": "shutdown.target multi-user.target",
            "BlockIOAccounting": "no",
            "BlockIOWeight": "1000",
            "CPUAccounting": "no",
            "CPUSchedulingPolicy": "0",
            "CPUSchedulingPriority": "0",
            "CPUSchedulingResetOnFork": "no",
            "CPUShares": "1024",
            "CanIsolate": "no",
            "CanReload": "yes",
            "CanStart": "yes",
            "CanStop": "yes",
            "CapabilityBoundingSet": "18446744073709551615",
            "ConditionResult": "yes",
            "ConditionTimestamp": "Sun 2016-05-15 18:28:49 EDT",
            "ConditionTimestampMonotonic": "7902742",
            "Conflicts": "shutdown.target",
            "ControlGroup": "/system.slice/crond.service",
            "ControlPID": "0",
            "DefaultDependencies": "yes",
            "Delegate": "no",
            "Description": "Command Scheduler",
            "DevicePolicy": "auto",
            "EnvironmentFile": "/etc/sysconfig/crond (ignore_errors=no)",
            "ExecMainCode": "0",
            "ExecMainExitTimestampMonotonic": "0",
            "ExecMainPID": "595",
            "ExecMainStartTimestamp": "Sun 2016-05-15 18:28:49 EDT",
            "ExecMainStartTimestampMonotonic": "8134990",
            "ExecMainStatus": "0",
            "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -HUP $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
            "ExecStart": "{ path=/usr/sbin/crond ; argv[]=/usr/sbin/crond -n $CRONDARGS ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
            "FragmentPath": "/usr/lib/systemd/system/crond.service",
            "GuessMainPID": "yes",
            "IOScheduling": "0",
            "Id": "crond.service",
            "IgnoreOnIsolate": "no",
            "IgnoreOnSnapshot": "no",
            "IgnoreSIGPIPE": "yes",
            "InactiveEnterTimestampMonotonic": "0",
            "InactiveExitTimestamp": "Sun 2016-05-15 18:28:49 EDT",
            "InactiveExitTimestampMonotonic": "8135942",
            "JobTimeoutUSec": "0",
            "KillMode": "process",
            "KillSignal": "15",
            "LimitAS": "18446744073709551615",
            "LimitCORE": "18446744073709551615",
            "LimitCPU": "18446744073709551615",
            "LimitDATA": "18446744073709551615",
            "LimitFSIZE": "18446744073709551615",
            "LimitLOCKS": "18446744073709551615",
            "LimitMEMLOCK": "65536",
            "LimitMSGQUEUE": "819200",
            "LimitNICE": "0",
            "LimitNOFILE": "4096",
            "LimitNPROC": "3902",
            "LimitRSS": "18446744073709551615",
            "LimitRTPRIO": "0",
            "LimitRTTIME": "18446744073709551615",
            "LimitSIGPENDING": "3902",
            "LimitSTACK": "18446744073709551615",
            "LoadState": "loaded",
            "MainPID": "595",
            "MemoryAccounting": "no",
            "MemoryLimit": "18446744073709551615",
            "MountFlags": "0",
            "Names": "crond.service",
            "NeedDaemonReload": "no",
            "Nice": "0",
            "NoNewPrivileges": "no",
            "NonBlocking": "no",
            "NotifyAccess": "none",
            "OOMScoreAdjust": "0",
            "OnFailureIsolate": "no",
            "PermissionsStartOnly": "no",
            "PrivateNetwork": "no",
            "PrivateTmp": "no",
            "RefuseManualStart": "no",
            "RefuseManualStop": "no",
            "RemainAfterExit": "no",
            "Requires": "basic.target",
            "Restart": "no",
            "RestartUSec": "100ms",
            "Result": "success",
            "RootDirectoryStartOnly": "no",
            "SameProcessGroup": "no",
            "SecureBits": "0",
            "SendSIGHUP": "no",
            "SendSIGKILL": "yes",
            "Slice": "system.slice",
            "StandardError": "inherit",
            "StandardInput": "null",
            "StandardOutput": "journal",
            "StartLimitAction": "none",
            "StartLimitBurst": "5",
            "StartLimitInterval": "10000000",
            "StatusErrno": "0",
            "StopWhenUnneeded": "no",
            "SubState": "running",
            "SyslogLevelPrefix": "yes",
            "SyslogPriority": "30",
            "TTYReset": "no",
            "TTYVHangup": "no",
            "TTYVTDisallocate": "no",
            "TimeoutStartUSec": "1min 30s",
            "TimeoutStopUSec": "1min 30s",
            "TimerSlackNSec": "50000",
            "Transient": "no",
            "Type": "simple",
            "UMask": "0022",
            "UnitFileState": "enabled",
            "WantedBy": "multi-user.target",
            "Wants": "system.slice",
            "WatchdogTimestampMonotonic": "0",
            "WatchdogUSec": "0",
        }


MAINTAINERS: Ansible Core Team

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> TAIGA_ISSUE    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/taiga_issue.py)

  Creates/deletes an issue in a Taiga Project Management Platform (https://taiga.io). An issue is identified by the
  combination of project, issue subject and issue type. This module implements the creation or deletion of issues (not
  the update).

Options (= is mandatory):

- attachment
        Path to a file to be attached to the issue.
        [Default: None]
- attachment_description
        A string describing the file to be attached to the issue.
        [Default: ]
- description
        The issue description.
        [Default: ]
= issue_type
        The issue type. Must exist previously.

- priority
        The issue priority. Must exist previously.
        [Default: Normal]
= project
        Name of the project containing the issue. Must exist previously.

- severity
        The issue severity. Must exist previously.
        [Default: Normal]
- state
        Whether the issue should be present or not.
        (Choices: present, absent)[Default: present]
- status
        The issue status. Must exist previously.
        [Default: New]
= subject
        The issue subject.

- tags
        A lists of tags to be assigned to the issue.
        [Default: []]
- taiga_host
        The hostname of the Taiga instance.
        [Default: https://api.taiga.io]
Notes:
  * The authentication is achieved either by the environment variable TAIGA_TOKEN or by the pair of environment
        variables TAIGA_USERNAME and TAIGA_PASSWORD
Requirements:  python-taiga

EXAMPLES:
# Create an issue in the my hosted Taiga environment and attach an error log
- taiga_issue:
    taiga_host: https://mytaigahost.example.com
    project: myproject
    subject: An error has been found
    issue_type: Bug
    priority: High
    status: New
    severity: Important
    description: An error has been found. Please check the attached error log for details.
    attachment: /path/to/error.log
    attachment_description: Error log file
    tags:
      - Error
      - Needs manual check
    state: present

# Deletes the previously created issue
- taiga_issue:
    taiga_host: https://mytaigahost.example.com
    project: myproject
    subject: An error has been found
    issue_type: Bug
    state: absent

RETURN VALUES:
 

MAINTAINERS: Alejandro Guirao (@lekum)

METADATA:
	Status: ['preview']
	Supported_by: community
> TELEGRAM    (/usr/lib/python2.7/site-packages/ansible/modules/notification/telegram.py)

  Send notifications via telegram bot, to a verified group or user

Options (= is mandatory):

= chat_id
        Telegram group or user chat_id

= msg
        What message you wish to send.

= token
        Token identifying your telegram bot.

Notes:
  * You will require a telegram account and create telegram bot to use this module.
EXAMPLES:

- name: send a message to chat in playbook
  telegram:
    token: 'bot9999999:XXXXXXXXXXXXXXXXXXXXXXX'
    chat_id: 000000
    msg: Ansible task finished

RETURN VALUES:

msg:
  description: The message you attempted to send
  returned: success
  type: string
  sample: "Ansible task finished"


MAINTAINERS: Artem Feofanov (@tyouxa)

METADATA:
	Status: ['preview']
	Supported_by: community
> TEMPFILE    (/usr/lib/python2.7/site-packages/ansible/modules/files/tempfile.py)

  The `tempfile' module creates temporary files and directories. `mktemp' command takes different parameters on various
  systems, this module helps to avoid troubles related to that. Files/directories created by module are accessible only
  by creator. In case you need to make them world-accessible you need to use [file] module.

Options (= is mandatory):

- path
        Location where temporary file or directory should be created. If path is not specified default system temporary
        directory will be used.
        [Default: None]
- prefix
        Prefix of file/directory name created by module.
        [Default: ansible.]
- state
        Whether to create file or directory.
        (Choices: file, directory)[Default: file]
- suffix
        Suffix of file/directory name created by module.
        [Default: ]
EXAMPLES:
- name: create temporary build directory
  tempfile:
    state: directory
    suffix: build

- name: create temporary file
  tempfile:
    state: file
    suffix: temp

RETURN VALUES:
path:
  description: Path to created file or directory
  returned: success
  type: string
  sample: "/tmp/ansible.bMlvdk"


MAINTAINERS: Krzysztof Magosa

METADATA:
	Status: ['preview']
	Supported_by: community
> TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/files/template.py)

  Templates are processed by the Jinja2 templating language (http://jinja.pocoo.org/docs/) - documentation on the
  template formatting can be found in the Template Designer Documentation (http://jinja.pocoo.org/docs/templates/). Six
  additional variables can be used in templates: `ansible_managed' (configurable via the `defaults' section of
  `ansible.cfg') contains a string which can be used to describe the template name, host, modification time of the
  template file and the owner uid. `template_host' contains the node name of the template's machine. `template_uid' the
  numeric user id of the owner. `template_path' the path of the template. `template_fullpath' is the absolute path of the
  template. `template_run_date' is the date that the template was rendered.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
= dest
        Location to render the template to on the remote machine.

- force
        the default is `yes', which will replace the remote file when contents are different than the source.  If `no',
        the file will only be transferred if the destination does not exist.
        (Choices: yes, no)[Default: yes]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
= src
        Path of a Jinja2 formatted template on the Ansible controller. This can be a relative or absolute path.

- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- validate
        The validation command to run before copying into place. The path to the file to validate is passed in via '%s'
        which must be present as in the example below. The command is passed securely so shell features like expansion
        and pipes won't work.
        [Default: None]
Notes:
  * Including a string that uses a date in the template will result in the template being marked 'changed' each
        time
  * Since Ansible version 0.9, templates are loaded with `trim_blocks=True'.
  * Also, you can override jinja2 settings by adding a special header to template file. i.e.
        `#jinja2:variable_start_string:'[%' , variable_end_string:'%]', trim_blocks: False' which changes the
        variable interpolation markers to  [% var %] instead of  {{ var }}. This is the best way to prevent
        evaluation of things that look like, but should not be Jinja2. raw/endraw in Jinja2 will not work as you
        expect because templates in Ansible are recursively evaluated.
EXAMPLES:
# Example from Ansible Playbooks
- template:
    src: /mytemplates/foo.j2
    dest: /etc/file.conf
    owner: bin
    group: wheel
    mode: 0644

# The same example, but using symbolic modes equivalent to 0644
- template:
    src: /mytemplates/foo.j2
    dest: /etc/file.conf
    owner: bin
    group: wheel
    mode: "u=rw,g=r,o=r"

# Copy a new "sudoers" file into place, after passing validation with visudo
- template:
    src: /mine/sudoers
    dest: /etc/sudoers
    validate: 'visudo -cf %s'

# Update sshd configuration safely, avoid locking yourself out
- template:
    src: etc/ssh/sshd_config.j2
    dest: /etc/ssh/sshd_config
    owner: root
    group: root
    mode: '0600'
    validate: /usr/sbin/sshd -t -f %s
    backup: yes


MAINTAINERS: Ansible Core Team, Michael DeHaan

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> TIMEZONE    (/usr/lib/python2.7/site-packages/ansible/modules/system/timezone.py)

  This module configures the timezone setting, both of the system clock and of the hardware clock. If you want to set up
  the NTP, use [service] module. It is recommended to restart `crond' after changing the timezone, otherwise the jobs may
  run at the wrong time. Several different tools are used depending on the OS/Distribution involved. For Linux it can use
  `timedatectl'  or edit `/etc/sysconfig/clock' or `/etc/timezone' and`hwclock'. On SmartOS , `sm-set-timezone', for BSD,
  `/etc/localtime' is modified. As of version 2.3 support was added for SmartOS and BSDs. Windows, AIX and HPUX are not
  supported, please let us know if you find any other OS/distro in which this fails.

Options (= is mandatory):

- hwclock
        Whether the hardware clock is in UTC or in local timezone. Default is to keep current setting. Note that this
        option is recommended not to change and may fail to configure, especially on virtual environments such as AWS.
        *At least one of name and hwclock are required.* `Only used on Linux.'
        [Default: (null)]
- name
        Name of the timezone for the system clock. Default is to keep current setting. *At least one of name and hwclock
        are required.*
        [Default: (null)]
Notes:
  * On SmartOS the `sm-set-timezone' utility (part of the smtools package) is required to set the zone timezone
EXAMPLES:
- name: set timezone to Asia/Tokyo
  timezone:
    name: Asia/Tokyo

RETURN VALUES:
diff:
  description: The differences about the given arguments.
  returned: success
  type: dictionary
  contains:
    before:
      description: The values before change
      type: dict
    after:
      description: The values after change
      type: dict


MAINTAINERS: Shinichi TAMURA (@tmshn), Jasper Lievisse Adriaanse (@jasperla)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_CREDENTIAL    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_credential.py)

  Create, update, or destroy Ansible Tower credentials. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- authorize
        Should use authroize for net type.
        [Default: False]
- authorize_password
        Password for net credentials that require authroize.
        [Default: None]
- become_method
        Become method to Use for privledge escalation.
        (Choices: None, sudo, su, pbrun, pfexec)[Default: None]
- become_password
        Become password. Use ASK for prompting.
        [Default: None]
- become_username
        Become username. Use ASK for prompting.
        [Default: None]
- client
        Client or application ID for azure_rm type.
        [Default: None]
- description
        The description to use for the credential.
        [Default: (null)]
- domain
        Domain for openstack type.
        [Default: None]
- host
        Host for this credential.
        [Default: None]
= kind
        Type of credential being added.
        (Choices: ssh, net, scm, aws, rax, vmware, satellite6, cloudforms, gce, azure, azure_rm, openstack)
= name
        The name to use for the credential.

- organization
        Organization that should own the credential.
        [Default: None]
- password
        Password for this credential. Use ASK for prompting. secret_key for AWS. api_key for RAX.
        [Default: None]
- project
        Project that should for this credential.
        [Default: None]
- secret
        Secret token for azure_rm type.
        [Default: None]
- ssh_key_data
        Path to SSH private key.
        [Default: None]
- ssh_key_unlock
        Unlock password for ssh_key. Use ASK for prompting.
        [Default: (null)]
- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- subscription
        Subscription ID for azure_rm type.
        [Default: None]
- team
        Team that should own this credential.
        [Default: None]
- tenant
        Tenant ID for azure_rm type.
        [Default: None]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
- user
        User that should own this credential.
        [Default: None]
- username
        Username for this credential. access_key for AWS.
        [Default: None]
- vault_password
        Valut password. Use ASK for prompting.
        [Default: (null)]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.2

EXAMPLES:
- name: Add tower credential
  tower_credential:
    name: Team Name
    description: Team Description
    organization: test-org
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_group.py)

  Create, update, or destroy Ansible Tower groups. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- credential
        Credential to use for the group.
        [Default: None]
- description
        The description to use for the group.
        [Default: None]
- group_by
        Limit groups automatically created from inventory source.
        [Default: None]
- instance_filters
        Comma-separated list of filter expressions for matching hosts.
        [Default: None]
= inventory
        Inventory the group should be made a member of.

= name
        The name to use for the group.

- overwrite
        Delete child roups and hosts not found in source.
        [Default: False]
- overwrite_vars
        Override vars in child groups and hosts with those from external source.
        [Default: None]
- source
        The source to use for this group.
        (Choices: manual, file, ec2, rax, vmware, gce, azure, azure_rm, openstack, satellite6, cloudforms,
        custom)[Default: null,]
- source_regions
        Regions for cloud provider.
        [Default: None]
- source_script
        Inventory script to be used when group type is "custom".
        [Default: None]
- source_vars
        Override variables from source with variables from this field.
        [Default: None]
- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
- update_on_launch
        Refresh inventory data from its source each time a job is run.
        [Default: False]
- variables
        Variables to use for the group, use '@' for a file.
        [Default: None]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.2

EXAMPLES:
- name: Add tower group
  tower_group:
    name: localhost
    description: "Local Host Group"
    inventory: "Local Inventory"
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_host.py)

  Create, update, or destroy Ansible Tower hosts. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- description
        The description to use for the host.
        [Default: None]
- enabled
        If the host should be enabled.
        [Default: True]
= inventory
        Inventory the host should be made a member of.

= name
        The name to use for the host.

- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
- variables
        Variables to use for the host. Use '@' for a file.
        [Default: (null)]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Add tower host
  tower_host:
    name: localhost
    description: "Local Host Group"
    inventory: "Local Inventory"
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_INVENTORY    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_inventory.py)

  Create, update, or destroy Ansible Tower inventories. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- description
        The description to use for the inventory.
        [Default: None]
= name
        The name to use for the inventory.

= organization
        Organization the inventory belongs to.

- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
- variables
        Inventory variables. Use '@' to get from file.
        [Default: None]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Add tower inventory
  tower_inventory:
    name: "Foo Inventory"
    description: "Our Foo Cloud Servers"
    organization: "Bar Org"
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_JOB_CANCEL    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_job_cancel.py)

  Cancel Ansible Tower jobs. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- fail_if_not_running
        Fail loudly if the job_id does not reference a running job.
        [Default: False]
= job_id
        ID of the job to cancel

- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.2

EXAMPLES:
- name: Cancel job
  tower_job_cancel:
    job_id: job.id

RETURN VALUES:
id:
    description: job id requesting to cancel
    returned: success
    type: int
    sample: 94
status:
    description: status of the cancel request
    returned: success
    type: string
    sample: canceled


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_JOB_LAUNCH    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_job_launch.py)

  Launch an Ansible Tower jobs. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- credential
        Credential to use for job, only used if prompt for credential is set.
        [Default: None]
- extra_vars
        Extra_vars to use for the job_template. Use '@' for a file.
        [Default: None]
- inventory
        Inventory to use for the job, only used if prompt for inventory is set.
        [Default: None]
- job_explanation
        Job explanation field.
        [Default: None]
= job_template
        Name of the job_template to use.

- job_type
        Job_type to use for the job, only used if prompt for job_type is set.
        (Choices: run, check, scan)[Default: None]
- limit
        Limit to use for the job_template.
        [Default: None]
- tags
        Specific tags to use for from playbook.
        [Default: None]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
- use_job_endpoint
        Disable launching jobs from job template.
        [Default: False]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.2

EXAMPLES:
- name: Launch a job
  tower_job_launch:
    job_template: "My Job Template"
    register: job
- name: Wait for job max 120s
  tower_job_wait:
    job_id: job.id
    timeout: 120

RETURN VALUES:
id:
    description: job id of the newly launched job
    returned: success
    type: int
    sample: 86
status:
    description: status of newly launched job
    returned: success
    type: string
    sample: pending


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_JOB_LIST    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_job_list.py)

  List Ansible Tower jobs. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- all_pages
        Fetch all the pages and return a single result.
        [Default: False]
- page
        Page number of the results to fetch.
        [Default: None]
- query
        Query used to further filter the list of jobs. {"foo":"bar"} will be passed at ?foo=bar
        [Default: None]
- status
        Only list jobs with this status.
        (Choices: pending, waiting, running, error, failed, canceled, successful)[Default: None]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.2

EXAMPLES:
- name: List running jobs for the testing.yml playbook
  tower_job_list:
    status: running
    query: {"playbook": "testing.yml"}
    register: testing_jobs
    tower_config_file: "~/tower_cli.cfg"

RETURN VALUES:
count:
    description: Total count of objects return
    returned: success
    type: int
    sampled: 51
next:
    description: next page available for the listing
    returned: success
    type: int
    sample: 3
previous:
    description: previous page available for the listing
    returned: success
    type: int
    sample: 1
results:
    description: a list of job objects represented as dictionaries
    returned: success
    type: list
    sample: [{"allow_simultaneous": false, "artifacts": {}, "ask_credential_on_launch": false,
              "ask_inventory_on_launch": false, "ask_job_type_on_launch": false, "failed": false,
              "finished": "2017-02-22T15:09:05.633942Z", "force_handlers": false, "forks": 0, "id": 2,
              "inventory": 1, "job_explanation": "", "job_tags": "", "job_template": 5, "job_type": "run"}, ...]


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_JOB_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_job_template.py)

  Create, update, or destroy Ansible Tower job templates. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- ask_credential
        Prompt user for credential on launch.
        [Default: False]
- ask_extra_vars
        Prompt user for extra_vars on launch.
        [Default: False]
- ask_inventory
        Propmt user for inventory on launch.
        [Default: False]
- ask_job_type
        Prompt user for job type on launch.
        [Default: False]
- ask_tags
        Prompt user for job tags on launch.
        [Default: False]
- become_enabled
        Should become_enabled.
        [Default: False]
- cloud_credential
        Cloud_credential to use for the job_template.
        [Default: None]
- description
        Description to use for the job_template.
        [Default: None]
- extra_vars_path
        Path to the extra_vars yaml file.
        [Default: None]
- forks
        The number of parallel or simultaneous processes to use while executing the playbook.
        [Default: None]
- host_config_key
        Allow provisioning callbacks using this host config key.
        [Default: None]
- inventory
        Inventory to use for the job_template.
        [Default: None]
- job_tags
        The job_tags to use for the job_template.
        [Default: None]
= job_type
        The job_type to use for the job_template.
        (Choices: run, check, scan)
- limit
        A host pattern to further constrain the list of hosts managed or affected by the playbook
        [Default: None]
- machine_credential
        Machine_credential to use for the job_template.
        [Default: None]
= name
        Name to use for the job_template.

- network_credential
        The network_credential to use for the job_template.
        [Default: None]
= playbook
        Playbook to use for the job_template.

= project
        Project to use for the job_template.

- skip_tags
        The skip_tags to use for the job_template.
        [Default: None]
- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
- verbosity
        Control the output level Ansible produces as the playbook runs.
        (Choices: verbose, debug)[Default: None]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Create tower Ping job template
  tower_job_template:
    name: Ping
    job_type: run
    inventory: Local
    project: Demo
    playbook: ping.yml
    machine_credential: Local
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_JOB_WAIT    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_job_wait.py)

  Wait for Ansible Tower job to finish and report success or failure. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

= job_id
        ID of the job to monitor.

- max_interval
        Maximum interval in seconds, to request an update from Tower.
        [Default: 30]
- min_interval
        Minimum interval in seconds, to request an update from Tower.
        [Default: 1]
- timeout
        Maximum time in seconds to wait for a job to finish.
        [Default: None]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.2

EXAMPLES:
- name: Launch a job
  tower_job_launch:
    job_template: "My Job Template"
    register: job
- name: Wait for job max 120s
  tower_job_wait:
    job_id: job.id
    timeout: 120

RETURN VALUES:
id:
    description: job id that is being waited on
    returned: success
    type: int
    sample: 99
elapsed:
    description: total time in seconds the job took to run
    returned: success
    type: float
    sample: 10.879
started:
    description: timestamp of when the job started running
    returned: success
    type: string
    sample: 2017-03-01T17:03:53.200234Z
finished:
    description: timestamp of when the job finished running
    returned: success
    type: string
    sample: 2017-03-01T17:04:04.078782Z
status:
    description: current status of job
    returned: success
    type: string
    sample: successful


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_LABEL    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_label.py)

  Create, update, or destroy Ansible Tower labels. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

= name
        Name to use for the label.
        [Default: None]
= organization
        Organization the label should be applied to.
        [Default: None]
- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Add label to tower organization
  tower_label:
    name: Custom Label
    organization: My Organization
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_ORGANIZATION    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_organization.py)

  Create, update, or destroy Ansible Tower organizations. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- description
        The description to use for the organization.
        [Default: None]
= name
        Name to use for the organization.

- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
Notes:
  * If no `tower_config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower
        host information.
  * `tower_config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Create tower organization
  tower_organization:
    name: "Foo"
    description: "Foo bar organization"
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_PROJECT    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_project.py)

  Create, update, or destroy Ansible Tower projects. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- description
        Description to use for the project.
        [Default: None]
- local_path
        The server playbook directory for manual projects.
        [Default: None]
= name
        Name to use for the project.
        [Default: None]
- organization
        Primary key of organization for project.
        [Default: None]
- scm_branch
        The branch to use for the scm resource.
        [Default: None]
- scm_clean
        Remove local modifications before updating.
        [Default: False]
- scm_credential
        Name of the credential to use with this scm resource.
        [Default: None]
- scm_delete_on_update
        Remove the repository completely before updating.
        [Default: False]
- scm_type
        Type of scm resource.
        (Choices: manual, git, hg, svn)[Default: manual]
- scm_update_on_launch
        Before an update to the local repository before launching a job with this project.
        [Default: False]
- scm_url
        URL of scm resource.
        [Default: None]
- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Add tower project
  tower_project:
    name: "Foo"
    description: "Foo bar project"
    organization: "test"
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_role.py)

  Create, update, or destroy Ansible Tower roles. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- credential
        Credential the role acts on.
        [Default: None]
- inventory
        Inventory the role acts on.
        [Default: None]
- job_template
        The job_template the role acts on.
        [Default: None]
- organization
        Organiation the role acts on.
        [Default: None]
- project
        Project the role acts on.
        [Default: None]
= role
        The role type to grant/revoke.
        (Choices: admin, read, member, execute, adhoc, update, use, auditor)
- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- target_team
        Team that the role acts on.
        [Default: None]
- team
        Team that receives the permissions specified by the role.
        [Default: None]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
- user
        User that receives the permissions specified by the role.
        [Default: None]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Add jdoe to the member role of My Team
  tower_role:
    user: jdoe
    target_team: "My Team"
    role: member
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_TEAM    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_team.py)

  Create, update, or destroy Ansible Tower teams. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

= name
        Name to use for the team.
        [Default: None]
= organization
        Organization the team should be made a member of.
        [Default: None]
- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Create tower team
  tower_team:
    name: Team Name
    description: Team Description
    organization: test-org
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TOWER_USER    (/usr/lib/python2.7/site-packages/ansible/modules/web_infrastructure/ansible_tower/tower_user.py)

  Create, update, or destroy Ansible Tower users. See https://www.ansible.com/tower for an overview.

Options (= is mandatory):

- auditor
        User is a system wide auditor.
        [Default: False]
= email
        Email address of the user.

- first_name
        First name of the user.
        [Default: None]
- last_name
        Last name of the user.
        [Default: None]
- organization
        Organization the user should be made a member of.
        [Default: None]
- password
        Password of the user.
        [Default: None]
- state
        Desired state of the resource.
        (Choices: present, absent)[Default: present]
- superuser
        User is a system wide administator.
        [Default: False]
- tower_config_file
        Path to the Tower config file. See notes.
        [Default: None]
- tower_host
        URL to your Tower instance.
        [Default: None]
- tower_password
        Password for your Tower instance.
        [Default: None]
- tower_username
        Username for your Tower instance.
        [Default: None]
- tower_verify_ssl
        Dis/allow insecure connections to Tower. If `no', SSL certificates will not be validated. This should only be
        used on personally controlled sites using self-signed certificates.
        [Default: True]
= username
        The username of the user.

Notes:
  * If no `config_file' is provided we will attempt to use the tower-cli library defaults to find your Tower host
        information.
  * `config_file' should contain Tower configuration in the following format host=hostname username=username
        password=password
Requirements:  python >= 2.6, ansible-tower-cli >= 3.0.3

EXAMPLES:
- name: Add tower user
  tower_user:
    username: jdoe
    password: foobarbaz
    email: jdoe@example.org
    first_name: John
    last_name: Doe
    state: present
    tower_config_file: "~/tower_cli.cfg"


MAINTAINERS: Wayne Witzel III (@wwitzel3)

METADATA:
	Status: ['preview']
	Supported_by: community
> TWILIO    (/usr/lib/python2.7/site-packages/ansible/modules/notification/twilio.py)

  Sends a text message to a phone number through the Twilio messaging API.

Options (= is mandatory):

= account_sid
        user's Twilio account token found on the account page

= auth_token
        user's Twilio authentication token

= from_number
        the Twilio number to send the text message from, format +15551112222

- media_url
        a URL with a picture, video or sound clip to send with an MMS (multimedia message) instead of a plain SMS
        [Default: (null)]
= msg
        the body of the text message

= to_number
        one or more phone numbers to send the text message to, format +15551112222

Notes:
  * This module is non-idempotent because it sends an email through the external API. It is idempotent only in the
        case that the module fails.
  * Like the other notification modules, this one requires an external dependency to work. In this case, you'll
        need a Twilio account with a purchased or verified phone number to send the text message.
EXAMPLES:
# send an SMS about the build status to (555) 303 5681
# note: replace account_sid and auth_token values with your credentials
# and you have to have the 'from_number' on your Twilio account
- twilio:
    msg: All servers with webserver role are now configured.
    account_sid: ACXXXXXXXXXXXXXXXXX
    auth_token: ACXXXXXXXXXXXXXXXXX
    from_number: +15552014545
    to_number: +15553035681
  delegate_to: localhost

# send an SMS to multiple phone numbers about the deployment
# note: replace account_sid and auth_token values with your credentials
# and you have to have the 'from_number' on your Twilio account
- twilio:
    msg: This server configuration is now complete.
    account_sid: ACXXXXXXXXXXXXXXXXX
    auth_token: ACXXXXXXXXXXXXXXXXX
    from_number: +15553258899
    to_number:
      - +15551113232
      - +12025551235
      - +19735559010
  delegate_to: localhost

# send an MMS to a single recipient with an update on the deployment
# and an image of the results
# note: replace account_sid and auth_token values with your credentials
# and you have to have the 'from_number' on your Twilio account
- twilio:
    msg: Deployment complete!
    account_sid: ACXXXXXXXXXXXXXXXXX
    auth_token: ACXXXXXXXXXXXXXXXXX
    from_number: +15552014545
    to_number: +15553035681
    media_url: https://demo.twilio.com/logo.png
  delegate_to: localhost


MAINTAINERS: Matt Makai (@makaimc)

METADATA:
	Status: ['preview']
	Supported_by: community
> TYPETALK    (/usr/lib/python2.7/site-packages/ansible/modules/notification/typetalk.py)

  Send a message to typetalk using typetalk API ( http://developers.typetalk.in/ )

Options (= is mandatory):

= client_id
        OAuth2 client ID

= client_secret
        OAuth2 client secret

= msg
        message body

= topic
        topic id to post message

Requirements:  json

EXAMPLES:
- typetalk:
    client_id: 12345
    client_secret: 12345
    topic: 1
    msg: install completed


MAINTAINERS: Takashi Someda (@tksmd)

METADATA:
	Status: ['preview']
	Supported_by: community
> UDM_DNS_RECORD    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/univention/udm_dns_record.py)

  This module allows to manage dns records on a univention corporate server (UCS). It uses the python API of the UCS to
  create a new object or edit it.

Options (= is mandatory):

- data
        Additional data for this record, e.g. ['a': '192.0.2.1']. Required if `state=present'.
        [Default: []]
= name
        Name of the record, this is also the DNS record. E.g. www for www.example.com.

- state
        Whether the dns record is present or not.
        (Choices: present, absent)[Default: present]
= type
        Define the record type. `host_record' is a A or AAAA record, `alias' is a CNAME, `ptr_record' is a PTR record,
        `srv_record' is a SRV record and `txt_record' is a TXT record.
        (Choices: host_record, alias, ptr_record, srv_record, txt_record)
= zone
        Corresponding DNS zone for this record, e.g. example.com.

Requirements:  Python >= 2.6, Univention

EXAMPLES:
# Create a DNS record on a UCS
- udm_dns_zone:
    name: www
    zone: example.com
    type: host_record
    data:
      - a: 192.0.2.1

RETURN VALUES:
 

MAINTAINERS: Tobias Rueetschi (@2-B)

METADATA:
	Status: ['preview']
	Supported_by: community
> UDM_DNS_ZONE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/univention/udm_dns_zone.py)

  This module allows to manage dns zones on a univention corporate server (UCS). It uses the python API of the UCS to
  create a new object or edit it.

Options (= is mandatory):

- contact
        Contact person in the SOA record.
        [Default: ]
- expire
        Specifies the upper limit on the time interval that can elapse before the zone is no longer authoritative.
        [Default: 604800]
- interfaces
        List of interface IP addresses, on which the server should response this zone. Required if `state=present'.
        [Default: (null)]
- mx
        List of MX servers. (Must declared as A or AAAA records).
        [Default: []]
- nameserver
        List of appropriate name servers. Required if `state=present'.
        [Default: (null)]
- refresh
        Interval before the zone should be refreshed.
        [Default: 3600]
- retry
        Interval that should elapse before a failed refresh should be retried.
        [Default: 1800]
- state
        Whether the dns zone is present or not.
        (Choices: present, absent)[Default: present]
- ttl
        Minimum TTL field that should be exported with any RR from this zone.
        [Default: 600]
= type
        Define if the zone is a forward or reverse DNS zone.
        (Choices: forward_zone, reverse_zone)
= zone
        DNS zone name, e.g. `example.com'.

Requirements:  Python >= 2.6

EXAMPLES:
# Create a DNS zone on a UCS
- udm_dns_zone:
    zone: example.com
    type: forward_zone
    nameserver:
      - ucs.example.com
    interfaces:
      - 192.0.2.1

RETURN VALUES:
 

MAINTAINERS: Tobias Rueetschi (@2-B)

METADATA:
	Status: ['preview']
	Supported_by: community
> UDM_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/univention/udm_group.py)

  This module allows to manage user groups on a univention corporate server (UCS). It uses the python API of the UCS to
  create a new object or edit it.

Options (= is mandatory):

- description
        Group description.
        [Default: (null)]
= name
        Name of the posix group.

- ou
        LDAP OU, e.g. school for LDAP OU `ou=school,dc=example,dc=com'.
        [Default: (null)]
- position
        define the whole ldap position of the group, e.g. `cn=g123m-
        1A,cn=classes,cn=schueler,cn=groups,ou=schule,dc=example,dc=com'.
        [Default: (null)]
- state
        Whether the group is present or not.
        (Choices: present, absent)[Default: present]
- subpath
        Subpath inside the OU, e.g. `cn=classes,cn=students,cn=groups'.
        [Default: (null)]
Requirements:  Python >= 2.6

EXAMPLES:
# Create a POSIX group
- udm_group:
    name: g123m-1A

# Create a POSIX group with the exact DN
# C(cn=g123m-1A,cn=classes,cn=students,cn=groups,ou=school,dc=school,dc=example,dc=com)
- udm_group:
    name: g123m-1A
    subpath: 'cn=classes,cn=students,cn=groups'
    ou: school
# or
- udm_group:
    name: g123m-1A
    position: 'cn=classes,cn=students,cn=groups,ou=school,dc=school,dc=example,dc=com'

RETURN VALUES:
 

MAINTAINERS: Tobias Rueetschi (@2-B)

METADATA:
	Status: ['preview']
	Supported_by: community
> UDM_SHARE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/univention/udm_share.py)

  This module allows to manage samba shares on a univention corporate server (UCS). It uses the python API of the UCS to
  create a new object or edit it.

Options (= is mandatory):

- directorymode
        Permissions for the share's root directory.
        [Default: 00755]
- group
        Directory owner group of the share's root directory.
        [Default: 0]
- host
        Host FQDN (server which provides the share), e.g. `{{ ansible_fqdn }}'. Required if `state=present'.
        [Default: None]
= name
        Name

- nfs_custom_settings
        Option name in exports file.
        [Default: []]
- nfs_hosts
        Only allow access for this host, IP address or network.
        [Default: []]
= ou
        Organisational unit, inside the LDAP Base DN.

- owner
        Directory owner of the share's root directory.
        [Default: 0]
- path
        Directory on the providing server, e.g. `/home'. Required if `state=present'.
        [Default: None]
- root_squash
        Modify user ID for root user (root squashing).
        (Choices: 0, 1)[Default: 1]
- samba_block_size
        Blocking size.
        [Default: None]
- samba_blocking_locks
        Blocking locks.
        (Choices: 0, 1)[Default: 1]
- samba_browseable
        Show in Windows network environment.
        (Choices: 0, 1)[Default: 1]
- samba_create_mode
        File mode.
        [Default: 0744]
- samba_csc_policy
        Client-side caching policy.
        [Default: manual]
- samba_custom_settings
        Option name in smb.conf and its value.
        [Default: []]
- samba_directory_mode
        Directory mode.
        [Default: 0755]
- samba_directory_security_mode
        Directory security mode.
        [Default: 0777]
- samba_dos_filemode
        Users with write access may modify permissions.
        (Choices: 0, 1)[Default: 0]
- samba_fake_oplocks
        Fake oplocks.
        (Choices: 0, 1)[Default: 0]
- samba_force_create_mode
        Force file mode.
        (Choices: 0, 1)[Default: 0]
- samba_force_directory_mode
        Force directory mode.
        (Choices: 0, 1)[Default: 0]
- samba_force_directory_security_mode
        Force directory security mode.
        (Choices: 0, 1)[Default: 0]
- samba_force_group
        Force group.
        [Default: None]
- samba_force_security_mode
        Force security mode.
        (Choices: 0, 1)[Default: 0]
- samba_force_user
        Force user.
        [Default: None]
- samba_hide_files
        Hide files.
        [Default: None]
- samba_hide_unreadable
        Hide unreadable files/directories.
        (Choices: 0, 1)[Default: 0]
- samba_hosts_allow
        Allowed host/network.
        [Default: []]
- samba_hosts_deny
        Denied host/network.
        [Default: []]
- samba_inherit_acls
        Inherit ACLs.
        (Choices: 0, 1)[Default: 1]
- samba_inherit_owner
        Create files/directories with the owner of the parent directory.
        (Choices: 0, 1)[Default: 0]
- samba_inherit_permissions
        Create files/directories with permissions of the parent directory.
        (Choices: 0, 1)[Default: 0]
- samba_invalid_users
        Invalid users or groups.
        [Default: None]
- samba_level_2_oplocks
        Level 2 oplocks.
        (Choices: 0, 1)[Default: 1]
- samba_locking
        Locking.
        (Choices: 0, 1)[Default: 1]
- samba_msdfs_root
        MSDFS root.
        (Choices: 0, 1)[Default: 0]
- samba_name
        Windows name. Required if `state=present'.
        [Default: None]
- samba_nt_acl_support
        NT ACL support.
        (Choices: 0, 1)[Default: 1]
- samba_oplocks
        Oplocks.
        (Choices: 0, 1)[Default: 1]
- samba_postexec
        Postexec script.
        [Default: None]
- samba_preexec
        Preexec script.
        [Default: None]
- samba_public
        Allow anonymous read-only access with a guest user.
        (Choices: 0, 1)[Default: 0]
- samba_security_mode
        Security mode.
        [Default: 0777]
- samba_strict_locking
        Strict locking.
        [Default: Auto]
- samba_valid_users
        Valid users or groups.
        [Default: None]
- samba_vfs_objects
        VFS objects.
        [Default: None]
- samba_write_list
        Restrict write access to these users/groups.
        [Default: None]
- samba_writeable
        Samba write access.
        (Choices: 0, 1)[Default: 1]
- state
        Whether the share is present or not.
        (Choices: present, absent)[Default: present]
- subtree_checking
        Subtree checking.
        (Choices: 0, 1)[Default: 1]
- sync
        NFS synchronisation.
        [Default: sync]
- writeable
        NFS write access.
        (Choices: 0, 1)[Default: 1]
Requirements:  Python >= 2.6

EXAMPLES:
# Create a share named home on the server ucs.example.com with the path /home.
- udm_share:
    name: home
    path: /home
    host: ucs.example.com
    sambaName: Home

RETURN VALUES:
 

MAINTAINERS: Tobias Rueetschi (@2-B)

METADATA:
	Status: ['preview']
	Supported_by: community
> UDM_USER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/univention/udm_user.py)

  This module allows to manage posix users on a univention corporate server (UCS). It uses the python API of the UCS to
  create a new object or edit it.

Options (= is mandatory):

- birthday
        Birthday
        [Default: None]
- city
        City of users business address.
        [Default: None]
- country
        Country of users business address.
        [Default: None]
- department_number
        Department number of users business address.
        [Default: None]
- description
        Description (not gecos)
        [Default: None]
- display_name
        Display name (not gecos)
        [Default: None]
- email
        A list of e-mail addresses.
        [Default: [u'']]
- employee_number
        Employee number
        [Default: None]
- employee_type
        Employee type
        [Default: None]
- firstname
        First name. Required if `state=present'.
        [Default: (null)]
- gecos
        GECOS
        [Default: None]
- groups
        POSIX groups, the LDAP DNs of the groups will be found with the LDAP filter for each group as $GROUP:
        `(&(objectClass=posixGroup'(cn=$GROUP))).
        [Default: []]
- home_share
        Home NFS share. Must be a LDAP DN, e.g. `cn=home,cn=shares,ou=school,dc=example,dc=com'.
        [Default: None]
- home_share_path
        Path to home NFS share, inside the homeShare.
        [Default: None]
- home_telephone_number
        List of private telephone numbers.
        [Default: []]
- homedrive
        Windows home drive, e.g. `"H:"'.
        [Default: None]
- lastname
        Last name. Required if `state=present'.
        [Default: (null)]
- mail_alternative_address
        List of alternative e-mail addresses.
        [Default: []]
- mail_home_server
        FQDN of mail server
        [Default: None]
- mail_primary_address
        Primary e-mail address
        [Default: None]
- mobile_telephone_number
        Mobile phone number
        [Default: []]
- organisation
        Organisation
        [Default: None]
- ou
        Organizational Unit inside the LDAP Base DN, e.g. `school' for LDAP OU `ou=school,dc=example,dc=com'.
        [Default: ]
- override_pw_history
        Override password history
        [Default: False]
- override_pw_length
        Override password check
        [Default: False]
- pager_telephonenumber
        List of pager telephone numbers.
        [Default: []]
- password
        Password. Required if `state=present'.
        [Default: None]
- phone
        List of telephone numbers.
        [Default: []]
- position
        Define the whole position of users object inside the LDAP tree, e.g.
        `cn=employee,cn=users,ou=school,dc=example,dc=com'.
        [Default: ]
- postcode
        Postal code of users business address.
        [Default: None]
- primary_group
        Primary group. This must be the group LDAP DN.
        [Default: cn=Domain Users,cn=groups,$LDAP_BASE_DN]
- profilepath
        Windows profile directory
        [Default: None]
- pwd_change_next_login
        Change password on next login.
        (Choices: 0, 1)[Default: None]
- room_number
        Room number of users business address.
        [Default: None]
- samba_privileges
        Samba privilege, like allow printer administration, do domain join.
        [Default: []]
- samba_user_workstations
        Allow the authentication only on this Microsoft Windows host.
        [Default: []]
- sambahome
        Windows home path, e.g. `'\\$FQDN\$USERNAME''.
        [Default: None]
- scriptpath
        Windows logon script.
        [Default: None]
- secretary
        A list of superiors as LDAP DNs.
        [Default: []]
- serviceprovider
        Enable user for the following service providers.
        [Default: [u'']]
- shell
        Login shell
        [Default: /bin/bash]
- state
        Whether the user is present or not.
        (Choices: present, absent)[Default: present]
- street
        Street of users business address.
        [Default: None]
- subpath
        LDAP subpath inside the organizational unit, e.g. `cn=teachers,cn=users' for LDAP container
        `cn=teachers,cn=users,dc=example,dc=com'.
        [Default: cn=users]
- title
        Title, e.g. `Prof.'.
        [Default: None]
- unixhome
        Unix home directory
        [Default: /home/$USERNAME]
- update_password
        `always' will update passwords if they differ. `on_create' will only set the password for newly created users.
        [Default: always]
- userexpiry
        Account expiry date, e.g. `1999-12-31'.
        [Default: Today + 1 year]
= username
        User name

Requirements:  Python >= 2.6

EXAMPLES:
# Create a user on a UCS
- udm_user:
    name: FooBar
    password: secure_password
    firstname: Foo
    lastname: Bar

# Create a user with the DN
# C(uid=foo,cn=teachers,cn=users,ou=school,dc=school,dc=example,dc=com)
- udm_user:
    name: foo
    password: secure_password
    firstname: Foo
    lastname: Bar
    ou: school
    subpath: 'cn=teachers,cn=users'
# or define the position
- udm_user:
    name: foo
    password: secure_password
    firstname: Foo
    lastname: Bar
    position: 'cn=teachers,cn=users,ou=school,dc=school,dc=example,dc=com'

RETURN VALUES:
 

MAINTAINERS: Tobias Rueetschi (@2-B)

METADATA:
	Status: ['preview']
	Supported_by: community
> UFW    (/usr/lib/python2.7/site-packages/ansible/modules/system/ufw.py)

  Manage firewall with UFW.

Options (= is mandatory):

- delete
        Delete rule.
        (Choices: yes, no)[Default: (null)]
- direction
        Select direction for a rule or default policy command.
        (Choices: in, out, incoming, outgoing, routed)[Default: (null)]
- from_ip
        Source IP address.
        [Default: any]
- from_port
        Source port.
        [Default: (null)]
- insert
        Insert the corresponding rule as rule number NUM
        [Default: (null)]
- interface
        Specify interface for rule.
        [Default: (null)]
- log
        Log new connections matched to this rule
        (Choices: yes, no)[Default: (null)]
- logging
        Toggles logging. Logged packets use the LOG_KERN syslog facility.
        (Choices: on, off, low, medium, high, full)[Default: (null)]
- name
        Use profile located in `/etc/ufw/applications.d'
        [Default: (null)]
- policy
        Change the default policy for incoming or outgoing traffic.
        (Choices: allow, deny, reject)[Default: (null)]
- proto
        TCP/IP protocol.
        (Choices: any, tcp, udp, ipv6, esp, ah)[Default: (null)]
- route
        Apply the rule to routed/forwarded packets.
        (Choices: yes, no)[Default: (null)]
- rule
        Add firewall rule
        (Choices: allow, deny, reject, limit)[Default: (null)]
- state
        `enabled' reloads firewall and enables firewall on boot.
        `disabled' unloads firewall and disables firewall on boot.
        `reloaded' reloads firewall.
        `reset' disables and resets firewall to installation defaults.
        (Choices: enabled, disabled, reloaded, reset)[Default: (null)]
- to_ip
        Destination IP address.
        [Default: any]
- to_port
        Destination port.
        [Default: (null)]
Notes:
  * See `man ufw' for more examples.
Requirements:  `ufw' package

EXAMPLES:
# Allow everything and enable UFW
- ufw:
    state: enabled
    policy: allow

# Set logging
- ufw:
    logging: on

# Sometimes it is desirable to let the sender know when traffic is
# being denied, rather than simply ignoring it. In these cases, use
# reject instead of deny. In addition, log rejected connections:
- ufw:
    rule: reject
    port: auth
    log: yes

# ufw supports connection rate limiting, which is useful for protecting
# against brute-force login attacks. ufw will deny connections if an IP
# address has attempted to initiate 6 or more connections in the last
# 30 seconds. See  http://www.debian-administration.org/articles/187
# for details. Typical usage is:
- ufw:
    rule: limit
    port: ssh
    proto: tcp

# Allow OpenSSH. (Note that as ufw manages its own state, simply removing
# a rule=allow task can leave those ports exposed. Either use delete=yes
# or a separate state=reset task)
- ufw:
    rule: allow
    name: OpenSSH

# Delete OpenSSH rule
- ufw:
    rule: allow
    name: OpenSSH
    delete: yes

# Deny all access to port 53:
- ufw:
    rule: deny
    port: 53

# Allow port range 60000-61000
- ufw:
    rule: allow
    port: '60000:61000'

# Allow all access to tcp port 80:
- ufw:
    rule: allow
    port: 80
    proto: tcp

# Allow all access from RFC1918 networks to this host:
- ufw:
    rule: allow
    src: '{{ item }}'
  with_items:
    - 10.0.0.0/8
    - 172.16.0.0/12
    - 192.168.0.0/16

# Deny access to udp port 514 from host 1.2.3.4:
- ufw:
    rule: deny
    proto: udp
    src: 1.2.3.4
    port: 514

# Allow incoming access to eth0 from 1.2.3.5 port 5469 to 1.2.3.4 port 5469
- ufw:
    rule: allow
    interface: eth0
    direction: in
    proto: udp
    src: 1.2.3.5
    from_port: 5469
    dest: 1.2.3.4
    to_port: 5469

# Deny all traffic from the IPv6 2001:db8::/32 to tcp port 25 on this host.
# Note that IPv6 must be enabled in /etc/default/ufw for IPv6 firewalling to work.
- ufw:
    rule: deny
    proto: tcp
    src: '2001:db8::/32'
    port: 25

# Deny forwarded/routed traffic from subnet 1.2.3.0/24 to subnet 4.5.6.0/24.
# Can be used to further restrict a global FORWARD policy set to allow
- ufw:
    rule: deny
    route: yes
    src: 1.2.3.0/24
    dest: 4.5.6.0/24


MAINTAINERS: Aleksey Ovcharenko (@ovcharenko), Jarno Keskikangas (@pyykkis), Ahti Kitsik (@ahtik)

METADATA:
	Status: ['preview']
	Supported_by: community
> UNARCHIVE    (/usr/lib/python2.7/site-packages/ansible/modules/files/unarchive.py)

  The `unarchive' module unpacks an archive. By default, it will copy the source file from the local system to the target
  before unpacking - set remote_src=yes to unpack an archive which already exists on the target..

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- copy
        If true, the file is copied from local 'master' to the target machine, otherwise, the plugin will look for src
        archive at the target machine.
        This option has been deprecated in favor of `remote_src'
        This option is mutually exclusive with `remote_src'.
        (Choices: yes, no)[Default: yes]
- creates
        a filename, when it already exists, this step will *not* be run.
        [Default: None]
= dest
        Remote absolute path where the archive should be unpacked
        [Default: None]
- exclude
        List the directory and file entries that you would like to exclude from the unarchive action.
        [Default: []]
- extra_opts
        Specify additional options by passing in an array.
        [Default: None]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- keep_newer
        Do not replace existing files that are newer than files from the archive.
        [Default: False]
- list_files
        If set to True, return the list of files that are contained in the tarball.
        (Choices: yes, no)[Default: no]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- remote_src
        Set to `yes' to indicate the archived file is already on the remote system and not local to the Ansible
        controller.
        This option is mutually exclusive with `copy'.
        (Choices: yes, no)[Default: no]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
= src
        If remote_src=no (default), local path to archive file to copy to the target server; can be absolute or relative.
        If remote_src=yes, path on the target server to existing archive file to unpack.
        If remote_src=yes and src contains ://, the remote machine will download the file from the url first.
        (version_added 2.0). This is only for simple cases, for full download support look at the [get_url] module.
        [Default: None]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- validate_certs
        This only applies if using a https url as the source of the file.
        This should only set to `no' used on personally controlled sites using self-signed cer
        Prior to 2.2 the code worked as if this was set to `yes'.
        (Choices: yes, no)[Default: yes]
Notes:
  * requires `gtar'/`unzip' command on target host
  * can handle `.zip' files using `unzip' as well as `.tar', `.tar.gz', `.tar.bz2' and `.tar.xz' files using `gtar'
  * uses gtar's `--diff arg' to calculate if changed or not. If this `arg' is not supported, it will always unpack
        the archive
  * existing files/directories in the destination which are not in the archive are not touched.  This is the same
        behavior as a normal archive extraction
  * existing files/directories in the destination which are not in the archive are ignored for purposes of deciding
        if the archive should be unpacked or not
EXAMPLES:
# Example from Ansible Playbooks
- unarchive:
    src: foo.tgz
    dest: /var/lib/foo

# Unarchive a file that is already on the remote machine
- unarchive:
    src: /tmp/foo.zip
    dest: /usr/local/bin
    remote_src: True

# Unarchive a file that needs to be downloaded (added in 2.0)
- unarchive:
    src: https://example.com/example.zip
    dest: /usr/local/bin
    remote_src: True


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['preview']
	Supported_by: core
> UPTIMEROBOT    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/uptimerobot.py)

  This module will let you start and pause Uptime Robot Monitoring

Options (= is mandatory):

= apikey
        Uptime Robot API key.
        (Choices: )[Default: None]
= monitorid
        ID of the monitor to check.
        (Choices: )[Default: None]
= state
        Define whether or not the monitor should be running or paused.
        (Choices: started, paused)[Default: None]
Notes:
  * Support for adding and removing monitors and alert contacts has not yet been implemented.
Requirements:  Valid Uptime Robot API Key

EXAMPLES:
# Pause the monitor with an ID of 12345.
- uptimerobot:
    monitorid: 12345
    apikey: 12345-1234512345
    state: paused

# Start the monitor with an ID of 12345.
- uptimerobot:
    monitorid: 12345
    apikey: 12345-1234512345
    state: started


MAINTAINERS: Nate Kingsley (@nate-kingsley)

METADATA:
	Status: ['preview']
	Supported_by: community
> URI    (/usr/lib/python2.7/site-packages/ansible/modules/network/basics/uri.py)

  Interacts with HTTP and HTTPS web services and supports Digest, Basic and WSSE HTTP authentication mechanisms.

Options (= is mandatory):

- HEADER_
        Any parameter starting with "HEADER_" is a sent with your request as a header. For example, HEADER_Content-
        Type="application/json" would send the header "Content-Type" along with your request with a value of
        "application/json". This option is deprecated as of `2.1' and may be removed in a future release. Use `headers'
        instead.
        [Default: None]
- body
        The body of the http request/response to the web service. If `body_format' is set to 'json' it will take an
        already formatted JSON string or convert a data structure into JSON.
        [Default: None]
- body_format
        The serialization format of the body. When set to json, encodes the body argument, if needed, and automatically
        sets the Content-Type header accordingly. As of `2.3' it is possible to override the `Content-Type` header, when
        set to json via the `headers' option.
        (Choices: raw, json)[Default: raw]
- creates
        a filename, when it already exists, this step will not be run.
        [Default: (null)]
- dest
        path of where to download the file to (if desired). If `dest' is a directory, the basename of the file on the
        remote server will be used.
        [Default: None]
- follow_redirects
        Whether or not the URI module should follow redirects. `all' will follow all redirects. `safe' will follow only
        "safe" redirects, where "safe" means that the client is only doing a GET or HEAD on the URI to which it is being
        redirected. `none' will not follow any redirects. Note that `yes' and `no' choices are accepted for backwards
        compatibility, where `yes' is the equivalent of `all' and `no' is the equivalent of `safe'. `yes' and `no' are
        deprecated and will be removed in some future version of Ansible.
        (Choices: all, safe, none)[Default: safe]
- force_basic_auth
        The library used by the uri module only sends authentication information when a webservice responds to an initial
        request with a 401 status. Since some basic auth services do not properly send a 401, logins will fail. This
        option forces the sending of the Basic authentication header upon initial request.
        (Choices: yes, no)[Default: no]
- headers
        Add custom HTTP headers to a request in the format of a YAML hash. As of `2.3' supplying `Content-Type' here will
        override the header generated by supplying `json' for `body_format'.
        [Default: None]
- method
        The HTTP method of the request or response. It MUST be uppercase.
        (Choices: GET, POST, PUT, HEAD, DELETE, OPTIONS, PATCH, TRACE, CONNECT, REFRESH)[Default: GET]
- others
        all arguments accepted by the [file] module also work here
        [Default: (null)]
- password
        password for the module to use for Digest, Basic or WSSE authentication.
        [Default: None]
- removes
        a filename, when it does not exist, this step will not be run.
        [Default: (null)]
- return_content
        Whether or not to return the body of the request as a "content" key in the dictionary result. If the reported
        Content-type is "application/json", then the JSON is additionally loaded into a key called `json' in the
        dictionary results.
        (Choices: yes, no)[Default: no]
- status_code
        A valid, numeric, HTTP status code that signifies success of the request. Can also be comma separated list of
        status codes.
        [Default: 200]
- timeout
        The socket level timeout in seconds
        [Default: 30]
= url
        HTTP or HTTPS URL in the form (http|https)://host.domain[:port]/path
        [Default: None]
- user
        username for the module to use for Digest, Basic or WSSE authentication.
        [Default: None]
- validate_certs
        If `no', SSL certificates will not be validated.  This should only set to `no' used on personally controlled
        sites using self-signed certificates.  Prior to 1.9.2 the code defaulted to `no'.
        (Choices: yes, no)[Default: yes]
Notes:
  * The dependency on httplib2 was removed in Ansible 2.1
EXAMPLES:
- name: Check that you can connect (GET) to a page and it returns a status 200
  uri:
    url: http://www.example.com

# Check that a page returns a status 200 and fail if the word AWESOME is not
# in the page contents.
- uri:
    url: http://www.example.com
    return_content: yes
  register: webpage

- name: Fail if AWESOME is not in the page content
  fail:
  when: "'AWESOME' not in webpage.content"


- name: Create a JIRA issue
  uri:
    url: https://your.jira.example.com/rest/api/2/issue/
    method: POST
    user: your_username
    password: your_pass
    body: "{{ lookup('file','issue.json') }}"
    force_basic_auth: yes
    status_code: 201
    body_format: json

# Login to a form based webpage, then use the returned cookie to
# access the app in later tasks

- uri:
    url: https://your.form.based.auth.example.com/index.php
    method: POST
    body: "name=your_username&password=your_password&enter=Sign%20in"
    status_code: 302
    headers:
      Content-Type: "application/x-www-form-urlencoded"
  register: login

- uri:
    url: https://your.form.based.auth.example.com/dashboard.php
    method: GET
    return_content: yes
    headers:
      Cookie: "{{login.set_cookie}}"

- name: Queue build of a project in Jenkins
  uri:
    url: "http://{{ jenkins.host }}/job/{{ jenkins.job }}/build?token={{ jenkins.token }}"
    method: GET
    user: "{{ jenkins.user }}"
    password: "{{ jenkins.password }}"
    force_basic_auth: yes
    status_code: 201



MAINTAINERS: Romeo Theriault (@romeotheriault)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> URPMI    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/urpmi.py)

  Manages packages with `urpmi' (such as for Mageia or Mandriva)

Options (= is mandatory):

- force
        Assume "yes" is the answer to any question urpmi has to ask. Corresponds to the `--force' option for `urpmi'.
        (Choices: yes, no)[Default: True]
- no-recommends
        Corresponds to the `--no-recommends' option for `urpmi'.
        (Choices: yes, no)[Default: True]
= pkg
        name of package to install, upgrade or remove.
        [Default: None]
- state
        Indicates the desired package state
        (Choices: absent, present)[Default: present]
- update_cache
        update the package database first `urpmi.update -a'.
        (Choices: yes, no)[Default: False]
EXAMPLES:
# install package foo
- urpmi:
    pkg: foo
    state: present

# remove package foo
- urpmi:
    pkg: foo
    state: absent

# description: remove packages foo and bar
- urpmi:
    pkg: foo,bar
    state: absent

# description: update the package database (urpmi.update -a -q) and install bar (bar will be the updated if a newer version exists)
- urpmi:
    name: bar
    state: present
    update_cache: yes


MAINTAINERS: Philippe Makowski (@pmakowski)

METADATA:
	Status: ['preview']
	Supported_by: community
> USER    (/usr/lib/python2.7/site-packages/ansible/modules/system/user.py)

  Manage user accounts and user attributes.

Options (= is mandatory):

- append
        If `yes', will only add groups, not set them to just the list in `groups'.
        (Choices: yes, no)[Default: no]
- comment
        Optionally sets the description (aka `GECOS') of user account.
        [Default: (null)]
- createhome
        Unless set to `no', a home directory will be made for the user when the account is created or if the home
        directory does not exist.
        (Choices: yes, no)[Default: yes]
- expires
        An expiry time for the user in epoch, it will be ignored on platforms that do not support this. Currently
        supported on Linux and FreeBSD.
        [Default: None]
- force
        When used with `state=absent', behavior is as with `userdel --force'.
        (Choices: yes, no)[Default: no]
- generate_ssh_key
        Whether to generate a SSH key for the user in question. This will *not* overwrite an existing SSH key.
        (Choices: yes, no)[Default: no]
- group
        Optionally sets the user's primary group (takes a group name).
        [Default: (null)]
- groups
        Puts the user in  list of groups. When set to the empty string ('groups='), the user is removed from all groups
        except the primary group.
        Before version 2.3, the only input format allowed was a 'comma separated string', now it should be able to accept
        YAML lists also.
        [Default: (null)]
- home
        Optionally set the user's home directory.
        [Default: (null)]
- login_class
        Optionally sets the user's login class for FreeBSD, OpenBSD and NetBSD systems.
        [Default: (null)]
- move_home
        If set to `yes' when used with `home=', attempt to move the user's home directory to the specified directory if
        it isn't there already.
        (Choices: yes, no)[Default: no]
= name
        Name of the user to create, remove or modify.

- non_unique
        Optionally when used with the -u option, this option allows to change the user ID to a non-unique value.
        (Choices: yes, no)[Default: no]
- password
        Optionally set the user's password to this crypted value.  See the user example in the github examples directory
        for what this looks like in a playbook. See http://docs.ansible.com/ansible/faq.html#how-do-i-generate-crypted-
        passwords-for-the-user-module for details on various ways to generate these password values. Note on Darwin
        system, this value has to be cleartext. Beware of security issues.
        [Default: (null)]
- remove
        When used with `state=absent', behavior is as with `userdel --remove'.
        (Choices: yes, no)[Default: no]
- seuser
        Optionally sets the seuser type (user_u) on selinux enabled systems.
        [Default: (null)]
- shell
        Optionally set the user's shell.
        [Default: (null)]
- skeleton
        Optionally set a home skeleton directory. Requires createhome option!
        [Default: (null)]
- ssh_key_bits
        Optionally specify number of bits in SSH key to create.
        [Default: default set by ssh-keygen]
- ssh_key_comment
        Optionally define the comment for the SSH key.
        [Default: ansible-generated on $HOSTNAME]
- ssh_key_file
        Optionally specify the SSH key filename. If this is a relative filename then it will be relative to the user's
        home directory.
        [Default: .ssh/id_rsa]
- ssh_key_passphrase
        Set a passphrase for the SSH key.  If no passphrase is provided, the SSH key will default to having no
        passphrase.
        [Default: (null)]
- ssh_key_type
        Optionally specify the type of SSH key to generate. Available SSH key types will depend on implementation present
        on target host.
        [Default: rsa]
- state
        Whether the account should exist or not, taking action if the state is different from what is stated.
        (Choices: present, absent)[Default: present]
- system
        When creating an account, setting this to `yes' makes the user a system account.  This setting cannot be changed
        on existing users.
        (Choices: yes, no)[Default: no]
- uid
        Optionally sets the `UID' of the user.
        [Default: (null)]
- update_password
        `always' will update passwords if they differ.  `on_create' will only set the password for newly created users.
        (Choices: always, on_create)[Default: always]
Notes:
  * There are specific requirements per platform on user management utilities. However they generally come pre-
        installed with the system and Ansible will require they are present at runtime. If they are not, a
        descriptive error message will be shown.
EXAMPLES:
# Add the user 'johnd' with a specific uid and a primary group of 'admin'
- user:
    name: johnd
    comment: "John Doe"
    uid: 1040
    group: admin

# Add the user 'james' with a bash shell, appending the group 'admins' and 'developers' to the user's groups
- user:
    name: james
    shell: /bin/bash
    groups: admins,developers
    append: yes

# Remove the user 'johnd'
- user:
    name: johnd
    state: absent
    remove: yes

# Create a 2048-bit SSH key for user jsmith in ~jsmith/.ssh/id_rsa
- user:
    name: jsmith
    generate_ssh_key: yes
    ssh_key_bits: 2048
    ssh_key_file: .ssh/id_rsa

# added a consultant whose account you want to expire
- user:
    name: james18
    shell: /bin/zsh
    groups: developers
    expires: 1422403387


MAINTAINERS: Stephen Fromm (@sfromm)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> VCA_FW    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vca_fw.py)

  Adds or removes firewall rules from a gateway in a vca environment

Options (= is mandatory):

- api_version
        The api version to be used with the vca.
        [Default: 5.7]
= fw_rules
        A list of firewall rules to be added to the gateway, Please see examples on valid entries
        [Default: False]
- gateway_name
        The name of the gateway of the vdc where the rule should be added.
        [Default: gateway]
- host
        The authentication host to be used when service type is vcd.
        [Default: None]
- instance_id
        The instance id in a vchs environment to be used for creating the vapp.
        [Default: None]
- org
        The org to login to for creating vapp. This option is required when the `service_type' is `vdc'.
        [Default: None]
- password
        The vca password, if not set the environment variable `VCA_PASS' is checked for the password.
        [Default: None]
- service_type
        The type of service we are authenticating against.
        (Choices: vca, vchs, vcd)[Default: vca]
- state
        If the object should be added or removed.
        (Choices: present, absent)[Default: present]
- username
        The vca username or email address, if not set the environment variable `VCA_USER' is checked for the username.
        [Default: None]
- vdc_name
        The name of the vdc where the gateway is located.
        [Default: None]
- verify_certs
        If the certificates of the authentication is to be verified.
        [Default: True]
EXAMPLES:

#Add a set of firewall rules

- hosts: localhost
  connection: local
  tasks:
   - vca_fw:
       instance_id: 'b15ff1e5-1024-4f55-889f-ea0209726282'
       vdc_name: 'benz_ansible'
       state: 'absent'
       fw_rules:
         - description: "ben testing"
           source_ip: "Any"
           dest_ip: 192.0.2.23
         - description: "ben testing 2"
           source_ip: 192.0.2.50
           source_port: "Any"
           dest_port: "22"
           dest_ip: 192.0.2.101
           is_enable: "true"
           enable_logging: "false"
           protocol: "Tcp"
           policy: "allow"



MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> VCA_NAT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vca_nat.py)

  Adds or removes nat rules from a gateway in a vca environment

Options (= is mandatory):

- api_version
        The api version to be used with the vca.
        [Default: 5.7]
- gateway_name
        The name of the gateway of the vdc where the rule should be added.
        [Default: gateway]
- host
        The authentication host to be used when service type is vcd.
        [Default: None]
- instance_id
        The instance id in a vchs environment to be used for creating the vapp.
        [Default: None]
= nat_rules
        A list of rules to be added to the gateway, Please see examples on valid entries
        [Default: False]
- org
        The org to login to for creating vapp. This option is required when the `service_type' is `vdc'.
        [Default: None]
- password
        The vca password, if not set the environment variable `VCA_PASS' is checked for the password.
        [Default: None]
- purge_rules
        If set to true, it will delete all rules in the gateway that are not given as paramter to this module.
        [Default: False]
- service_type
        The type of service we are authenticating against.
        (Choices: vca, vchs, vcd)[Default: vca]
- state
        If the object should be added or removed.
        (Choices: present, absent)[Default: present]
- username
        The vca username or email address, if not set the environment variable `VCA_USER' is checked for the username.
        [Default: None]
- vdc_name
        The name of the vdc where the gateway is located.
        [Default: None]
- verify_certs
        If the certificates of the authentication is to be verified.
        [Default: True]
EXAMPLES:

#An example for a source nat

- hosts: localhost
  connection: local
  tasks:
   - vca_nat:
       instance_id: 'b15ff1e5-1024-4f55-889f-ea0209726282'
       vdc_name: 'benz_ansible'
       state: 'present'
       nat_rules:
         - rule_type: SNAT
           original_ip: 192.0.2.42
           translated_ip: 203.0.113.23

#example for a DNAT
- hosts: localhost
  connection: local
  tasks:
   - vca_nat:
       instance_id: 'b15ff1e5-1024-4f55-889f-ea0209726282'
       vdc_name: 'benz_ansible'
       state: 'present'
       nat_rules:
         - rule_type: DNAT
           original_ip: 203.0.113.23
           original_port: 22
           translated_ip: 192.0.2.42
           translated_port: 22



MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> VCA_VAPP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vca_vapp.py)

  This module will actively managed vCloud Air vApp instances.  Instances can be created and deleted as well as both
  deployed and undeployed.

Options (= is mandatory):

- api_version
        The api version to be used with the vca
        [Default: 5.7]
- host
        The authentication host to be used when service type  is vcd.
        [Default: None]
- instance_id
        The instance id in a vchs environment to be used for creating the vapp
        [Default: None]
- network_mode
        Configures the mode of the network connection.
        (Choices: pool, dhcp, static)[Default: pool]
- network_name
        The name of the network that should be attached to the virtual machine in the vApp.  The virtual network
        specified must already be created in the vCloud Air VDC.  If the `state' is not 'absent' then the `network_name'
        argument must be provided.
        [Default: None]
- operation
        Specifies an operation to be performed on the vApp.
        (Choices: noop, poweron, poweroff, suspend, shutdown, reboot, reset)[Default: noop]
- org
        The org to login to for creating vapp, mostly set when the service_type is vdc.
        [Default: None]
- password
        The vCloud Air password to use during authentication
        [Default: None]
- service_type
        The type of service we are authenticating against
        (Choices: vca, vchs, vcd)[Default: vca]
- state
        Configures the state of the vApp.
        (Choices: present, absent, deployed, undeployed)[Default: present]
- template_name
        The name of the vApp template to use to create the vApp instance.  If the `state' is not `absent` then the
        `template_name' value must be provided.  The `template_name' must be previously uploaded to the catalog specified
        by `catalog_name'
        [Default: None]
- username
        The vCloud Air username to use during authentication
        [Default: None]
= vapp_name
        The name of the vCloud Air vApp instance

- vdc_name
        The name of the virtual data center (VDC) where the vm should be created or contains the vAPP.
        [Default: None]
- vm_cpus
        The number of vCPUs to configure for the VM in the vApp.   If the `vm_name' argument is provided, then this
        becomes a per VM setting otherwise it is applied to all VMs in the vApp.
        [Default: None]
- vm_memory
        The amount of memory in MB to allocate to VMs in the vApp.  If the `vm_name' argument is provided, then this
        becomes a per VM setting otherise it is applied to all VMs in the vApp.
        [Default: None]
- vm_name
        The name of the virtual machine instance in the vApp to manage.
        [Default: None]
EXAMPLES:

- name: Creates a new vApp in a VCA instance
  vca_vapp:
    vapp_name: tower
    state: present
    template_name: 'Ubuntu Server 12.04 LTS (amd64 20150127)'
    vdc_name: VDC1
    instance_id: '<your instance id here>'
    username: '<your username here>'
    password: '<your password here>'



MAINTAINERS: Peter Sprygada (@privateip)

METADATA:
	Status: ['preview']
	Supported_by: community
> VERTICA_CONFIGURATION    (/usr/lib/python2.7/site-packages/ansible/modules/database/vertica/vertica_configuration.py)

  Updates Vertica configuration parameters.

Options (= is mandatory):

- cluster
        Name of the Vertica cluster.
        [Default: localhost]
- db
        Name of the Vertica database.
        [Default: None]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: dbadmin]
= name
        Name of the parameter to update.

- port
        Vertica cluster port to connect to.
        [Default: 5433]
= value
        Value of the parameter to be set.

Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the `dbadmin' account on
        the host.
  * This module uses `pyodbc', a Python ODBC database adapter. You must ensure that `unixODBC' and `pyodbc' is
        installed on the host and properly configured.
  * Configuring `unixODBC' for Vertica requires `Driver = /opt/vertica/lib64/libverticaodbc.so' to be added to the
        `Vertica' section of either `/etc/odbcinst.ini' or `$HOME/.odbcinst.ini' and both `ErrorMessagesPath =
        /opt/vertica/lib64' and `DriverManagerEncoding = UTF-16' to be added to the `Driver' section of either
        `/etc/vertica.ini' or `$HOME/.vertica.ini'.
Requirements:  unixODBC, pyodbc

EXAMPLES:
- name: updating load_balance_policy
  vertica_configuration: name=failovertostandbyafter value='8 hours'


MAINTAINERS: Dariusz Owczarek (@dareko)

METADATA:
	Status: ['preview']
	Supported_by: community
> VERTICA_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/database/vertica/vertica_facts.py)

  Gathers Vertica database facts.

Options (= is mandatory):

- cluster
        Name of the cluster running the schema.
        [Default: localhost]
- db
        Name of the database running the schema.
        [Default: None]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: dbadmin]
- port
        Database port to connect to.
        [Default: 5433]
Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the `dbadmin' account on
        the host.
  * This module uses `pyodbc', a Python ODBC database adapter. You must ensure that `unixODBC' and `pyodbc' is
        installed on the host and properly configured.
  * Configuring `unixODBC' for Vertica requires `Driver = /opt/vertica/lib64/libverticaodbc.so' to be added to the
        `Vertica' section of either `/etc/odbcinst.ini' or `$HOME/.odbcinst.ini' and both `ErrorMessagesPath =
        /opt/vertica/lib64' and `DriverManagerEncoding = UTF-16' to be added to the `Driver' section of either
        `/etc/vertica.ini' or `$HOME/.vertica.ini'.
Requirements:  unixODBC, pyodbc

EXAMPLES:
- name: gathering vertica facts
  vertica_facts: db=db_name


MAINTAINERS: Dariusz Owczarek (@dareko)

METADATA:
	Status: ['preview']
	Supported_by: community
> VERTICA_ROLE    (/usr/lib/python2.7/site-packages/ansible/modules/database/vertica/vertica_role.py)

  Adds or removes Vertica database role and, optionally, assign other roles.

Options (= is mandatory):

- assigned_roles
        Comma separated list of roles to assign to the role.
        [Default: None]
- cluster
        Name of the Vertica cluster.
        [Default: localhost]
- db
        Name of the Vertica database.
        [Default: None]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: dbadmin]
= name
        Name of the role to add or remove.

- port
        Vertica cluster port to connect to.
        [Default: 5433]
- state
        Whether to create `present', drop `absent' or lock `locked' a role.
        (Choices: present, absent)[Default: present]
Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the `dbadmin' account on
        the host.
  * This module uses `pyodbc', a Python ODBC database adapter. You must ensure that `unixODBC' and `pyodbc' is
        installed on the host and properly configured.
  * Configuring `unixODBC' for Vertica requires `Driver = /opt/vertica/lib64/libverticaodbc.so' to be added to the
        `Vertica' section of either `/etc/odbcinst.ini' or `$HOME/.odbcinst.ini' and both `ErrorMessagesPath =
        /opt/vertica/lib64' and `DriverManagerEncoding = UTF-16' to be added to the `Driver' section of either
        `/etc/vertica.ini' or `$HOME/.vertica.ini'.
Requirements:  unixODBC, pyodbc

EXAMPLES:
- name: creating a new vertica role
  vertica_role: name=role_name db=db_name state=present

- name: creating a new vertica role with other role assigned
  vertica_role: name=role_name assigned_role=other_role_name state=present


MAINTAINERS: Dariusz Owczarek (@dareko)

METADATA:
	Status: ['preview']
	Supported_by: community
> VERTICA_SCHEMA    (/usr/lib/python2.7/site-packages/ansible/modules/database/vertica/vertica_schema.py)

  Adds or removes Vertica database schema and, optionally, roles with schema access privileges. A schema will not be
  removed until all the objects have been dropped. In such a situation, if the module tries to remove the schema it will
  fail and only remove roles created for the schema if they have no dependencies.

Options (= is mandatory):

- cluster
        Name of the Vertica cluster.
        [Default: localhost]
- create_roles
        Comma separated list of roles to create and grant usage and create access to the schema.
        [Default: None]
- db
        Name of the Vertica database.
        [Default: None]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: dbadmin]
= name
        Name of the schema to add or remove.

- owner
        Name of the user to set as owner of the schema.
        [Default: None]
- port
        Vertica cluster port to connect to.
        [Default: 5433]
- state
        Whether to create `present', or drop `absent' a schema.
        (Choices: present, absent)[Default: present]
- usage_roles
        Comma separated list of roles to create and grant usage access to the schema.
        [Default: None]
Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the `dbadmin' account on
        the host.
  * This module uses `pyodbc', a Python ODBC database adapter. You must ensure that `unixODBC' and `pyodbc' is
        installed on the host and properly configured.
  * Configuring `unixODBC' for Vertica requires `Driver = /opt/vertica/lib64/libverticaodbc.so' to be added to the
        `Vertica' section of either `/etc/odbcinst.ini' or `$HOME/.odbcinst.ini' and both `ErrorMessagesPath =
        /opt/vertica/lib64' and `DriverManagerEncoding = UTF-16' to be added to the `Driver' section of either
        `/etc/vertica.ini' or `$HOME/.vertica.ini'.
Requirements:  unixODBC, pyodbc

EXAMPLES:
- name: creating a new vertica schema
  vertica_schema: name=schema_name db=db_name state=present

- name: creating a new schema with specific schema owner
  vertica_schema: name=schema_name owner=dbowner db=db_name state=present

- name: creating a new schema with roles
  vertica_schema:
    name=schema_name
    create_roles=schema_name_all
    usage_roles=schema_name_ro,schema_name_rw
    db=db_name
    state=present


MAINTAINERS: Dariusz Owczarek (@dareko)

METADATA:
	Status: ['preview']
	Supported_by: community
> VERTICA_USER    (/usr/lib/python2.7/site-packages/ansible/modules/database/vertica/vertica_user.py)

  Adds or removes Vertica database user and, optionally, assigns roles. A user will not be removed until all the
  dependencies have been dropped. In such a situation, if the module tries to remove the user it will fail and only
  remove roles granted to the user.

Options (= is mandatory):

- cluster
        Name of the Vertica cluster.
        [Default: localhost]
- db
        Name of the Vertica database.
        [Default: None]
- expired
        Sets the user's password expiration.
        [Default: None]
- ldap
        Set to true if users are authenticated via LDAP.
        The user will be created with password expired and set to `$ldap$'.
        [Default: None]
- login_password
        The password used to authenticate with.
        [Default: None]
- login_user
        The username used to authenticate with.
        [Default: dbadmin]
= name
        Name of the user to add or remove.

- password
        The user's password encrypted by the MD5 algorithm.
        The password must be generated with the format `"md5" + md5[password + username]', resulting in a total of 35
        characters. An easy way to do this is by querying the Vertica database with select
        'md5'||md5('<user_password><user_name>').
        [Default: None]
- port
        Vertica cluster port to connect to.
        [Default: 5433]
- profile
        Sets the user's profile.
        [Default: None]
- resource_pool
        Sets the user's resource pool.
        [Default: None]
- roles
        Comma separated list of roles to assign to the user.
        [Default: None]
- state
        Whether to create `present', drop `absent' or lock `locked' a user.
        (Choices: present, absent, locked)[Default: present]
Notes:
  * The default authentication assumes that you are either logging in as or sudo'ing to the `dbadmin' account on
        the host.
  * This module uses `pyodbc', a Python ODBC database adapter. You must ensure that `unixODBC' and `pyodbc' is
        installed on the host and properly configured.
  * Configuring `unixODBC' for Vertica requires `Driver = /opt/vertica/lib64/libverticaodbc.so' to be added to the
        `Vertica' section of either `/etc/odbcinst.ini' or `$HOME/.odbcinst.ini' and both `ErrorMessagesPath =
        /opt/vertica/lib64' and `DriverManagerEncoding = UTF-16' to be added to the `Driver' section of either
        `/etc/vertica.ini' or `$HOME/.vertica.ini'.
Requirements:  unixODBC, pyodbc

EXAMPLES:
- name: creating a new vertica user with password
  vertica_user: name=user_name password=md5<encrypted_password> db=db_name state=present

- name: creating a new vertica user authenticated via ldap with roles assigned
  vertica_user:
    name=user_name
    ldap=true
    db=db_name
    roles=schema_name_ro
    state=present


MAINTAINERS: Dariusz Owczarek (@dareko)

METADATA:
	Status: ['preview']
	Supported_by: community
> VIRT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/virt.py)

  Manages virtual machines supported by `libvirt'.

Options (= is mandatory):

- autostart
        start VM at host startup
        (Choices: True, False)[Default: None]
- command
        in addition to state management, various non-idempotent commands are available. See examples
        (Choices: create, status, start, stop, pause, unpause, shutdown, undefine, destroy, get_xml, freemem, list_vms,
        info, nodeinfo, virttype, define)[Default: (null)]
= name
        name of the guest VM being managed. Note that VM must be previously defined with xml.
        [Default: None]
- state
        Note that there may be some lag for state requests like `shutdown' since these refer only to VM states. After
        starting a guest, it may not be immediately accessible.
        (Choices: running, shutdown, destroyed, paused)[Default: no]
- uri
        libvirt connection uri
        [Default: qemu:///system]
- xml
        XML document used with the define command
        [Default: None]
Requirements:  python >= 2.6, libvirt-python

EXAMPLES:
# a playbook task line:
- virt:
    name: alpha
    state: running

# /usr/bin/ansible invocations
# ansible host -m virt -a "name=alpha command=status"
# ansible host -m virt -a "name=alpha command=get_xml"
# ansible host -m virt -a "name=alpha command=create uri=lxc:///"

---
# a playbook example of defining and launching an LXC guest
tasks:
  - name: define vm
    virt:
        name: foo
        command: define
        xml: "{{ lookup('template', 'container-template.xml.j2') }}"
        uri: 'lxc:///'
  - name: start vm
    virt:
        name: foo
        state: running
        uri: 'lxc:///'

RETURN VALUES:
# for list_vms command
list_vms:
    description: The list of vms defined on the remote system
    type: dictionary
    returned: success
    sample: [
        "build.example.org",
        "dev.example.org"
    ]
# for status command
status:
    description: The status of the VM, among running, crashed, paused and shutdown
    type: string
    sample: "success"
    returned: success


MAINTAINERS: Ansible Core Team, Seth Vidal, Michael DeHaan

METADATA:
	Status: ['preview']
	Supported_by: community
> VIRT_NET    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/virt_net.py)

  Manage `libvirt' networks.

Options (= is mandatory):

- autostart
        Specify if a given storage pool should be started automatically on system boot.
        (Choices: yes, no)[Default: (null)]
- command
        in addition to state management, various non-idempotent commands are available. See examples. Modify was added in
        version 2.1
        (Choices: define, create, start, stop, destroy, undefine, get_xml, list_nets, facts, info, status,
        modify)[Default: (null)]
= name
        name of the network being managed. Note that network must be previously defined with xml.

- state
        specify which state you want a network to be in. If 'active', network will be started. If 'present', ensure that
        network is present but do not change its state; if it's missing, you need to specify xml argument. If 'inactive',
        network will be stopped. If 'undefined' or 'absent', network will be removed from `libvirt' configuration.
        (Choices: active, inactive, present, absent)[Default: (null)]
- uri
        libvirt connection uri.
        [Default: qemu:///system]
- xml
        XML document used with the define command.
        [Default: (null)]
Requirements:  python >= 2.6, python-libvirt, python-lxml

EXAMPLES:
# Define a new network
- virt_net:
    command: define
    name: br_nat
    xml: '{{ lookup("template", "network/bridge.xml.j2") }}'

# Start a network
- virt_net:
    command: create
    name: br_nat

# List available networks
- virt_net:
    command: list_nets

# Get XML data of a specified network
- virt_net:
    command: get_xml
    name: br_nat

# Stop a network
- virt_net:
    command: destroy
    name: br_nat

# Undefine a network
- virt_net:
    command: undefine
    name: br_nat

# Gather facts about networks
# Facts will be available as 'ansible_libvirt_networks'
- virt_net:
    command: facts

# Gather information about network managed by 'libvirt' remotely using uri
- virt_net:
    command: info
    uri: '{{ item }}'
  with_items: '{{ libvirt_uris }}'
  register: networks

# Ensure that a network is active (needs to be defined and built first)
- virt_net:
    state: active
    name: br_nat

# Ensure that a network is inactive
- virt_net:
    state: inactive
    name: br_nat

# Ensure that a given network will be started at boot
- virt_net:
    autostart: yes
    name: br_nat

# Disable autostart for a given network
- virt_net:
    autostart: no
    name: br_nat


MAINTAINERS: Maciej Delmanowski (@drybjed)

METADATA:
	Status: ['preview']
	Supported_by: community
> VIRT_POOL    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/virt_pool.py)

  Manage `libvirt' storage pools.

Options (= is mandatory):

- autostart
        Specify if a given storage pool should be started automatically on system boot.
        (Choices: yes, no)[Default: (null)]
- command
        in addition to state management, various non-idempotent commands are available. See examples.
        (Choices: define, build, create, start, stop, destroy, delete, undefine, get_xml, list_pools, facts, info,
        status)[Default: (null)]
- mode
        Pass additional parameters to 'build' or 'delete' commands.
        (Choices: new, repair, resize, no_overwrite, overwrite, normal, zeroed)[Default: (null)]
- name
        name of the storage pool being managed. Note that pool must be previously defined with xml.
        [Default: (null)]
- state
        specify which state you want a storage pool to be in. If 'active', pool will be started. If 'present', ensure
        that pool is present but do not change its state; if it's missing, you need to specify xml argument. If
        'inactive', pool will be stopped. If 'undefined' or 'absent', pool will be removed from `libvirt' configuration.
        If 'deleted', pool contents will be deleted and then pool undefined.
        (Choices: active, inactive, present, absent, undefined, deleted)[Default: (null)]
- uri
        `libvirt' connection uri.
        [Default: qemu:///system]
- xml
        XML document used with the define command.
        [Default: (null)]
Requirements:  python >= 2.6, python-libvirt, python-lxml

EXAMPLES:
# Define a new storage pool
- virt_pool:
    command: define
    name: vms
    xml: '{{ lookup("template", "pool/dir.xml.j2") }}'

# Build a storage pool if it does not exist
- virt_pool:
    command: build
    name: vms

# Start a storage pool
- virt_pool:
    command: create
    name: vms

# List available pools
- virt_pool:
    command: list_pools

# Get XML data of a specified pool
- virt_pool:
    command: get_xml
    name: vms

# Stop a storage pool
- virt_pool:
    command: destroy
    name: vms

# Delete a storage pool (destroys contents)
- virt_pool:
    command: delete
    name: vms

# Undefine a storage pool
- virt_pool:
    command: undefine
    name: vms

# Gather facts about storage pools
# Facts will be available as 'ansible_libvirt_pools'
- virt_pool:
    command: facts

# Gather information about pools managed by 'libvirt' remotely using uri
- virt_pool:
    command: info
    uri: '{{ item }}'
  with_items: '{{ libvirt_uris }}'
  register: storage_pools

# Ensure that a pool is active (needs to be defined and built first)
- virt_pool:
    state: active
    name: vms

# Ensure that a pool is inactive
- virt_pool:
    state: inactive
    name: vms

# Ensure that a given pool will be started at boot
- virt_pool:
    autostart: yes
    name: vms

# Disable autostart for a given pool
- virt_pool:
    autostart: no
    name: vms


MAINTAINERS: Maciej Delmanowski (@drybjed)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMADM    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/smartos/vmadm.py)

  Manage SmartOS virtual machines through vmadm(1M).

Options (= is mandatory):

- archive_on_delete
        When enabled, the zone dataset will be mounted on `/zones/archive' upon removal.
        [Default: (null)]
- autoboot
        Whether or not a VM is booted when the system is rebooted.
        [Default: (null)]
- boot
        Set the boot order for KVM VMs.
        [Default: (null)]
= brand
        Type of virtual machine.
        (Choices: joyent, joyent-minimal, kvm, lx)[Default: joyent]
- cpu_cap
        Sets a limit on the amount of CPU time that can be used by a VM. Use `0' for no cap.
        [Default: (null)]
- cpu_shares
        Sets a limit on the number of fair share scheduler (FSS) CPU shares for a VM. This limit is relative to all other
        VMs on the system.
        [Default: (null)]
- cpu_type
        Control the type of virtual CPU exposed to KVM VMs.
        (Choices: qemu64, host)[Default: qemu64]
- customer_metadata
        Metadata to be set and associated with this VM, this contain customer modifiable keys.
        [Default: (null)]
- delegate_dataset
        Whether to delegate a ZFS dataset to an OS VM.
        [Default: (null)]
- disk_driver
        Default value for a virtual disk model for KVM guests.
        [Default: (null)]
- disks
        A list of disks to add, valid properties are documented in vmadm(1M).
        [Default: (null)]
- dns_domain
        Domain value for `/etc/hosts'.
        [Default: (null)]
- filesystems
        Mount additional filesystems into an OS VM.
        [Default: (null)]
- firewall_enabled
        Enables the firewall, allowing fwadm(1M) rules to be applied.
        [Default: (null)]
- force
        Force a particular action (i.e. stop or delete a VM).
        [Default: (null)]
- fs_allowed
        Comma separated list of filesystem types this zone is allowed to mount.
        [Default: (null)]
- hostname
        Zone/VM hostname.
        [Default: (null)]
- image_uuid
        Image UUID.
        [Default: (null)]
- indestructible_delegated
        Adds an `@indestructible' snapshot to delegated datasets.
        [Default: (null)]
- indestructible_zoneroot
        Adds an `@indestructible' snapshot to zoneroot.
        [Default: (null)]
- internal_metadata
        Metadata to be set and associated with this VM, this contains operator generated keys.
        [Default: (null)]
- internal_metadata_namespace
        List of namespaces to be set as `internal_metadata-only'; these namespaces will come from `internal_metadata'
        rather than `customer_metadata'.
        [Default: (null)]
- kernel_version
        Kernel version to emulate for LX VMs.
        [Default: (null)]
- limit_priv
        Set (comma separated) list of privileges the zone is allowed to use.
        [Default: (null)]
- maintain_resolvers
        Resolvers in `/etc/resolv.conf' will be updated when updating the `resolvers' property.
        [Default: (null)]
- max_locked_memory
        Total amount of memory (in MiBs) on the host that can be locked by this VM.
        [Default: (null)]
- max_lwps
        Maximum number of lightweight processes this VM is allowed to have running.
        [Default: (null)]
- max_physical_memory
        Maximum amount of memory (in MiBs) on the host that the VM is allowed to use.
        [Default: (null)]
- max_swap
        Maximum amount of virtual memory (in MiBs) the VM is allowed to use.
        [Default: (null)]
- mdata_exec_timeout
        Timeout in seconds (or 0 to disable) for the `svc:/smartdc/mdata:execute' service that runs user-scripts in the
        zone.
        [Default: (null)]
- name
        Name of the VM. vmadm(1M) uses this as an optional name.
        [Default: (null)]
- nic_driver
        Default value for a virtual NIC model for KVM guests.
        [Default: (null)]
- nics
        A list of nics to add, valid properties are documented in vmadm(1M).
        [Default: (null)]
- nowait
        Consider the provisioning complete when the VM first starts, rather than when the VM has rebooted.
        [Default: (null)]
- qemu_extra_opts
        Additional qemu cmdline arguments for KVM guests.
        [Default: (null)]
- qemu_opts
        Additional qemu arguments for KVM guests. This overwrites the default arguments provided by vmadm(1M) and should
        only be used for debugging.
        [Default: (null)]
- quota
        Quota on zone filesystems (in MiBs).
        [Default: (null)]
- ram
        Amount of virtual RAM for a KVM guest (in MiBs).
        [Default: (null)]
- resolvers
        List of resolvers to be put into `/etc/resolv.conf'.
        [Default: (null)]
- routes
        Dictionary that maps destinations to gateways, these will be set as static routes in the VM.
        [Default: (null)]
- spice_opts
        Addition options for SPICE-enabled KVM VMs.
        [Default: (null)]
- spice_password
        Password required to connect to SPICE. By default no password is set. Please note this can be read from the
        Global Zone.
        [Default: (null)]
= state
        States for the VM to be in. Please note that `present', `stopped' and `restarted' operate on a VM that is
        currently provisioned. `present' means that the VM will be created if it was absent, and that it will be in a
        running state. `absent' will shutdown the zone before removing it. `stopped' means the zone will be created if it
        doesn't exist already, before shutting it down.
        (Choices: present, absent, stopped, restarted)
- tmpfs
        Amount of memory (in MiBs) that will be available in the VM for the `/tmp' filesystem.
        [Default: (null)]
- uuid
        UUID of the VM. Can either be a full UUID or `*' for all VMs.
        [Default: (null)]
- vcpus
        Number of virtual CPUs for a KVM guest.
        [Default: (null)]
- vga
        Specify VGA emulation used by KVM VMs.
        [Default: (null)]
- virtio_txburst
        Number of packets that can be sent in a single flush of the tx queue of virtio NICs.
        [Default: (null)]
- virtio_txtimer
        Timeout (in nanoseconds) for the TX timer of virtio NICs.
        [Default: (null)]
- vnc_password
        Password required to connect to VNC. By default no password is set. Please note this can be read from the Global
        Zone.
        [Default: (null)]
- vnc_port
        TCP port to listen of the VNC server. Or set `0' for random, or `-1' to disable.
        [Default: (null)]
- zfs_data_compression
        Specifies compression algorithm used for this VMs data dataset. This option only has effect on delegated
        datasets.
        [Default: (null)]
- zfs_data_recsize
        Suggested block size (power of 2) for files in the delegated dataset's filesystem.
        [Default: (null)]
- zfs_filesystem_limit
        Maximum number of filesystems the VM can have.
        [Default: (null)]
- zfs_io_priority
        IO throttle priority value relative to other VMs.
        [Default: (null)]
- zfs_root_compression
        Specifies compression algorithm used for this VMs root dataset. This option only has effect on the zoneroot
        dataset.
        [Default: (null)]
- zfs_root_recsize
        Suggested block size (power of 2) for files in the zoneroot dataset's filesystem.
        [Default: (null)]
- zfs_snapshot_limit
        Number of snapshots the VM can have.
        [Default: (null)]
- zpool
        ZFS pool the VM's zone dataset will be created in.
        [Default: (null)]
Requirements:  python >= 2.6

EXAMPLES:
- name: create SmartOS zone
  vmadm:
    brand: joyent
    state: present
    alias: fw_zone
    image_uuid: 95f265b8-96b2-11e6-9597-972f3af4b6d5
    firewall_enabled: yes
    indestructible_zoneroot: yes
    nics:
      - nic_tag: admin
        ip: dhcp
        primary: true
    internal_metadata:
      root_pw: 'secret'
    quota: 1

- name: Delete a zone
  vmadm:
    alias: test_zone
    state: deleted

- name: Stop all zones
  vmadm:
    uuid: '*'
    state: stopped

RETURN VALUES:
uuid:
  description: UUID of the managed VM.
  returned: always
  type: string
  sample: 'b217ab0b-cf57-efd8-cd85-958d0b80be33'
alias:
  description: Alias of the managed VM.
  returned: When addressing a VM by alias.
  type: string
  sample: 'dns-zone'
state:
  description: State of the target, after execution.
  returned: success
  type: string
  sample: 'running'


MAINTAINERS: Jasper Lievisse Adriaanse (@jasperla)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_CLUSTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_cluster.py)

  Create VMware vSphere Cluster

Options (= is mandatory):

= cluster_name
        The name of the cluster that will be created

= datacenter_name
        The name of the datacenter the cluster will be created in.

- enable_drs
        If set to True will enable DRS when the cluster is created.
        [Default: False]
- enable_ha
        If set to True will enable HA when the cluster is created.
        [Default: False]
- enable_vsan
        If set to True will enable vSAN when the cluster is created.
        [Default: False]
= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Requirements:  Tested on ESXi 5.5, PyVmomi installed

EXAMPLES:
# Example vmware_cluster command from Ansible Playbooks
- name: Create Cluster
  local_action:
    module: vmware_cluster
    hostname: "{{ ansible_ssh_host }}"
    username: root
    password: vmware
    datacenter_name: "datacenter"
    cluster_name: "cluster"
    enable_ha: True
    enable_drs: True
    enable_vsan: True


MAINTAINERS: Joseph Callen (@jcpowermac)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_DATACENTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_datacenter.py)

  Manage VMware vSphere Datacenters

Options (= is mandatory):

= datacenter_name
        The name of the datacenter the cluster will be created in.

= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

- state
        If the datacenter should be present or absent
        (Choices: present, absent)[Default: present]
= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 6.0
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example vmware_datacenter command from Ansible Playbooks
- name: Create Datacenter
  local_action:
    module: vmware_datacenter
    hostname: "{{ ansible_ssh_host }}"
    username: root
    password: vmware
    datacenter_name: "datacenter"
    state: present


MAINTAINERS: Joseph Callen (@jcpowermac), Kamil Szczygiel (@kamsz)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_DNS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_dns_config.py)

  Manage VMware ESXi DNS Configuration

Options (= is mandatory):

= change_hostname_to
        The hostname that an ESXi host should be changed to.

= dns_servers
        The DNS servers that the host should be configured to use.

= domainname
        The domain the ESXi host should be apart of.

= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example vmware_dns_config command from Ansible Playbooks
- name: Configure ESXi hostname and DNS servers
  local_action:
    module: vmware_dns_config
    hostname: esxi_hostname
    username: root
    password: your_password
    change_hostname_to: esx01
    domainname: foo.org
    dns_servers:
        - 8.8.8.8
        - 8.8.4.4


MAINTAINERS: Joseph Callen (@jcpowermac)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_DVS_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_dvs_host.py)

  Add or remove a host from distributed virtual switch

Options (= is mandatory):

= esxi_hostname
        The ESXi hostname

= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= state
        If the host should be present or absent attached to the vSwitch
        (Choices: present, absent)
= switch_name
        The name of the Distributed vSwitch

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
= vmnics
        The ESXi hosts vmnics to use with the Distributed vSwitch

Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example vmware_dvs_host command from Ansible Playbooks
- name: Add Host to dVS
  local_action:
    module: vmware_dvs_host
    hostname: vcenter_ip_or_hostname
    username: vcenter_username
    password: vcenter_password
    esxi_hostname: esxi_hostname_as_listed_in_vcenter
    switch_name: dvSwitch
    vmnics:
        - vmnic0
        - vmnic1
    state: present


MAINTAINERS: Joseph Callen (@jcpowermac)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_DVS_PORTGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_dvs_portgroup.py)

  Create or remove a Distributed vSwitch portgroup

Options (= is mandatory):

= hostname
        The hostname or IP address of the vSphere vCenter.

= num_ports
        The number of ports the portgroup should contain

= password
        The password of the vSphere vCenter.

= portgroup_name
        The name of the portgroup that is to be created or deleted

= portgroup_type
        See VMware KB 1022312 regarding portgroup types
        (Choices: earlyBinding, lateBinding, ephemeral)
= switch_name
        The name of the distributed vSwitch the port group should be created on.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
= vlan_id
        The VLAN ID that should be configured with the portgroup

Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
   - name: Create Management portgroup
     local_action:
        module: vmware_dvs_portgroup
        hostname: vcenter_ip_or_hostname
        username: vcenter_username
        password: vcenter_password
        portgroup_name: Management
        switch_name: dvSwitch
        vlan_id: 123
        num_ports: 120
        portgroup_type: earlyBinding
        state: present


MAINTAINERS: Joseph Callen (@jcpowermac)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_DVSWITCH    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_dvswitch.py)

  Create or remove a distributed vSwitch

Options (= is mandatory):

= datacenter_name
        The name of the datacenter that will contain the dvSwitch

- discovery_operation
        Select the discovery operation
        (Choices: both, none, advertise, listen)[Default: (null)]
= discovery_proto
        Link discovery protocol between Cisco and Link Layer discovery
        (Choices: cdp, lldp)
= hostname
        The hostname or IP address of the vSphere vCenter.

= mtu
        The switch maximum transmission unit

= password
        The password of the vSphere vCenter.

- state
        Create or remove dvSwitch
        (Choices: present, absent)[Default: present]
= switch_name
        The name of the switch to create or remove

= uplink_quantity
        Quantity of uplink per ESXi host added to the switch

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
- name: Create dvswitch
  local_action:
    module: vmware_dvswitch
    hostname: vcenter_ip_or_hostname
    username: vcenter_username
    password: vcenter_password
    datacenter_name: datacenter
    switch_name: dvSwitch
    mtu: 9000
    uplink_quantity: 2
    discovery_proto: lldp
    discovery_operation: both
    state: present


MAINTAINERS: Joseph Callen (@jcpowermac)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_GUEST    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_guest.py)

  Create new virtual machines (from templates or not) Power on/power off/restart a virtual machine Modify, rename or
  remove a virtual machine

Options (= is mandatory):

- annotation
        A note or annotation to include in the VM
        [Default: (null)]
- cluster
        The cluster name where the VM will run.
        [Default: (null)]
- customization
        Parameters to customize template
        Common parameters (Linux/Windows):
          dns_servers (list): List of DNS servers to configure
          dns_suffix (list): List of domain suffixes, aka DNS search path (default: `domain' parameter)
          domain (string): DNS domain name to use
          hostname (string): Computer hostname (default: `name' parameter)
        Parameters related to windows customization:
          autologon (bool): Auto logon after VM customization (default: False)
          autologoncount (int): Number of autologon after reboot (default: 1)
          domainadmin (string): User used to join in AD domain (mandatory with joindomain)
          domainadminpassword (string): Password used to join in AD domain (mandatory with joindomain)
          fullname (string): Server owner name (default: Administrator)
          joindomain (string): AD domain to join (Not compatible with `joinworkgroup')
          joinworkgroup (string): Workgroup to join (Not compatible with `joindomain', default: WORKGROUP)
          orgname (string): Organisation name (default: ACME)
          password (string): Local administrator password (mandatory)
          productid (string): Product ID
          runonce (list): List of commands to run at first user logon
          timezone (int): Timezone (default: 85) See https://msdn.microsoft.com/en-
        us/library/ms912391(v=winembedded.11).aspx
        [Default: (null)]
- customvalues
        Define a list of customvalues to set on VM.
        A customvalue object takes 2 fields 'key' and 'value'.
        [Default: (null)]
- datacenter
        Destination datacenter for the deploy operation
        [Default: ha-datacenter]
- disk
        A list of disks to add
        Valid attributes are: size_[tb,gb,mb,kb], type, datastore and autoselect_datastore
        type: Valid value is thin (default: None)
        datastore: Datastore to use for the disk. If autoselect_datastore is True, filter datastore selection.
        autoselect_datastore (bool): select the less used datastore.
        [Default: (null)]
- esxi_hostname
        The esxi hostname where the VM will run.
        [Default: (null)]
- folder
        Destination folder, absolute path to find an existing guest or create the new guest
        [Default: (null)]
- force
        Ignore warnings and complete the actions
        [Default: (null)]
- guest_id
        Set the guest ID (Debian, RHEL, Windows...)
        This field is required when creating a VM
        Valid values are referenced here: https://www.vmware.com/support/developer/converter-
        sdk/conv55_apireference/vim.vm.GuestOsDescriptor.GuestOsIdentifier.html
        [Default: (null)]
- hardware
        Manage some VM hardware attributes.
        Valid attributes are: memory_mb, num_cpus and scsi
        scsi: Valid values are buslogic, lsilogic, lsilogicsas and paravirtual (default)
        [Default: (null)]
= hostname
        The hostname or IP address of the vSphere vCenter.

- is_template
        Flag the instance as a template
        [Default: False]
= name
        Name of the VM to work with

- name_match
        If multiple VMs matching the name, use the first or last found
        (Choices: first, last)[Default: first]
- networks
        Network to use should include `name' or `vlan' entry
        Add an optional `ip' and `netmask' for network configuration
        Add an optional `gateway' entry to configure a gateway
        Add an optional `mac' entry to customize mac address
        Add an optional `dns_servers' or `domain' entry per interface (Windows)
        Add an optional `device_type' to configure the virtual NIC (pcnet32, vmxnet2, vmxnet3, e1000, e1000e)
        [Default: (null)]
= password
        The password of the vSphere vCenter.

- resource_pool
        Affect machine to the given resource pool
        Resource pool should be child of the selected host parent
        [Default: None]
= state
        What state should the virtual machine be in?
        If `state' is set to `present' and VM exists, ensure the VM configuration conforms to task arguments
        (Choices: present, absent, poweredon, poweredoff, restarted, suspended, shutdownguest, rebootguest)
- template
        Template used to create VM.
        If this value is not set, VM is created without using a template.
        If the VM exists already this setting will be ignored.
        [Default: (null)]
= username
        The username of the vSphere vCenter.

- uuid
        UUID of the instance to manage if known, this is VMware's unique identifier.
        This is required if name is not supplied.
        [Default: (null)]
- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
- wait_for_ip_address
        Wait until vCenter detects an IP address for the VM
        This requires vmware-tools (vmtoolsd) to properly work after creation
        [Default: False]
Notes:
  * Tested on vSphere 5.5 and 6.0
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Create a VM from a template
  - name: create the VM
    vmware_guest:
      hostname: 192.0.2.44
      username: administrator@vsphere.local
      password: vmware
      validate_certs: no
      esxi_hostname: 192.0.2.117
      datacenter: datacenter1
      folder: testvms
      name: testvm_2
      state: poweredon
      guest_id: centos64guest
      disk:
      - size_gb: 10
        type: thin
        datastore: g73_datastore
      hardware:
        memory_mb: 512
        num_cpus: 1
        scsi: paravirtual
      networks:
      - name: VM Network
        ip: 192.168.1.100
        netmask: 255.255.255.0
        mac: 'aa:bb:dd:aa:00:14'
      template: template_el7
      wait_for_ip_address: yes
    register: deploy

# Clone a VM from Template and customize
  - name: Clone template and customize
    vmware_guest:
      hostname: 192.168.1.209
      username: administrator@vsphere.local
      password: vmware
      validate_certs: no
      datacenter: datacenter1
      cluster: cluster
      name: testvm-2
      template: template_windows
      networks:
      - name: VM Network
        ip: 192.168.1.100
        netmask: 255.255.255.0
        gateway: 192.168.1.1
        mac: 'aa:bb:dd:aa:00:14'
        domain: my_domain
        dns_servers:
        - 192.168.1.1
        - 192.168.1.2
      customization:
        autologon: True
        dns_servers:
        - 192.168.1.1
        - 192.168.1.2
        domain: my_domain
        password: new_vm_password
        runonce:
        - powershell.exe -ExecutionPolicy Unrestricted -File C:\Windows\Temp\Enable-WinRM.ps1 -ForceNewSSLCert

# Create a VM template
  - name: create a VM template
    vmware_guest:
      hostname: 192.0.2.88
      username: administrator@vsphere.local
      password: vmware
      validate_certs: no
      datacenter: datacenter1
      cluster: vmware_cluster_esx
      resource_pool: highperformance_pool
      folder: testvms
      name: testvm_6
      is_template: yes
      guest_id: debian6_64Guest
      disk:
      - size_gb: 10
        type: thin
        datastore: g73_datastore
      hardware:
        memory_mb: 512
        num_cpus: 1
        scsi: lsilogic
      wait_for_ip_address: yes
    register: deploy

# Rename a VM (requires the VM's uuid)
  - vmware_guest:
      hostname: 192.168.1.209
      username: administrator@vsphere.local
      password: vmware
      uuid: 421e4592-c069-924d-ce20-7e7533fab926
      name: new_name
      state: present

# Remove a VM by uuid
  - vmware_guest:
      hostname: 192.168.1.209
      username: administrator@vsphere.local
      password: vmware
      uuid: 421e4592-c069-924d-ce20-7e7533fab926
      state: absent

RETURN VALUES:
instance:
    descripton: metadata about the new virtualmachine
    returned: always
    type: dict
    sample: None


MAINTAINERS: James Tanner (@jctanner) <tanner.jc@gmail.com>, Loic Blot (@nerzhul) <loic.blot@unix-experience.fr>

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_GUEST_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_guest_facts.py)

  Gather facts about a single VM on a VMware ESX cluster

Options (= is mandatory):

= datacenter
        Destination datacenter for the deploy operation

- folder
        Destination folder, absolute path to find an existing guest.
        This is required if name is supplied.
        [Default: (null)]
= hostname
        The hostname or IP address of the vSphere vCenter.

= name
        Name of the VM to work with

- name_match
        If multiple VMs matching the name, use the first or last found
        (Choices: first, last)[Default: first]
= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- uuid
        UUID of the instance to manage if known, this is VMware's unique identifier.
        This is required if name is not supplied.
        [Default: (null)]
- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Gather facts
  - name: gather the VM facts
    vmware_guest_facts:
      hostname: 192.168.1.209
      username: administrator@vsphere.local
      password: vmware
      validate_certs: no
      uuid: 421e4592-c069-924d-ce20-7e7533fab926
    register: facts

RETURN VALUES:
instance:
    description: metadata about the virtual machine
    returned: always
    type: dict
    sample: None


MAINTAINERS: Loic Blot (@nerzhul) <loic.blot@unix-experience.fr>

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_GUEST_SNAPSHOT    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_guest_snapshot.py)

  Create virtual machines snapshots

Options (= is mandatory):

= datacenter
        Destination datacenter for the deploy operation

- description
        Define an arbitrary description to attach to snapshot.
        [Default: (null)]
- folder
        Define instance folder location.
        [Default: (null)]
= hostname
        The hostname or IP address of the vSphere vCenter.

= name
        Name of the VM to work with

- name_match
        If multiple VMs matching the name, use the first or last found
        (Choices: first, last)[Default: first]
= password
        The password of the vSphere vCenter.

- snapshot_name
        Sets the snapshot name to manage.
        This param is required only if state is not `remove_all'
        [Default: (null)]
= state
        Manage snapshots attached to a specific virtual machine.
        (Choices: present, absent, revert, remove_all)
= username
        The username of the vSphere vCenter.

- uuid
        UUID of the instance to manage if known, this is VMware's unique identifier.
        This is required if name is not supplied.
        [Default: (null)]
- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
  - name: Create snapshot
    vmware_guest_snapshot:
      hostname: 192.168.1.209
      username: administrator@vsphere.local
      password: vmware
      name: dummy_vm
      state: present
      snapshot_name: snap1
      description: snap1_description

  - name: Remove a snapshot
    vmware_guest_snapshot:
      hostname: 192.168.1.209
      username: administrator@vsphere.local
      password: vmware
      name: dummy_vm
      state: remove
      snapshot_name: snap1

  - name: Revert to a snapshot
    vmware_guest_snapshot:
      hostname: 192.168.1.209
      username: administrator@vsphere.local
      password: vmware
      name: dummy_vm
      state: revert
      snapshot_name: snap1

  - name: Remove all snapshots of a VM
    vmware_guest_snapshot:
      hostname: 192.168.1.209
      username: administrator@vsphere.local
      password: vmware
      name: dummy_vm
      state: remove_all

RETURN VALUES:
instance:
    descripton: metadata about the new virtualmachine
    returned: always
    type: dict
    sample: None


MAINTAINERS: James Tanner (@jctanner) <tanner.jc@gmail.com>, Loic Blot (@nerzhul) <loic.blot@unix-experience.fr>

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_host.py)

  This module can be used to add/remove an ESXi host to/from vCenter

Options (= is mandatory):

= cluster_name
        Name of the cluster to add the host

= datacenter_name
        Name of the datacenter to add the host

= esxi_hostname
        ESXi hostname to manage

= esxi_password
        ESXi password

= esxi_username
        ESXi username

= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

- state
        Add or remove the host
        (Choices: present, absent)[Default: present]
= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example from Ansible playbook

    - name: Add ESXi Host to VCSA
      local_action:
        module: vmware_host
        hostname: vcsa_host
        username: vcsa_user
        password: vcsa_pass
        datacenter_name: datacenter_name
        cluster_name: cluster_name
        esxi_hostname: esxi_hostname
        esxi_username: esxi_username
        esxi_password: esxi_password
        state: present


MAINTAINERS: Joseph Callen (@jcpowermac), Russell Teague (@mtnbikenc)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_LOCAL_USER_MANAGER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_local_user_manager.py)

  Manage local users on an ESXi host

Options (= is mandatory):

= hostname
        The hostname or IP address of the vSphere vCenter.

- local_user_description
        Description for the user
        [Default: (null)]
= local_user_name
        The local user name to be changed

- local_user_password
        The password to be set
        [Default: (null)]
= password
        The password of the vSphere vCenter.

- state
        Indicate desired state of the user. If the user already exists when `state=present', the user info is updated
        (Choices: present, absent)[Default: present]
= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on ESXi 6.0
  * Be sure that the ESXi user used for login, has the appropriate rights to create / delete / edit users
Requirements:  python >= 2.6, PyVmomi installed

EXAMPLES:
# Example vmware_local_user_manager command from Ansible Playbooks
- name: Add local user to ESXi
  local_action:
      module: vmware_local_user_manager
      hostname: esxi_hostname
      username: root
      password: vmware
      local_user_name: foo

RETURN VALUES:
 

MAINTAINERS: Andreas Nafpliotis

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_MAINTENANCEMODE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_maintenancemode.py)

  Place an ESXI host into maintenance mode Support for VSAN compliant maintenance mode when selected

Options (= is mandatory):

= esxi_hostname
        Name of the host as defined in vCenter

- evacuate
        If True, evacuate all powered off VMs
        (Choices: True, False)[Default: False]
= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

- state
        Enter or exit maintenance mode
        (Choices: present, absent)[Default: present]
- timeout
        Specify a timeout for the operation
        [Default: 0]
= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
- vsan_mode
        Specify which VSAN compliant mode to enter
        (Choices: ensureObjectAccessibility, evacuateAllData, noAction)[Default: (null)]
Notes:
  * Tested on vSphere 5.5 and 6.0
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
- name: Enter VSAN-Compliant Maintenance Mode
  local_action:
    module: vmware_maintenancemode
    hostname: vc_host
    username: vc_user
    password: vc_pass
    esxi_hostname: esxi.host.example
    vsan: ensureObjectAccessibility
    evacuate: yes
    timeout: 3600
    state: present

RETURN VALUES:
hostsystem:
    description: Name of vim reference
    returned: always
    type: string
    sample: "'vim.HostSystem:host-236'"
hostname:
    description: Name of host in vCenter
    returned: always
    type: string
    sample: "esxi.local.domain"
status:
    description: Action taken
    return: always
    type: string
    sample: "ENTER"


MAINTAINERS: Jay Jahns <jjahns@vmware.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_MIGRATE_VMK    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_migrate_vmk.py)

  Migrate a VMK interface from VSS to VDS

Options (= is mandatory):

= current_portgroup_name
        Portgroup name VMK interface is currently on

= current_switch_name
        Switch VMK interface is currently on

= device
        VMK interface name

= esxi_hostname
        ESXi hostname to be managed

= hostname
        The hostname or IP address of the vSphere vCenter.

= migrate_portgroup_name
        Portgroup name to migrate VMK interface to

= migrate_switch_name
        Switch name to migrate VMK interface to

= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example from Ansible playbook

    - name: Migrate Management vmk
      local_action:
        module: vmware_migrate_vmk
        hostname: vcsa_host
        username: vcsa_user
        password: vcsa_pass
        esxi_hostname: esxi_hostname
        device: vmk1
        current_switch_name: temp_vswitch
        current_portgroup_name: esx-mgmt
        migrate_switch_name: dvSwitch
        migrate_portgroup_name: Management


MAINTAINERS: Joseph Callen (@jcpowermac), Russell Teague (@mtnbikenc)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_PORTGROUP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_portgroup.py)

  Create a VMware portgroup

Options (= is mandatory):

= hostname
        The hostname or IP address of the vSphere vCenter.

- network_policy
        Network policy specifies layer 2 security settings for a portgroup such as promiscuous mode, where guest adapter
        listens to all the packets, MAC address changes and forged transmits. Settings are promiscuous_mode,
        forged_transmits, mac_changes
        [Default: (null)]
= password
        The password of the vSphere vCenter.

= portgroup_name
        Portgroup name to add

= switch_name
        vSwitch to modify

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
= vlan_id
        VLAN ID to assign to portgroup

Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example from Ansible playbook

    - name: Add Management Network VM Portgroup
      local_action:
        module: vmware_portgroup
        hostname: esxi_hostname
        username: esxi_username
        password: esxi_password
        switch_name: vswitch_name
        portgroup_name: portgroup_name
        vlan_id: vlan_id

    - name: Add Portgroup with Promiscuous Mode Enabled
      local_action:
        module: vmware_portgroup
        hostname: esxi_hostname
        username: esxi_username
        password: esxi_password
        switch_name: vswitch_name
        portgroup_name: portgroup_name
        network_policy:
            promiscuous_mode: True


MAINTAINERS: Joseph Callen (@jcpowermac), Russell Teague (@mtnbikenc)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_TARGET_CANONICAL_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_target_canonical_facts.py)

  Return canonical (NAA) from an ESXi host based on SCSI target ID

Options (= is mandatory):

= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= target_id
        The target id based on order of scsi device

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Requirements:  Tested on vSphere 5.5, PyVmomi installed

EXAMPLES:
# Example vmware_target_canonical_facts command from Ansible Playbooks
- name: Get Canonical name
  local_action:
    module: vmware_target_canonical_facts
    hostname: "{{ ansible_ssh_host }}"
    username: root
    password: vmware
    target_id: 7


MAINTAINERS: Joseph Callen

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_VM_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_vm_facts.py)

  Return basic facts pertaining to a vSphere virtual machine guest

Options (= is mandatory):

= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
- name: Gather all registered virtual machines
  local_action:
    module: vmware_vm_facts
    hostname: esxi_or_vcenter_ip_or_hostname
    username: username
    password: password


MAINTAINERS: Joseph Callen (@jcpowermac)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_VM_SHELL    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_vm_shell.py)

  Start a program in a VM without the need for network connection

Options (= is mandatory):

- cluster
        The cluster hosting the VM
        Will help speed up search
        [Default: None]
- datacenter
        The datacenter hosting the VM
        Will help speed up search
        [Default: None]
= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
= vm_id
        The identification for the VM

- vm_id_type
        The identification tag for the VM
        (Choices: uuid, dns_name, inventory_path, vm_name)[Default: vm_name]
- vm_password
        The password used to login to the VM.
        [Default: None]
= vm_shell
        The absolute path to the program to start. On Linux this is executed via bash.

- vm_shell_args
        The argument to the program.
        [Default: None]
- vm_shell_cwd
        The current working directory of the application from which it will be run
        [Default: None]
- vm_shell_env
        Comma separated list of envirnoment variable, specified in the guest OS notation
        [Default: None]
- vm_username
        The user to connect to the VM.
        [Default: None]
Notes:
  * Tested on vSphere 5.5
  * Only the first match against vm_id is used, even if there are multiple matches
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
    - name: shell execution
      local_action:
        module: vmware_vm_shell
        hostname: myVSphere
        username: myUsername
        password: mySecret
        datacenter: myDatacenter
        vm_id: NameOfVM
        vm_username: root
        vm_password: superSecret
        vm_shell: /bin/echo
        vm_shell_args: " $var >> myFile "
        vm_shell_env:
          - "PATH=/bin"
          - "VAR=test"
        vm_shell_cwd: "/tmp"



MAINTAINERS: Ritesh Khadgaray (@ritzk)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_VM_VSS_DVS_MIGRATE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_vm_vss_dvs_migrate.py)

  Migrates a virtual machine from a standard vswitch to distributed

Options (= is mandatory):

= dvportgroup_name
        Name of the portgroup to migrate to the virtual machine to

= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
= vm_name
        Name of the virtual machine to migrate to a dvSwitch

Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
- name: Migrate VCSA to vDS
  local_action:
    module: vmware_vm_vss_dvs_migrate
    hostname: vcenter_ip_or_hostname
    username: vcenter_username
    password: vcenter_password
    vm_name: virtual_machine_name
    dvportgroup_name: distributed_portgroup_name


MAINTAINERS: Joseph Callen (@jcpowermac)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_VMKERNEL    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_vmkernel.py)

  Create a VMware VMkernel Interface

Options (= is mandatory):

- enable_ft
        Enable the VMK interface for Fault Tolerance traffic
        [Default: (null)]
- enable_mgmt
        Enable the VMK interface for Management traffic
        [Default: (null)]
- enable_vmotion
        Enable the VMK interface for vMotion traffic
        [Default: (null)]
- enable_vsan
        Enable the VMK interface for VSAN traffic
        [Default: (null)]
= hostname
        The hostname or IP address of the vSphere vCenter.

= ip_address
        The IP Address for the VMK interface

- mtu
        The MTU for the VMK interface
        [Default: (null)]
= password
        The password of the vSphere vCenter.

= portgroup_name
        The name of the portgroup for the VMK interface

= subnet_mask
        The Subnet Mask for the VMK interface

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
= vland_id
        The VLAN ID for the VMK interface

= vswitch_name
        The name of the vswitch where to add the VMK interface

Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example command from Ansible Playbook

-  name: Add Management vmkernel port (vmk1)
   local_action:
      module: vmware_vmkernel
      hostname: esxi_hostname
      username: esxi_username
      password: esxi_password
      vswitch_name: vswitch_name
      portgroup_name: portgroup_name
      vlan_id: vlan_id
      ip_address: ip_address
      subnet_mask: subnet_mask
      enable_mgmt: True


MAINTAINERS: Joseph Callen (@jcpowermac), Russell Teague (@mtnbikenc)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_VMKERNEL_IP_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_vmkernel_ip_config.py)

  Configure the VMkernel IP Address

Options (= is mandatory):

= hostname
        The hostname or IP address of the vSphere vCenter.

= ip_address
        IP address to assign to VMkernel interface

= password
        The password of the vSphere vCenter.

= subnet_mask
        Subnet Mask to assign to VMkernel interface

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
= vmk_name
        VMkernel interface name

Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example command from Ansible Playbook

- name: Configure IP address on ESX host
  local_action:
    module: vmware_vmkernel_ip_config
    hostname: esxi_hostname
    username: esxi_username
    password: esxi_password
    vmk_name: vmk0
    ip_address: 10.0.0.10
    subnet_mask: 255.255.255.0


MAINTAINERS: Joseph Callen (@jcpowermac), Russell Teague (@mtnbikenc)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_VMOTION    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_vmotion.py)

  Using VMware vCenter, move a virtual machine using vMotion to a different host.

Options (= is mandatory):

= destination_host
        Name of the end host the VM should be running on

= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
= vm_name
        Name of the VM to perform a vMotion on

Notes:
  * Tested on vSphere 6.0
Requirements:  python >= 2.6, pyVmomi

EXAMPLES:
# Example from Ansible playbook

    - name: Perform vMotion of VM
      local_action:
        module: vmware_vmotion
        hostname: 'vcenter_hostname'
        username: 'vcenter_username'
        password: 'vcenter_password'
        validate_certs: False
        vm_name: 'vm_name_as_per_vcenter'
        destination_host: 'destination_host_as_per_vcenter'

RETURN VALUES:
running_host:
    description: List the host the virtual machine is registered to
    returned:
        - changed
        - success
    type: string
    sample: 'host1.example.com'


MAINTAINERS: Bede Carroll (@bedecarroll)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_VSAN_CLUSTER    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_vsan_cluster.py)

  This module can be used to configure VSAN clustering on an ESXi host

Options (= is mandatory):

- cluster_uuid
        Desired cluster UUID
        [Default: (null)]
= hostname
        The hostname or IP address of the vSphere vCenter.

= password
        The password of the vSphere vCenter.

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example command from Ansible Playbook

- name: Configure VMware VSAN Cluster
  hosts: deploy_node
  gather_facts: False
  tags:
    - vsan
  tasks:
    - name: Configure VSAN on first host
      vmware_vsan_cluster:
         hostname: "{{ groups['esxi'][0] }}"
         username: "{{ esxi_username }}"
         password: "{{ site_password }}"
      register: vsan_cluster

    - name: Configure VSAN on remaining hosts
      vmware_vsan_cluster:
         hostname: "{{ item }}"
         username: "{{ esxi_username }}"
         password: "{{ site_password }}"
         cluster_uuid: "{{ vsan_cluster.cluster_uuid }}"
      with_items: "{{ groups['esxi'][1:] }}"



MAINTAINERS: Russell Teague (@mtnbikenc)

METADATA:
	Status: ['preview']
	Supported_by: community
> VMWARE_VSWITCH    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vmware_vswitch.py)

  Add a VMware Standard Switch to an ESXi host

Options (= is mandatory):

= hostname
        The hostname or IP address of the vSphere vCenter.

- mtu
        MTU to configure on vswitch
        [Default: (null)]
= nic_name
        vmnic name to attach to vswitch

- number_of_ports
        Number of port to configure on vswitch
        [Default: 128]
= password
        The password of the vSphere vCenter.

- state
        Add or remove the switch
        (Choices: present, absent)[Default: present]
= switch_name
        vSwitch name to add

= username
        The username of the vSphere vCenter.

- validate_certs
        Allows connection when SSL certificates are not valid. Set to false when certificates are not trusted.
        (Choices: True, False)[Default: True]
Notes:
  * Tested on vSphere 5.5
Requirements:  python >= 2.6, PyVmomi

EXAMPLES:
# Example from Ansible playbook

    - name: Add a VMware vSwitch
      local_action:
        module: vmware_vswitch
        hostname: esxi_hostname
        username: esxi_username
        password: esxi_password
        switch_name: vswitch_name
        nic_name: vmnic_name
        mtu: 9000


MAINTAINERS: Joseph Callen (@jcpowermac), Russell Teague (@mtnbikenc)

METADATA:
	Status: ['preview']
	Supported_by: community
> VSPHERE_COPY    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vsphere_copy.py)

  Upload files to a vCenter datastore

Options (= is mandatory):

= datacenter
        The datacenter on the vCenter server that holds the datastore.

= datastore
        The datastore on the vCenter server to push files to.

= host
        The vCenter server on which the datastore is available.

= login
        The login name to authenticate on the vCenter server.

= password
        The password to authenticate on the vCenter server.

= path
        The file to push to the datastore on the vCenter server.

= src
        The file to push to vCenter

- validate_certs
        If `no', SSL certificates will not be validated. This should only be set to `no' when no other option exists.
        (Choices: yes, no)[Default: yes]
Notes:
  * This module ought to be run from a system that can access vCenter directly and has the file to transfer. It can
        be the normal remote target or you can change it either by using `transport: local' or using `delegate_to'.
  * Tested on vSphere 5.5
EXAMPLES:
- vsphere_copy:
    host: vhost
    login: vuser
    password: vpass
    src: /some/local/file
    datacenter: DC1 Someplace
    datastore: datastore1
    path: some/remote/file
  transport: local
- vsphere_copy:
    host: vhost
    login: vuser
    password: vpass
    src: /other/local/file
    datacenter: DC2 Someplace
    datastore: datastore2
    path: other/remote/file
  delegate_to: other_system


MAINTAINERS: Dag Wieers (@dagwieers) <dag@wieers.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> VSPHERE_GUEST    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/vmware/vsphere_guest.py)

  Create/delete/reconfigure a guest VM through VMware vSphere. This module has a dependency on pysphere >= 1.7

Options (= is mandatory):

- cluster
        The name of the cluster to create the VM in. By default this is derived from the host you tell the module to
        build the guest on.
        [Default: None]
- esxi
        Dictionary which includes datacenter and hostname on which the VM should be created. For standalone ESXi hosts,
        ha-datacenter should be used as the datacenter name
        [Default: None]
- force
        Boolean. Allows you to run commands which may alter the running state of a guest. Also used to reconfigure and
        destroy.
        (Choices: yes, no)[Default: no]
- from_template
        Specifies if the VM should be deployed from a template (mutually exclusive with 'state' parameter). No guest
        customization changes to hardware such as CPU, RAM, NICs or Disks can be applied when launching from template.
        (Choices: yes, no)[Default: False]
= guest
        The virtual server name you wish to manage.

= password
        Password of the user to connect to vcenter as.
        [Default: None]
- power_on_after_clone
        Specifies if the VM should be powered on after the clone.
        (Choices: yes, no)[Default: True]
- resource_pool
        The name of the resource_pool to create the VM in.
        [Default: None]
- snapshot_to_clone
        A string that when specified, will create a linked clone copy of the VM. Snapshot must already be taken in
        vCenter.
        [Default: none]
- state
        Indicate desired state of the vm. 'reconfigured' only applies changes to 'vm_cdrom', 'memory_mb', and 'num_cpus'
        in vm_hardware parameter. The 'memory_mb' and 'num_cpus' changes are applied to powered-on vms when hot-plugging
        is enabled for the guest.
        (Choices: present, powered_off, absent, powered_on, restarted, reconfigured)[Default: present]
- template_src
        Name of the source template to deploy from
        [Default: None]
= username
        Username to connect to vcenter as.
        [Default: None]
- validate_certs
        Validate SSL certs.  Note, if running on python without SSLContext support (typically, python < 2.7.9) you will
        have to set this to `no' as pysphere does not support validating certificates on older python. Prior to 2.1, this
        module would always validate on python >= 2.7.9 and never validate on python <= 2.7.8.
        (Choices: yes, no)[Default: True]
= vcenter_hostname
        The hostname of the vcenter server the module will connect to, to create the guest.
        [Default: None]
- vm_disk
        A key, value list of disks and their sizes and which datastore to keep it in.
        [Default: None]
- vm_extra_config
        A key, value pair of any extra values you want set or changed in the vmx file of the VM. Useful to set advanced
        options on the VM.
        [Default: None]
- vm_hardware
        A key, value list of VM config settings. Must include ['memory_mb', 'num_cpus', 'osid', 'scsi'].
        [Default: None]
- vm_hw_version
        Desired hardware version identifier (for example, "vmx-08" for vms that needs to be managed with vSphere Client).
        Note that changing hardware version of existing vm is not supported.
        [Default: None]
- vm_nic
        A key, value list of nics, their types and what network to put them on.
        [Default: None]
- vmware_guest_facts
        Gather facts from vCenter on a particular VM
        [Default: None]
Notes:
  * This module should run from a system that can access vSphere directly. Either by using local_action, or using
        delegate_to.
Requirements:  python >= 2.6, pysphere

EXAMPLES:
---
# Create a new VM on an ESX server
# Returns changed = False when the VM already exists
# Returns changed = True and a adds ansible_facts from the new VM
# State will set the power status of a guest upon creation. Use powered_on to create and boot.
# Options ['state', 'vm_extra_config', 'vm_disk', 'vm_nic', 'vm_hardware', 'esxi'] are required together
# Note: vm_floppy support added in 2.0

- vsphere_guest:
    vcenter_hostname: vcenter.mydomain.local
    username: myuser
    password: mypass
    guest: newvm001
    state: powered_on
    vm_extra_config:
      vcpu.hotadd: yes
      mem.hotadd:  yes
      notes: This is a test VM
      folder: MyFolder
    vm_disk:
      disk1:
        size_gb: 10
        type: thin
        datastore: storage001
        # VMs can be put into folders. The value given here is either the full path
        # to the folder (e.g. production/customerA/lamp) or just the last component
        # of the path (e.g. lamp):
        folder: production/customerA/lamp
    vm_nic:
      nic1:
        type: vmxnet3
        network: VM Network
        network_type: standard
      nic2:
        type: vmxnet3
        network: dvSwitch Network
        network_type: dvs
    vm_hardware:
      memory_mb: 2048
      num_cpus: 2
      osid: centos64Guest
      scsi: paravirtual
      vm_cdrom:
        type: "iso"
        iso_path: "DatastoreName/cd-image.iso"
      vm_floppy:
        type: "image"
        image_path: "DatastoreName/floppy-image.flp"
    esxi:
      datacenter: MyDatacenter
      hostname: esx001.mydomain.local

# Reconfigure the CPU and Memory on the newly created VM
# Will return the changes made

- vsphere_guest:
    vcenter_hostname: vcenter.mydomain.local
    username: myuser
    password: mypass
    guest: newvm001
    state: reconfigured
    vm_extra_config:
      vcpu.hotadd: yes
      mem.hotadd:  yes
      notes: This is a test VM
    vm_disk:
      disk1:
        size_gb: 10
        type: thin
        datastore: storage001
    vm_nic:
      nic1:
        type: vmxnet3
        network: VM Network
        network_type: standard
    vm_hardware:
      memory_mb: 4096
      num_cpus: 4
      osid: centos64Guest
      scsi: paravirtual
    esxi:
      datacenter: MyDatacenter
      hostname: esx001.mydomain.local

# Deploy a guest from a template
- vsphere_guest:
    vcenter_hostname: vcenter.mydomain.local
    username: myuser
    password: mypass
    guest: newvm001
    from_template: yes
    template_src: centosTemplate
    cluster: MainCluster
    resource_pool: "/Resources"
    vm_extra_config:
      folder: MyFolder

# Task to gather facts from a vSphere cluster only if the system is a VMware guest

- vsphere_guest:
    vcenter_hostname: vcenter.mydomain.local
    username: myuser
    password: mypass
    guest: newvm001
    vmware_guest_facts: yes

---
# Typical output of a vsphere_facts run on a guest
# If vmware tools is not installed, ipadresses with return None

- hw_eth0:
  - addresstype: "assigned"
    label: "Network adapter 1"
    macaddress: "00:22:33:33:44:55"
    macaddress_dash: "00-22-33-33-44-55"
    ipaddresses: ['192.0.2.100', '2001:DB8:56ff:feac:4d8a']
    summary: "VM Network"
  hw_guest_full_name: "newvm001"
  hw_guest_id: "rhel6_64Guest"
  hw_memtotal_mb: 2048
  hw_name: "centos64Guest"
  hw_power_status: "POWERED ON"
  hw_processor_count: 2
  hw_product_uuid: "ef50bac8-2845-40ff-81d9-675315501dac"

# hw_power_status will be one of the following values:
#   - POWERED ON
#   - POWERED OFF
#   - SUSPENDED
#   - POWERING ON
#   - POWERING OFF
#   - SUSPENDING
#   - RESETTING
#   - BLOCKED ON MSG
#   - REVERTING TO SNAPSHOT
#   - UNKNOWN
# as seen in the VMPowerState-Class of PySphere: http://git.io/vlwOq

---
# Remove a vm from vSphere
# The VM must be powered_off or you need to use force to force a shutdown
- vsphere_guest:
    vcenter_hostname: vcenter.mydomain.local
    username: myuser
    password: mypass
    guest: newvm001
    state: absent
    force: yes


MAINTAINERS: Richard Hoop (@rhoop) <wrhoop@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> VYOS_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/network/vyos/vyos_command.py)

  The command module allows running one or more commands on remote devices running VyOS.  This module can also be
  introspected to validate key parameters before returning successfully.  If the conditional statements are not met in
  the wait period, the task fails. Certain `show' commands in VyOS produce many lines of output and use a custom pager
  that can cause this module to hang.  If the value of the environment variable `ANSIBLE_VYOS_TERMINAL_LENGTH' is not
  set, the default number of 10000 is used.

Options (= is mandatory):

= commands
        The ordered set of commands to execute on the remote device running VyOS.  The output from the command execution
        is returned to the playbook.  If the `wait_for' argument is provided, the module is not returned until the
        condition is satisfied or the number of retries has been exceeded.

- interval
        Configures the interval in seconds to wait between `retries' of the command. If the command does not pass the
        specified conditions, the interval indicates how long to wait before trying the command again.
        [Default: 1]
- match
        The `match' argument is used in conjunction with the `wait_for' argument to specify the match policy. Valid
        values are `all' or `any'.  If the value is set to `all' then all conditionals in the wait_for must be satisfied.
        If the value is set to `any' then only one of the values must be satisfied.
        (Choices: any, all)[Default: all]
- provider
        A dict object containing connection details.
        [Default: None]
- retries
        Specifies the number of retries a command should be tried before it is considered failed. The command is run on
        the target device every retry and evaluated against the `wait_for' conditionals.
        [Default: 10]
- wait_for
        Specifies what to evaluate from the output of the command and what conditionals to apply.  This argument will
        cause the task to wait for a particular conditional to be true before moving forward.  If the conditional is not
        true by the configured `retries', the task fails. See examples.
        [Default: None]
Notes:
  * Running `show system boot-messages all' will cause the module to hang since VyOS is using a custom pager
        setting to display the output of that command.
EXAMPLES:
tasks:
  - name: show configuration on ethernet devices eth0 and eth1
    vyos_command:
      commands:
        - show interfaces ethernet {{ item }}
    with_items:
      - eth0
      - eth1

  - name: run multiple commands and check if version output contains specific version string
    vyos_command:
      commands:
        - show version
        - show hardware cpu
      wait_for:
        - "result[0] contains 'VyOS 1.1.7'"

RETURN VALUES:
stdout:
  description: The set of responses from the commands
  returned: always apart from low level errors (such as action plugin)
  type: list
  sample: ['...', '...']
stdout_lines:
  description: The value of stdout split into a list
  returned: always
  type: list
  sample: [['...', '...'], ['...'], ['...']]
failed_conditions:
  description: The list of conditionals that have failed
  returned: failed
  type: list
  sample: ['...', '...']
warnings:
  description: The list of warnings (if any) generated by module based on arguments
  returned: always
  type: list
  sample: ['...', '...']


MAINTAINERS: Nathaniel Case (@qalthos)

METADATA:
	Status: ['preview']
	Supported_by: community
> VYOS_CONFIG    (/usr/lib/python2.7/site-packages/ansible/modules/network/vyos/vyos_config.py)

  This module provides configuration file management of VyOS devices.  It provides arguments for managing both the
  configuration file and state of the active configuration.   All configuration statements are based on `set` and
  `delete` commands in the device configuration.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- backup
        The `backup' argument will backup the current devices active configuration to the Ansible control host prior to
        making any changes.  The backup file will be located in the backup folder in the root of the playbook
        (Choices: yes, no)[Default: False]
- comment
        Allows a commit description to be specified to be included when the configuration is committed.  If the
        configuration is not changed or committed, this argument is ignored.
        [Default: configured by vyos_config]
- config
        The `config' argument specifies the base configuration to use to compare against the desired configuration.  If
        this value is not specified, the module will automatically retrieve the current active configuration from the
        remote device.
        [Default: None]
- lines
        The ordered set of configuration lines to be managed and compared with the existing configuration on the remote
        device.
        [Default: None]
- match
        The `match' argument controls the method used to match against the current active configuration.  By default, the
        desired config is matched against the active config and the deltas are loaded.  If the `match' argument is set to
        `none' the active configuration is ignored and the configuration is always loaded.
        (Choices: line, none)[Default: line]
- provider
        A dict object containing connection details.
        [Default: None]
- save
        The `save' argument controls whether or not changes made to the active configuration are saved to disk.  This is
        independent of committing the config.  When set to True, the active configuration is saved.
        (Choices: yes, no)[Default: False]
- src
        The `src' argument specifies the path to the source config file to load.  The source config file can either be in
        bracket format or set format.  The source file can include Jinja2 template variables.
        [Default: None]
EXAMPLES:
- name: configure the remote device
  vyos_config:
    lines:
      - set system host-name {{ inventory_hostname }}
      - set service lldp
      - delete service dhcp-server

- name: backup and load from file
  vyos_config:
    src: vyos.cfg
    backup: yes

RETURN VALUES:
commands:
  description: The list of configuration commands sent to the device
  returned: always
  type: list
  sample: ['...', '...']
filtered:
  description: The list of configuration commands removed to avoid a load failure
  returned: always
  type: list
  sample: ['...', '...']


MAINTAINERS: Nathaniel Case (@qalthos)

METADATA:
	Status: ['preview']
	Supported_by: core
> VYOS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/network/vyos/vyos_facts.py)

  Collects a base set of device facts from a remote device that is running VyOS.  This module prepends all of the base
  network fact keys with ansible_net_<fact>.  The facts module will always collect a base set of facts from the device
  and can enable or disable collection of additional facts.

Options (= is mandatory):

- gather_subset
        When supplied, this argument will restrict the facts collected to a given subset.  Possible values for this
        argument include all, default, config, and neighbors.  Can specify a list of values to include a larger subset.
        Values can also be used with an initial `[!]' to specify that a specific subset should not be collected.
        [Default: !config]
- provider
        A dict object containing connection details.
        [Default: None]
EXAMPLES:
- name: collect all facts from the device
  vyos_facts:
    gather_subset: all

- name: collect only the config and default facts
  vyos_facts:
    gather_subset: config

- name: collect everything exception the config
  vyos_facts:
    gather_subset: "!config"

RETURN VALUES:
ansible_net_config:
  description: The running-config from the device
  returned: when config is configured
  type: str
ansible_net_commits:
  description: The set of available configuration revisions
  returned: when present
  type: list
ansible_net_hostname:
  description: The configured system hostname
  returned: always
  type: str
ansible_net_model:
  description: The device model string
  returned: always
  type: str
ansible_net_serialnum:
  description: The serial number of the device
  returned: always
  type: str
ansible_net_version:
  description: The version of the software running
  returned: always
  type: str
ansible_net_neighbors:
  description: The set of LLDP neighbors
  returned: when interface is configured
  type: list
ansible_net_gather_subset:
  description: The list of subsets gathered by the module
  returned: always
  type: list


MAINTAINERS: Nathaniel Case (@qalthos)

METADATA:
	Status: ['preview']
	Supported_by: core
> VYOS_SYSTEM    (/usr/lib/python2.7/site-packages/ansible/modules/network/vyos/vyos_system.py)

  Runs one or more commands on remote devices running VyOS. This module can also be introspected to validate key
  parameters before returning successfully.

Options (= is mandatory):

- domain_name
        The new domain name to apply to the device.
        [Default: (null)]
- domain_search
        A list of domain names to search. Mutually exclusive with `name_server'
        [Default: (null)]
- hostname
        Configure the device hostname parameter. This option takes an ASCII string value.
        [Default: (null)]
- name_server
        A list of name servers to use with the device. Mutually exclusive with `domain_search'
        [Default: None]
- provider
        A dict object containing connection details.
        [Default: None]
- state
        Whether to apply (`present') or remove (`absent') the settings.
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: configure hostname and domain-name
  vyos_system:
    hostname: vyos01
    domain_name: test.example.com

- name: remove all configuration
  vyos_system:
    state: absent

- name: configure name servers
  vyos_system:
    name_server:
      - 8.8.8.8
      - 8.8.4.4

- name: configure domain search suffixes
  vyos_system:
    domain_search:
      - sub1.example.com
      - sub2.example.com

RETURN VALUES:
commands:
  description: The list of configuration mode commands to send to the device
  returned: always
  type: list
  sample:
    - set system hostname vyos01
    - set system domain-name foo.example.com


MAINTAINERS: Nathaniel Case (@qalthos)

METADATA:
	Status: ['preview']
	Supported_by: community
> WAIT_FOR    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/wait_for.py)

  You can wait for a set amount of time `timeout', this is the default if nothing is specified. Waiting for a port to
  become available is useful for when services are not immediately available after their init scripts return which is
  true of certain Java application servers. It is also useful when starting guests with the [virt] module and needing to
  pause until they are ready. This module can also be used to wait for a regex match a string to be present in a file. In
  1.6 and later, this module can also be used to wait for a file to be available or absent on the filesystem. In 1.8 and
  later, this module can also be used to wait for active connections to be closed before continuing, useful if a node is
  being rotated out of a load balancer pool.

Options (= is mandatory):

- active_connection_states
        The list of tcp connection states which are counted as active connections
        [Default: [u'ESTABLISHED', u'SYN_SENT', u'SYN_RECV', u'FIN_WAIT1', u'FIN_WAIT2', u'TIME_WAIT']]
- connect_timeout
        maximum number of seconds to wait for a connection to happen before closing and retrying
        [Default: 5]
- delay
        number of seconds to wait before starting to poll
        [Default: 0]
- exclude_hosts
        list of hosts or IPs to ignore when looking for active TCP connections for `drained' state
        [Default: None]
- host
        A resolvable hostname or IP address to wait for
        [Default: 127.0.0.1]
- path
        path to a file on the filesytem that must exist before continuing
        [Default: None]
- port
        port number to poll
        [Default: None]
- search_regex
        Can be used to match a string in either a file or a socket connection. Defaults to a multiline regex.
        [Default: None]
- sleep
        Number of seconds to sleep between checks, before 2.3 this was hardcoded to 1 second.
        [Default: 1]
- state
        either `present', `started', or `stopped', `absent', or `drained'
        When checking a port `started' will ensure the port is open, `stopped' will check that it is closed, `drained'
        will check for active connections
        When checking for a file or a search string `present' or `started' will ensure that the file or string is present
        before continuing, `absent' will check that file is absent or removed
        (Choices: present, started, stopped, absent, drained)[Default: started]
- timeout
        maximum number of seconds to wait for
        [Default: 300]
Notes:
  * The ability to use search_regex with a port connection was added in 1.7.
EXAMPLES:

# wait 300 seconds for port 8000 to become open on the host, don't start checking for 10 seconds
- wait_for:
    port: 8000
    delay: 10

# wait 300 seconds for port 8000 of any IP to close active connections, don't start checking for 10 seconds
- wait_for:
    host: 0.0.0.0
    port: 8000
    delay: 10
    state: drained

# wait 300 seconds for port 8000 of any IP to close active connections, ignoring connections for specified hosts
- wait_for:
    host: 0.0.0.0
    port: 8000
    state: drained
    exclude_hosts: 10.2.1.2,10.2.1.3

# wait until the file /tmp/foo is present before continuing
- wait_for:
    path: /tmp/foo

# wait until the string "completed" is in the file /tmp/foo before continuing
- wait_for:
    path: /tmp/foo
    search_regex: completed

# wait until the lock file is removed
- wait_for:
    path: /var/lock/file.lock
    state: absent

# wait until the process is finished and pid was destroyed
- wait_for:
    path: /proc/3466/status
    state: absent

# wait 300 seconds for port 22 to become open and contain "OpenSSH", don't assume the inventory_hostname is resolvable
# and don't start checking for 10 seconds
- local_action: wait_for port=22 host="{{ ansible_ssh_host | default(inventory_hostname) }}" search_regex=OpenSSH delay=10


MAINTAINERS: Andrii Radyk (@AnderEnder), Jeroen Hoekx (@jhoekx), John Jarvis (@jarv)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WAIT_FOR_CONNECTION    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/wait_for_connection.py)

  Waits for a total of `timeout' seconds. Retries the transport connection after a timeout of `connect_timeout'. Tests
  the transport connection every `sleep' seconds. This module makes use of internal ansible transport (and configuration)
  and the ping/win_ping module to guarantee correct end-to-end functioning.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- connect_timeout
        Maximum number of seconds to wait for a connection to happen before closing and retrying.
        [Default: 5]
- delay
        Number of seconds to wait before starting to poll.
        [Default: 0]
- sleep
        Number of seconds to sleep between checks.
        [Default: 1]
- timeout
        Maximum number of seconds to wait for.
        [Default: 600]
EXAMPLES:
- name: Wait 600 seconds for target connection to become reachable/usable
  wait_for_connection:

- name: Wait 300 seconds, but only start checking after 60 seconds
  wait_for_connection:
    delay: 60
    timeout: 300

# Wake desktops, wait for them to become ready and continue playbook
- hosts: all
  gather_facts: no
  tasks:
  - name: Send magic Wake-On-Lan packet to turn on individual systems
    wakeonlan:
      mac: '{{ mac }}'
      broadcast: 192.168.0.255
    delegate_to: localhost

  - name: Wait for system to become reachable
    wait_for_connection:

  - name: Gather facts for first time
    setup:

# Build a new VM, wait for it to become ready and continue playbook
- hosts: all
  gather_facts: no
  tasks:
  - name: Clone new VM, if missing
    vmware_guest:
      hostname: '{{ vcenter_ipaddress }}'
      name: '{{ inventory_hostname_short }}'
      template: Windows 2012R2
      customization:
        hostname: '{{ vm_shortname }}'
        runonce:
        - powershell.exe -ExecutionPolicy Unrestricted -File C:\Windows\Temp\ConfigureRemotingForAnsible.ps1 -ForceNewSSLCert -EnableCredSSP
    delegate_to: localhost

  - name: Wait for system to become reachable over WinRM
    wait_for_connection:
      timeout: 900

  - name: Gather facts for first time
    setup:

RETURN VALUES:
elapsed:
  description: The number of seconds that elapsed waiting for the connection to appear.
  returned: always
  type: integer
  sample: 23


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WAKEONLAN    (/usr/lib/python2.7/site-packages/ansible/modules/remote_management/wakeonlan.py)

  The `wakeonlan' module sends magic Wake-on-LAN (WoL) broadcast packets.

Options (= is mandatory):

- broadcast
        Network broadcast address to use for broadcasting magic Wake-on-LAN packet.
        [Default: 255.255.255.255]
= mac
        MAC address to send Wake-on-LAN broadcast packet for.

- port
        UDP port to use for magic Wake-on-LAN packet.
        [Default: 7]
Notes:
  * This module sends a magic packet, without knowing whether it worked
  * Only works if the target system was properly configured for Wake-on-LAN (in the BIOS and/or the OS)
  * Some BIOSes have a different (configurable) Wake-on-LAN boot order (i.e. PXE first) when turned off
EXAMPLES:
- name: Send a magic Wake-on-LAN packet to 00:00:5E:00:53:66
  wakeonlan:
    mac: '00:00:5E:00:53:66'
    broadcast: 192.0.2.23
  delegate_to: localhost

- wakeonlan:
    mac: 00:00:5E:00:53:66
    port: 9
  delegate_to: localhost

RETURN VALUES:
# Default return values


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['preview']
	Supported_by: community
> WEBFACTION_APP    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/webfaction/webfaction_app.py)

  Add or remove applications on a Webfaction host.  Further documentation at http://github.com/quentinsf/ansible-
  webfaction.

Options (= is mandatory):

- autostart
        Whether the app should restart with an autostart.cgi script
        [Default: no]
- extra_info
        Any extra parameters required by the app
        [Default: None]
= login_name
        The webfaction account to use

= login_password
        The webfaction password to use

- machine
        The machine name to use (optional for accounts with only one machine)
        [Default: (null)]
= name
        The name of the application

- port_open
        IF the port should be opened
        [Default: False]
- state
        Whether the application should exist
        (Choices: present, absent)[Default: present]
= type
        The type of application to create. See the Webfaction docs at http://docs.webfaction.com/xmlrpc-api/apps.html for
        a list.

Notes:
  * You can run playbooks that use this on a local machine, or on a Webfaction host, or elsewhere, since the
        scripts use the remote webfaction API - the location is not important. However, running them on multiple
        hosts `simultaneously' is best avoided. If you don't specify `localhost' as your host, you may want to add
        `serial: 1' to the plays.
  * See `the webfaction API <http://docs.webfaction.com/xmlrpc-api/>`_ for more info.
EXAMPLES:
  - name: Create a test app
    webfaction_app:
      name="my_wsgi_app1"
      state=present
      type=mod_wsgi35-python27
      login_name={{webfaction_user}}
      login_password={{webfaction_passwd}}
      machine={{webfaction_machine}}


MAINTAINERS: Quentin Stafford-Fraser (@quentinsf)

METADATA:
	Status: ['preview']
	Supported_by: community
> WEBFACTION_DB    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/webfaction/webfaction_db.py)

  Add or remove a database on a Webfaction host. Further documentation at http://github.com/quentinsf/ansible-webfaction.

Options (= is mandatory):

= login_name
        The webfaction account to use

= login_password
        The webfaction password to use

- machine
        The machine name to use (optional for accounts with only one machine)
        [Default: (null)]
= name
        The name of the database

- password
        The password for the new database user.
        [Default: None]
- state
        Whether the database should exist
        (Choices: present, absent)[Default: present]
= type
        The type of database to create.
        (Choices: mysql, postgresql)
Notes:
  * You can run playbooks that use this on a local machine, or on a Webfaction host, or elsewhere, since the
        scripts use the remote webfaction API - the location is not important. However, running them on multiple
        hosts `simultaneously' is best avoided. If you don't specify `localhost' as your host, you may want to add
        `serial: 1' to the plays.
  * See `the webfaction API <http://docs.webfaction.com/xmlrpc-api/>`_ for more info.
EXAMPLES:
  # This will also create a default DB user with the same
  # name as the database, and the specified password.

  - name: Create a database
    webfaction_db:
      name: "{{webfaction_user}}_db1"
      password: mytestsql
      type: mysql
      login_name: "{{webfaction_user}}"
      login_password: "{{webfaction_passwd}}"
      machine: "{{webfaction_machine}}"

  # Note that, for symmetry's sake, deleting a database using
  # 'state: absent' will also delete the matching user.



MAINTAINERS: Quentin Stafford-Fraser (@quentinsf)

METADATA:
	Status: ['preview']
	Supported_by: community
> WEBFACTION_DOMAIN    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/webfaction/webfaction_domain.py)

  Add or remove domains or subdomains on a Webfaction host. Further documentation at http://github.com/quentinsf/ansible-
  webfaction.

Options (= is mandatory):

= login_name
        The webfaction account to use

= login_password
        The webfaction password to use

= name
        The name of the domain

- state
        Whether the domain should exist
        (Choices: present, absent)[Default: present]
- subdomains
        Any subdomains to create.
        [Default: None]
Notes:
  * If you are `deleting' domains by using `state=absent', then note that if you specify subdomains, just those
        particular subdomains will be deleted.  If you don't specify subdomains, the domain will be deleted.
  * You can run playbooks that use this on a local machine, or on a Webfaction host, or elsewhere, since the
        scripts use the remote webfaction API - the location is not important. However, running them on multiple
        hosts `simultaneously' is best avoided. If you don't specify `localhost' as your host, you may want to add
        `serial: 1' to the plays.
  * See `the webfaction API <http://docs.webfaction.com/xmlrpc-api/>`_ for more info.
EXAMPLES:
  - name: Create a test domain
    webfaction_domain:
      name: mydomain.com
      state: present
      subdomains:
       - www
       - blog
      login_name: "{{webfaction_user}}"
      login_password: "{{webfaction_passwd}}"

  - name: Delete test domain and any subdomains
    webfaction_domain:
      name: mydomain.com
      state: absent
      login_name: "{{webfaction_user}}"
      login_password: "{{webfaction_passwd}}"



MAINTAINERS: Quentin Stafford-Fraser (@quentinsf)

METADATA:
	Status: ['preview']
	Supported_by: community
> WEBFACTION_MAILBOX    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/webfaction/webfaction_mailbox.py)

  Add or remove mailboxes on a Webfaction account. Further documentation at http://github.com/quentinsf/ansible-
  webfaction.

Options (= is mandatory):

= login_name
        The webfaction account to use

= login_password
        The webfaction password to use

= mailbox_name
        The name of the mailbox

= mailbox_password
        The password for the mailbox
        [Default: None]
- state
        Whether the mailbox should exist
        (Choices: present, absent)[Default: present]
Notes:
  * You can run playbooks that use this on a local machine, or on a Webfaction host, or elsewhere, since the
        scripts use the remote webfaction API - the location is not important. However, running them on multiple
        hosts `simultaneously' is best avoided. If you don't specify `localhost' as your host, you may want to add
        `serial: 1' to the plays.
  * See `the webfaction API <http://docs.webfaction.com/xmlrpc-api/>`_ for more info.
EXAMPLES:
  - name: Create a mailbox
    webfaction_mailbox:
      mailbox_name="mybox"
      mailbox_password="myboxpw"
      state=present
      login_name={{webfaction_user}}
      login_password={{webfaction_passwd}}


MAINTAINERS: Quentin Stafford-Fraser (@quentinsf)

METADATA:
	Status: ['preview']
	Supported_by: community
> WEBFACTION_SITE    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/webfaction/webfaction_site.py)

  Add or remove a website on a Webfaction host.  Further documentation at http://github.com/quentinsf/ansible-webfaction.

Options (= is mandatory):

= host
        The webfaction host on which the site should be created.

- https
        Whether or not to use HTTPS
        (Choices: True, False)[Default: false]
= login_name
        The webfaction account to use

= login_password
        The webfaction password to use

= name
        The name of the website

- site_apps
        A mapping of URLs to apps
        [Default: (null)]
- state
        Whether the website should exist
        (Choices: present, absent)[Default: present]
- subdomains
        A list of subdomains associated with this site.
        [Default: None]
Notes:
  * Sadly, you `do' need to know your webfaction hostname for the `host' parameter.  But at least, unlike the API,
        you don't need to know the IP address - you can use a DNS name.
  * If a site of the same name exists in the account but on a different host, the operation will exit.
  * You can run playbooks that use this on a local machine, or on a Webfaction host, or elsewhere, since the
        scripts use the remote webfaction API - the location is not important. However, running them on multiple
        hosts `simultaneously' is best avoided. If you don't specify `localhost' as your host, you may want to add
        `serial: 1' to the plays.
  * See `the webfaction API <http://docs.webfaction.com/xmlrpc-api/>`_ for more info.
EXAMPLES:
  - name: create website
    webfaction_site:
      name: testsite1
      state: present
      host: myhost.webfaction.com
      subdomains:
        - 'testsite1.my_domain.org'
      site_apps:
        - ['testapp1', '/']
      https: no
      login_name: "{{webfaction_user}}"
      login_password: "{{webfaction_passwd}}"


MAINTAINERS: Quentin Stafford-Fraser (@quentinsf)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_ACL    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_acl.py)

  Add or remove rights/permissions for a given user or group for the specified src file or folder. If adding ACL's for
  AppPool identities (available since 2.3), the Windows "Feature Web-Scripting-Tools" must be enabled

Options (= is mandatory):

- inherit
        Inherit flags on the ACL rules.  Can be specified as a comma separated list (Ex. "ContainerInherit,
        ObjectInherit").  For more information on the choices see MSDN InheritanceFlags Enumeration.
        (Choices: ContainerInherit, ObjectInherit, None)[Default: For Leaf File, None; For Directory, ContainerInherit,
        ObjectInherit;]
= path
        File or Directory

- propagation
        Propagation flag on the ACL rules.  For more information on the choices see MSDN PropagationFlags Enumeration.
        (Choices: None, NoPropagateInherit, InheritOnly)[Default: None]
= rights
        The rights/permissions that are to be allowed/denyed for the specified user or group for the given src file or
        directory.  Can be entered as a comma separated list (Ex. "Modify, Delete, ExecuteFile").  For more information
        on the choices see MSDN FileSystemRights Enumeration.
        (Choices: AppendData, ChangePermissions, Delete, DeleteSubdirectoriesAndFiles, ExecuteFile, FullControl,
        ListDirectory, Modify, Read, ReadAndExecute, ReadAttributes, ReadData, ReadExtendedAttributes, ReadPermissions,
        Synchronize, TakeOwnership, Traverse, Write, WriteAttributes, WriteData, WriteExtendedAttributes)[Default: none]
- state
        Specify whether to add `present' or remove `absent' the specified access rule
        (Choices: present, absent)[Default: present]
= type
        Specify whether to allow or deny the rights specified
        (Choices: allow, deny)[Default: none]
= user
        User or Group to add specified rights to act on src file/folder
        [Default: none]
EXAMPLES:
- name: Restrict write and execute access to User Fed-Phil
  win_acl:
    user: Fed-Phil
    path: C:\Important\Executable.exe
    type: deny
    rights: ExecuteFile,Write

- name: Add IIS_IUSRS allow rights
  win_acl:
    path: C:\inetpub\wwwroot\MySite
    user: IIS_IUSRS
    rights: FullControl
    type: allow
    state: present
    inherit: ContainerInherit, ObjectInherit
    propagation: 'None'

# Remove previously added rule for IIS_IUSRS
- name: Remove FullControl AccessRule for IIS_IUSRS
  win_acl:
    path: C:\inetpub\wwwroot\MySite
    user: IIS_IUSRS
    rights: FullControl
    type: allow
    state: absent
    inherit: ContainerInherit, ObjectInherit
    propagation: 'None'

# Deny Intern
- name: Deny Deny
  win_acl:
    path: C:\Administrator\Documents
    user: Intern
    rights: Read,Write,Modify,FullControl,Delete
    type: deny
    state: present


MAINTAINERS: Phil Schwartz (@schwartzmx), Trond Hindenes (@trondhindenes), Hans-Joachim Kliemeck (@h0nIg)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_ACL_INHERITANCE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_acl_inheritance.py)

  Change ACL (Access Control List) inheritance and optionally copy inherited ACE's (Access Control Entry) to dedicated
  ACE's or vice versa.

Options (= is mandatory):

= path
        Path to be used for changing inheritance

- reorganize
        For P(state) = `absent', indicates if the inherited ACE's should be copied from the parent directory. This is
        necessary (in combination with removal) for a simple ACL instead of using multiple ACE deny entries.
        For P(state) = `present', indicates if the inherited ACE's should be deduplicated compared to the parent
        directory. This removes complexity of the ACL structure.
        (Choices: False, True)[Default: False]
- state
        Specify whether to enable `present' or disable `absent' ACL inheritance
        (Choices: present, absent)[Default: absent]
EXAMPLES:
- name: Disable inherited ACE's
  win_acl_inheritance:
    path: C:\apache
    state: absent

- name: Disable and copy inherited ACE's
  win_acl_inheritance:
    path: C:\apache
    state: absent
    reorganize: True

- name: Enable and remove dedicated ACE's
  win_acl_inheritance:
    path: C:\apache
    state: present
    reorganize: True

RETURN VALUES:



MAINTAINERS: Hans-Joachim Kliemeck (@h0nIg)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_CHOCOLATEY    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_chocolatey.py)

  Installs packages using Chocolatey (http://chocolatey.org/). If Chocolatey is missing from the system, the module will
  install it. List of packages can be found at http://chocolatey.org/packages

Options (= is mandatory):

- allow_empty_checksums
        Allow empty checksums to be used.
        [Default: False]
- force
        Forces install of the package (even if it already exists).
        Using `force' will cause ansible to always report that a change was made.
        (Choices: True, False)[Default: False]
- ignore_checksums
        Ignore checksums altogether.
        [Default: False]
- ignore_dependencies
        Ignore dependencies, only install/upgrade the package itself.
        [Default: False]
- install_args
        Arguments to pass to the native installer.
        [Default: (null)]
= name
        Name of the package to be installed.

- params
        Parameters to pass to the package
        [Default: (null)]
- source
        Specify source rather than using default chocolatey repository.
        [Default: (null)]
- state
        State of the package on the system.
        (Choices: present, absent, latest, reinstalled)[Default: present]
- timeout
        The time to allow chocolatey to finish before timing out.
        [Default: 2700]
- upgrade
        If package is already installed it, try to upgrade to the latest version or to the specified version.
        As of Ansible v2.3 this is deprecated, set parameter `state' to "latest" for the same result.
        (Choices: True, False)[Default: False]
- version
        Specific version of the package to be installed.
        Ignored when `state' is set to "absent".
        [Default: (null)]
EXAMPLES:
  # Install git
  win_chocolatey:
    name: git
    state: present

  # Upgrade installed packages
  win_chocolatey:
    name: all
    state: latest

  # Install notepadplusplus version 6.6
  win_chocolatey:
    name: notepadplusplus.install
    version: '6.6'

  # Install git from specified repository
  win_chocolatey:
    name: git
    source: https://someserver/api/v2/

  # Uninstall git
  win_chocolatey:
    name: git
    state: absent


MAINTAINERS: Trond Hindenes (@trondhindenes), Peter Mounce (@petemounce), Pepe Barbe (@elventear), Adam Keech (@smadam813)

METADATA:
	Status: ['preview']
	Supported_by: curated
> WIN_COMMAND    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_command.py)

  The `win_command' module takes the command name followed by a list of space-delimited arguments. The given command will
  be executed on all selected nodes. It will not be processed through the shell, so variables like `$env:HOME' and
  operations like `"<"', `">"', `"|"', and `";"' will not work (use the [win_shell] module if you need these features).

Options (= is mandatory):

- chdir
        set the specified path as the current working directory before executing a command
        [Default: (null)]
- creates
        a path or path filter pattern; when the referenced path exists on the target host, the task will be skipped.
        [Default: (null)]
= free_form
        the win_command module takes a free form command to run.  There is no parameter actually named 'free form'. See
        the examples!

- removes
        a path or path filter pattern; when the referenced path *does not* exist on the target host, the task will be
        skipped.
        [Default: (null)]
Notes:
  * If you want to run a command through a shell (say you are using `<', `>', `|', etc), you actually want the
        [win_shell] module instead. The `win_command' module is much more secure as it's not affected by the user's
        environment.
  *  `creates', `removes', and `chdir' can be specified after the command. For instance, if you only want to run a
        command if a certain file does not exist, use this.
EXAMPLES:
# Example from Ansible Playbooks.
- win_command: whoami
  register: whoami_out

# Run the command only if the specified file does not exist.
- win_command: wbadmin -backupTarget:C:\backup\ creates=C:\backup\

# You can also use the 'args' form to provide the options. This command
# will change the working directory to C:\somedir\\ and will only run when
# C:\backup\ doesn't exist.
- win_command: wbadmin -backupTarget:C:\backup\ creates=C:\backup\
  args:
    chdir: C:\somedir\
    creates: C:\backup\

RETURN VALUES:
msg:
    description: changed
    returned: always
    type: boolean
    sample: True
start:
    description: The command execution start time
    returned: always
    type: string
    sample: '2016-02-25 09:18:26.429568'
end:
    description: The command execution end time
    returned: always
    type: string
    sample: '2016-02-25 09:18:26.755339'
delta:
    description: The command execution delta time
    returned: always
    type: string
    sample: '0:00:00.325771'
stdout:
    description: The command standard output
    returned: always
    type: string
    sample: 'Clustering node rabbit@slave1 with rabbit@master ...'
stderr:
    description: The command standard error
    returned: always
    type: string
    sample: 'ls: cannot access foo: No such file or directory'
cmd:
    description: The command executed by the task
    returned: always
    type: string
    sample: 'rabbitmqctl join_cluster rabbit@master'
rc:
    description: The command return code (0 means success)
    returned: always
    type: int
    sample: 0
stdout_lines:
    description: The command standard output split in lines
    returned: always
    type: list of strings
    sample: [u'Clustering node rabbit@slave1 with rabbit@master ...']


MAINTAINERS: Matt Davis

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_COPY    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_copy.py)

  The `win_copy' module copies a file on the local box to remote windows locations.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- content
        When used instead of `src', sets the contents of a file directly to the specified value. This is for simple
        values, for anything complex or with formatting please switch to the template module.
        [Default: (null)]
= dest
        Remote absolute path where the file should be copied to. If src is a directory, this must be a directory too.
        Use \ for path separators or \\ when in "double quotes".

- force
        If set to `yes', the remote file will be replaced when content is different than the source.
        If set to `no', the remote file will only be transferred if the destination does not exist.
        (Choices: True, False)[Default: True]
- remote_src
        If False, it will search for src at originating/master machine, if True it will go to the remote/target machine
        for the src.
        (Choices: True, False)[Default: False]
= src
        Local path to a file to copy to the remote server; can be absolute or relative. If path is a directory, it is
        copied recursively. In this case, if path ends with "/", only inside contents of that directory are copied to
        destination. Otherwise, if it does not end with "/", the directory itself with all contents is copied. This
        behavior is similar to Rsync.

EXAMPLES:
- name: Copy a single file
  win_copy:
    src: /srv/myfiles/foo.conf
    dest: c:\Temp\foo.conf
- name: Copy files/temp_files to c:\temp
  win_copy:
    src: files/temp_files/
    dest: c:\Temp
- name: Copy a single file where the source is on the remote host
  win_copy:
    src: C:\temp\foo.txt
    dest: C:\ansible\foo.txt
    remote_src: True
- name: Copy a folder recursively where the source is on the remote host
  win_copy:
    src: C:\temp
    dest: C:\ansible
    remote_src: True
- name: Set the contents of a file
  win_copy:
    dest: C:\temp\foo.txt
    content: abc123

RETURN VALUES:
dest:
    description: destination file/path
    returned: changed
    type: string
    sample: C:\Temp\
src:
    description: source file used for the copy on the target machine
    returned: changed
    type: string
    sample: /home/httpd/.ansible/tmp/ansible-tmp-1423796390.97-147729857856000/source
checksum:
    description: sha1 checksum of the file after running copy
    returned: success, src is a file
    type: string
    sample: 6e642bb8dd5c2e027bf21dd923337cbb4214f827
size:
    description: size of the target, after execution
    returned: changed (src is a file or remote_src == True)
    type: int
    sample: 1220
operation:
    description: whether a single file copy took place or a folder copy
    returned: changed
    type: string
    sample: file_copy
original_basename:
    description: basename of the copied file
    returned: changed, src is a file
    type: string
    sample: foo.txt


MAINTAINERS: Jon Hawkesworth (@jhawkesworth)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_DISK_IMAGE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_disk_image.py)

  Manages mount behavior for a specified ISO, VHD, or VHDX image on a Windows host. When `state' is `present', the image
  will be mounted under a system-assigned drive letter, which will be returned in the `mount_path' value of the module
  result. Requires Windows 8+ or Windows Server 2012+.

Options (= is mandatory):

= image_path
        path to an ISO, VHD, or VHDX image on the target Windows host (the file cannot reside on a network share)

- state
        whether the image should be present as a drive-letter mount or not.
        (Choices: present, absent)[Default: present]
EXAMPLES:
# ensure an iso is mounted
- win_disk_image:
    image_path: C:\install.iso
    state: present
  register: disk_image_out

# run installer from mounted iso
- win_package:
    path: '{{ disk_image_out.mount_path }}setup\setup.exe'
    product_id: '35a4e767-0161-46b0-979f-e61f282fee21'
    state: present

# unmount iso
- win_disk_image:
    image_path: C:\install.iso
    state: absent


RETURN VALUES:
mount_path:
    description: filesystem path where the target image is mounted
    returned: when C(state) is C(present)
    type: string
    sample: F:\


MAINTAINERS: Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_DNS_CLIENT    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_dns_client.py)

  The `win_dns_client' module configures the DNS client on Windows network adapters.

Options (= is mandatory):

= adapter_names
        Adapter name or list of adapter names for which to manage DNS settings ('*' is supported as a wildcard value).
        The adapter name used is the connection caption in the Network Control Panel or via `Get-NetAdapter', eg `Local
        Area Connection'.

= ipv4_addresses
        Single or ordered list of DNS server IPv4 addresses to configure for lookup. An empty list will configure the
        adapter to use the DHCP-assigned values on connections where DHCP is enabled, or disable DNS lookup on
        statically-configured connections.

Notes:
  * When setting an empty list of DNS server addresses on an adapter with DHCP enabled, a change will always be
        registered, since it is not possible to detect the difference between a DHCP-sourced server value and one
        that is statically set.
EXAMPLES:
  # set a single address on the adapter named Ethernet
  - win_dns_client:
      adapter_names: Ethernet
      ipv4_addresses: 192.168.34.5

  # set multiple lookup addresses on all visible adapters (usually physical adapters that are in the Up state), with debug logging to a file
  - win_dns_client:
      adapter_names: "*"
      ipv4_addresses:
      - 192.168.34.5
      - 192.168.34.6
      log_path: c:\dns_log.txt

  # configure all adapters whose names begin with Ethernet to use DHCP-assigned DNS values
  - win_dns_client:
      adapter_names: "Ethernet*"
      ipv4_addresses: []

RETURN VALUES:



MAINTAINERS: Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_DOMAIN    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_domain.py)

  Ensure that the domain named by `dns_domain_name' exists and is reachable. If the domain is not reachable, the domain
  is created in a new forest on the target Windows Server 2012R2+ host. This module may require subsequent use of the
  [win_reboot] action if changes are made.

Options (= is mandatory):

= dns_domain_name
        the DNS name of the domain which should exist and be reachable or reside on the target Windows host

= safe_mode_password
        safe mode password for the domain controller

EXAMPLES:
# ensure the named domain is reachable from the target host; if not, create the domain in a new forest residing on the target host
- win_domain:
    dns_domain_name: ansible.vagrant
    safe_mode_password: password123!


RETURN VALUES:
reboot_required:
    description: True if changes were made that require a reboot.
    returned: always
    type: boolean
    sample: true



MAINTAINERS: Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_DOMAIN_CONTROLLER    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_domain_controller.py)

  Ensure that a Windows Server 2012+ host is configured as a domain controller or demoted to member server. This module
  may require subsequent use of the [win_reboot] action if changes are made.

Options (= is mandatory):

- dns_domain_name
        when `state' is `domain_controller', the DNS name of the domain for which the targeted Windows host should be a
        DC
        [Default: (null)]
= domain_admin_password
        password for the specified `domain_admin_user'

= domain_admin_user
        username of a domain admin for the target domain (necessary to promote or demote a domain controller)

- local_admin_password
        password to be assigned to the local `Administrator' user (required when `state' is `member_server')
        [Default: (null)]
- safe_mode_password
        safe mode password for the domain controller (required when `state' is `domain_controller')
        [Default: (null)]
- state
        whether the target host should be a domain controller or a member server
        (Choices: domain_controller, member_server)[Default: (null)]
EXAMPLES:
# ensure a server is a domain controller
- hosts: winclient
  gather_facts: no
  tasks:
  - win_domain_controller:
      dns_domain_name: ansible.vagrant
      domain_admin_user: testguy@ansible.vagrant
      domain_admin_password: password123!
      safe_mode_password: password123!
      state: domain_controller
      log_path: c:\ansible_win_domain_controller.txt

# ensure a server is not a domain controller
# note that without an action wrapper, in the case where a DC is demoted,
# the task will fail with a 401 Unauthorized, because the domain credential
# becomes invalid to fetch the final output over WinRM. This requires win_async
# with credential switching (or other clever credential-switching
# mechanism to get the output and trigger the required reboot)
- hosts: winclient
  gather_facts: no
  tasks:
  - win_domain_controller:
      domain_admin_user: testguy@ansible.vagrant
      domain_admin_password: password123!
      local_admin_password: password123!
      state: member_server
      log_path: c:\ansible_win_domain_controller.txt


RETURN VALUES:
reboot_required:
    description: True if changes were made that require a reboot.
    returned: always
    type: boolean
    sample: true



MAINTAINERS: Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_DOMAIN_MEMBERSHIP    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_domain_membership.py)

  Manages domain membership or workgroup membership for a Windows host. Also supports hostname changes. This module may
  require subsequent use of the [win_reboot] action if changes are made.

Options (= is mandatory):

- dns_domain_name
        when `state' is `domain', the DNS name of the domain to which the targeted Windows host should be joined
        [Default: (null)]
- domain_admin_password
        password for the specified `domain_admin_user'
        [Default: (null)]
= domain_admin_user
        username of a domain admin for the target domain (required to join or leave the domain)

- hostname
        the desired hostname for the Windows host
        [Default: (null)]
- state
        whether the target host should be a member of a domain or workgroup
        (Choices: domain, workgroup)[Default: (null)]
- workgroup_name
        when `state' is `workgroup', the name of the workgroup that the Windows host should be in
        [Default: (null)]
EXAMPLES:

# host should be a member of domain ansible.vagrant; module will ensure the hostname is mydomainclient
# and will use the passed credentials to join domain if necessary.
# Ansible connection should use local credentials if possible.
# If a reboot is required, the second task will trigger one and wait until the host is available.
- hosts: winclient
  gather_facts: no
  tasks:
  - win_domain_membership:
      dns_domain_name: ansible.vagrant
      hostname: mydomainclient
      domain_admin_user: testguy@ansible.vagrant
      domain_admin_password: password123!
      state: domain
    register: domain_state

  - win_reboot:
    when: domain_state.reboot_required



# Host should be in workgroup mywg- module will use the passed credentials to clean-unjoin domain if possible.
# Ansible connection should use local credentials if possible.
# The domain admin credentials can be sourced from a vault-encrypted variable
- hosts: winclient
  gather_facts: no
  tasks:
  - win_domain_membership:
      workgroup_name: mywg
      domain_admin_user: '{{ win_domain_admin_user }}'
      domain_admin_password: '{{ win_domain_admin_password }}'
      state: workgroup

RETURN VALUES:
reboot_required:
    description: True if changes were made that require a reboot.
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_DOTNET_NGEN    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_dotnet_ngen.py)

  After .NET framework is installed/updated, Windows will probably want to recompile things to optimise for the host.
  This happens via scheduled task, usually at some inopportune time. This module allows you to run this task on your own
  schedule, so you incur the CPU hit at some more convenient and controlled time.
  http://blogs.msdn.com/b/dotnet/archive/2013/08/06/wondering-why-mscorsvw-exe-has-high-cpu-usage-you-can-speed-it-
  up.aspx

Notes:
  * there are in fact two scheduled tasks for ngen but they have no triggers so aren't a problem
  * there's no way to test if they've been completed (?)
  * the stdout is quite likely to be several megabytes
EXAMPLES:
  # Run ngen tasks
  win_dotnet_ngen:


MAINTAINERS: Peter Mounce

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_ENVIRONMENT    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_environment.py)

  Uses .net Environment to set or remove environment variables and can set at User, Machine or Process level. User level
  environment variables will be set, but not available until the user has logged off and on again.

Options (= is mandatory):

= level
        The level at which to set the environment variable.
        Use 'machine' to set for all users.
        Use 'user' to set for the current user that ansible is connected as.
        Use 'process' to set for the current process.  Probably not that useful.
        (Choices: machine, process, user)[Default: no default]
= name
        The name of the environment variable
        [Default: no default]
- state
        present to ensure environment variable is set, or absent to ensure it is removed
        (Choices: present, absent)[Default: present]
- value
        The value to store in the environment variable. Can be omitted for state=absent
        [Default: no default]
Notes:
  * This module is best-suited for setting the entire value of an environment variable. For safe element-based
        management of path-like environment vars, use the [win_path] module.
  * This module does not broadcast change events. This means that the minority of windows applications which can
        have their environment changed without restarting will not be notified and therefore will need restarting
        to pick up new environment settings. User level environment variables will require the user to log out and
        in again before they become available.
EXAMPLES:
  # Set an environment variable for all users
  win_environment:
    state: present
    name: TestVariable
    value: Test value
    level: machine
  # Remove an environment variable for the current users
  win_environment:
    state: absent
    name: TestVariable
    level: user


MAINTAINERS: Jon Hawkesworth (@jhawkesworth)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_FEATURE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_feature.py)

  Installs or uninstalls Windows Roles or Features on Windows Server. This module uses the Add/Remove-WindowsFeature
  Cmdlets on Windows 2008 and Install/Uninstall-WindowsFeature Cmdlets on Windows 2012, which are not available on client
  os machines.

Options (= is mandatory):

- include_management_tools
        Adds the corresponding management tools to the specified feature.
        Not supported in Windows 2008. If present when using Windows 2008 this option will be ignored.
        (Choices: True, False)[Default: (null)]
- include_sub_features
        Adds all subfeatures of the specified feature
        (Choices: True, False)[Default: (null)]
= name
        Names of roles or features to install as a single feature or a comma-separated list of features

- restart
        Restarts the computer automatically when installation is complete, if restarting is required by the roles or
        features installed.
        (Choices: True, False)[Default: (null)]
- source
        Specify a source to install the feature from.
        Not supported in Windows 2008. If present when using Windows 2008 this option will be ignored.
        (Choices:  {driveletter}:\sources\sxs,  {IP}\Share\sources\sxs)[Default: (null)]
- state
        State of the features or roles on the system
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: Install IIS (Web-Server only)
  win_feature:
    name: Web-Server
    state: present

- name: Install IIS (Web-Server and Web-Common-Http)
  win_feature:
    name: Web-Server,Web-Common-Http
    state: present

- name: Install NET-Framework-Core from file
  win_feature:
    name: NET-Framework-Core
    source: C:\Temp\iso\sources\sxs
    state: present

- name: Install IIS Web-Server with sub features and management tools
  win_feature:
    name: Web-Server
    state: present
    restart: True
    include_sub_features: True
    include_management_tools: True


MAINTAINERS: Trond Hindenes (@trondhindenes), Paul Durivage (@angstwad)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_FILE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_file.py)

  Creates (empty) files, updates file modification stamps of existing files, and can create or remove directories. Unlike
  [file], does not modify ownership, permissions or manipulate links.

Options (= is mandatory):

= path
        path to the file being managed.  Aliases: `dest', `name'

- state
        If `directory', all immediate subdirectories will be created if they do not exist. If `file', the file will NOT
        be created if it does not exist, see the [copy] or [template] module if you want that behavior.  If `absent',
        directories will be recursively deleted, and files will be removed. If `touch', an empty file will be created if
        the `path' does not exist, while an existing file or directory will receive updated file access and modification
        times (similar to the way `touch' works from the command line).
        (Choices: file, directory, touch, absent)[Default: (null)]
Notes:
  * See also [win_copy], [win_template], [copy], [template], [assemble]
EXAMPLES:
- name: Create a file
  win_file:
    path: C:\Temp\foo.conf
    state: file

- name: Touch a file (creates if not present, updates modification time if present)
  win_file:
    path: C:\Temp\foo.conf
    state: touch

- name: Remove a file, if present
  win_file:
    path: C:\Temp\foo.conf
    state: absent

- name: Create directory structure
  win_file:
    path: C:\Temp\folder\subfolder
    state: directory

- name: Remove directory structure
  win_file:
    path: C:\Temp
    state: absent


MAINTAINERS: Jon Hawkesworth (@jhawkesworth)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_FILE_VERSION    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_file_version.py)

  Get DLL or EXE file build version change state alway be false

Options (= is mandatory):

= path
        File to get version(provide absolute path)

EXAMPLES:
- name: Get acm instance version
  win_file_version:
    path: C:\Windows\System32\cmd.exe
  register: exe_file_version

- debug:
    msg: '{{ exe_file_version }}'

RETURN VALUES:
win_file_version.path:
  description: file path
  returned: always
  type: string

win_file_version.file_version:
  description: file version number.
  returned: no error
  type: string

win_file_version.product_version:
  description: the version of the product this file is distributed with.
  returned: no error
  type: string

win_file_version.file_major_part:
  description: the major part of the version number.
  returned: no error
  type: string

win_file_version.file_minor_part:
  description: the minor part of the version number of the file.
  returned: no error
  type: string

win_file_version.file_build_part:
  description: build number of the file.
  returned: no error
  type: string

win_file_version.file_private_part:
  description: file private part number.
  returned: no error
  type: string



MAINTAINERS: Sam Liu

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_FIND    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_find.py)

  Return a list of files based on specified criteria. Multiple criteria are AND'd together.

Options (= is mandatory):

- age
        Select files or folders whose age is equal to or greater than the specified time. Use a negative age to find
        files equal to or less than the specified time. You can choose seconds, minutes, hours, days or weeks by
        specifying the first letter of an of those words (e.g., "2s", "10d", 1w").
        [Default: (null)]
- age_stamp
        Choose the file property against which we compare `age'. The default attribute we compare with is the last
        modification time.
        (Choices: atime, mtime, ctime)[Default: mtime]
- checksum_algorithm
        Algorithm to determine the checksum of a file. Will throw an error if the host is unable to use specified
        algorithm.
        (Choices: md5, sha1, sha256, sha384, sha512)[Default: sha1]
- file_type
        Type of file to search for
        (Choices: file, directory)[Default: file]
- follow
        Set this to true to follow symlinks in the path. This needs to be used in conjunction with `recurse'.
        (Choices: true, false)[Default: False]
- get_checksum
        Whether to return a checksum of the file in the return info (default sha1), use `checksum_algorithm' to change
        from the default.
        (Choices: true, false)[Default: True]
- hidden
        Set this to include hidden files or folders
        (Choices: true, false)[Default: False]
= paths
        List of paths of directories to search for files or folders in. This can be supplied as a single path or a list
        of paths.

- patterns
        One or more (powershell or regex) patterns to compare filenames with. The type of pattern matching is controlled
        by `use_regex' option. The patterns retrict the list of files or folders to be returned based on the filenames.
        For a file to be matched it only has to match with one pattern in a list provided.
        [Default: (null)]
- recurse
        Will recursively descend into the directory looking for files or folders
        (Choices: true, false)[Default: False]
- size
        Select files or folders whose size is equal to or greater than the specified size. Use a negative value to find
        files equal to or less than the specified size. You can specify the size with a suffix of the byte type i.e. kilo
        = k, mega = m... Size is not evaluated for symbolic links.
        [Default: False]
- use_regex
        Will set patterns to run as a regex check if true
        (Choices: true, false)[Default: False]
EXAMPLES:
# Find files in path
- win_find:
    paths: D:\temp

# Find hidden files in path
- win_find:
    paths: D:\temp
    hidden: True

# Find files in multiple paths
- win_find:
    paths: ['C:\temp', 'D:\temp']

# Find files in directory while searching recursively
- win_find:
    paths: D:\temp
    recurse: True

# Find files in directory while following symlinks
- win_find:
    paths: D:\temp
    recurse: True
    follow: True

# Find files with .log and .out extension using powershell wildcards
- win_find:
    paths: D:\temp
    patterns: ['*.log', '*.out']

# Find files in path based on regex pattern
- win_find:
    paths: D:\temp
    patterns: 'out_\d{8}-\d{6}.log'

# Find files older than 1 day
- win_find:
    paths: D:\temp
    age: 86400

# Find files older than 1 day based on create time
- win_find:
    paths: D:\temp
    age: 86400
    age_stamp: ctime

# Find files older than 1 day with unit syntax
- win_find:
    paths: D:\temp
    age: 1d

# Find files newer than 1 hour
- win_find:
    paths: D:\temp
    age: -3600

# Find files newer than 1 hour with unit syntax
- win_find:
    paths: D:\temp
    age: -1h

# Find files larger than 1MB
- win_find:
    paths: D:\temp
    size: 1048576

# Find files larger than 1GB with unit syntax
- win_find:
    paths: D:\temp
    size: 1g

# Find files smaller than 1MB
- win_find:
    paths: D:\temp
    size: -1048576

# Find files smaller than 1GB with unit syntax
- win_find:
    paths: D:\temp
    size: -1g

# Find folders/symlinks in multiple paths
- win_find:
    paths: ['C:\temp', 'D:\temp']
    file_type: directory

# Find files and return SHA256 checksum of files found
- win_find:
    paths: C:\temp
    get_checksum: True
    checksum_algorithm: sha256

# Find files and do not return the checksum
- win_find:
    path: C:\temp
    get_checksum: False

RETURN VALUES:
changed:
    description: Whether anything was chagned
    returned: always
    type: boolean
    sample: True
examined:
    description: The number of files/folders that was checked
    returned: always
    type: int
    sample: 10
matched:
    description: The number of files/folders that match the criteria
    returns: always
    type: int
    sample: 2
files:
    description: Information on the files/folders that match the criteria returned as a list of dictionary elements for each file matched
    returned: success
    type: dictionary
    contains:
        attributes:
            description: attributes of the file at path in raw form
            returned: success, path exists
            type: string
            sample: "Archive, Hidden"
        checksum:
            description: The checksum of a file based on checksum_algorithm specified
            returned: success, path exists, path is a file, get_checksum == True
            type: string
            sample: 09cb79e8fc7453c84a07f644e441fd81623b7f98
        creationtime:
            description: the create time of the file represented in seconds since epoch
            returned: success, path exists
            type: float
            sample: 1477984205.15
        extension:
            description: the extension of the file at path
            returned: success, path exists, path is a file
            type: string
            sample: ".ps1"
        isarchive:
            description: if the path is ready for archiving or not
            returned: success, path exists
            type: boolean
            sample: True
        isdir:
            description: if the path is a directory or not
            returned: success, path exists
            type: boolean
            sample: True
        ishidden:
            description: if the path is hidden or not
            returned: success, path exists
            type: boolean
            sample: True
        islnk:
            description: if the path is a symbolic link or junction or not
            returned: success, path exists
            type: boolean
            sample: True
        isreadonly:
            description: if the path is read only or not
            returned: success, path exists
            type: boolean
            sample: True
        isshared:
            description: if the path is shared or not
            returned: success, path exists
            type: boolean
            sample: True
        lastaccesstime:
            description: the last access time of the file represented in seconds since epoch
            returned: success, path exists
            type: float
            sample: 1477984205.15
        lastwritetime:
            description: the last modification time of the file represented in seconds since epoch
            returned: success, path exists
            type: float
            sample: 1477984205.15
        lnk_source:
            description: the target of the symbolic link, will return null if not a link or the link is broken
            return: success, path exists, path is a symbolic link
            type: string
            sample: C:\temp
        owner:
            description: the owner of the file
            returned: success, path exists
            type: string
            sample: BUILTIN\Administrators
        path:
            description: the full absolute path to the file
            returned: success, path exists
            type: string
            sample: BUILTIN\Administrators
        sharename:
            description: the name of share if folder is shared
            returned: success, path exists, path is a directory and isshared == True
            type: string
            sample: file-share
        size:
            description: the size in bytes of a file or folder
            returned: success, path exists, path is not a link
            type: int
            sample: 1024


MAINTAINERS: Jordan Borean (@jborean93)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_FIREWALL_RULE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_firewall_rule.py)

  allows you to create/remove/update firewall rules

Options (= is mandatory):

= action
        what to do with the items this rule is for
        (Choices: allow, block, bypass)[Default: None]
- description
        description for the firewall rule
        [Default: None]
= direction
        is this rule for inbound or outbound traffic
        (Choices: in, out)[Default: None]
- enable
        is this firewall rule enabled or disabled
        [Default: True]
- force
        Enforces the change if a rule with different values exists
        [Default: False]
- localip
        the local ip address this rule applies to
        [Default: any]
- localport
        the local port this rule applies to
        [Default: any]
= name
        the rules name
        [Default: None]
- profile
        the profile this rule applies to, e.g. Domain,Private,Public
        [Default: any]
- program
        the program this rule applies to
        [Default: None]
- protocol
        the protocol this rule applies to
        [Default: any]
- remoteip
        the remote ip address/range this rule applies to
        [Default: any]
- remoteport
        the remote port this rule applies to
        [Default: any]
- service
        the service this rule applies to
        [Default: any]
= state
        should this rule be added or removed
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: Firewall rule to allow smtp on TCP port 25
  action: win_firewall_rule
  args:
      name: smtp
      enable: yes
      state: present
      localport: 25
      action: allow
      direction: In
      protocol: TCP



MAINTAINERS: Timothy Vandenbrande

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_GET_URL    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_get_url.py)

  Fetches a file from a URL and saves to locally

Options (= is mandatory):

= dest
        The absolute path of the location to save the file at the URL. Be sure to include a filename and extension as
        appropriate.
        [Default: None]
- force
        If `yes', will always download the file. If `no', will only download the file if it does not exist or the remote
        file has been modified more recently than the local file. This works by sending an http HEAD request to retrieve
        last modified time of the requested resource, so for this to work, the remote web server must support HEAD
        requests.
        (Choices: yes, no)[Default: True]
- password
        Basic authentication password
        [Default: None]
- proxy_password
        Proxy authentication password
        [Default: (null)]
- proxy_url
        The full URL of the proxy server to download through.
        [Default: (null)]
- proxy_username
        Proxy authentication username
        [Default: (null)]
- skip_certificate_validation
        Skip SSL certificate validation if true
        [Default: False]
= url
        The full URL of a file to download
        [Default: None]
- username
        Basic authentication username
        [Default: None]
EXAMPLES:
- name: Download earthrise.jpg to specified path
  win_get_url:
    url: http://www.example.com/earthrise.jpg
    dest: C:\Users\RandomUser\earthrise.jpg

- name: Download earthrise.jpg to specified path only if modified
  win_get_url:
    url: http://www.example.com/earthrise.jpg
    dest: C:\Users\RandomUser\earthrise.jpg
    force: no

- name: Download earthrise.jpg to specified path through a proxy server.
  win_get_url:
    url: http://www.example.com/earthrise.jpg
    dest: C:\Users\RandomUser\earthrise.jpg
    proxy_url: http://10.0.0.1:8080
    proxy_username: username
    proxy_password: password

RETURN VALUES:
url:
    description: requested url
    returned: always
    type: string
    sample: http://www.example.com/earthrise.jpg
dest:
    description: destination file/path
    returned: always
    type: string
    sample: C:\Users\RandomUser\earthrise.jpg


MAINTAINERS: Takeshi Kuramochi (tksarah), Paul Durivage (@angstwad)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_group.py)

  Add and remove local groups

Options (= is mandatory):

- description
        Description of the group
        [Default: None]
= name
        Name of the group
        [Default: None]
- state
        Create or remove the group
        (Choices: present, absent)[Default: present]
EXAMPLES:
- name: Create a new group
  win_group:
    name: deploy
    description: Deploy Group
    state: present

- name: Remove a group
  win_group:
    name: deploy
    state: absent


MAINTAINERS: Chris Hoffman (@chrishoffman)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_IIS_VIRTUALDIRECTORY    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_iis_virtualdirectory.py)

  Creates, Removes and configures a virtual directory in IIS.

Options (= is mandatory):

- application
        The application under which the virtual directory is created or exists.
        [Default: None]
= name
        The name of the virtual directory to create or remove

- physical_path
        The physical path to the folder in which the new virtual directory is created. The specified folder must already
        exist.
        [Default: None]
= site
        The site name under which the virtual directory is created or exists.

- state
        Whether to add or remove the specified virtual directory
        (Choices: absent, present)[Default: present]
EXAMPLES:
- name: Create a virtual directory if it does not exist
  win_iis_virtualdirectory:
    name: somedirectory
    site: somesite
    state: present
    physical_path: c:\virtualdirectory\some

- name: Remove a virtual directory if it exists
  win_iis_virtualdirectory:
    name: somedirectory
    site: somesite
    state: absent

- name: Create a virtual directory on an application if it does not exist
  win_iis_virtualdirectory:
    name: somedirectory
    site: somesite
    application: someapp
    state: present
    physical_path: c:\virtualdirectory\some


MAINTAINERS: Henrik Wallström

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_IIS_WEBAPPLICATION    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_iis_webapplication.py)

  Creates, removes, and configures IIS web applications.

Options (= is mandatory):

- application_pool
        The application pool in which the new site executes.
        [Default: None]
= name
        Name of the web application.
        [Default: None]
- physical_path
        The physical path on the remote host to use for the new application. The specified folder must already exist.
        [Default: None]
= site
        Name of the site on which the application is created.
        [Default: None]
- state
        State of the web application.
        (Choices: present, absent)[Default: None]
EXAMPLES:
- name: Add ACME webapplication on IIS.
  win_iis_webapplication:
    name: api
    site: acme
    state: present
    physical_path: C:\apps\acme\api


MAINTAINERS: Henrik Wallström

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_IIS_WEBAPPPOOL    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_iis_webapppool.py)

  Creates, Removes and configures an IIS Web Application Pool

Options (= is mandatory):

- attributes
        Application Pool attributes from string where attributes are separated by a pipe and attribute name/values by
        colon Ex. "foo:1|bar:2".
        The following attributes may only have the following names.
        managedPipelineMode may be either "Integrated" or  "Classic".
        startMode may be either "OnDemand" or  "AlwaysRunning".
        state may be one of "Starting", "Started", "Stopping", "Stopped", "Unknown". Use the `state' module parameter to
        modify, states shown are reflect the possible runtime values.
        [Default: None]
= name
        Name of application pool
        [Default: None]
- state
        State of the binding
        (Choices: absent, stopped, started, restarted)[Default: None]
EXAMPLES:
- name: return information about an existing application pool
  win_iis_webapppool:
    name: DefaultAppPool

- name: Create a new application pool in 'Started' state
  win_iis_webapppool:
    name: AppPool
    state: started

- name: Stop an application pool
  win_iis_webapppool:
    name: AppPool
    state: stopped

- name: Restart an application pool
  win_iis_webapppool:
    name: AppPool
    state: restart

- name: Changes application pool attributes without touching state
  win_iis_webapppool:
    name: AppPool
    attributes: 'managedRuntimeVersion:v4.0|autoStart:false'

- name: Creates an application pool and sets attributes
  win_iis_webapppool:
    name: AnotherAppPool
    state: started
    attributes: 'managedRuntimeVersion:v4.0|autoStart:false'

# Playbook example
---

- name: App Pool with .NET 4.0
  win_iis_webapppool:
    name: 'AppPool'
    state: started
    attributes: managedRuntimeVersion:v4.0
  register: webapppool


RETURN VALUES:
attributes:
  description:
    - Application Pool attributes from that were processed by this module invocation.
  returned: success
  type: dictionary
  sample:
     "enable32BitAppOnWin64": "true"
     "managedRuntimeVersion": "v4.0"
     "managedPipelineMode": "Classic"
info:
  description: Information on current state of the Application Pool
  returned: success
  type: dictionary
  sample:
  contains:
    attributes:
      description: key value pairs showing the current Application Pool attributes
      returned: success
      type: dictionary
      sample:
            "autoStart": true
            "managedRuntimeLoader": "webengine4.dll"
            "managedPipelineMode": "Classic"
            "name": "DefaultAppPool"
            "CLRConfigFile": ""
            "passAnonymousToken": true
            "applicationPoolSid": "S-1-5-82-1352790163-598702362-1775843902-1923651883-1762956711"
            "queueLength": 1000
            "managedRuntimeVersion": "v4.0"
            "state": "Started"
            "enableConfigurationOverride": true
            "startMode": "OnDemand"
            "enable32BitAppOnWin64": true
    name:
      description:
        - Name of Application Pool that was processed by this module invocation.
      returned: success
      type: string
      sample: "DefaultAppPool"
    state:
      description:
        - Current runtime state of the pool as the module completed.
      returned: success
      type: string
      sample: "Started"


MAINTAINERS: Henrik Wallström

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_IIS_WEBBINDING    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_iis_webbinding.py)

  Creates, Removes and configures a binding to an existing IIS Web site

Options (= is mandatory):

- certificate_hash
        Certificate hash for the SSL binding. The certificate hash is the unique identifier for the certificate.
        [Default: None]
- certificate_store_name
        Name of the certificate store where the certificate for the binding is located.
        [Default: My]
- host_header
        The host header to bind to / use for the new site.
        [Default: None]
- ip
        The IP address to bind to / use for the new site.
        [Default: None]
= name
        Names of web site
        [Default: None]
- port
        The port to bind to / use for the new site.
        [Default: None]
- protocol
        The protocol to be used for the Web binding (usually HTTP, HTTPS, or FTP).
        [Default: None]
- state
        State of the binding
        (Choices: present, absent)[Default: None]
EXAMPLES:
- name: Return binding information for an existing host
  win_iis_webbinding:
    name: Default Web Site

- name: Return the HTTPS binding information for an existing host
  win_iis_webbinding:
    name: Default Web Site
    protocol: https

- name: Add a HTTP binding on port 9090
  win_iis_webbinding:
    name: Default Web Site
    port: 9090
    state: present

- name: Remove the HTTP binding on port 9090
  win_iis_webbinding:
    name: Default Web Site
    port: 9090
    state: absent

- name: Add a HTTPS binding
  win_iis_webbinding:
    name: Default Web Site
    protocol: https
    state: present

- name: Add a HTTPS binding and select certificate to use
  win_iis_webbinding:
    name: Default Web Site
    protocol: https
    certificate_hash: B0D0FA8408FC67B230338FCA584D03792DA73F4C
    state: present

- name: Website https biding to specific port
  win_iis_webbinding:
    name: Default Web Site
    protocol: https
    port: 443
    certificate_hash: D1A3AF8988FD32D1A3AF8988FD323792DA73F4C
    state: present


MAINTAINERS: Henrik Wallström

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_IIS_WEBSITE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_iis_website.py)

  Creates, Removes and configures a IIS Web site

Options (= is mandatory):

- application_pool
        The application pool in which the new site executes.
        [Default: None]
- hostname
        The host header to bind to / use for the new site.
        [Default: None]
- ip
        The IP address to bind to / use for the new site.
        [Default: None]
= name
        Names of web site
        [Default: None]
- parameters
        Custom site Parameters from string where properties are separated by a pipe and property name/values by colon Ex.
        "foo:1|bar:2"
        [Default: None]
- physical_path
        The physical path on the remote host to use for the new site. The specified folder must already exist.
        [Default: None]
- port
        The port to bind to / use for the new site.
        [Default: None]
- site_id
        Explicitly set the IIS numeric ID for a site. Note that this value cannot be changed after the website has been
        created.
        [Default: None]
- ssl
        Enables HTTPS binding on the site..
        [Default: None]
- state
        State of the web site
        (Choices: started, restarted, stopped, absent)[Default: None]
EXAMPLES:

# Start a website

- name: Acme IIS site
  win_iis_website:
    name: "Acme"
    state: started
    port: 80
    ip: 127.0.0.1
    hostname: acme.local
    application_pool: "acme"
    physical_path: c:\sites\acme
    parameters: logfile.directory:c:\sites\logs
  register: website

# Some commandline examples:

# This return information about an existing host
# $ ansible -i vagrant-inventory -m win_iis_website -a "name='Default Web Site'" window
# host | success >> {
#     "changed": false,
#     "site": {
#         "ApplicationPool": "DefaultAppPool",
#         "Bindings": [
#             "*:80:"
#         ],
#         "ID": 1,
#         "Name": "Default Web Site",
#         "PhysicalPath": "%SystemDrive%\\inetpub\\wwwroot",
#         "State": "Stopped"
#     }
# }

# This stops an existing site.
# $ ansible -i hosts -m win_iis_website -a "name='Default Web Site' state=stopped" host

# This creates a new site.
# $ ansible -i hosts -m win_iis_website -a "name=acme physical_path=c:\\sites\\acme" host

# Change logfile.
# $ ansible -i hosts -m win_iis_website -a "name=acme physical_path=c:\\sites\\acme" host


MAINTAINERS: Henrik Wallström

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_LINEINFILE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_lineinfile.py)

  This module will search a file for a line, and ensure that it is present or absent. This is primarily useful when you
  want to change a single line in a file only.

Options (= is mandatory):

- backrefs
        Used with `state=present'. If set, line can contain backreferences (both positional and named) that will get
        populated if the `regexp' matches. This flag changes the operation of the module slightly; `insertbefore' and
        `insertafter' will be ignored, and if the `regexp' doesn't match anywhere in the file, the file will be left
        unchanged.
        If the `regexp' does match, the last matching line will be replaced by the expanded line parameter.
        (Choices: yes, no)[Default: no]
- backup
        Create a backup file including the timestamp information so you can get the original file back if you somehow
        clobbered it incorrectly.
        (Choices: yes, no)[Default: no]
- create
        Used with `state=present'. If specified, the file will be created if it does not already exist. By default it
        will fail if the file is missing.
        (Choices: yes, no)[Default: no]
- encoding
        Specifies the encoding of the source text file to operate on (and thus what the output encoding will be). The
        default of `auto' will cause the module to auto-detect the encoding of the source file and ensure that the
        modified file is written with the same encoding.
        An explicit encoding can be passed as a string that is a valid value to pass to the .NET framework
        System.Text.Encoding.GetEncoding() method - see https://msdn.microsoft.com/en-
        us/library/system.text.encoding%28v=vs.110%29.aspx.
        This is mostly useful with `create=yes' if you want to create a new file with a specific encoding. If
        `create=yes' is specified without a specific encoding, the default encoding (UTF-8, no BOM) will be used.
        [Default: auto]
- insertafter
        Used with `state=present'. If specified, the line will be inserted after the last match of specified regular
        expression. A special value is available; `EOF' for inserting the line at the end of the file.
        If specified regular expression has no matches, EOF will be used instead. May not be used with `backrefs'.
        (Choices: EOF, *regex*)[Default: EOF]
- insertbefore
        Used with `state=present'. If specified, the line will be inserted before the last match of specified regular
        expression. A value is available; `BOF' for inserting the line at the beginning of the file.
        If specified regular expression has no matches, the line will be inserted at the end of the file. May not be used
        with `backrefs'.
        (Choices: BOF, *regex*)[Default: (null)]
- line
        Required for `state=present'. The line to insert/replace into the file. If `backrefs' is set, may contain
        backreferences that will get expanded with the `regexp' capture groups if the regexp matches.
        [Default: (null)]
- newline
        Specifies the line separator style to use for the modified file. This defaults to the windows line separator (`
        '). Note that the indicated line separator will be used for file output regardless of the original line separator
        that appears in the input file.
        (Choices: windows, unix)[Default: windows]
= path
        The path of the file to modify.
        Note that the Windows path delimiter `\' must be escaped as `\\' when the line is double quoted.
        Before 2.3 this option was only usable as `dest', `destfile' and `name'.

- regexp
        The regular expression to look for in every line of the file. For `state=present', the pattern to replace if
        found; only the last line found will be replaced. For `state=absent', the pattern of the line to remove. Uses
        .NET compatible regular expressions; see https://msdn.microsoft.com/en-us/library/hs600312%28v=vs.110%29.aspx.
        [Default: (null)]
- state
        Whether the line should be there or not.
        (Choices: present, absent)[Default: present]
- validate
        Validation to run before copying into place. Use %s in the command to indicate the current file to validate.
        The command is passed securely so shell features like expansion and pipes won't work.
        [Default: None]
Notes:
  * As of Ansible 2.3, the `dest' option has been changed to `path' as default, but `dest' still works as well.
EXAMPLES:
# Before 2.3, option 'dest', 'destfile' or 'name' was used instead of 'path'
- win_lineinfile:
    path: C:\temp\example.conf
    regexp: '^name='
    line: 'name=JohnDoe'

- win_lineinfile:
    path: C:\temp\example.conf
    regexp: '^name='
    state: absent

- win_lineinfile:
    path: C:\temp\example.conf
    regexp: '^127\.0\.0\.1'
    line: '127.0.0.1 localhost'

- win_lineinfile:
    path: C:\temp\httpd.conf
    regexp: '^Listen '
    insertafter: '^#Listen '
    line: Listen 8080

- win_lineinfile:
    path: C:\temp\services
    regexp: '^# port for http'
    insertbefore: '^www.*80/tcp'
    line: '# port for http by default'

# Create file if it doesn't exist with a specific encoding
- win_lineinfile:
    path: C:\temp\utf16.txt
    create: yes
    encoding: utf-16
    line: This is a utf-16 encoded file

# Add a line to a file and ensure the resulting file uses unix line separators
- win_lineinfile:
    path: C:\temp\testfile.txt
    line: Line added to file
    newline: unix

# Update a line using backrefs
- win_lineinfile:
    path: C:\temp\example.conf
    backrefs: yes
    regexp: '(^name=)'
    line: '$1JohnDoe'


MAINTAINERS: Brian Lloyd <brian.d.lloyd@gmail.com>

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_MSG    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_msg.py)

  Wraps the msg.exe command in order to send messages to Windows hosts.

Options (= is mandatory):

- display_seconds
        How long to wait for receiver to acknowledge message, in seconds.
        [Default: 10]
- msg
        The text of the message to be displayed.
        [Default: Hello world!]
- to
        Who to send the message to. Can be a username, sessionname or sessionid.
        [Default: *]
- wait
        Whether to wait for users to respond.  Module will only wait for the number of seconds specified in
        display_seconds or 10 seconds if not specified. However, if `wait' is true, the message is sent to each logged on
        user in turn, waiting for the user to either press 'ok' or for the timeout to elapse before moving on to the next
        user.
        [Default: False]
Notes:
  * This module must run on a windows host, so ensure your play targets windows hosts, or delegates to a windows
        host.
  * Messages are only sent to the local host where the module is run.
  * The module does not support sending to users listed in a file.
  * Setting wait to true can result in long run times on systems with many logged in users.
EXAMPLES:
  # Warn logged in users of impending upgrade
  win_msg:
    display_seconds: 60
    msg: "Automated upgrade about to start.  Please save your work and log off before {{ deployment_start_time  }}"

RETURN VALUES:
msg:
    description: Test of the message that was sent.
    returned: changed
    type: string
    sample: "Automated upgrade about to start.  Please save your work and log off before 22 July 2016 18:00:00"
display_seconds:
    description: Value of display_seconds module parameter.
    returned: success
    type: string
    sample: 10
runtime_seconds:
    description: How long the module took to run on the remote windows host.
    returned: success
    type: string
    sample: 22 July 2016 17:45:51
sent_localtime:
    description: local time from windows host when the message was sent.
    returned: success
    type: string
    sample: 22 July 2016 17:45:51
wait:
    description: Value of wait module parameter.
    returned: success
    type: boolean
    sample: false


MAINTAINERS: Jon Hawkesworth (@jhawkesworth)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_MSI    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_msi.py)

  Installs or uninstalls a Windows MSI file that is already located on the target server

Options (= is mandatory):

- creates
        Path to a file created by installing the MSI to prevent from attempting to reinstall the package on every run
        [Default: (null)]
- extra_args
        Additional arguments to pass to the msiexec.exe command
        [Default: (null)]
= path
        File system path to the MSI file to install

- state
        Whether the MSI file should be installed or uninstalled
        (Choices: present, absent)[Default: present]
- wait
        Specify whether to wait for install or uninstall to complete before continuing.
        (Choices: True, False)[Default: False]
Notes:
  * Check-mode support is currently not supported.
  * Please look into [win_package] instead, this package will be deprecated in Ansible v2.3.
EXAMPLES:
- name: Install an MSI file
  win_msi:
    path: C:\7z920-x64.msi

- name: Install an MSI, and wait for it to complete before continuing
  win_msi:
    path: C:\7z920-x64.msi
    wait: true

- name: Uninstall an MSI file
  win_msi:
    path: C:\7z920-x64.msi
    state: absent


MAINTAINERS: Matt Martz (@sivel)

METADATA:
	Status: ['deprecated']
	Supported_by: community
> WIN_NSSM    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_nssm.py)

  nssm is a service helper which doesn't suck. See https://nssm.cc/ for more information.

Options (= is mandatory):

- app_parameters
        Parameters to be passed to the application when it starts.
        Use either this or `app_parameters_free_form', not both
        [Default: (null)]
- app_parameters_free_form
        Single string of parameters to be passed to the service.
        Use either this or `app_parameters', not both
        [Default: (null)]
- application
        The application binary to run as a service
        Specify this whenever the service may need to be installed (state: present, started, stopped, restarted)
        Note that the application name must look like the following, if the directory includes spaces:
        nssm install service "c:\\Program Files\\app.exe\\" "C:\\Path with spaces\\"
        See commit 0b386fc1984ab74ee59b7bed14b7e8f57212c22b in the nssm.git project for more info:
        https://git.nssm.cc/?p=nssm.git;a=commit;h=0b386fc1984ab74ee59b7bed14b7e8f57212c22b
        [Default: (null)]
- dependencies
        Service dependencies that has to be started to trigger startup, separated by comma.
        [Default: (null)]
= name
        Name of the service to operate on

- password
        Password to be used for service startup
        [Default: (null)]
- start_mode
        If `auto' is selected, the service will start at bootup. `manual' means that the service will start only when
        another service needs it. `disabled' means that the service will stay off, regardless if it is needed or not.
        (Choices: auto, manual, disabled)[Default: auto]
- state
        State of the service on the system
        Note that NSSM actions like "pause", "continue", "rotate" do not fit the declarative style of ansible, so these
        should be implemented via the ansible command module
        (Choices: present, started, stopped, restarted, absent)[Default: started]
- stderr_file
        Path to receive error output
        [Default: (null)]
- stdout_file
        Path to receive output
        [Default: (null)]
- user
        User to be used for service startup
        [Default: (null)]
Requirements:  nssm >= 2.24.0 # (install via win_chocolatey) win_chocolatey: name=nssm

EXAMPLES:
# Install and start the foo service
- win_nssm:
    name: foo
    application: C:\windows\foo.exe

# Install and start the foo service with a key-value pair argument
# This will yield the following command: C:\windows\foo.exe bar "true"
- win_nssm:
    name: foo
    application: C:\windows\foo.exe
    app_parameters:
      bar: true

# Install and start the foo service with a key-value pair argument, where the argument needs to start with a dash
# This will yield the following command: C:\windows\\foo.exe -bar "true"
- win_nssm:
    name: foo
    application: C:\windows\foo.exe
    app_parameters:
      "-bar": true

# Install and start the foo service with a single parameter
# This will yield the following command: C:\windows\\foo.exe bar
- win_nssm:
    name: foo
    application: C:\windows\foo.exe
    app_parameters:
      _: bar

# Install and start the foo service with a mix of single params, and key value pairs
# This will yield the following command: C:\windows\\foo.exe bar -file output.bat
- win_nssm:
    name: foo
    application: C:\windows\foo.exe
    app_parameters:
      _: bar
      "-file": "output.bat"

# Use the single line parameters option to specify an arbitrary string of parameters
# for the service executable
- name: Make sure the Consul service runs
  win_nssm:
    name: consul
    application: C:\consul\consul.exe
    app_parameters_free_form: agent -config-dir=C:\consul\config
    stdout_file: C:\consul\log.txt
    stderr_file: C:\consul\error.txt

# Install and start the foo service, redirecting stdout and stderr to the same file
- win_nssm:
    name: foo
    application: C:\windows\foo.exe
    stdout_file: C:\windows\foo.log
    stderr_file: C:\windows\foo.log

# Install and start the foo service, but wait for dependencies tcpip and adf
- win_nssm:
    name: foo
    application: C:\windows\foo.exe
    dependencies: 'adf,tcpip'

# Install and start the foo service with dedicated user
- win_nssm:
    name: foo
    application: C:\windows\foo.exe
    user: foouser
    password: secret

# Install the foo service but do not start it automatically
- win_nssm:
    name: foo
    application: C:\windows\foo.exe
    state: present
    start_mode: manual

# Remove the foo service
- win_nssm:
    name: foo
    state: absent


MAINTAINERS: George Frank (@georgefrank), Adam Keech (@smadam813), Hans-Joachim Kliemeck (@h0nIg)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_OWNER    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_owner.py)

  Set owner of files or directories

Options (= is mandatory):

= path
        Path to be used for changing owner

- recurse
        Indicates if the owner should be changed recursively
        (Choices: False, True)[Default: False]
= user
        Name to be used for changing owner

EXAMPLES:
- name: Change owner of Path
  win_owner:
    path: C:\apache
    user: apache
    recurse: True

- name: Set the owner of root directory
  win_owner:
    path: C:\apache
    user: SYSTEM
    recurse: False

RETURN VALUES:



MAINTAINERS: Hans-Joachim Kliemeck (@h0nIg)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_PACKAGE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_package.py)

  Installs or uninstalls a package. Optionally uses a product_id to check if the package needs installing. You can find
  product ids for installed programs in the windows registry either in
  `HKLM:Software\Microsoft\Windows\CurrentVersion\Uninstall' or for 32 bit programs
  `HKLM:Software\Wow6432Node\Microsoft\Windows\CurrentVersion\Uninstall'

Options (= is mandatory):

- arguments
        Any arguments the installer needs
        [Default: None]
- expected_return_code
        One or more return codes from the package installation that indicates success.
        If not provided, defaults to 0
        [Default: 0]
- name
        Name of the package, if name isn't specified the path will be used for log messages
        [Default: None]
= path
        Location of the package to be installed (either on file system, network share or url)

= product_id
        Product id of the installed package (used for checking if already installed)
        You can find product ids for installed programs in the windows registry either in
        `HKLM:Software\Microsoft\Windows\CurrentVersion\Uninstall' or for 32 bit programs
        `HKLM:Software\Wow6432Node\Microsoft\Windows\CurrentVersion\Uninstall''

- state
        Install or Uninstall
        (Choices: present, absent)[Default: present]
- user_name
        Username of an account with access to the package if it's located on a file share. Only needed if the winrm user
        doesn't have access to the package. Also specify user_password for this to function properly.
        [Default: None]
- user_password
        Password of an account with access to the package if it's located on a file share. Only needed if the winrm user
        doesn't have access to the package. Also specify user_name for this to function properly.
        [Default: None]
EXAMPLES:
- name: Install the Visual C thingy
  win_package:
    name: Microsoft Visual C thingy
    path: http://download.microsoft.com/download/1/6/B/16B06F60-3B20-4FF2-B699-5E9B7962F9AE/VSU_4/vcredist_x64.exe
    product_id: '{CF2BEA3C-26EA-32F8-AA9B-331F7E34BA97}'
    arguments: /install /passive /norestart

- name: Install Remote Desktop Connection Manager from msi
  win_package:
    path: https://download.microsoft.com/download/A/F/0/AF0071F3-B198-4A35-AA90-C68D103BDCCF/rdcman.msi
    product_id: '{0240359E-6A4C-4884-9E94-B397A02D893C}'

- name: Uninstall Remote Desktop Connection Manager installed from msi
  win_package:
    path: https://download.microsoft.com/download/A/F/0/AF0071F3-B198-4A35-AA90-C68D103BDCCF/rdcman.msi
    product_id: '{0240359E-6A4C-4884-9E94-B397A02D893C}'
    state: absent

# Specify the expected non-zero return code when successful
# In this case 3010 indicates 'reboot required'
- name: 'Microsoft .NET Framework 4.5.1'
  win_package:
    path: https://download.microsoft.com/download/1/6/7/167F0D79-9317-48AE-AEDB-17120579F8E2/NDP451-KB2858728-x86-x64-AllOS-ENU.exe
    productid: '{7DEBE4EB-6B40-3766-BB35-5CBBC385DA37}'
    arguments: '/q /norestart'
    ensure: present
    expected_return_code: 3010

# Specify multiple non-zero return codes when successful
# In this case we can say that both 0 (SUCCESSFUL) and 3010 (REBOOT REQUIRED) codes are acceptable
- name: 'Microsoft .NET Framework 4.5.1'
  win_package:
    path: https://download.microsoft.com/download/1/6/7/167F0D79-9317-48AE-AEDB-17120579F8E2/NDP451-KB2858728-x86-x64-AllOS-ENU.exe
    productid: '{7DEBE4EB-6B40-3766-BB35-5CBBC385DA37}'
    arguments: '/q /norestart'
    ensure: present
    expected_return_code: [0,3010]


MAINTAINERS: Trond Hindenes

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_PATH    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_path.py)

  Allows element-based ordering, addition, and removal of Windows path environment variables.

Options (= is mandatory):

= elements
        A single path element, or a list of path elements (ie, directories) to add or remove.
        When multiple elements are included in the list (and `state' is `present'), the elements are guaranteed to appear
        in the same relative order in the resultant path value.
        Variable expansions (eg, `%VARNAME%') are allowed, and are stored unexpanded in the target path element.
        Any existing path elements not mentioned in `elements' are always preserved in their current order.
        New path elements are appended to the path, and existing path elements may be moved closer to the end to satisfy
        the requested ordering.
        Paths are compared in a case-insensitive fashion, and trailing backslashes are ignored for comparison purposes.
        However, note that trailing backslashes in YAML require quotes.

- name
        Target path environment variable name
        [Default: PATH]
- scope
        The level at which the environment variable specified by `name' should be managed (either for the current user or
        global machine scope).
        (Choices: machine, user)[Default: machine]
- state
        Whether the path elements specified in `elements' should be present or absent.
        (Choices: present, absent)[Default: (null)]
Notes:
  * This module is for modifying indidvidual elements of path-like environment variables. For general-purpose
        management of other environment vars, use the [win_environment] module.
  * This module does not broadcast change events. This means that the minority of windows applications which can
        have their environment changed without restarting will not be notified and therefore will need restarting
        to pick up new environment settings. User level environment variables will require an interactive user to
        log out and in again before they become available.
EXAMPLES:
- name: Ensure that system32 and Powershell are present on the global system path, and in the specified order
  win_path:
    elements:
    - '%SystemRoot%\system32'
    - '%SystemRoot%\system32\WindowsPowerShell\v1.0'

- name: Ensure that C:\Program Files\MyJavaThing is not on the current user's CLASSPATH
  win_path:
    name: CLASSPATH
    elements: C:\Program Files\MyJavaThing
    scope: user
    state: absent


MAINTAINERS: Matt Davis (@nitzmahone)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_PING    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_ping.py)

  Checks management connectivity of a windows host

Options (= is mandatory):

- data
        Alternate data to return instead of 'pong'
        [Default: pong]
EXAMPLES:
# Test connectivity to a windows host
# ansible winserver -m win_ping

# Example from an Ansible Playbook
- win_ping:

# Induce a crash to see what happens
- win_ping:
    data: crash


MAINTAINERS: Chris Church (@cchurch)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_PSEXEC    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_psexec.py)

  Run commands (remotely) through the PsExec service Run commands as another (domain) user (with elevated privileges)

Options (= is mandatory):

- chdir
        Run the command from this (remote) directory.
        [Default: (null)]
= command
        The command line to run through PsExec (limited to 260 characters).

- elevated
        Run the command with elevated privileges.
        [Default: False]
- executable
        The location of the PsExec utility (in case it is not located in your PATH).
        [Default: psexec.exe]
- hostnames
        The hostnames to run the command.
        If not provided, the command is run locally.
        [Default: (null)]
- interactive
        Run the program so that it interacts with the desktop on the remote system.
        [Default: False]
- limited
        Run the command as limited user (strips the Administrators group and allows only privileges assigned to the Users
        group).
        [Default: False]
- noprofile
        Run the command without loading the account's profile.
        [Default: False]
- password
        The password for the (remote) user to run the command as.
        This is mandatory in order authenticate yourself.
        [Default: (null)]
- priority
        Used to run the command at a different priority.
        (Choices: background, low, belownormal, abovenormal, high, realtime)[Default: (null)]
- system
        Run the remote command in the System account.
        [Default: False]
- timeout
        The connection timeout in seconds
        [Default: (null)]
- username
        The (remote) user to run the command as.
        If not provided, the current user is used.
        [Default: (null)]
- wait
        Wait for the application to terminate.
        Only use for non-interactive applications.
        [Default: True]
Requirements:  psexec

EXAMPLES:
# Test the PsExec connection to the local system (target node) with your user
- win_psexec:
    command: whoami.exe

# Run regedit.exe locally (on target node) as SYSTEM and interactively
- win_psexec:
    command: regedit.exe
    interactive: yes
    system: yes

# Run the setup.exe installer on multiple servers using the Domain Administrator
- win_psexec:
    command: E:\setup.exe /i /IACCEPTEULA
    hostnames:
    - remote_server1
    - remote_server2
    username: DOMAIN\Administrator
    password: some_password
    priority: high

# Run PsExec from custom location C:\Program Files\sysinternals\
- win_psexec:
    command: netsh advfirewall set allprofiles state off
    executable: C:\Program Files\sysinternals\psexec.exe
    hostnames: [ remote_server ]
    password: some_password
    priority: low

RETURN VALUES:
cmd:
    description: The complete command line used by the module, including PsExec call and additional options.
    returned: always
    type: string
    sample: psexec.exe \\remote_server -u DOMAIN\Administrator -p some_password E:\setup.exe
rc:
    description: The return code for the command
    returned: always
    type: int
    sample: 0
stdout:
    description: The standard output from the command
    returned: always
    type: string
    sample: Success.
stderr:
    description: The error output from the command
    returned: always
    type: string
    sample: Error 15 running E:\setup.exe
msg:
    description: Possible error message on failure
    returned: failed
    type: string
    sample: The 'password' parameter is a required parameter.
changed:
    description: Whether or not any changes were made.
    returned: always
    type: bool
    sample: True


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_REBOOT    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_reboot.py)

  Reboot a Windows machine, wait for it to go down, come back up, and respond to commands.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

- connect_timeout_sec
        Maximum seconds to wait for a single successful TCP connection to the WinRM endpoint before trying again
        [Default: 5]
- msg
        Message to display to users
        [Default: Reboot initiated by Ansible]
- pre_reboot_delay_sec
        Seconds for shutdown to wait before requesting reboot
        [Default: 2]
- reboot_timeout_sec
        Maximum seconds to wait for machine to re-appear on the network and respond to a test command
        This timeout is evaluated separately for both network appearance and test command success (so maximum clock time
        is actually twice this value)
        [Default: 600]
- shutdown_timeout_sec
        Maximum seconds to wait for shutdown to occur
        Increase this timeout for very slow hardware, large update applications, etc
        [Default: 600]
- test_command
        Command to expect success for to determine the machine is ready for management
        [Default: whoami]
Notes:
  * If a shutdown was already scheduled on the system, `win_reboot' will abort the scheduled shutdown and enforce
        its own shutdown.
EXAMPLES:
# Unconditionally reboot the machine with all defaults
- win_reboot:

# Apply updates and reboot if necessary
- win_updates:
  register: update_result
- win_reboot:
  when: update_result.reboot_required

# Reboot a slow machine that might have lots of updates to apply
- win_reboot:
    shutdown_timeout_sec: 3600
    reboot_timeout_sec: 3600

RETURN VALUES:
rebooted:
    description: true if the machine was rebooted
    returned: always
    type: boolean
    sample: true


MAINTAINERS: Matt Davis (@nitzmahone)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_REG_STAT    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_reg_stat.py)

  Like [win_file], [win_reg_stat] will return whether the key/property exists. It also returns the sub keys and
  properties of the key specified. If specifying a property name through `property', it will return the information
  specific for that property.

Options (= is mandatory):

- name
        The registry property name to get information for, the return json will not include the sub_keys and properties
        entries for the `key' specified.
        [Default: (null)]
= path
        The full registry key path including the hive to search for.

EXAMPLES:
# Obtain information about a registry key using short form
- win_reg_stat:
    path: HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion
  register: current_version

# Obtain information about a registry key property
- win_reg_stat:
    path: HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion
    name: CommonFilesDir
  register: common_files_dir

RETURN VALUES:
changed:
  description: Whether anything was changed.
  returned: always
  type: boolean
  sample: True
exists:
  description: States whether the registry key/property exists.
  returned: success and path/property exists
  type: boolean
  sample: True
properties:
  description: A list of all the properties and their values in the key.
  returned: success, path exists and property not specified
  type: list
  sample: [
    "binary_property" : {
      "raw_value": ["0x01", "0x16"],
      "type": "REG_BINARY",
      "value": [1, 22]
    },
    "multi_string_property" : {
      "raw_value": ["a", "b"],
      "type": "REG_MULTI_SZ",
      "value": ["a", "b"]
    }
    ]
sub_keys:
  description: A list of all the sub keys of the key specified.
  returned: success, path exists and property not specified
  type: list
  sample: [
    "AppHost",
    "Casting",
    "DateTime"
  ]
raw_value:
  description: Returns the raw value of the registry property, REG_EXPAND_SZ has no string expansion, REG_BINARY or REG_NONE is in hex 0x format.
    REG_NONE, this value is a hex string in the 0x format.
  returned: success, path/property exists and property specified
  type: string
  sample: '%ProgramDir%\\Common Files'
type:
  description: The property type.
  returned: success, path/property exists and property specified
  type: string
  sample: "REG_EXPAND_SZ"
value:
  description: The value of the property.
  returned: success, path/property exists and property specified
  type: string
  sample: 'C:\\Program Files\\Common Files'


MAINTAINERS: Jordan Borean (@jborean93)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_REGEDIT    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_regedit.py)

  Add, modify or remove registry keys and values. More information about the windows registry from Wikipedia
  (https://en.wikipedia.org/wiki/Windows_Registry).

Options (= is mandatory):

- data
        Value of the registry entry `name' in `path'.
        Binary data should be expressed a yaml byte array or as comma separated hex values.  An easy way to generate this
        is to run `regedit.exe' and use the `Export' option to save the registry values to a file.  In the exported file
        binary values will look like `hex:be,ef,be,ef'.  The `hex:' prefix is optional.
        [Default: (null)]
- name
        Name of registry entry in `path'.
        This is an entry in the above `key' parameter.
        If not provided, or empty we use the default name '(default)'
        [Default: (null)]
= path
        Name of registry path.
        Should be in one of the following registry hives: HKCC, HKCR, HKCU, HKLM, HKU.

- state
        State of registry entry.
        (Choices: present, absent)[Default: present]
- type
        Registry value data type.
        (Choices: binary, dword, expandstring, multistring, string, qword)[Default: string]
Notes:
  * Check-mode `-C/--check' and diff output (-D/--diff) are supported, so that you can test every change against
        the active configuration before applying changes.
  * Beware that some registry hives (HKEY_USERS in particular) do not allow to create new registry paths.
EXAMPLES:
- name: Create registry path MyCompany
  win_regedit:
    path: HKCU:\Software\MyCompany

- name: Add or update registry path MyCompany, with entry 'hello', and containing 'world'
  win_regedit:
    path: HKCU:\Software\MyCompany
    name: hello
    data: world

- name: Add or update registry path MyCompany, with entry 'hello', and containing 1337
  win_regedit:
    path: HKCU:\Software\MyCompany
    name: hello
    data: 1337
    type: dword

- name: Add or update registry path MyCompany, with entry 'hello', and containing binary data in hex-string format
  win_regedit:
    path: HKCU:\Software\MyCompany
    name: hello
    data: hex:be,ef,be,ef,be,ef,be,ef,be,ef
    type: binary

- name: Add or update registry path MyCompany, with entry 'hello', and containing binary data in yaml format
  win_regedit:
    path: HKCU:\Software\MyCompany
    name: hello
    data: [0xbe,0xef,0xbe,0xef,0xbe,0xef,0xbe,0xef,0xbe,0xef]
    type: binary

- name: Disable keyboard layout hotkey for all users (changes existing)
  win_regedit:
    path: HKU:\.DEFAULT\Keyboard Layout\Toggle
    name: Layout Hotkey
    data: 3
    type: dword

- name: Disable language hotkey for current users (adds new)
  win_regedit:
    path: HKCU:\Keyboard Layout\Toggle
    name: Language Hotkey
    data: 3
    type: dword

- name: Remove registry path MyCompany (including all entries it contains)
  win_regedit:
    path: HKCU:\Software\MyCompany
    state: absent

- name: Remove entry 'hello' from registry path MyCompany
  win_regedit:
    path: HKCU:\Software\MyCompany
    name: hello
    state: absent

RETURN VALUES:
data_changed:
    description: whether this invocation changed the data in the registry value
    returned: success
    type: boolean
    sample: False
data_type_changed:
    description: whether this invocation changed the datatype of the registry value
    returned: success
    type: boolean
    sample: True


MAINTAINERS: Adam Keech (@smadam813), Josh Ludwig (@joshludwig)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_REGION    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_region.py)

  Set the location settings of a Windows Server. Set the format settings of a Windows Server. Set the unicode language
  settings of a Windows Server. Copy across these settings to the default profile.

Options (= is mandatory):

- copy_settings
        This will copy the current format and location values to new user profiles and the welcome screen. This will only
        run if `location', `format' or `unicode_language' has resulted in a change. If this process runs then it will
        always result in a change.
        (Choices: true, false)[Default: False]
- format
        The language format to set for the current user, see https://msdn.microsoft.com/en-
        us/library/system.globalization.cultureinfo.aspx for a list of culture names to use. This needs to be set if
        `location' or `unicode_language' is not set.
        [Default: (null)]
- location
        The location to set for the current user, see https://msdn.microsoft.com/en-us/library/dd374073.aspx for a list
        of GeoIDs you can use and what location it relates to. This needs to be set if `format' or `unicode_language' is
        not set.
        [Default: (null)]
- unicode_language
        The unicode language format to set for all users, see https://msdn.microsoft.com/en-
        us/library/system.globalization.cultureinfo.aspx for a list of culture names to use. This needs to be set if
        `location' or `format' is not set. After setting this value a reboot is required for it to take effect.
        [Default: (null)]
EXAMPLES:
# Set the region format to English United States
- win_region:
    format: en-US

# Set the region format to English Australia and copy settings to new profiles
- win_region:
    format: en-AU
    copy_settings: True

# Set the unicode language to English Great Britain
- win_region:
    unicode_language: en-GB
  register: result

- action: win_reboot
  when: result.restart_required

# Set the location to United States
- win_region:
    location: 244

# Set format, location and unicode to English Australia and copy settings
- win_region:
    location: 12
    format: en-AU
    unicode_language: en-AU
  register: result

- action: win_reboot
  when: result.restart_required

RETURN VALUES:
changed:
    description: Whether anything was changed
    returned: always
    type: boolean
    sample: True
restart_required:
    description: Whether a reboot is required for the change to take effect
    returned: success
    type: boolean
    sample: True


MAINTAINERS: Jordan Borean (@jborean93)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_REGMERGE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_regmerge.py)

  Wraps the reg.exe command to import the contents of a registry file. Suitable for use with registry files created using
  [win_template]. Windows registry files have a specific format and must be constructed correctly with carriage return
  and line feed line endings otherwise they will not be merged. Exported registry files often start with a Byte Order
  Mark which must be removed if the file is to templated using [win_template]. Registry file format is described at
  https://support.microsoft.com/en-us/kb/310516 See also [win_template], [win_regedit]

Options (= is mandatory):

- compare_key
        The parent key to use when comparing the contents of the registry to the contents of the file.  Needs to be in
        HKLM or HKCU part of registry.  Use a PS-Drive style path for example HKLM:\SOFTWARE not
        HKEY_LOCAL_MACHINE\SOFTWARE If not supplied, or the registry key is not found, no comparison will be made, and
        the module will report changed.
        [Default: no default]
= path
        The full path including file name to the registry file on the remote machine to be merged
        [Default: no default]
Notes:
  * Organise your registry files so that they contain a single root registry key if you want to use the compare_to
        functionality. This module does not force registry settings to be in the state described in the file.  If
        registry settings have been modified externally the module will merge the contents of the file but continue
        to report differences on subsequent runs. To force registry change, use [win_regedit] with state=absent
        before using [win_regmerge].
EXAMPLES:
  # Merge in a registry file without comparing to current registry
  # Note that paths using / to separate are preferred as they require less special handling than \
  win_regmerge:
    path: C:/autodeploy/myCompany-settings.reg
  # Compare and merge registry file
  win_regmerge:
    path: C:/autodeploy/myCompany-settings.reg
    compare_to: HKLM:\SOFTWARE\myCompany

RETURN VALUES:
compare_to_key_found:
    description: whether the parent registry key has been found for comparison
    returned: when comparison key not found in registry
    type: boolean
    sample: false
difference_count:
    description: number of differences between the registry and the file
    returned: changed
    type: integer
    sample: 1
compared:
    description: whether a comparison has taken place between the registry and the file
    returned: when a comparison key has been supplied and comparison has been attempted
    type: boolean
    sample: true


MAINTAINERS: Jon Hawkesworth (@jhawkesworth)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_ROBOCOPY    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_robocopy.py)

  Synchronizes the contents of two directories on the remote machine. Under the hood this just calls out to RoboCopy,
  since that should be available on most modern Windows Systems.

Options (= is mandatory):

= dest
        Destination file/directory to sync (Will receive contents of src).

- flags
        Directly supply Robocopy flags. If set, purge and recurse will be ignored.
        [Default: None]
- purge
        Deletes any files/directories found in the destination that do not exist in the source (Toggles the `/purge` flag
        to RoboCopy). If "flags" is set, this will be ignored.
        (Choices: True, False)[Default: False]
- recurse
        Includes all subdirectories (Toggles the `/e` flag to RoboCopy). If "flags" is set, this will be ignored.
        (Choices: True, False)[Default: False]
= src
        Source file/directory to sync.

Notes:
  * This is not a complete port of the "synchronize" module. Unlike the "synchronize" module this only performs the
        sync/copy on the remote machine, not from the master to the remote machine.
  * This module does not currently support all Robocopy flags.
  * Works on Windows 7, Windows 8, Windows Server 2k8, and Windows Server 2k12
EXAMPLES:
- name: Sync the contents of one directory to another
  win_robocopy:
    src: C:\DirectoryOne
    dest: C:\DirectoryTwo

- name: Sync the contents of one directory to another, including subdirectories
  win_robocopy:
    src: C:\DirectoryOne
    dest: C:\DirectoryTwo
    recurse: True

- name: Sync the contents of one directory to another, and remove any files/directories found in destination that do not exist in the source
  win_robocopy:
    src: C:\DirectoryOne
    dest: C:\DirectoryTwo
    purge: True

- name: Sync content in recursive mode, removing any files/directories found in destination that do not exist in the source
  win_robocopy:
    src: C:\DirectoryOne
    dest: C:\DirectoryTwo
    recurse: True
    purge: True

- name: Sync Two Directories in recursive and purging mode, specifying additional special flags
  win_robocopy:
    src: C:\DirectoryOne
    dest: C:\DirectoryTwo
    flags: /E /PURGE /XD SOME_DIR /XF SOME_FILE /MT:32

RETURN VALUES:
src:
    description: The Source file/directory of the sync.
    returned: always
    type: string
    sample: c:\Some\Path
dest:
    description: The Destination file/directory of the sync.
    returned: always
    type: string
    sample: c:\Some\Path
recurse:
    description: Whether or not the recurse flag was toggled.
    returned: always
    type: bool
    sample: False
purge:
    description: Whether or not the purge flag was toggled.
    returned: always
    type: bool
    sample: False
flags:
    description: Any flags passed in by the user.
    returned: always
    type: string
    sample: "/e /purge"
rc:
    description: The return code retuned by robocopy.
    returned: success
    type: int
    sample: 1
output:
    description: The output of running the robocopy command.
    returned: success
    type: string
    sample: "-------------------------------------------------------------------------------\n   ROBOCOPY     ::     Robust File Copy for Windows                              \n-------------------------------------------------------------------------------\n"
msg:
    description: Output intrepreted into a concise message.
    returned: always
    type: string
    sample: No files copied!
changed:
    description: Whether or not any changes were made.
    returned: always
    type: bool
    sample: False


MAINTAINERS: Corwin Brown (@blakfeld)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_SAY    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_say.py)

  Uses .NET libraries to convert text to speech and optionally play .wav sounds.  Audio Service needs to be running and
  some kind of speakers or headphones need to be attached to the windows target(s) for the speech to be audible.

Options (= is mandatory):

- end_sound_path
        Full path to a `.wav' file containing a sound to play after the text has been spoken.  Useful on conference calls
        to alert other speakers that ansible has finished speaking.
        [Default: None]
- msg
        The text to be spoken.  Use either msg or msg_file.  Optional so that you can use this module just to play
        sounds.
        [Default: none]
- msg_file
        Full path to a windows format text file containing the text to be spokend.  Use either msg or msg_file.  Optional
        so that you can use this module just to play sounds.
        [Default: none]
- speech_speed
        How fast or slow to speak the text.  Must be an integer value in the range -10 to 10.  -10 is slowest, 10 is
        fastest.
        [Default: 0]
- start_sound_path
        Full path to a `.wav' file containing a sound to play before the text is spoken.  Useful on conference calls to
        alert other speakers that ansible has something to say.
        [Default: None]
- voice
        Which voice to use. See notes for how to discover installed voices.  If the requested voice is not available the
        default voice will be used. Example voice names from Windows 10 are 'Microsoft Zira Desktop' and 'Microsoft Hazel
        Desktop'.
        [Default: system default voice]
Notes:
  * Needs speakers or headphones to do anything useful.
  * To find which voices are installed, run the following powershell Add-Type -AssemblyName System.Speech $speech =
        New-Object -TypeName System.Speech.Synthesis.SpeechSynthesizer $speech.GetInstalledVoices() | ForEach-
        Object { $_.VoiceInfo } $speech.Dispose()
  * Speech can be surprisingly slow, so its best to keep message text short.
EXAMPLES:
  # Warn of impending deployment
- win_say:
    msg: Warning, deployment commencing in 5 minutes, please log out.
  # Using a different voice and a start sound
- win_say:
    start_sound_path: C:\Windows\Media\ding.wav
    msg: Warning, deployment commencing in 5 minutes, please log out.
    voice: Microsoft Hazel Desktop
  # example with start and end sound
- win_say:
    start_sound_path: C:\Windows\Media\Windows Balloon.wav
    msg: New software installed
    end_sound_path: C:\Windows\Media\chimes.wav
  # text from file example
- win_say:
    start_sound_path: C:\Windows\Media\Windows Balloon.wav
    msg_file: AppData\Local\Temp\morning_report.txt
    end_sound_path: C:\Windows\Media\chimes.wav

RETURN VALUES:
message_text:
    description: the text that the module attempted to speak
    returned: success
    type: string
    sample: "Warning, deployment commencing in 5 minutes."
voice:
    description: the voice used to speak the text.
    returned: success
    type: string
    sample: Microsoft Hazel Desktop
voice_info:
    description: the voice used to speak the text.
    returned: when requested voice could not be loaded
    type: string
    sample: Could not load voice TestVoice, using system default voice


MAINTAINERS: Jon Hawkesworth (@jhawkesworth)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_SCHEDULED_TASK    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_scheduled_task.py)

  Manage scheduled tasks

Options (= is mandatory):

- arguments
        Arguments to provide scheduled task action
        [Default: (null)]
- days_of_week
        Days of the week to run a weekly task, not idempotent
        [Default: (null)]
- description
        The description for the scheduled task
        [Default: (null)]
- enabled
        Enable/disable the task
        (Choices: True, False)[Default: True]
- executable
        Command the scheduled task should execute
        [Default: (null)]
- frequency
        The frequency of the command, not idempotent
        (Choices: once, daily, weekly)[Default: (null)]
= name
        Name of the scheduled task

- path
        Task folder in which this task will be stored
        [Default: \]
= state
        State that the task should become
        (Choices: present, absent)
- time
        Time to execute scheduled task, not idempotent
        [Default: (null)]
- user
        User to run scheduled task as
        [Default: (null)]
Notes:
  * This module requires Windows Server 2012 or later.
EXAMPLES:
# Create a scheduled task to open a command prompt
- win_scheduled_task:
    name: TaskName
    description: open command prompt
    executable: cmd
    arguments: -opt1 -opt2
    path: example
    time: 9am
    frequency: daily
    state: present
    enabled: yes
    user: SYSTEM


MAINTAINERS: Peter Mounce

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_SERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_service.py)

  Manages Windows services

Options (= is mandatory):

- dependencies
        A list of service dependencies to set for this particular service.
        This should be a list of service names and not the display name of the service.
        This works by `dependency_action' to either add/remove or set the services in this list.
        [Default: (null)]
- dependency_action
        Used in conjunction with `dependency' to either add the dependencies to the existing service dependencies.
        Remove the dependencies to the existing dependencies.
        Set the dependencies to only the values in the list replacing the existing dependencies.
        (Choices: set, add, remove)[Default: set]
- description
        The description to set for the service.
        [Default: (null)]
- desktop_interact
        Whether to allow the service user to interact with the desktop.
        This should only be set to true when using the LocalSystem username.
        [Default: False]
- display_name
        The display name to set for the service.
        [Default: (null)]
- force_dependent_services
        If True, stopping or restarting a service with dependent services will force the dependent services to stop or
        restart also.
        If False, stopping or restarting a service with dependent services may fail.
        [Default: False]
= name
        Name of the service

- password
        The password to set the service to start as.
        This and the `username' argument must be supplied together.
        If specifying LocalSystem, NetworkService or LocalService this field must be an empty string and not null.
        [Default: (null)]
- path
        The path to the executable to set for the service.
        [Default: (null)]
- start_mode
        Set the startup type for the service.
        `delayed' added in Ansible 2.3
        (Choices: auto, manual, disabled, delayed)[Default: (null)]
- state
        `started'/`stopped'/`absent' are idempotent actions that will not run commands unless necessary.
        `restarted' will always bounce the service.
        `absent' added in Ansible 2.3
        (Choices: started, stopped, restarted, absent)[Default: (null)]
- username
        The username to set the service to start as.
        This and the `password' argument must be supplied together.
        [Default: (null)]
EXAMPLES:
- name: Restart a service
  win_service:
    name: spooler
    state: restarted

- name: Set service startup mode to auto and ensure it is started
  win_service:
    name: spooler
    start_mode: auto
    state: started

# a new service will also default to the following values:
# - username: LocalSystem
# - state: stopped
# - start_mode: auto
- name: create a new service
  win_service:
    name: service name
    path: C:\temp\test.exe

- name: create a new service with extra details
  win_service:
    name: service name
    path: C:\temp\test.exe
    display_name: Service Name
    description: A test service description

- name: remove a service
  win_service:
    name: service name
    state: absent

- name: check if a service is installed
  win_service:
    name: service name
  register: service_info

- name: set the log on user to a domain account
  win_service:
    name: service name
    state: restarted
    username: DOMAIN\User
    password: Password

- name: set the log on user to a local account
  win_service:
    name: service name
    state: restarted
    username: .\Administrator
    password: Password

- name: set the log on user to Local System
  win_service:
    name: service name
    state: restarted
    username: LocalSystem
    password: ""

- name: set the log on user to Local System and allow it to interact with the desktop
  win_service:
    name: service name
    state: restarted
    username: LocalSystem
    password: ""
    desktop_interact: True

- name: set the log on user to Network Service
  win_service:
    name: service name
    state: restarted
    username: NT AUTHORITY\NetworkService
    password: ""

- name: set the log on user to Local Service
  win_service:
    name: service name
    state: restarted
    username: NT AUTHORITY\LocalService
    password: ""

- name: set dependencies to ones only in the list
  win_service:
    name: service name
    dependencies: ['service1', 'service2']

- name: add dependencies to existing dependencies
  win_service:
    name: service name
    dependencies: ['service1', 'service2']
    dependency_action: add

- name: remove dependencies from existing dependencies
  win_service:
    name: service name
    dependencies: ['service1', 'service2']
    dependency_action: remove

RETURN VALUES:
exists:
    description: whether the service exists or not
    returned: success
    type: boolean
    sample: true
name:
    description: the service name or id of the service
    returned: success and service exists
    type: string
    sample: CoreMessagingRegistrar
display_name:
    description: the display name of the installed service
    returned: success and service exists
    type: string
    sample: CoreMessaging
status:
    description: the current running status of the service
    returned: success and service exists
    type: string
    sample: stopped
start_mode:
    description: the startup type of the service
    returned: success and service exists
    type: string
    sample: manual
path:
    description:
    returned: success and service exists
    type: string
    sample: C:\Windows\system32\svchost.exe -k LocalServiceNoNetwork
description:
    description: the path to the executable of the service
    returned: success and service exists
    type: string
    sample: Manages communication between system components.
username:
    description: the username that runs the service
    returned: success and service exists
    type: string
    sample: LocalSystem
desktop_interact:
    description: Whether the current user is allowed to interact with the desktop
    returned: success and service exists
    type: boolean
    sample: False
dependencies:
    description: A list of dependencies the service relies on
    returned: success and service exists
    type: List
    sample: False
depended_by:
    description: A list of dependencies this service relies on
    returned: success and service exists
    type: List
    sample: False


MAINTAINERS: Chris Hoffman (@chrishoffman)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_SHARE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_share.py)

  Add, modify or remove Windows share and set share permissions.

Options (= is mandatory):

- caching_mode
        Set the CachingMode for this share.
        (Choices: BranchCache, Documents, Manual, None, Programs, Unknown)[Default: Manual]
- change
        Specify user list that should get read and write access on share, separated by comma.
        [Default: (null)]
- deny
        Specify user list that should get no access, regardless of implied access on share, separated by comma.
        [Default: (null)]
- description
        Share description
        [Default: (null)]
- full
        Specify user list that should get full access on share, separated by comma.
        [Default: (null)]
- list
        Specify whether to allow or deny file listing, in case user got no permission on share
        (Choices: True, False)[Default: (null)]
= name
        Share name

= path
        Share directory

- read
        Specify user list that should get read access on share, separated by comma.
        [Default: (null)]
- state
        Specify whether to add `present' or remove `absent' the specified share
        (Choices: present, absent)[Default: present]
Requirements:  Windows 8.1 / Windows 2012 or newer

EXAMPLES:
# Playbook example
# Add share and set permissions
---
- name: Add secret share
  win_share:
    name: internal
    description: top secret share
    path: C:\shares\internal
    list: 'no'
    full: Administrators,CEO
    read: HR-Global
    deny: HR-External

- name: Add public company share
  win_share:
    name: company
    description: top secret share
    path: C:\shares\company
    list: 'yes'
    full: Administrators,CEO
    read: Global

# Remove previously added share
  win_share:
    name: internal
    state: absent

RETURN VALUES:



MAINTAINERS: Hans-Joachim Kliemeck (@h0nIg), David Baumann (@daBONDi)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_SHELL    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_shell.py)

  The `win_shell' module takes the command name followed by a list of space-delimited arguments. It is similar to the
  [win_command] module, but runs the command via a shell (defaults to PowerShell) on the target host.

Options (= is mandatory):

- chdir
        set the specified path as the current working directory before executing a command
        [Default: (null)]
- creates
        a path or path filter pattern; when the referenced path exists on the target host, the task will be skipped.
        [Default: (null)]
- executable
        change the shell used to execute the command (eg, `cmd'). The target shell must accept a `/c' parameter followed
        by the raw command line to be executed.
        [Default: (null)]
= free_form
        the win_shell module takes a free form command to run.  There is no parameter actually named 'free form'. See the
        examples!

- removes
        a path or path filter pattern; when the referenced path *does not* exist on the target host, the task will be
        skipped.
        [Default: (null)]
Notes:
  * If you want to run an executable securely and predictably, it may be better to use the [win_command] module
        instead. Best practices when writing playbooks will follow the trend of using [win_command] unless
        `win_shell' is explicitly required. When running ad-hoc commands, use your best judgement.
  * WinRM will not return from a command execution until all child processes created have exited. Thus, it is not
        possible to use win_shell to spawn long-running child or background processes. Consider creating a Windows
        service for managing background processes.
EXAMPLES:
# Execute a command in the remote shell; stdout goes to the specified
# file on the remote.
- win_shell: C:\somescript.ps1 >> c:\somelog.txt

# Change the working directory to somedir/ before executing the command.
- win_shell: C:\somescript.ps1 >> c:\somelog.txt chdir=c:\somedir

# You can also use the 'args' form to provide the options. This command
# will change the working directory to somedir/ and will only run when
# somedir/somelog.txt doesn't exist.
- win_shell: C:\somescript.ps1 >> c:\somelog.txt
  args:
    chdir: c:\somedir
    creates: c:\somelog.txt

# Run a command under a non-Powershell interpreter (cmd in this case)
- win_shell: echo %HOMEDIR%
  args:
    executable: cmd
  register: homedir_out

RETURN VALUES:
msg:
    description: changed
    returned: always
    type: boolean
    sample: True
start:
    description: The command execution start time
    returned: always
    type: string
    sample: '2016-02-25 09:18:26.429568'
end:
    description: The command execution end time
    returned: always
    type: string
    sample: '2016-02-25 09:18:26.755339'
delta:
    description: The command execution delta time
    returned: always
    type: string
    sample: '0:00:00.325771'
stdout:
    description: The command standard output
    returned: always
    type: string
    sample: 'Clustering node rabbit@slave1 with rabbit@master ...'
stderr:
    description: The command standard error
    returned: always
    type: string
    sample: 'ls: cannot access foo: No such file or directory'
cmd:
    description: The command executed by the task
    returned: always
    type: string
    sample: 'rabbitmqctl join_cluster rabbit@master'
rc:
    description: The command return code (0 means success)
    returned: always
    type: int
    sample: 0
stdout_lines:
    description: The command standard output split in lines
    returned: always
    type: list of strings
    sample: [u'Clustering node rabbit@slave1 with rabbit@master ...']


MAINTAINERS: Matt Davis

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_SHORTCUT    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_shortcut.py)

  Create, manage and delete Windows shortcuts

Options (= is mandatory):

- args
        Additional arguments for the executable defined in `src'.
        [Default: (null)]
- description
        Description for the shortcut.
        This is usually shown when hoovering the icon.
        [Default: (null)]
= dest
        Destination file for the shortcuting file.
        File name should have a `.lnk' or `.url' extension.

- directory
        Working directory for executable defined in `src'.
        [Default: (null)]
- hotkey
        Key combination for the shortcut.
        [Default: (null)]
- icon
        Icon used for the shortcut
        File name should have a `.ico' extension.
        The file name is followed by a comma and the number in the library file (.dll) or use 0 for an image file.
        [Default: (null)]
- src
        Executable or URL the shortcut points to.
        [Default: (null)]
- state
        When `present', creates or updates the shortcut.  When `absent', removes the shortcut if it exists.
        (Choices: present, absent)[Default: present]
- windowstyle
        Influences how the application is displayed when it is launched.
        (Choices: default, maximized, minimized)[Default: (null)]
Notes:
  * The following options can include Windows environment variables: `dest', `args', `description', `dest',
        `directory', `icon' `src'
  * Windows has two types of shortcuts: Application and URL shortcuts. URL shortcuts only consists of `dest' and
        `src'
EXAMPLES:
# Create an application shortcut on the desktop
- win_shortcut:
    src: C:\Program Files\Mozilla Firefox\Firefox.exe
    dest: C:\Users\Public\Desktop\Mozilla Firefox.lnk
    icon: C:\Program Files\Mozilla Firefox\Firefox.exe,0

# Create the same shortcut using environment variables
- win_shortcut:
    description: The Mozilla Firefox web browser
    src: '%PROGRAMFILES%\Mozilla Firefox\Firefox.exe'
    dest: '%PUBLIC%\Desktop\Mozilla Firefox.lnk'
    icon: '%PROGRAMFILES\Mozilla Firefox\Firefox.exe,0'
    directory: '%PROGRAMFILES%\Mozilla Firefox'

# Create a URL shortcut to the Ansible website
- win_shortcut:
    src: 'https://ansible.com/'
    dest: '%PUBLIC%\Desktop\Ansible website.url'

# Create an application shortcut for the Ansible website
- win_shortcut:
    src: '%PROGRAMFILES%\Google\Chrome\Application\chrome.exe'
    dest: '%PUBLIC%\Desktop\Ansible website.lnk'
    args: '--new-window https://ansible.com/'
    directory: '%PROGRAMFILES%\Google\Chrome\Application'
    icon: '%PROGRAMFILES%\Google\Chrome\Application\chrome.exe,0'

RETURN VALUES:


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_STAT    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_stat.py)

  Returns information about a Windows file

Options (= is mandatory):

- checksum_algorithm
        Algorithm to determine checksum of file. Will throw an error if the host is unable to use specified algorithm.
        (Choices: md5, sha1, sha256, sha384, sha512)[Default: sha1]
- get_checksum
        Whether to return a checksum of the file (default sha1)
        [Default: True]
- get_md5
        Whether to return the checksum sum of the file. Between Ansible 1.9 and 2.2 this is no longer an MD5, but a SHA1
        instead. As of Ansible 2.3 this is back to an MD5. Will return None if host is unable to use specified algorithm.
        This option is deprecated in Ansible 2.3 and is replaced with `checksum_algorithm=md5'.
        [Default: True]
= path
        The full path of the file/object to get the facts of; both forward and back slashes are accepted.

EXAMPLES:
- name: Obtain information about a file
  win_stat:
    path: C:\foo.ini
  register: file_info

# Obtain information about a folder
- win_stat:
    path: C:\bar
  register: folder_info

# Get MD5 checksum of a file
- win_stat:
    path: C:\foo.ini
    get_checksum: yes
    checksum_algorithm: md5
  register: md5_checksum

- debug:
    var: md5_checksum.stat.checksum

# Get SHA1 checksum of file
- win_stat:
    path: C:\foo.ini
    get_checksum: yes
  register: sha1_checksum

- debug:
    var: sha1_checksum.stat.checksum

# Get SHA256 checksum of file
- win_stat:
    path: C:\foo.ini
    get_checksum: yes
    checksum_algorithm: sha256
  register: sha256_checksum

- debug:
    var: sha256_checksum.stat.checksum

RETURN VALUES:
changed:
    description: Whether anything was changed
    returned: always
    type: boolean
    sample: True
stat:
    description: dictionary containing all the stat data
    returned: success
    type: dictionary
    contains:
        attributes:
            description: attributes of the file at path in raw form
            returned: success, path exists
            type: string
            sample: "Archive, Hidden"
        checksum:
            description: The checksum of a file based on checksum_algorithm specified
            returned: success, path exist, path is a file, get_checksum == True
              checksum_algorithm specified is supported
            type: string
            sample: 09cb79e8fc7453c84a07f644e441fd81623b7f98
        creationtime:
            description: the create time of the file represented in seconds since epoch
            returned: success, path exists
            type: float
            sample: 1477984205.15
        extension:
            description: the extension of the file at path
            returned: success, path exists, path is a file
            type: string
            sample: ".ps1"
        isarchive:
            description: if the path is ready for archiving or not
            returned: success, path exists
            type: boolean
            sample: True
        isdir:
            description: if the path is a directory or not
            returned: success, path exists
            type: boolean
            sample: True
        ishidden:
            description: if the path is hidden or not
            returned: success, path exists
            type: boolean
            sample: True
        islnk:
            description: if the path is a symbolic link or junction or not
            returned: success, path exists
            type: boolean
            sample: True
        isreadonly:
            description: if the path is read only or not
            returned: success, path exists
            type: boolean
            sample: True
        isshared:
            description: if the path is shared or not
            returned: success, path exists
            type: boolean
            sample: True
        lastaccesstime:
            description: the last access time of the file represented in seconds since epoch
            returned: success, path exists
            type: float
            sample: 1477984205.15
        lastwritetime:
            description: the last modification time of the file represented in seconds since epoch
            returned: success, path exists
            type: float
            sample: 1477984205.15
        lnk_source:
            description: the target of the symbolic link, will return null if not a link or the link is broken
            return: success, path exists, file is a symbolic link
            type: string
            sample: C:\temp
        md5:
            description: The MD5 checksum of a file (Between Ansible 1.9 and 2.2 this was returned as a SHA1 hash)
            returned: success, path exist, path is a file, get_md5 == True, md5 is supported
            type: string
            sample: 09cb79e8fc7453c84a07f644e441fd81623b7f98
        owner:
            description: the owner of the file
            returned: success, path exists
            type: string
            sample: BUILTIN\Administrators
        path:
            description: the full absolute path to the file
            returned: success, path exists
            type: string
            sample: BUILTIN\Administrators
        sharename:
            description: the name of share if folder is shared
            returned: success, path exists, file is a directory and isshared == True
            type: string
            sample: file-share
        size:
            description: the size in bytes of a file or folder
            returned: success, path exists, file is not a link
            type: int
            sample: 1024


MAINTAINERS: Chris Church (@cchurch)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_TEMPFILE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_tempfile.py)

  Creates temporary files and directories.

Options (= is mandatory):

- path
        Location where temporary file or directory should be created.
        If path is not specified default system temporary directory (%TEMP%) will be used.
        [Default: %TEMP%]
- prefix
        Prefix of file/directory name created by module.
        [Default: ansible.]
- state
        Whether to create file or directory.
        (Choices: file, directory)[Default: file]
- suffix
        Suffix of file/directory name created by module.
        [Default: ]
EXAMPLES:
- name: Create temporary build directory
  win_tempfile:
    state: directory
    suffix: build

- name: Create temporary file
  win_tempfile:
    state: file
    suffix: temp

RETURN VALUES:
path:
  description: Path to created file or directory
  returned: success
  type: string
  sample: C:\Users\Administrator\AppData\Local\Temp\ansible.bMlvdk


MAINTAINERS: Dag Wieers (@dagwieers)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_TEMPLATE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_template.py)

  Templates are processed by the Jinja2 templating language (http://jinja.pocoo.org/docs/) - documentation on the
  template formatting can be found in the Template Designer Documentation (http://jinja.pocoo.org/docs/templates/). Six
  additional variables can be used in templates: `ansible_managed' (configurable via the `defaults' section of
  `ansible.cfg') contains a string which can be used to describe the template name, host, modification time of the
  template file and the owner uid, `template_host' contains the node name of the template's machine, `template_uid' the
  owner, `template_path' the absolute path of the template, `template_fullpath' is the absolute path of the template, and
  `template_run_date' is the date that the template was rendered. Note that including a string that uses a date in the
  template will result in the template being marked 'changed' each time.

  * note: This module has a corresponding action plugin.

Options (= is mandatory):

= dest
        Location to render the template to on the remote machine.

= src
        Path of a Jinja2 formatted template on the local server. This can be a relative or absolute path.

Notes:
  * templates are loaded with `trim_blocks=True'.
  * By default, windows line endings are not created in the generated file.
  * In order to ensure windows line endings are in the generated file, add the following header as the first line
        of your template: ``#jinja2: newline_sequence:'\r\n'`` and ensure each line of the template ends with
        \\r\\n
  * Beware fetching files from windows machines when creating templates because certain tools, such as Powershell
        ISE,  and regedit's export facility add a Byte Order Mark as the first character of the file, which can
        cause tracebacks.
  * Use "od -cx" to examine your templates for Byte Order Marks.
EXAMPLES:
- name: Create a file from a Jinja2 template
  win_template:
    src: /mytemplates/file.conf.j2
    dest: C:\temp\file.conf


MAINTAINERS: Jon Hawkesworth (@jhawkesworth)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_TIMEZONE    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_timezone.py)

  Sets machine time to the specified timezone, the module will check if the provided timezone is supported on the
  machine.

Options (= is mandatory):

= timezone
        Timezone to set to.  Example Central Standard Time
        [Default: None]
EXAMPLES:
  # Set machine's timezone to Central Standard Time
  win_timezone:
    timezone: "Central Standard Time"

RETURN VALUES:
 

MAINTAINERS: Phil Schwartz

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_UNZIP    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_unzip.py)

  Unzips compressed files and archives. Supports .zip files natively Supports other formats supported by the Powershell
  Community Extensions (PSCX) module (basically everything 7zip supports)

Options (= is mandatory):

- creates
        If this file or directory exists the specified src will not be extracted.
        [Default: None]
= dest
        Destination of zip file (provide absolute path of directory). If it does not exist, the directory will be
        created.

- recurse
        Recursively expand zipped files within the src file.
        (Choices: True, False, True, False)[Default: False]
- rm
        Remove the zip file, after unzipping
        (Choices: True, False, True, False)[Default: False]
= src
        File to be unzipped (provide absolute path)

Notes:
  * For extracting any compression types other than .zip, the PowerShellCommunityExtensions (PSCX) Module is
        required.  This module (in conjunction with PSCX) has the ability to recursively unzip files within the src
        zip file provided and also functionality for many other compression types. If the destination directory
        does not exist, it will be created before unzipping the file.  Specifying rm parameter will force removal
        of the src file after extraction.
Requirements:  PSCX

EXAMPLES:
# This unzips a library that was downloaded with win_get_url, and removes the file after extraction
# $ ansible -i hosts -m win_unzip -a "src=C:\\LibraryToUnzip.zip dest=C:\\Lib rm=true" all
# Playbook example

# Simple unzip
---
- name: Unzip a bz2 (BZip) file
  win_unzip:
    src: C:\Users\Phil\Logs.bz2
    dest: C:\Users\Phil\OldLogs
    creates: C:\Users\Phil\OldLogs

# This playbook example unzips a .zip file and recursively decompresses the contained .gz files and removes all unneeded compressed files after completion.
- name: Unzip ApplicationLogs.zip and decompress all GZipped log files
  hosts: all
  gather_facts: false
  tasks:
    - name: Recursively decompress GZ files in ApplicationLogs.zip
      win_unzip:
        src: C:\Downloads\ApplicationLogs.zip
        dest: C:\Application\Logs
        recurse: yes
        rm: true

# Install PSCX to use for extracting a gz file
- name: Grab PSCX msi
  win_get_url:
    url: http://download-codeplex.sec.s-msft.com/Download/Release?ProjectName=pscx&DownloadId=923562&FileTime=130585918034470000&Build=20959
    dest: C:\pscx.msi
- name: Install PSCX
  win_msi:
    path: C:\pscx.msi
- name: Unzip gz log
  win_unzip:
    src: C:\Logs\application-error-logs.gz
    dest: C:\ExtractedLogs\application-error-logs


MAINTAINERS: Phil Schwartz

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_UPDATES    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_updates.py)

  Searches, downloads, and installs Windows updates synchronously by automating the Windows Update client

Options (= is mandatory):

- category_names
        A scalar or list of categories to install updates from
        (Choices: Application, Connectors, CriticalUpdates, DefinitionUpdates, DeveloperKits, FeaturePacks, Guidance,
        SecurityUpdates, ServicePacks, Tools, UpdateRollups, Updates)[Default: [u'CriticalUpdates', u'SecurityUpdates',
        u'UpdateRollups']]
- log_path
        If set, win_updates will append update progress to the specified file. The directory must already exist.
        [Default: (null)]
- state
        Controls whether found updates are returned as a list or actually installed.
        This module also supports Ansible check mode, which has the same effect as setting state=searched
        (Choices: installed, searched)[Default: installed]
Notes:
  * win_updates must be run by a user with membership in the local Administrators group
  * win_updates will use the default update service configured for the machine (Windows Update, Microsoft Update,
        WSUS, etc)
  * win_updates does not manage reboots, but will signal when a reboot is required with the reboot_required return
        value.
  * win_updates can take a significant amount of time to complete (hours, in some cases). Performance depends on
        many factors, including OS version, number of updates, system load, and update server load.
EXAMPLES:
# Install all security, critical, and rollup updates
- win_updates:
    category_names:
      - SecurityUpdates
      - CriticalUpdates
      - UpdateRollups

# Install only security updates
- win_updates:
    category_names: SecurityUpdates

# Search-only, return list of found updates (if any), log to c:\ansible_wu.txt
- win_updates:
    category_names: SecurityUpdates
    state: searched
    log_path: c:\ansible_wu.txt

RETURN VALUES:
reboot_required:
    description: True when the target server requires a reboot to complete updates (no further updates can be installed until after a reboot)
    returned: success
    type: boolean
    sample: True

updates:
    description: List of updates that were found/installed
    returned: success
    type: dictionary
    sample:
    contains:
        title:
            description: Display name
            returned: always
            type: string
            sample: "Security Update for Windows Server 2012 R2 (KB3004365)"
        kb:
            description: A list of KB article IDs that apply to the update
            returned: always
            type: list of strings
            sample: [ '3004365' ]
        id:
            description: Internal Windows Update GUID
            returned: always
            type: string (guid)
            sample: "fb95c1c8-de23-4089-ae29-fd3351d55421"
        installed:
            description: Was the update successfully installed
            returned: always
            type: boolean
            sample: True
        failure_hresult_code:
            description: The HRESULT code from a failed update
            returned: on install failure
            type: boolean
            sample: 2147942402

found_update_count:
    description: The number of updates found needing to be applied
    returned: success
    type: int
    sample: 3
installed_update_count:
    description: The number of updates successfully installed
    returned: success
    type: int
    sample: 2
failed_update_count:
    description: The number of updates that failed to install
    returned: always
    type: int
    sample: 0


MAINTAINERS: Matt Davis (@mattdavispdx)

METADATA:
	Status: ['preview']
	Supported_by: core
> WIN_URI    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_uri.py)

  Interacts with HTTP and HTTPS web services and supports Digest, Basic and WSSE HTTP authentication mechanisms.

Options (= is mandatory):

- body
        The body of the HTTP request/response to the web service.
        [Default: (null)]
- content_type
        Sets the "Content-Type" header.
        [Default: (null)]
- dest
        Output the response body to a file.
        [Default: (null)]
- headers
        Key Value pairs for headers. Example "Host: www.somesite.com"
        [Default: (null)]
- method
        The HTTP Method of the request or response.
        (Choices: GET, POST, PUT, HEAD, DELETE, OPTIONS, PATCH, TRACE, CONNECT, REFRESH)[Default: GET]
= url
        HTTP or HTTPS URL in the form of (http|https)://host.domain:port/path

- use_basic_parsing
        This module relies upon 'Invoke-WebRequest', which by default uses the Internet Explorer Engine to parse a
        webpage. There's an edge-case where if a user hasn't run IE before, this will fail. The only advantage to using
        the Internet Explorer praser is that you can traverse the DOM in a powershell script. That isn't useful for
        Ansible, so by default we toggle 'UseBasicParsing'. However, you can toggle that off here.
        (Choices: True, False)[Default: True]
EXAMPLES:
- name: Perform a GET and Store Output
  win_uri:
    url: http://example.com/endpoint
  register: http_output

# Set a HOST header to hit an internal webserver:
- name: Hit a Specific Host on the Server
  win_uri:
    url: http://example.com/
    method: GET
    headers:
      host: www.somesite.com

- name: Perform a HEAD on an Endpoint
  win_uri:
    url: http://www.example.com/
    method: HEAD

- name: POST a Body to an Endpoint
  win_uri:
    url: http://www.somesite.com/
    method: POST
    body: "{ 'some': 'json' }"

RETURN VALUES:
url:
  description: The Target URL
  returned: always
  type: string
  sample: https://www.ansible.com
method:
  description: The HTTP method used.
  returned: always
  type: string
  sample: GET
content_type:
  description: The "content-type" header used.
  returned: always
  type: string
  sample: application/json
use_basic_parsing:
  description: The state of the "use_basic_parsing" flag.
  returned: always
  type: bool
  sample: True
body:
  description: The content of the body used
  returned: when body is specified
  type: string
  sample: '{"id":1}'
  version_added: "2.3"
status_code:
  description: The HTTP Status Code of the response.
  returned: success
  type: int
  sample: 200
status_description:
  description: A summery of the status.
  returned: success
  type: string
  sample: OK
raw_content:
  description: The raw content of the HTTP response.
  returned: success
  type: string
  sample: 'HTTP/1.1 200 OK\nX-XSS-Protection: 1; mode=block\nX-Frame-Options: SAMEORIGIN\nAlternate-Protocol: 443:quic,p=1\nAlt-Svc: quic="www.google.com:443"; ma=2592000; v="30,29,28,27,26,25",quic=":443"; ma=2...'
headers:
  description: The Headers of the response.
  returned: success
  type: dict
  sample: {"Content-Type": "application/json"}
raw_content_length:
  description: The byte size of the response.
  returned: success
  type: int
  sample: 54447


MAINTAINERS: Corwin Brown (@blakfeld)

METADATA:
	Status: ['preview']
	Supported_by: community
> WIN_USER    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_user.py)

  Manages local Windows user accounts

Options (= is mandatory):

- account_disabled
        `yes' will disable the user account.  `no' will clear the disabled flag.
        (Choices: yes, no)[Default: None]
- account_locked
        `no' will unlock the user account if locked.
        (Choices: no)[Default: None]
- description
        Description of the user
        [Default: None]
- fullname
        Full name of the user
        [Default: None]
- groups
        Adds or removes the user from this comma-separated lis of groups, depending on the value of `groups_action'. When
        `groups_action' is `replace' and `groups' is set to the empty string ('groups='), the user is removed from all
        groups.
        [Default: (null)]
- groups_action
        If `replace', the user is added as a member of each group in `groups' and removed from any other groups.  If
        `add', the user is added to each group in `groups' where not already a member.  If `remove', the user is removed
        from each group in `groups'.
        (Choices: replace, add, remove)[Default: replace]
= name
        Name of the user to create, remove or modify.

- password
        Optionally set the user's password to this (plain text) value.
        [Default: None]
- password_expired
        `yes' will require the user to change their password at next login. `no' will clear the expired password flag.
        (Choices: yes, no)[Default: None]
- password_never_expires
        `yes' will set the password to never expire.  `no' will allow the password to expire.
        (Choices: yes, no)[Default: None]
- state
        When `present', creates or updates the user account.  When `absent', removes the user account if it exists.  When
        `query' (new in 1.9), retrieves the user account details without making any changes.
        (Choices: present, absent, query)[Default: present]
- update_password
        `always' will update passwords if they differ.  `on_create' will only set the password for newly created users.
        (Choices: always, on_create)[Default: always]
- user_cannot_change_password
        `yes' will prevent the user from changing their password.  `no' will allow the user to change their password.
        (Choices: yes, no)[Default: None]
EXAMPLES:
- name: Ensure user bob is present
  win_user:
    name: bob
    password: B0bP4ssw0rd
    state: present
    groups:
      - Users

- name: Ensure user bob is absent
  win_user:
    name: bob
    state: absent


MAINTAINERS: Chris Church (@cchurch), Paul Durivage (@angstwad)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> WIN_WEBPICMD    (/usr/lib/python2.7/site-packages/ansible/modules/windows/win_webpicmd.py)

  Installs packages using Web Platform Installer command-line (http://www.iis.net/learn/install/web-platform-installer
  /web-platform-installer-v4-command-line-webpicmdexe-rtw-release). Must be installed and present in PATH (see
  win_chocolatey module; 'webpicmd' is the package name, and you must install 'lessmsi' first too) Install IIS first (see
  win_feature module)

Options (= is mandatory):

= name
        Name of the package to be installed

Notes:
  * accepts EULAs and suppresses reboot - you will need to check manage reboots yourself (see win_reboot module)
EXAMPLES:
  # Install URLRewrite2.
  win_webpicmd:
    name: URLRewrite2


MAINTAINERS: Peter Mounce

METADATA:
	Status: ['preview']
	Supported_by: community
> XATTR    (/usr/lib/python2.7/site-packages/ansible/modules/files/xattr.py)

  Manages filesystem user defined extended attributes, requires that they are enabled on the target filesystem and that
  the setfattr/getfattr utilities are present.

Options (= is mandatory):

- follow
        if yes, dereferences symlinks and sets/gets attributes on symlink target, otherwise acts on symlink itself.
        (Choices: yes, no)[Default: True]
- key
        The name of a specific Extended attribute key to set/retrieve
        [Default: None]
= path
        The full path of the file/object to get the facts of.
        Before 2.3 this option was only usable as `name'.
        [Default: None]
- state
        defines which state you want to do. `read' retrieves the current value for a `key' (default) `present' sets
        `name' to `value', default if value is set `all' dumps all data `keys' retrieves all keys `absent' deletes the
        key
        (Choices: read, present, all, keys, absent)[Default: get]
- value
        The value to set the named name/key to, it automatically sets the `state' to 'set'
        [Default: None]
Notes:
  * As of Ansible 2.3, the `name' option has been changed to `path' as default, but `name' still works as well.
EXAMPLES:
# Obtain the extended attributes  of /etc/foo.conf
- xattr:
    path: /etc/foo.conf

# Sets the key 'foo' to value 'bar'
- xattr:
    path: /etc/foo.conf
    key: user.foo
    value: bar

# Removes the key 'foo'
- xattr:
    path: /etc/foo.conf
    key: user.foo
    state: absent


MAINTAINERS: Brian Coca (@bcoca)

METADATA:
	Status: ['stableinterface']
	Supported_by: community
> XBPS    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/xbps.py)

  Manage packages with the XBPS package manager.

Options (= is mandatory):

- name
        Name of the package to install, upgrade, or remove.
        [Default: None]
- recurse
        When removing a package, also remove its dependencies, provided that they are not required by other packages and
        were not explicitly installed by a user.
        (Choices: yes, no)[Default: False]
- state
        Desired state of the package.
        (Choices: present, absent, latest)[Default: present]
- update_cache
        Whether or not to refresh the master package lists. This can be run as part of a package installation or as a
        separate step.
        (Choices: yes, no)[Default: True]
- upgrade
        Whether or not to upgrade whole system
        (Choices: yes, no)[Default: False]
EXAMPLES:
# Install package foo
- xbps: name=foo state=present
# Upgrade package foo
- xbps: name=foo state=latest update_cache=yes
# Remove packages foo and bar
- xbps: name=foo,bar state=absent
# Recursively remove package foo
- xbps: name=foo state=absent recurse=yes
# Update package cache
- xbps: update_cache=yes
# Upgrade packages
- xbps: upgrade=yes

RETURN VALUES:
msg:
    description: Message about results
    returned: success
    type: string
    sample: "System Upgraded"
packages:
    description: Packages that are affected/would be affected
    type: list
    sample: ["ansible"]


MAINTAINERS: Michael Aldridge (@the-maldridge), Dino Occhialini (@dinoocch)

METADATA:
	Status: ['preview']
	Supported_by: community
> XENSERVER_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/cloud/misc/xenserver_facts.py)

  Reads data out of XenAPI, can be used instead of multiple xe commands.

EXAMPLES:
- name: Gather facts from xenserver
  xenserver:

- name: Print running VMs
  debug:
    msg: "{{ item }}"
  with_items: "{{ xs_vms.keys() }}"
  when: xs_vms[item]['power_state'] == "Running"

# Which will print:
#
# TASK: [Print running VMs] ***********************************************************
# skipping: [10.13.0.22] => (item=CentOS 4.7 (32-bit))
# ok: [10.13.0.22] => (item=Control domain on host: 10.0.13.22) => {
#     "item": "Control domain on host: 10.0.13.22",
#     "msg": "Control domain on host: 10.0.13.22"
# }


MAINTAINERS: Tim Rupp, Andy Hill (@andyhky)

METADATA:
	Status: ['preview']
	Supported_by: community
> YUM    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/yum.py)

  Installs, upgrade, removes, and lists packages and groups with the `yum' package manager.

Options (= is mandatory):

- conf_file
        The remote yum configuration file to use for the transaction.
        [Default: None]
- disable_gpg_check
        Whether to disable the GPG checking of signatures of packages being installed. Has an effect only if state is
        `present' or `latest'.
        (Choices: yes, no)[Default: no]
- disablerepo
        `Repoid' of repositories to disable for the install/update operation. These repos will not persist beyond the
        transaction. When specifying multiple repos, separate them with a ",".
        [Default: None]
- enablerepo
        `Repoid' of repositories to enable for the install/update operation. These repos will not persist beyond the
        transaction. When specifying multiple repos, separate them with a ",".
        [Default: None]
- exclude
        Package name(s) to exclude when state=present, or latest
        [Default: None]
- installroot
        Specifies an alternative installroot, relative to which all packages will be installed.
        [Default: /]
- list
        Package name to run the equivalent of yum list <package> against.
        [Default: None]
= name
        Package name, or package specifier with version, like `name-1.0'. When using state=latest, this can be '*' which
        means run: yum -y update. You can also pass a url or a local path to a rpm file (using state=present).  To
        operate on several packages this can accept a comma separated list of packages or (as of 2.0) a list of packages.
        [Default: None]
- skip_broken
        Resolve depsolve problems by removing packages that are causing problems from the trans‐ action.
        (Choices: yes, no)[Default: no]
- state
        Whether to install (`present' or `installed', `latest'), or remove (`absent' or `removed') a package.
        (Choices: present, installed, latest, absent, removed)[Default: present]
- update_cache
        Force yum to check if cache is out of date and redownload if needed. Has an effect only if state is `present' or
        `latest'.
        (Choices: yes, no)[Default: no]
- validate_certs
        This only applies if using a https url as the source of the rpm. e.g. for localinstall. If set to `no', the SSL
        certificates will not be validated.
        This should only set to `no' used on personally controlled sites using self-signed certificates as it avoids
        verifying the source site.
        Prior to 2.1 the code worked as if this was set to `yes'.
        (Choices: yes, no)[Default: yes]
Notes:
  * When used with a loop of package names in a playbook, ansible optimizes the call to the yum module.  Instead of
        calling the module with a single package each time through the loop, ansible calls the module once with all
        of the package names from the loop.
  * In versions prior to 1.9.2 this module installed and removed each package given to the yum module separately.
        This caused problems when packages specified by filename or url had to be installed or removed together. In
        1.9.2 this was fixed so that packages are installed in one yum transaction. However, if one of the packages
        adds a new yum repository that the other packages come from (such as epel-release) then that package needs
        to be installed in a separate task. This mimics yum's command line behaviour.
  * Yum itself has two types of groups.  "Package groups" are specified in the rpm itself while "environment
        groups" are specified in a separate file (usually by the distribution).  Unfortunately, this division
        becomes apparent to ansible users because ansible needs to operate on the group of packages in a single
        transaction and yum requires groups to be specified in different ways when used in that way.  Package
        groups are specified as "@development-tools" and environment groups are "@^gnome-desktop-environment". Use
        the "yum group list" command to see which category of group the group you want to install falls into.
Requirements:  yum

EXAMPLES:
- name: install the latest version of Apache
  yum:
    name: httpd
    state: latest

- name: remove the Apache package
  yum:
    name: httpd
    state: absent

- name: install the latest version of Apache from the testing repo
  yum:
    name: httpd
    enablerepo: testing
    state: present

- name: install one specific version of Apache
  yum:
    name: httpd-2.2.29-1.4.amzn1
    state: present

- name: upgrade all packages
  yum:
    name: '*'
    state: latest

- name: install the nginx rpm from a remote repo
  yum:
    name: http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm
    state: present

- name: install nginx rpm from a local file
  yum:
    name: /usr/local/src/nginx-release-centos-6-0.el6.ngx.noarch.rpm
    state: present

- name: install the 'Development tools' package group
  yum:
    name: "@Development tools"
    state: present

- name: install the 'Gnome desktop' environment group
  yum:
    name: "@^gnome-desktop-environment"
    state: present

- name: List ansible packages and register result to print with debug later.
  yum:
    list: ansible
  register: result


MAINTAINERS: Ansible Core Team, Seth Vidal, Berend De Schouwer (github.com/berenddeschouwer), Eduard Snesarev (github.com/verm666)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> YUM_REPOSITORY    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/yum_repository.py)

  Add or remove YUM repositories in RPM-based Linux distributions.

Options (= is mandatory):

- async
        If set to `yes' Yum will download packages and metadata from this repo in parallel, if possible.
        (Choices: yes, no)[Default: yes]
- attributes
        Attributes the file or directory should have. To get supported flags look at the man page for `chattr' on the
        target system. This string should contain the attributes in the same order as the one displayed by `lsattr'.
        [Default: None]
- bandwidth
        Maximum available network bandwidth in bytes/second. Used with the `throttle' option.
        If `throttle' is a percentage and bandwidth is `0' then bandwidth throttling will be disabled. If `throttle' is
        expressed as a data rate (bytes/sec) then this option is ignored. Default is `0' (no bandwidth throttling).
        [Default: 0]
- baseurl
        URL to the directory where the yum repository's 'repodata' directory lives.
        This or the `mirrorlist' parameter is required if `state' is set to `present'.
        [Default: None]
- cost
        Relative cost of accessing this repository. Useful for weighing one repo's packages as greater/less than any
        other.
        [Default: 1000]
- deltarpm_metadata_percentage
        When the relative size of deltarpm metadata vs pkgs is larger than this, deltarpm metadata is not downloaded from
        the repo. Note that you can give values over `100', so `200' means that the metadata is required to be half the
        size of the packages. Use `0' to turn off this check, and always download metadata.
        [Default: 100]
- deltarpm_percentage
        When the relative size of delta vs pkg is larger than this, delta is not used. Use `0' to turn off delta rpm
        processing. Local repositories (with file:// `baseurl') have delta rpms turned off by default.
        [Default: 75]
- description
        A human readable string describing the repository.
        This parameter is only required if `state' is set to `present'.
        [Default: None]
- enabled
        This tells yum whether or not use this repository.
        (Choices: yes, no)[Default: yes]
- enablegroups
        Determines whether yum will allow the use of package groups for this repository.
        (Choices: yes, no)[Default: yes]
- exclude
        List of packages to exclude from updates or installs. This should be a space separated list. Shell globs using
        wildcards (eg. `*' and `?') are allowed.
        The list can also be a regular YAML array.
        [Default: None]
- failovermethod
        `roundrobin' randomly selects a URL out of the list of URLs to start with and proceeds through each of them as it
        encounters a failure contacting the host.
        `priority' starts from the first `baseurl' listed and reads through them sequentially.
        (Choices: roundrobin, priority)[Default: roundrobin]
- file
        File to use to save the repo in. Defaults to the value of `name'.
        [Default: None]
- gpgcakey
        A URL pointing to the ASCII-armored CA key file for the repository.
        [Default: None]
- gpgcheck
        Tells yum whether or not it should perform a GPG signature check on packages.
        (Choices: yes, no)[Default: no]
- gpgkey
        A URL pointing to the ASCII-armored GPG key file for the repository.
        [Default: None]
- group
        Name of the group that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- http_caching
        Determines how upstream HTTP caches are instructed to handle any HTTP downloads that Yum does.
        `all' means that all HTTP downloads should be cached.
        `packages' means that only RPM package downloads should be cached (but not repository metadata downloads).
        `none' means that no HTTP downloads should be cached.
        (Choices: all, packages, none)[Default: all]
- include
        Include external configuration file. Both, local path and URL is supported. Configuration file will be inserted
        at the position of the `include=' line. Included files may contain further include lines. Yum will abort with an
        error if an inclusion loop is detected.
        [Default: None]
- includepkgs
        List of packages you want to only use from a repository. This should be a space separated list. Shell globs using
        wildcards (eg. `*' and `?') are allowed. Substitution variables (e.g. `$releasever') are honored here.
        The list can also be a regular YAML array.
        [Default: None]
- ip_resolve
        Determines how yum resolves host names.
        `4' or `IPv4' - resolve to IPv4 addresses only.
        `6' or `IPv6' - resolve to IPv6 addresses only.
        (Choices: 4, 6, IPv4, IPv6, whatever)[Default: whatever]
- keepalive
        This tells yum whether or not HTTP/1.1 keepalive should be used with this repository. This can improve transfer
        speeds by using one connection when downloading multiple files from a repository.
        (Choices: yes, no)[Default: no]
- keepcache
        Either `1' or `0'. Determines whether or not yum keeps the cache of headers and packages after successful
        installation.
        (Choices: 0, 1)[Default: 1]
- metadata_expire
        Time (in seconds) after which the metadata will expire.
        Default value is 6 hours.
        [Default: 21600]
- metadata_expire_filter
        Filter the `metadata_expire' time, allowing a trade of speed for accuracy if a command doesn't require it. Each
        yum command can specify that it requires a certain level of timeliness quality from the remote repos. from "I'm
        about to install/upgrade, so this better be current" to "Anything that's available is good enough".
        `never' - Nothing is filtered, always obey `metadata_expire'.
        `read-only:past' - Commands that only care about past information are filtered from metadata expiring. Eg. `yum
        history' info (if history needs to lookup anything about a previous transaction, then by definition the remote
        package was available in the past).
        `read-only:present' - Commands that are balanced between past and future. Eg. `yum list yum'.
        `read-only:future' - Commands that are likely to result in running other commands which will require the latest
        metadata. Eg. `yum check-update'.
        Note that this option does not override "yum clean expire-cache".
        (Choices: never, read-only:past, read-only:present, read-only:future)[Default: read-only:present]
- metalink
        Specifies a URL to a metalink file for the repomd.xml, a list of mirrors for the entire repository are generated
        by converting the mirrors for the repomd.xml file to a `baseurl'.
        [Default: None]
- mirrorlist
        Specifies a URL to a file containing a list of baseurls.
        This or the `baseurl' parameter is required if `state' is set to `present'.
        [Default: None]
- mirrorlist_expire
        Time (in seconds) after which the mirrorlist locally cached will expire.
        Default value is 6 hours.
        [Default: 21600]
- mode
        Mode the file or directory should be. For those used to `/usr/bin/chmod' remember that modes are actually octal
        numbers (like 0644). Leaving off the leading zero will likely have unexpected results. As of version 1.8, the
        mode may be specified as a symbolic mode (for example, `u+rwx' or `u=rw,g=r,o=r').
        [Default: None]
= name
        Unique repository ID.
        This parameter is only required if `state' is set to `present' or `absent'.

- owner
        Name of the user that should own the file/directory, as would be fed to `chown'.
        [Default: None]
- params
        Option used to allow the user to overwrite any of the other options. To remove an option, set the value of the
        option to `null'.
        [Default: None]
- password
        Password to use with the username for basic authentication.
        [Default: None]
- priority
        Enforce ordered protection of repositories. The value is an integer from 1 to 99.
        This option only works if the YUM Priorities plugin is installed.
        [Default: 99]
- protect
        Protect packages from updates from other repositories.
        (Choices: yes, no)[Default: no]
- proxy
        URL to the proxy server that yum should use. Set to `_none_' to disable the global proxy setting.
        [Default: None]
- proxy_password
        Username to use for proxy.
        [Default: None]
- proxy_username
        Password for this proxy.
        [Default: None]
- repo_gpgcheck
        This tells yum whether or not it should perform a GPG signature check on the repodata from this repository.
        (Choices: yes, no)[Default: no]
- reposdir
        Directory where the `.repo' files will be stored.
        [Default: /etc/yum.repos.d]
- retries
        Set the number of times any attempt to retrieve a file should retry before returning an error. Setting this to
        `0' makes yum try forever.
        [Default: 10]
- s3_enabled
        Enables support for S3 repositories.
        This option only works if the YUM S3 plugin is installed.
        (Choices: yes, no)[Default: no]
- selevel
        Level part of the SELinux file context. This is the MLS/MCS attribute, sometimes known as the `range'. `_default'
        feature works as for `seuser'.
        [Default: s0]
- serole
        Role part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- setype
        Type part of SELinux file context, `_default' feature works as for `seuser'.
        [Default: None]
- seuser
        User part of SELinux file context. Will default to system policy, if applicable. If set to `_default', it will
        use the `user' portion of the policy if available.
        [Default: None]
- skip_if_unavailable
        If set to `yes' yum will continue running if this repository cannot be contacted for any reason. This should be
        set carefully as all repos are consulted for any given command.
        (Choices: yes, no)[Default: no]
- ssl_check_cert_permissions
        Whether yum should check the permissions on the paths for the certificates on the repository (both remote and
        local).
        If we can't read any of the files then yum will force `skip_if_unavailable' to be `yes'. This is most useful for
        non-root processes which use yum on repos that have client cert files which are readable only by root.
        (Choices: yes, no)[Default: no]
- sslcacert
        Path to the directory containing the databases of the certificate authorities yum should use to verify SSL
        certificates.
        [Default: None]
- sslclientcert
        Path to the SSL client certificate yum should use to connect to repos/remote sites.
        [Default: None]
- sslclientkey
        Path to the SSL client key yum should use to connect to repos/remote sites.
        [Default: None]
- sslverify
        Defines whether yum should verify SSL certificates/hosts at all.
        (Choices: yes, no)[Default: yes]
- state
        State of the repo file.
        (Choices: absent, present)[Default: present]
- throttle
        Enable bandwidth throttling for downloads.
        This option can be expressed as a absolute data rate in bytes/sec. An SI prefix (k, M or G) may be appended to
        the bandwidth value.
        [Default: None]
- timeout
        Number of seconds to wait for a connection before timing out.
        [Default: 30]
- ui_repoid_vars
        When a repository id is displayed, append these yum variables to the string if they are used in the
        `baseurl'/etc. Variables are appended in the order listed (and found).
        [Default: releasever basearch]
- unsafe_writes
        Normally this module uses atomic operations to prevent data corruption or inconsistent reads from the target
        files, sometimes systems are configured or just broken in ways that prevent this. One example are docker mounted
        files, they cannot be updated atomically and can only be done in an unsafe manner.
        This boolean option allows ansible to fall back to unsafe methods of updating files for those cases in which you
        do not have any other choice. Be aware that this is subject to race conditions and can lead to data corruption.
        [Default: False]
- username
        Username to use for basic authentication to a repo or really any url.
        [Default: None]
Notes:
  * All comments will be removed if modifying an existing repo file.
  * Section order is preserved in an existing repo file.
  * Parameters in a section are ordered alphabetically in an existing repo file.
  * The repo file will be automatically deleted if it contains no repository.
  * When removing a repository, beware that the metadata cache may still remain on disk until you run `yum clean
        all'. Use a notification handler for this.
EXAMPLES:
- name: Add repository
  yum_repository:
    name: epel
    description: EPEL YUM repo
    baseurl: https://download.fedoraproject.org/pub/epel/$releasever/$basearch/

- name: Add multiple repositories into the same file (1/2)
  yum_repository:
    name: epel
    description: EPEL YUM repo
    file: external_repos
    baseurl: https://download.fedoraproject.org/pub/epel/$releasever/$basearch/
    gpgcheck: no

- name: Add multiple repositories into the same file (2/2)
  yum_repository:
    name: rpmforge
    description: RPMforge YUM repo
    file: external_repos
    baseurl: http://apt.sw.be/redhat/el7/en/$basearch/rpmforge
    mirrorlist: http://mirrorlist.repoforge.org/el7/mirrors-rpmforge
    enabled: no

# Handler showing how to clean yum metadata cache
- name: yum-clean-metadata
  command: yum clean metadata
  args:
    warn: no

# Example removing a repository and cleaning up metadata cache
- name: Remove repository (and clean up left-over metadata)
  yum_repository:
    name: epel
    state: absent
  notify: yum-clean-metadata

- name: Remove repository from a specific repo file
  yum_repository:
    name: epel
    file: external_repos
    state: absent

#
# Allow to overwrite the yum_repository parameters by defining the parameters
# as a variable in the defaults or vars file:
#
# my_role_somerepo_params:
#   # Disable GPG checking
#   gpgcheck: no
#   # Remove the gpgkey option
#   gpgkey: null
#
- name: Add Some repo
  yum_repository:
    name: somerepo
    description: Some YUM repo
    baseurl: http://server.com/path/to/the/repo
    gpgkey: http://server.com/keys/somerepo.pub
    gpgcheck: yes
    params: "{{ my_role_somerepo_params }}"

RETURN VALUES:
repo:
    description: repository name
    returned: success
    type: string
    sample: "epel"
state:
    description: state of the target, after execution
    returned: success
    type: string
    sample: "present"


MAINTAINERS: Jiri Tyr (@jtyr)

METADATA:
	Status: ['stableinterface']
	Supported_by: core
> ZABBIX_GROUP    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/zabbix_group.py)

  Create host groups if they do not exist. Delete existing host groups if they exist.

Options (= is mandatory):

= host_groups
        List of host groups to create or delete.

- http_login_password
        Basic Auth password
        [Default: None]
- http_login_user
        Basic Auth login
        [Default: None]
= login_password
        Zabbix user password.

= login_user
        Zabbix user name.

= server_url
        Url of Zabbix server, with protocol (http or https). `url' is an alias for `server_url'.

- state
        Create or delete host group.
        (Choices: present, absent)[Default: present]
- timeout
        The timeout of API request(seconds).
        [Default: 10]
Notes:
  * Too many concurrent updates to the same group may cause Zabbix to return errors, see examples for a workaround
        if needed.
Requirements:  python >= 2.6, zabbix-api

EXAMPLES:
# Base create host groups example
- name: Create host groups
  local_action:
    module: zabbix_group
    server_url: http://monitor.example.com
    login_user: username
    login_password: password
    state: present
    host_groups:
      - Example group1
      - Example group2

# Limit the Zabbix group creations to one host since Zabbix can return an error when doing concurent updates
- name: Create host groups
  local_action:
    module: zabbix_group
    server_url: http://monitor.example.com
    login_user: username
    login_password: password
    state: present
    host_groups:
      - Example group1
      - Example group2
  when: inventory_hostname==groups['group_name'][0]


MAINTAINERS: Tony Minfei Ding, Harrison Gu (@harrisongu), (@cove)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZABBIX_HOST    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/zabbix_host.py)

  This module allows you to create, modify and delete Zabbix host entries and associated group and template data.

Options (= is mandatory):

- force
        Overwrite the host configuration, even if already present
        (Choices: yes, no)[Default: yes]
- host_groups
        List of host groups the host is part of.
        [Default: (null)]
= host_name
        Name of the host in Zabbix.
        host_name is the unique identifier used and cannot be updated using this module.

- http_login_password
        Basic Auth password
        [Default: None]
- http_login_user
        Basic Auth login
        [Default: None]
- interfaces
        List of interfaces to be created for the host (see example below).
        Available values are: dns, ip, main, port, type and useip.
        Please review the interface documentation for more information on the supported properties
        https://www.zabbix.com/documentation/2.0/manual/appendix/api/hostinterface/definitions#host_interface
        [Default: []]
- inventory_mode
        Configure the inventory mode.
        (Choices: automatic, manual, disabled)[Default: None]
- link_templates
        List of templates linked to the host.
        [Default: None]
= login_password
        Zabbix user password.

= login_user
        Zabbix user name, used to authenticate against the server.

- proxy
        The name of the Zabbix Proxy to be used
        [Default: None]
= server_url
        Url of Zabbix server, with protocol (http or https).

- state
        State of the host.
        On `present', it will create if host does not exist or update the host if the associated data is different.
        On `absent' will remove a host if it exists.
        (Choices: present, absent)[Default: present]
- status
        Monitoring status of the host.
        (Choices: enabled, disabled)[Default: enabled]
- timeout
        The timeout of API request (seconds).
        [Default: 10]
- visible_name
        Visible name of the host in Zabbix.
        [Default: (null)]
Requirements:  python >= 2.6, zabbix-api

EXAMPLES:
- name: Create a new host or update an existing host's info
  local_action:
    module: zabbix_host
    server_url: http://monitor.example.com
    login_user: username
    login_password: password
    host_name: ExampleHost
    visible_name: ExampleName
    host_groups:
      - Example group1
      - Example group2
    link_templates:
      - Example template1
      - Example template2
    status: enabled
    state: present
    inventory_mode: automatic
    interfaces:
      - type: 1
        main: 1
        useip: 1
        ip: 10.xx.xx.xx
        dns: ""
        port: 10050
      - type: 4
        main: 1
        useip: 1
        ip: 10.xx.xx.xx
        dns: ""
        port: 12345
    proxy: a.zabbix.proxy


MAINTAINERS: Tony Minfei Ding, Harrison Gu (@harrisongu), (@cove)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZABBIX_HOSTMACRO    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/zabbix_hostmacro.py)

  manages Zabbix host macros, it can create, update or delete them.

Options (= is mandatory):

= host_name
        Name of the host.

- http_login_password
        Basic Auth password
        [Default: None]
- http_login_user
        Basic Auth login
        [Default: None]
= login_password
        Zabbix user password.

= login_user
        Zabbix user name.

= macro_name
        Name of the host macro.

= macro_value
        Value of the host macro.

= server_url
        Url of Zabbix server, with protocol (http or https).

- state
        State of the macro.
        On `present', it will create if macro does not exist or update the macro if the associated data is different.
        On `absent' will remove a macro if it exists.
        (Choices: present, absent)[Default: present]
- timeout
        The timeout of API request (seconds).
        [Default: 10]
Requirements:  python >= 2.6, zabbix-api

EXAMPLES:
- name: Create a new host macro or update an existing macro's value
  local_action:
    module: zabbix_hostmacro
    server_url: http://monitor.example.com
    login_user: username
    login_password: password
    host_name: ExampleHost
    macro_name: Example macro
    macro_value: Example value
    state: present


MAINTAINERS: (@cave), Dean Hailin Song

METADATA:
	Status: ['preview']
	Supported_by: community
> ZABBIX_MAINTENANCE    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/zabbix_maintenance.py)

  This module will let you create Zabbix maintenance windows.

Options (= is mandatory):

- collect_data
        Type of maintenance. With data collection, or without.
        [Default: true]
= desc
        Short description of maintenance window.
        [Default: Created by Ansible]
- host_groups
        Host groups to manage maintenance window for. Separate multiple groups with commas. `host_group' is an alias for
        `host_groups'. *Required* option when `state' is `present' and no `host_names' specified.
        [Default: None]
- host_names
        Hosts to manage maintenance window for. Separate multiple hosts with commas. `host_name' is an alias for
        `host_names'. *Required* option when `state' is `present' and no `host_groups' specified.
        [Default: None]
- http_login_password
        Basic Auth password
        [Default: None]
- http_login_user
        Basic Auth login
        [Default: None]
= login_password
        Zabbix user password.

= login_user
        Zabbix user name.

- minutes
        Length of maintenance window in minutes.
        [Default: 10]
= name
        Unique name of maintenance window.

= server_url
        Url of Zabbix server, with protocol (http or https). `url' is an alias for `server_url'.
        [Default: None]
- state
        Create or remove a maintenance window.
        (Choices: present, absent)[Default: present]
- timeout
        The timeout of API request (seconds).
        [Default: 10]
Notes:
  * Useful for setting hosts in maintenance mode before big update, and removing maintenance window after update.
  * Module creates maintenance window from now() to now() + minutes, so if Zabbix server's time and host's time are
        not synchronized, you will get strange results.
  * Install required module with 'pip install zabbix-api' command.
  * Checks existence only by maintenance name.
Requirements:  python >= 2.6, zabbix-api

EXAMPLES:
- name: Create a named maintenance window for host www1 for 90 minutes
  zabbix_maintenance:
    name: Update of www1
    host_name: www1.example.com
    state: present
    minutes: 90
    server_url: https://monitoring.example.com
    login_user: ansible
    login_password: pAsSwOrD

- name: Create a named maintenance window for host www1 and host groups Office and Dev
  zabbix_maintenance:
    name: Update of www1
    host_name: www1.example.com
    host_groups:
      - Office
      - Dev
    state: present
    server_url: https://monitoring.example.com
    login_user: ansible
    login_password: pAsSwOrD

- name: Create a named maintenance window for hosts www1 and db1, without data collection.
  zabbix_maintenance:
    name: update
    host_names:
      - www1.example.com
      - db1.example.com
    state: present
    collect_data: False
    server_url: https://monitoring.example.com
    login_user: ansible
    login_password: pAsSwOrD

- name: Remove maintenance window by name
  zabbix_maintenance:
    name: Test1
    state: absent
    server_url: https://monitoring.example.com
    login_user: ansible
    login_password: pAsSwOrD


MAINTAINERS: Alexander Bulimov (@abulimov)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZABBIX_SCREEN    (/usr/lib/python2.7/site-packages/ansible/modules/monitoring/zabbix_screen.py)

  This module allows you to create, modify and delete Zabbix screens and associated graph data.

Options (= is mandatory):

- http_login_password
        Basic Auth password
        [Default: None]
- http_login_user
        Basic Auth login
        [Default: None]
= login_password
        Zabbix user password.

= login_user
        Zabbix user name.

= screens
        List of screens to be created/updated/deleted(see example).
        If the screen(s) already been added, the screen(s) name won't be updated.
        When creating or updating screen(s), `screen_name', `host_group' are required.
        When deleting screen(s), the `screen_name' is required.
        The available states are: `present' (default) and `absent'. If the screen(s) already exists, and the state is not
        `absent', the screen(s) will just be updated as needed.

= server_url
        Url of Zabbix server, with protocol (http or https).

- timeout
        The timeout of API request (seconds).
        [Default: 10]
Notes:
  * Too many concurrent updates to the same screen may cause Zabbix to return errors, see examples for a workaround
        if needed.
Requirements:  python >= 2.6, zabbix-api

EXAMPLES:
# Create/update a screen.
- name: Create a new screen or update an existing screen's items
  local_action:
    module: zabbix_screen
    server_url: http://monitor.example.com
    login_user: username
    login_password: password
    screens:
      - screen_name: ExampleScreen1
        host_group: Example group1
        state: present
        graph_names:
          - Example graph1
          - Example graph2
        graph_width: 200
        graph_height: 100

# Create/update multi-screen
- name: Create two of new screens or update the existing screens' items
  local_action:
    module: zabbix_screen
    server_url: http://monitor.example.com
    login_user: username
    login_password: password
    screens:
      - screen_name: ExampleScreen1
        host_group: Example group1
        state: present
        graph_names:
          - Example graph1
          - Example graph2
        graph_width: 200
        graph_height: 100
      - screen_name: ExampleScreen2
        host_group: Example group2
        state: present
        graph_names:
          - Example graph1
          - Example graph2
        graph_width: 200
        graph_height: 100

# Limit the Zabbix screen creations to one host since Zabbix can return an error when doing concurent updates
- name: Create a new screen or update an existing screen's items
  local_action:
    module: zabbix_screen
    server_url: http://monitor.example.com
    login_user: username
    login_password: password
    state: present
    screens:
      - screen_name: ExampleScreen
        host_group: Example group
        state: present
        graph_names:
          - Example graph1
          - Example graph2
        graph_width: 200
        graph_height: 100
  when: inventory_hostname==groups['group_name'][0]


MAINTAINERS: Tony Minfei Ding, Harrison Gu (@harrisongu), (@cove)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZFS    (/usr/lib/python2.7/site-packages/ansible/modules/storage/zfs/zfs.py)

  Manages ZFS file systems, volumes, clones and snapshots.

Options (= is mandatory):

- key_value
        The `zfs' module takes key=value pairs for zfs properties to be set. See the zfs(8) man page for more
        information.
        [Default: None]
= name
        File system, snapshot or volume name e.g. `rpool/myfs'

- origin
        Snapshot from which to create a clone
        [Default: None]
= state
        Whether to create (`present'), or remove (`absent') a file system, snapshot or volume. All parents/children will
        be created/destroyed as needed to reach the desired state.
        (Choices: present, absent)
EXAMPLES:
# Create a new file system called myfs in pool rpool with the setuid property turned off
- zfs:
    name: rpool/myfs
    state: present
    setuid: off

# Create a new volume called myvol in pool rpool.
- zfs:
    name: rpool/myvol
    state: present
    volsize: 10M

# Create a snapshot of rpool/myfs file system.
- zfs:
    name: rpool/myfs@mysnapshot
    state: present

# Create a new file system called myfs2 with snapdir enabled
- zfs:
    name: rpool/myfs2
    state: present
    snapdir: enabled

# Create a new file system by cloning a snapshot
- zfs:
    name: rpool/cloned_fs
    state: present
    origin: rpool/myfs@mysnapshot

# Destroy a filesystem
- zfs:
    name: rpool/myfs
    state: absent


MAINTAINERS: Johan Wiren (@johanwiren)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZFS_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/storage/zfs/zfs_facts.py)

  Gather facts from ZFS dataset properties.

Options (= is mandatory):

- depth
        Specifiies recurion depth.
        [Default: None]
= name
        ZFS dataset name.

- parsable
        Specifies if property values should be displayed in machine friendly format.
        [Default: False]
- properties
        Specifies which dataset properties should be queried in comma-separated format. For more information about
        dataset properties, check zfs(1M) man page.
        [Default: all]
- recurse
        Specifies if properties for any children should be recursively displayed.
        [Default: False]
- type
        Specifies which datasets types to display. Multiple values have to be provided in comma-separated form.
        (Choices: all, filesystem, volume, snapshot, bookmark)[Default: all]
EXAMPLES:
- name: Gather facts about ZFS dataset rpool/export/home
  zfs_facts:
    dataset: rpool/export/home

- name: Report space usage on ZFS filesystems under data/home
  zfs_facts:
    name: data/home
    recurse: yes
    type: filesystem

- debug:
    msg: 'ZFS dataset {{ item.name }} consumes {{ item.used }} of disk space.'
  with_items: '{{ ansible_zfs_datasets }}'

RETURN VALUES:
name:
    description: ZFS dataset name
    returned: always
    type: string
    sample: rpool/var/spool
parsable:
    description: if parsable output should be provided in machine friendly format.
    returned: if 'parsable' is set to True
    type: boolean
    sample: True
recurse:
    description: if we should recurse over ZFS dataset
    returned: if 'recurse' is set to True
    type: boolean
    sample: True
zfs_datasets:
    description: ZFS dataset facts
    returned: always
    type: string
    sample:
            {
                "aclinherit": "restricted",
                "aclmode": "discard",
                "atime": "on",
                "available": "43.8G",
                "canmount": "on",
                "casesensitivity": "sensitive",
                "checksum": "on",
                "compression": "off",
                "compressratio": "1.00x",
                "copies": "1",
                "creation": "Thu Jun 16 11:37 2016",
                "dedup": "off",
                "devices": "on",
                "exec": "on",
                "filesystem_count": "none",
                "filesystem_limit": "none",
                "logbias": "latency",
                "logicalreferenced": "18.5K",
                "logicalused": "3.45G",
                "mlslabel": "none",
                "mounted": "yes",
                "mountpoint": "/rpool",
                "name": "rpool",
                "nbmand": "off",
                "normalization": "none",
                "org.openindiana.caiman:install": "ready",
                "primarycache": "all",
                "quota": "none",
                "readonly": "off",
                "recordsize": "128K",
                "redundant_metadata": "all",
                "refcompressratio": "1.00x",
                "referenced": "29.5K",
                "refquota": "none",
                "refreservation": "none",
                "reservation": "none",
                "secondarycache": "all",
                "setuid": "on",
                "sharenfs": "off",
                "sharesmb": "off",
                "snapdir": "hidden",
                "snapshot_count": "none",
                "snapshot_limit": "none",
                "sync": "standard",
                "type": "filesystem",
                "used": "4.41G",
                "usedbychildren": "4.41G",
                "usedbydataset": "29.5K",
                "usedbyrefreservation": "0",
                "usedbysnapshots": "0",
                "utf8only": "off",
                "version": "5",
                "vscan": "off",
                "written": "29.5K",
                "xattr": "on",
                "zoned": "off"
            }


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZNODE    (/usr/lib/python2.7/site-packages/ansible/modules/clustering/znode.py)

  Create, delete, retrieve, and update znodes using ZooKeeper.

Options (= is mandatory):

= hosts
        A list of ZooKeeper servers (format '[server]:[port]').

= name
        The path of the znode.

- op
        An operation to perform. Mutually exclusive with state.
        [Default: None]
- recursive
        Recursively delete node and all its children.
        [Default: False]
- state
        The state to enforce. Mutually exclusive with op.
        [Default: None]
- timeout
        The amount of time to wait for a node to appear.
        [Default: 300]
- value
        The value assigned to the znode.
        [Default: None]
Requirements:  kazoo >= 2.1, python >= 2.6

EXAMPLES:
# Creating or updating a znode with a given value
- znode:
    hosts: 'localhost:2181'
    name: /mypath
    value: myvalue
    state: present

# Getting the value and stat structure for a znode
- znode:
    hosts: 'localhost:2181'
    name: /mypath
    op: get

# Listing a particular znode's children
- znode:
    hosts: 'localhost:2181'
    name: /zookeeper
    op: list

# Waiting 20 seconds for a znode to appear at path /mypath
- znode:
    hosts: 'localhost:2181'
    name: /mypath
    op: wait
    timeout: 20

# Deleting a znode at path /mypath
- znode:
    hosts: 'localhost:2181'
    name: /mypath
    state: absent

# Creating or updating a znode with a given value on a remote Zookeeper
- znode:
    hosts: 'my-zookeeper-node:2181'
    name: /mypath
    value: myvalue
    state: present
  delegate_to: 127.0.0.1


MAINTAINERS: Trey Perry (@treyperry)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZPOOL_FACTS    (/usr/lib/python2.7/site-packages/ansible/modules/storage/zfs/zpool_facts.py)

  Gather facts from ZFS pool properties.

Options (= is mandatory):

- name
        ZFS pool name.
        [Default: (null)]
- parsable
        Specifies if property values should be displayed in machine friendly format.
        [Default: False]
- properties
        Specifies which dataset properties should be queried in comma-separated format. For more information about
        dataset properties, check zpool(1M) man page.
        [Default: all]
EXAMPLES:
# Gather facts about ZFS pool rpool
zpool_facts: pool=rpool

# Gather space usage about all imported ZFS pools
zpool_facts: properties='free,size'
debug: msg='ZFS pool {{ item.name }} has {{ item.free }} free space out of {{ item.size }}.'
with_items: '{{ ansible_zfs_pools }}'

RETURN VALUES:
name:
    description: ZFS pool name
    returned: always
    type: string
    sample: rpool
parsable:
    description: if parsable output should be provided in machine friendly format.
    returned: if 'parsable' is set to True
    type: boolean
    sample: True
zfs_pools:
    description: ZFS pool facts
    returned: always
    type: string
    sample:
            {
                "allocated": "3.46G",
                "altroot": "-",
                "autoexpand": "off",
                "autoreplace": "off",
                "bootfs": "rpool/ROOT/openindiana",
                "cachefile": "-",
                "capacity": "6%",
                "comment": "-",
                "dedupditto": "0",
                "dedupratio": "1.00x",
                "delegation": "on",
                "expandsize": "-",
                "failmode": "wait",
                "feature@async_destroy": "enabled",
                "feature@bookmarks": "enabled",
                "feature@edonr": "enabled",
                "feature@embedded_data": "active",
                "feature@empty_bpobj": "active",
                "feature@enabled_txg": "active",
                "feature@extensible_dataset": "enabled",
                "feature@filesystem_limits": "enabled",
                "feature@hole_birth": "active",
                "feature@large_blocks": "enabled",
                "feature@lz4_compress": "active",
                "feature@multi_vdev_crash_dump": "enabled",
                "feature@sha512": "enabled",
                "feature@skein": "enabled",
                "feature@spacemap_histogram": "active",
                "fragmentation": "3%",
                "free": "46.3G",
                "freeing": "0",
                "guid": "15729052870819522408",
                "health": "ONLINE",
                "leaked": "0",
                "listsnapshots": "off",
                "name": "rpool",
                "readonly": "off",
                "size": "49.8G",
                "version": "-"
            }


MAINTAINERS: Adam Števko (@xen0l)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZYPPER    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/zypper.py)

  Manage packages on SUSE and openSUSE using the zypper and rpm tools.

Options (= is mandatory):

- disable_gpg_check
        Whether to disable to GPG signature checking of the package signature being installed. Has an effect only if
        state is `present' or `latest'.
        (Choices: yes, no)[Default: no]
- disable_recommends
        Corresponds to the `--no-recommends' option for `zypper'. Default behavior (`yes') modifies zypper's default
        behavior; `no' does install recommended packages.
        (Choices: yes, no)[Default: yes]
- force
        Adds `--force' option to `zypper'. Allows to downgrade packages and change vendor or architecture.
        (Choices: yes, no)[Default: no]
= name
        Package name `name' or package specifier.
        Can include a version like `name=1.0', `name>3.4' or `name<=2.7'. If a version is given, `oldpackage' is implied
        and zypper is allowed to update the package within the version range given.
        You can also pass a url or a local path to a rpm file.
        When using state=latest, this can be '*', which updates all installed packages.

- oldpackage
        Adds `--oldpackage' option to `zypper'. Allows to downgrade packages with less side-effects than force. This is
        implied as soon as a version is specified as part of the package name.
        (Choices: yes, no)[Default: no]
- state
        `present' will make sure the package is installed. `latest'  will make sure the latest version of the package is
        installed. `absent'  will make sure the specified package is not installed.
        (Choices: present, latest, absent)[Default: present]
- type
        The type of package to be operated on.
        (Choices: package, patch, pattern, product, srcpackage, application)[Default: package]
- update_cache
        Run the equivalent of `zypper refresh' before the operation. Disabled in check mode.
        (Choices: yes, no)[Default: no]
Requirements:  zypper >= 1.0  # included in openSuSE >= 11.1 or SuSE Linux Enterprise Server/Desktop >= 11.0, python-
        xml, rpm

EXAMPLES:
# Install "nmap"
- zypper:
    name: nmap
    state: present

# Install apache2 with recommended packages
- zypper:
    name: apache2
    state: present
    disable_recommends: no

# Apply a given patch
- zypper:
    name: openSUSE-2016-128
    state: present
    type: patch

# Remove the "nmap" package
- zypper:
    name: nmap
    state: absent

# Install the nginx rpm from a remote repo
- zypper:
    name: 'http://nginx.org/packages/sles/12/x86_64/RPMS/nginx-1.8.0-1.sles12.ngx.x86_64.rpm'
    state: present

# Install local rpm file
- zypper:
    name: /tmp/fancy-software.rpm
    state: present

# Update all packages
- zypper:
    name: '*'
    state: latest

# Apply all available patches
- zypper:
    name: '*'
    state: latest
    type: patch

# Refresh repositories and update package "openssl"
- zypper:
    name: openssl
    state: present
    update_cache: yes

# Install specific version (possible comparisons: <, >, <=, >=, =)
- zypper:
    name: 'docker>=1.10'
    state: present

# Wait 20 seconds to acquire the lock before failing
- zypper:
    name: mosh
    state: present
  environment:
    ZYPP_LOCK_TIMEOUT: 20


MAINTAINERS: Thomas O'Donnell (@andytom), Alexander Gubin (@alxgu), Robin Roth (@robinro), Andrii Radyk (@AnderEnder), Patrick Callahan (@dirtyharrycallahan)

METADATA:
	Status: ['preview']
	Supported_by: community
> ZYPPER_REPOSITORY    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/zypper_repository.py)

  Add or remove Zypper repositories on SUSE and openSUSE

Options (= is mandatory):

- auto_import_keys
        Automatically import the gpg signing key of the new or changed repository.
        Has an effect only if state is `present'. Has no effect on existing (unchanged) repositories or in combination
        with `absent'.
        Implies runrefresh.
        (Choices: yes, no)[Default: no]
- autorefresh
        Enable autorefresh of the repository.
        (Choices: yes, no)[Default: yes]
- description
        A description of the repository
        [Default: none]
- disable_gpg_check
        Whether to disable GPG signature checking of all packages. Has an effect only if state is `present'.
        Needs zypper version >= 1.6.2.
        (Choices: yes, no)[Default: no]
- enabled
        Set repository to enabled (or disabled).
        (Choices: yes, no)[Default: yes]
- name
        A name for the repository. Not required when adding repofiles.
        [Default: none]
- overwrite_multiple
        Overwrite multiple repository entries, if repositories with both name and URL already exist.
        (Choices: yes, no)[Default: no]
- priority
        Set priority of repository. Packages will always be installed from the repository with the smallest priority
        number.
        Needs zypper version >= 1.12.25.
        [Default: (null)]
- repo
        URI of the repository or .repo file. Required when state=present.
        [Default: none]
- runrefresh
        Refresh the package list of the given repository.
        Can be used with repo=* to refresh all repositories.
        (Choices: yes, no)[Default: no]
- state
        A source string state.
        (Choices: absent, present)[Default: present]
Requirements:  zypper >= 1.0  # included in openSuSE >= 11.1 or SuSE Linux Enterprise Server/Desktop >= 11.0, python-
        xml

EXAMPLES:
# Add NVIDIA repository for graphics drivers
- zypper_repository:
    name: nvidia-repo
    repo: 'ftp://download.nvidia.com/opensuse/12.2'
    state: present

# Remove NVIDIA repository
- zypper_repository:
    name: nvidia-repo
    repo: 'ftp://download.nvidia.com/opensuse/12.2'
    state: absent

# Add python development repository
- zypper_repository:
    repo: 'http://download.opensuse.org/repositories/devel:/languages:/python/SLE_11_SP3/devel:languages:python.repo'

# Refresh all repos
- zypper_repository:
    repo: '*'
    runrefresh: yes

# Add a repo and add it's gpg key
- zypper_repository:
    repo: 'http://download.opensuse.org/repositories/systemsmanagement/openSUSE_Leap_42.1/'
    auto_import_keys: yes

# Force refresh of a repository
- zypper_repository:
    repo: 'http://my_internal_ci_repo/repo'
    name: my_ci_repo
    state: present
    runrefresh: yes


MAINTAINERS: Matthias Vogelgesang (@matze)

METADATA:
	Status: ['preview']
	Supported_by: community
